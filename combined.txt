

############################################################
### File: __main__.py
############################################################
import argparse

from certifi import contents, where

parser = argparse.ArgumentParser()
parser.add_argument("-c", "--contents", action="store_true")
args = parser.parse_args()

if args.contents:
    print(contents())
else:
    print(where())




############################################################
### File: __version__.py
############################################################
# .-. .-. .-. . . .-. .-. .-. .-.
# |(  |-  |.| | | |-  `-.  |  `-.
# ' ' `-' `-`.`-' `-' `-'  '  `-'

__title__ = 'requests'
__description__ = 'Python HTTP for Humans.'
__url__ = 'https://requests.readthedocs.io'
__version__ = '2.27.1'
__build__ = 0x022701
__author__ = 'Kenneth Reitz'
__author_email__ = 'me@kennethreitz.org'
__license__ = 'Apache 2.0'
__copyright__ = 'Copyright 2022 Kenneth Reitz'
__cake__ = u'\u2728 \U0001f370 \u2728'




############################################################
### File: _abnf.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA  02110-1335  USA

"""
import array
import os
import struct

import six

from ._exceptions import *
from ._utils import validate_utf8
from threading import Lock

try:
    if six.PY3:
        numpy = None #https://github.com/xbmc/repo-scripts/pull/2023
    else:
        numpy = None
except ImportError:
    numpy = None

try:
    # If wsaccel is available we use compiled routines to mask data.
    if not numpy:
        from wsaccel.xormask import XorMaskerSimple

        def _mask(_m, _d):
            return XorMaskerSimple(_m).process(_d)
except ImportError:
    # wsaccel is not available, we rely on python implementations.
    def _mask(_m, _d):
        for i in range(len(_d)):
            _d[i] ^= _m[i % 4]

        if six.PY3:
            return _d.tobytes()
        else:
            return _d.tostring()


__all__ = [
    'ABNF', 'continuous_frame', 'frame_buffer',
    'STATUS_NORMAL',
    'STATUS_GOING_AWAY',
    'STATUS_PROTOCOL_ERROR',
    'STATUS_UNSUPPORTED_DATA_TYPE',
    'STATUS_STATUS_NOT_AVAILABLE',
    'STATUS_ABNORMAL_CLOSED',
    'STATUS_INVALID_PAYLOAD',
    'STATUS_POLICY_VIOLATION',
    'STATUS_MESSAGE_TOO_BIG',
    'STATUS_INVALID_EXTENSION',
    'STATUS_UNEXPECTED_CONDITION',
    'STATUS_BAD_GATEWAY',
    'STATUS_TLS_HANDSHAKE_ERROR',
]

# closing frame status codes.
STATUS_NORMAL = 1000
STATUS_GOING_AWAY = 1001
STATUS_PROTOCOL_ERROR = 1002
STATUS_UNSUPPORTED_DATA_TYPE = 1003
STATUS_STATUS_NOT_AVAILABLE = 1005
STATUS_ABNORMAL_CLOSED = 1006
STATUS_INVALID_PAYLOAD = 1007
STATUS_POLICY_VIOLATION = 1008
STATUS_MESSAGE_TOO_BIG = 1009
STATUS_INVALID_EXTENSION = 1010
STATUS_UNEXPECTED_CONDITION = 1011
STATUS_BAD_GATEWAY = 1014
STATUS_TLS_HANDSHAKE_ERROR = 1015

VALID_CLOSE_STATUS = (
    STATUS_NORMAL,
    STATUS_GOING_AWAY,
    STATUS_PROTOCOL_ERROR,
    STATUS_UNSUPPORTED_DATA_TYPE,
    STATUS_INVALID_PAYLOAD,
    STATUS_POLICY_VIOLATION,
    STATUS_MESSAGE_TOO_BIG,
    STATUS_INVALID_EXTENSION,
    STATUS_UNEXPECTED_CONDITION,
    STATUS_BAD_GATEWAY,
)


class ABNF(object):
    """
    ABNF frame class.
    see http://tools.ietf.org/html/rfc5234
    and http://tools.ietf.org/html/rfc6455#section-5.2
    """

    # operation code values.
    OPCODE_CONT = 0x0
    OPCODE_TEXT = 0x1
    OPCODE_BINARY = 0x2
    OPCODE_CLOSE = 0x8
    OPCODE_PING = 0x9
    OPCODE_PONG = 0xa

    # available operation code value tuple
    OPCODES = (OPCODE_CONT, OPCODE_TEXT, OPCODE_BINARY, OPCODE_CLOSE,
               OPCODE_PING, OPCODE_PONG)

    # opcode human readable string
    OPCODE_MAP = {
        OPCODE_CONT: "cont",
        OPCODE_TEXT: "text",
        OPCODE_BINARY: "binary",
        OPCODE_CLOSE: "close",
        OPCODE_PING: "ping",
        OPCODE_PONG: "pong"
    }

    # data length threshold.
    LENGTH_7 = 0x7e
    LENGTH_16 = 1 << 16
    LENGTH_63 = 1 << 63

    def __init__(self, fin=0, rsv1=0, rsv2=0, rsv3=0,
                 opcode=OPCODE_TEXT, mask=1, data=""):
        """
        Constructor for ABNF.
        please check RFC for arguments.
        """
        self.fin = fin
        self.rsv1 = rsv1
        self.rsv2 = rsv2
        self.rsv3 = rsv3
        self.opcode = opcode
        self.mask = mask
        if data is None:
            data = ""
        self.data = data
        self.get_mask_key = os.urandom

    def validate(self, skip_utf8_validation=False):
        """
        validate the ABNF frame.
        skip_utf8_validation: skip utf8 validation.
        """
        if self.rsv1 or self.rsv2 or self.rsv3:
            raise WebSocketProtocolException("rsv is not implemented, yet")

        if self.opcode not in ABNF.OPCODES:
            raise WebSocketProtocolException("Invalid opcode %r", self.opcode)

        if self.opcode == ABNF.OPCODE_PING and not self.fin:
            raise WebSocketProtocolException("Invalid ping frame.")

        if self.opcode == ABNF.OPCODE_CLOSE:
            l = len(self.data)
            if not l:
                return
            if l == 1 or l >= 126:
                raise WebSocketProtocolException("Invalid close frame.")
            if l > 2 and not skip_utf8_validation and not validate_utf8(self.data[2:]):
                raise WebSocketProtocolException("Invalid close frame.")

            code = 256 * \
                six.byte2int(self.data[0:1]) + six.byte2int(self.data[1:2])
            if not self._is_valid_close_status(code):
                raise WebSocketProtocolException("Invalid close opcode.")

    @staticmethod
    def _is_valid_close_status(code):
        return code in VALID_CLOSE_STATUS or (3000 <= code < 5000)

    def __str__(self):
        return "fin=" + str(self.fin) \
            + " opcode=" + str(self.opcode) \
            + " data=" + str(self.data)

    @staticmethod
    def create_frame(data, opcode, fin=1):
        """
        create frame to send text, binary and other data.

        data: data to send. This is string value(byte array).
            if opcode is OPCODE_TEXT and this value is unicode,
            data value is converted into unicode string, automatically.

        opcode: operation code. please see OPCODE_XXX.

        fin: fin flag. if set to 0, create continue fragmentation.
        """
        if opcode == ABNF.OPCODE_TEXT and isinstance(data, six.text_type):
            data = data.encode("utf-8")
        # mask must be set if send data from client
        return ABNF(fin, 0, 0, 0, opcode, 1, data)

    def format(self):
        """
        format this object to string(byte array) to send data to server.
        """
        if any(x not in (0, 1) for x in [self.fin, self.rsv1, self.rsv2, self.rsv3]):
            raise ValueError("not 0 or 1")
        if self.opcode not in ABNF.OPCODES:
            raise ValueError("Invalid OPCODE")
        length = len(self.data)
        if length >= ABNF.LENGTH_63:
            raise ValueError("data is too long")

        frame_header = chr(self.fin << 7
                           | self.rsv1 << 6 | self.rsv2 << 5 | self.rsv3 << 4
                           | self.opcode)
        if length < ABNF.LENGTH_7:
            frame_header += chr(self.mask << 7 | length)
            frame_header = six.b(frame_header)
        elif length < ABNF.LENGTH_16:
            frame_header += chr(self.mask << 7 | 0x7e)
            frame_header = six.b(frame_header)
            frame_header += struct.pack("!H", length)
        else:
            frame_header += chr(self.mask << 7 | 0x7f)
            frame_header = six.b(frame_header)
            frame_header += struct.pack("!Q", length)

        if not self.mask:
            return frame_header + self.data
        else:
            mask_key = self.get_mask_key(4)
            return frame_header + self._get_masked(mask_key)

    def _get_masked(self, mask_key):
        s = ABNF.mask(mask_key, self.data)

        if isinstance(mask_key, six.text_type):
            mask_key = mask_key.encode('utf-8')

        return mask_key + s

    @staticmethod
    def mask(mask_key, data):
        """
        mask or unmask data. Just do xor for each byte

        mask_key: 4 byte string(byte).

        data: data to mask/unmask.
        """
        if data is None:
            data = ""

        if isinstance(mask_key, six.text_type):
            mask_key = six.b(mask_key)

        if isinstance(data, six.text_type):
            data = six.b(data)

        if numpy:
            origlen = len(data)
            _mask_key = mask_key[3] << 24 | mask_key[2] << 16 | mask_key[1] << 8 | mask_key[0]

            # We need data to be a multiple of four...
            data += bytes(" " * (4 - (len(data) % 4)), "us-ascii")
            a = numpy.frombuffer(data, dtype="uint32")
            masked = numpy.bitwise_xor(a, [_mask_key]).astype("uint32")
            if len(data) > origlen:
              return masked.tobytes()[:origlen]
            return masked.tobytes()
        else:
            _m = array.array("B", mask_key)
            _d = array.array("B", data)
            return _mask(_m, _d)


class frame_buffer(object):
    _HEADER_MASK_INDEX = 5
    _HEADER_LENGTH_INDEX = 6

    def __init__(self, recv_fn, skip_utf8_validation):
        self.recv = recv_fn
        self.skip_utf8_validation = skip_utf8_validation
        # Buffers over the packets from the layer beneath until desired amount
        # bytes of bytes are received.
        self.recv_buffer = []
        self.clear()
        self.lock = Lock()

    def clear(self):
        self.header = None
        self.length = None
        self.mask = None

    def has_received_header(self):
        return self.header is None

    def recv_header(self):
        header = self.recv_strict(2)
        b1 = header[0]

        if six.PY2:
            b1 = ord(b1)

        fin = b1 >> 7 & 1
        rsv1 = b1 >> 6 & 1
        rsv2 = b1 >> 5 & 1
        rsv3 = b1 >> 4 & 1
        opcode = b1 & 0xf
        b2 = header[1]

        if six.PY2:
            b2 = ord(b2)

        has_mask = b2 >> 7 & 1
        length_bits = b2 & 0x7f

        self.header = (fin, rsv1, rsv2, rsv3, opcode, has_mask, length_bits)

    def has_mask(self):
        if not self.header:
            return False
        return self.header[frame_buffer._HEADER_MASK_INDEX]

    def has_received_length(self):
        return self.length is None

    def recv_length(self):
        bits = self.header[frame_buffer._HEADER_LENGTH_INDEX]
        length_bits = bits & 0x7f
        if length_bits == 0x7e:
            v = self.recv_strict(2)
            self.length = struct.unpack("!H", v)[0]
        elif length_bits == 0x7f:
            v = self.recv_strict(8)
            self.length = struct.unpack("!Q", v)[0]
        else:
            self.length = length_bits

    def has_received_mask(self):
        return self.mask is None

    def recv_mask(self):
        self.mask = self.recv_strict(4) if self.has_mask() else ""

    def recv_frame(self):

        with self.lock:
            # Header
            if self.has_received_header():
                self.recv_header()
            (fin, rsv1, rsv2, rsv3, opcode, has_mask, _) = self.header

            # Frame length
            if self.has_received_length():
                self.recv_length()
            length = self.length

            # Mask
            if self.has_received_mask():
                self.recv_mask()
            mask = self.mask

            # Payload
            payload = self.recv_strict(length)
            if has_mask:
                payload = ABNF.mask(mask, payload)

            # Reset for next frame
            self.clear()

            frame = ABNF(fin, rsv1, rsv2, rsv3, opcode, has_mask, payload)
            frame.validate(self.skip_utf8_validation)

        return frame

    def recv_strict(self, bufsize):
        shortage = bufsize - sum(len(x) for x in self.recv_buffer)
        while shortage > 0:
            # Limit buffer size that we pass to socket.recv() to avoid
            # fragmenting the heap -- the number of bytes recv() actually
            # reads is limited by socket buffer and is relatively small,
            # yet passing large numbers repeatedly causes lots of large
            # buffers allocated and then shrunk, which results in
            # fragmentation.
            bytes_ = self.recv(min(16384, shortage))
            self.recv_buffer.append(bytes_)
            shortage -= len(bytes_)

        unified = six.b("").join(self.recv_buffer)

        if shortage == 0:
            self.recv_buffer = []
            return unified
        else:
            self.recv_buffer = [unified[bufsize:]]
            return unified[:bufsize]


class continuous_frame(object):

    def __init__(self, fire_cont_frame, skip_utf8_validation):
        self.fire_cont_frame = fire_cont_frame
        self.skip_utf8_validation = skip_utf8_validation
        self.cont_data = None
        self.recving_frames = None

    def validate(self, frame):
        if not self.recving_frames and frame.opcode == ABNF.OPCODE_CONT:
            raise WebSocketProtocolException("Illegal frame")
        if self.recving_frames and \
                frame.opcode in (ABNF.OPCODE_TEXT, ABNF.OPCODE_BINARY):
            raise WebSocketProtocolException("Illegal frame")

    def add(self, frame):
        if self.cont_data:
            self.cont_data[1] += frame.data
        else:
            if frame.opcode in (ABNF.OPCODE_TEXT, ABNF.OPCODE_BINARY):
                self.recving_frames = frame.opcode
            self.cont_data = [frame.opcode, frame.data]

        if frame.fin:
            self.recving_frames = None

    def is_fire(self, frame):
        return frame.fin or self.fire_cont_frame

    def extract(self, frame):
        data = self.cont_data
        self.cont_data = None
        frame.data = data[1]
        if not self.fire_cont_frame and data[0] == ABNF.OPCODE_TEXT and not self.skip_utf8_validation and not validate_utf8(frame.data):
            raise WebSocketPayloadException(
                "cannot decode: " + repr(frame.data))

        return [data[0], frame]




############################################################
### File: _app.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA  02110-1335  USA

"""

"""
WebSocketApp provides higher level APIs.
"""
import inspect
import select
import sys
import threading
import time
import traceback

import six

from ._abnf import ABNF
from ._core import WebSocket, getdefaulttimeout
from ._exceptions import *
from . import _logging


__all__ = ["WebSocketApp"]

class Dispatcher:
    def __init__(self, app, ping_timeout):
        self.app = app
        self.ping_timeout = ping_timeout

    def read(self, sock, read_callback, check_callback):
        while self.app.keep_running:
            r, w, e = select.select(
                    (self.app.sock.sock, ), (), (), self.ping_timeout)
            if r:
                if not read_callback():
                    break
            check_callback()

class SSLDispatcher:
    def __init__(self, app, ping_timeout):
        self.app = app
        self.ping_timeout = ping_timeout

    def read(self, sock, read_callback, check_callback):
        while self.app.keep_running:
            r = self.select()
            if r:
                if not read_callback():
                    break
            check_callback()

    def select(self):
        sock = self.app.sock.sock
        if sock.pending():
            return [sock,]

        r, w, e = select.select((sock, ), (), (), self.ping_timeout)
        return r


class WebSocketApp(object):
    """
    Higher level of APIs are provided.
    The interface is like JavaScript WebSocket object.
    """

    def __init__(self, url, header=None,
                 on_open=None, on_message=None, on_error=None,
                 on_close=None, on_ping=None, on_pong=None,
                 on_cont_message=None,
                 keep_running=True, get_mask_key=None, cookie=None,
                 subprotocols=None,
                 on_data=None):
        """
        url: websocket url.
        header: custom header for websocket handshake.
        on_open: callable object which is called at opening websocket.
          this function has one argument. The argument is this class object.
        on_message: callable object which is called when received data.
         on_message has 2 arguments.
         The 1st argument is this class object.
         The 2nd argument is utf-8 string which we get from the server.
        on_error: callable object which is called when we get error.
         on_error has 2 arguments.
         The 1st argument is this class object.
         The 2nd argument is exception object.
        on_close: callable object which is called when closed the connection.
         this function has one argument. The argument is this class object.
        on_cont_message: callback object which is called when receive continued
         frame data.
         on_cont_message has 3 arguments.
         The 1st argument is this class object.
         The 2nd argument is utf-8 string which we get from the server.
         The 3rd argument is continue flag. if 0, the data continue
         to next frame data
        on_data: callback object which is called when a message received.
          This is called before on_message or on_cont_message,
          and then on_message or on_cont_message is called.
          on_data has 4 argument.
          The 1st argument is this class object.
          The 2nd argument is utf-8 string which we get from the server.
          The 3rd argument is data type. ABNF.OPCODE_TEXT or ABNF.OPCODE_BINARY will be came.
          The 4th argument is continue flag. if 0, the data continue
        keep_running: this parameter is obsolete and ignored.
        get_mask_key: a callable to produce new mask keys,
          see the WebSocket.set_mask_key's docstring for more information
        subprotocols: array of available sub protocols. default is None.
        """
        self.url = url
        self.header = header if header is not None else []
        self.cookie = cookie

        self.on_open = on_open
        self.on_message = on_message
        self.on_data = on_data
        self.on_error = on_error
        self.on_close = on_close
        self.on_ping = on_ping
        self.on_pong = on_pong
        self.on_cont_message = on_cont_message
        self.keep_running = False
        self.get_mask_key = get_mask_key
        self.sock = None
        self.last_ping_tm = 0
        self.last_pong_tm = 0
        self.subprotocols = subprotocols

    def send(self, data, opcode=ABNF.OPCODE_TEXT):
        """
        send message.
        data: message to send. If you set opcode to OPCODE_TEXT,
              data must be utf-8 string or unicode.
        opcode: operation code of data. default is OPCODE_TEXT.
        """

        if not self.sock or self.sock.send(data, opcode) == 0:
            raise WebSocketConnectionClosedException(
                "Connection is already closed.")

    def close(self, **kwargs):
        """
        close websocket connection.
        """
        self.keep_running = False
        if self.sock:
            self.sock.close(**kwargs)
            self.sock = None

    def _send_ping(self, interval, event):
        while not event.wait(interval):
            self.last_ping_tm = time.time()
            if self.sock:
                try:
                    self.sock.ping()
                except Exception as ex:
                    _logging.warning("send_ping routine terminated: {}".format(ex))
                    break

    def run_forever(self, sockopt=None, sslopt=None,
                    ping_interval=0, ping_timeout=None,
                    http_proxy_host=None, http_proxy_port=None,
                    http_no_proxy=None, http_proxy_auth=None,
                    skip_utf8_validation=False,
                    host=None, origin=None, dispatcher=None,
                    suppress_origin=False, proxy_type=None):
        """
        run event loop for WebSocket framework.
        This loop is infinite loop and is alive during websocket is available.
        sockopt: values for socket.setsockopt.
            sockopt must be tuple
            and each element is argument of sock.setsockopt.
        sslopt: ssl socket optional dict.
        ping_interval: automatically send "ping" command
            every specified period(second)
            if set to 0, not send automatically.
        ping_timeout: timeout(second) if the pong message is not received.
        http_proxy_host: http proxy host name.
        http_proxy_port: http proxy port. If not set, set to 80.
        http_no_proxy: host names, which doesn't use proxy.
        skip_utf8_validation: skip utf8 validation.
        host: update host header.
        origin: update origin header.
        dispatcher: customize reading data from socket.
        suppress_origin: suppress outputting origin header.

        Returns
        -------
        False if caught KeyboardInterrupt
        True if other exception was raised during a loop
        """

        if ping_timeout is not None and ping_timeout <= 0:
            ping_timeout = None
        if ping_timeout and ping_interval and ping_interval <= ping_timeout:
            raise WebSocketException("Ensure ping_interval > ping_timeout")
        if not sockopt:
            sockopt = []
        if not sslopt:
            sslopt = {}
        if self.sock:
            raise WebSocketException("socket is already opened")
        thread = None
        self.keep_running = True
        self.last_ping_tm = 0
        self.last_pong_tm = 0

        def teardown(close_frame=None):
            """
            Tears down the connection.
            If close_frame is set, we will invoke the on_close handler with the
            statusCode and reason from there.
            """
            if thread and thread.isAlive():
                event.set()
                thread.join()
            self.keep_running = False
            if self.sock:
                self.sock.close()
            close_args = self._get_close_args(
                close_frame.data if close_frame else None)
            self._callback(self.on_close, *close_args)
            self.sock = None

        try:
            self.sock = WebSocket(
                self.get_mask_key, sockopt=sockopt, sslopt=sslopt,
                fire_cont_frame=self.on_cont_message is not None,
                skip_utf8_validation=skip_utf8_validation,
                enable_multithread=True if ping_interval else False)
            self.sock.settimeout(getdefaulttimeout())
            self.sock.connect(
                self.url, header=self.header, cookie=self.cookie,
                http_proxy_host=http_proxy_host,
                http_proxy_port=http_proxy_port, http_no_proxy=http_no_proxy,
                http_proxy_auth=http_proxy_auth, subprotocols=self.subprotocols,
                host=host, origin=origin, suppress_origin=suppress_origin,
                proxy_type=proxy_type)
            if not dispatcher:
                dispatcher = self.create_dispatcher(ping_timeout)

            self._callback(self.on_open)

            if ping_interval:
                event = threading.Event()
                thread = threading.Thread(
                    target=self._send_ping, args=(ping_interval, event))
                thread.setDaemon(True)
                thread.start()

            def read():
                if not self.keep_running:
                    return teardown()

                op_code, frame = self.sock.recv_data_frame(True)
                if op_code == ABNF.OPCODE_CLOSE:
                    return teardown(frame)
                elif op_code == ABNF.OPCODE_PING:
                    self._callback(self.on_ping, frame.data)
                elif op_code == ABNF.OPCODE_PONG:
                    self.last_pong_tm = time.time()
                    self._callback(self.on_pong, frame.data)
                elif op_code == ABNF.OPCODE_CONT and self.on_cont_message:
                    self._callback(self.on_data, frame.data,
                                   frame.opcode, frame.fin)
                    self._callback(self.on_cont_message,
                                   frame.data, frame.fin)
                else:
                    data = frame.data
                    if six.PY3 and op_code == ABNF.OPCODE_TEXT:
                        data = data.decode("utf-8")
                    self._callback(self.on_data, data, frame.opcode, True)
                    self._callback(self.on_message, data)

                return True

            def check():
                if (ping_timeout):
                    has_timeout_expired = time.time() - self.last_ping_tm > ping_timeout
                    has_pong_not_arrived_after_last_ping = self.last_pong_tm - self.last_ping_tm < 0
                    has_pong_arrived_too_late = self.last_pong_tm - self.last_ping_tm > ping_timeout

                    if (self.last_ping_tm
                            and has_timeout_expired
                            and (has_pong_not_arrived_after_last_ping or has_pong_arrived_too_late)):
                        raise WebSocketTimeoutException("ping/pong timed out")
                return True

            dispatcher.read(self.sock.sock, read, check)
        except (Exception, KeyboardInterrupt, SystemExit) as e:
            self._callback(self.on_error, e)
            if isinstance(e, SystemExit):
                # propagate SystemExit further
                raise
            teardown()
            return not isinstance(e, KeyboardInterrupt)

    def create_dispatcher(self, ping_timeout):
        timeout = ping_timeout or 10
        if self.sock.is_ssl():
            return SSLDispatcher(self, timeout)

        return Dispatcher(self, timeout)

    def _get_close_args(self, data):
        """ this functions extracts the code, reason from the close body
        if they exists, and if the self.on_close except three arguments """
        # if the on_close callback is "old", just return empty list
        if sys.version_info < (3, 0):
            if not self.on_close or len(inspect.getargspec(self.on_close).args) != 3:
                return []
        else:
            if not self.on_close or len(inspect.getfullargspec(self.on_close).args) != 3:
                return []

        if data and len(data) >= 2:
            code = 256 * six.byte2int(data[0:1]) + six.byte2int(data[1:2])
            reason = data[2:].decode('utf-8')
            return [code, reason]

        return [None, None]

    def _callback(self, callback, *args):
        if callback:
            try:
                if inspect.ismethod(callback):
                    callback(*args)
                else:
                    callback(self, *args)

            except Exception as e:
                _logging.error("error from callback {}: {}".format(callback, e))
                if _logging.isEnabledForDebug():
                    _, _, tb = sys.exc_info()
                    traceback.print_tb(tb)




############################################################
### File: _collections.py
############################################################
from __future__ import absolute_import

try:
    from collections.abc import Mapping, MutableMapping
except ImportError:
    from collections import Mapping, MutableMapping
try:
    from threading import RLock
except ImportError:  # Platform-specific: No threads available

    class RLock:
        def __enter__(self):
            pass

        def __exit__(self, exc_type, exc_value, traceback):
            pass


from collections import OrderedDict

from .exceptions import InvalidHeader
from .packages import six
from .packages.six import iterkeys, itervalues

__all__ = ["RecentlyUsedContainer", "HTTPHeaderDict"]


_Null = object()


class RecentlyUsedContainer(MutableMapping):
    """
    Provides a thread-safe dict-like container which maintains up to
    ``maxsize`` keys while throwing away the least-recently-used keys beyond
    ``maxsize``.

    :param maxsize:
        Maximum number of recent elements to retain.

    :param dispose_func:
        Every time an item is evicted from the container,
        ``dispose_func(value)`` is called.  Callback which will get called
    """

    ContainerCls = OrderedDict

    def __init__(self, maxsize=10, dispose_func=None):
        self._maxsize = maxsize
        self.dispose_func = dispose_func

        self._container = self.ContainerCls()
        self.lock = RLock()

    def __getitem__(self, key):
        # Re-insert the item, moving it to the end of the eviction line.
        with self.lock:
            item = self._container.pop(key)
            self._container[key] = item
            return item

    def __setitem__(self, key, value):
        evicted_value = _Null
        with self.lock:
            # Possibly evict the existing value of 'key'
            evicted_value = self._container.get(key, _Null)
            self._container[key] = value

            # If we didn't evict an existing value, we might have to evict the
            # least recently used item from the beginning of the container.
            if len(self._container) > self._maxsize:
                _key, evicted_value = self._container.popitem(last=False)

        if self.dispose_func and evicted_value is not _Null:
            self.dispose_func(evicted_value)

    def __delitem__(self, key):
        with self.lock:
            value = self._container.pop(key)

        if self.dispose_func:
            self.dispose_func(value)

    def __len__(self):
        with self.lock:
            return len(self._container)

    def __iter__(self):
        raise NotImplementedError(
            "Iteration over this class is unlikely to be threadsafe."
        )

    def clear(self):
        with self.lock:
            # Copy pointers to all values, then wipe the mapping
            values = list(itervalues(self._container))
            self._container.clear()

        if self.dispose_func:
            for value in values:
                self.dispose_func(value)

    def keys(self):
        with self.lock:
            return list(iterkeys(self._container))


class HTTPHeaderDict(MutableMapping):
    """
    :param headers:
        An iterable of field-value pairs. Must not contain multiple field names
        when compared case-insensitively.

    :param kwargs:
        Additional field-value pairs to pass in to ``dict.update``.

    A ``dict`` like container for storing HTTP Headers.

    Field names are stored and compared case-insensitively in compliance with
    RFC 7230. Iteration provides the first case-sensitive key seen for each
    case-insensitive pair.

    Using ``__setitem__`` syntax overwrites fields that compare equal
    case-insensitively in order to maintain ``dict``'s api. For fields that
    compare equal, instead create a new ``HTTPHeaderDict`` and use ``.add``
    in a loop.

    If multiple fields that are equal case-insensitively are passed to the
    constructor or ``.update``, the behavior is undefined and some will be
    lost.

    >>> headers = HTTPHeaderDict()
    >>> headers.add('Set-Cookie', 'foo=bar')
    >>> headers.add('set-cookie', 'baz=quxx')
    >>> headers['content-length'] = '7'
    >>> headers['SET-cookie']
    'foo=bar, baz=quxx'
    >>> headers['Content-Length']
    '7'
    """

    def __init__(self, headers=None, **kwargs):
        super(HTTPHeaderDict, self).__init__()
        self._container = OrderedDict()
        if headers is not None:
            if isinstance(headers, HTTPHeaderDict):
                self._copy_from(headers)
            else:
                self.extend(headers)
        if kwargs:
            self.extend(kwargs)

    def __setitem__(self, key, val):
        self._container[key.lower()] = [key, val]
        return self._container[key.lower()]

    def __getitem__(self, key):
        val = self._container[key.lower()]
        return ", ".join(val[1:])

    def __delitem__(self, key):
        del self._container[key.lower()]

    def __contains__(self, key):
        return key.lower() in self._container

    def __eq__(self, other):
        if not isinstance(other, Mapping) and not hasattr(other, "keys"):
            return False
        if not isinstance(other, type(self)):
            other = type(self)(other)
        return dict((k.lower(), v) for k, v in self.itermerged()) == dict(
            (k.lower(), v) for k, v in other.itermerged()
        )

    def __ne__(self, other):
        return not self.__eq__(other)

    if six.PY2:  # Python 2
        iterkeys = MutableMapping.iterkeys
        itervalues = MutableMapping.itervalues

    __marker = object()

    def __len__(self):
        return len(self._container)

    def __iter__(self):
        # Only provide the originally cased names
        for vals in self._container.values():
            yield vals[0]

    def pop(self, key, default=__marker):
        """D.pop(k[,d]) -> v, remove specified key and return the corresponding value.
        If key is not found, d is returned if given, otherwise KeyError is raised.
        """
        # Using the MutableMapping function directly fails due to the private marker.
        # Using ordinary dict.pop would expose the internal structures.
        # So let's reinvent the wheel.
        try:
            value = self[key]
        except KeyError:
            if default is self.__marker:
                raise
            return default
        else:
            del self[key]
            return value

    def discard(self, key):
        try:
            del self[key]
        except KeyError:
            pass

    def add(self, key, val):
        """Adds a (name, value) pair, doesn't overwrite the value if it already
        exists.

        >>> headers = HTTPHeaderDict(foo='bar')
        >>> headers.add('Foo', 'baz')
        >>> headers['foo']
        'bar, baz'
        """
        key_lower = key.lower()
        new_vals = [key, val]
        # Keep the common case aka no item present as fast as possible
        vals = self._container.setdefault(key_lower, new_vals)
        if new_vals is not vals:
            vals.append(val)

    def extend(self, *args, **kwargs):
        """Generic import function for any type of header-like object.
        Adapted version of MutableMapping.update in order to insert items
        with self.add instead of self.__setitem__
        """
        if len(args) > 1:
            raise TypeError(
                "extend() takes at most 1 positional "
                "arguments ({0} given)".format(len(args))
            )
        other = args[0] if len(args) >= 1 else ()

        if isinstance(other, HTTPHeaderDict):
            for key, val in other.iteritems():
                self.add(key, val)
        elif isinstance(other, Mapping):
            for key in other:
                self.add(key, other[key])
        elif hasattr(other, "keys"):
            for key in other.keys():
                self.add(key, other[key])
        else:
            for key, value in other:
                self.add(key, value)

        for key, value in kwargs.items():
            self.add(key, value)

    def getlist(self, key, default=__marker):
        """Returns a list of all the values for the named field. Returns an
        empty list if the key doesn't exist."""
        try:
            vals = self._container[key.lower()]
        except KeyError:
            if default is self.__marker:
                return []
            return default
        else:
            return vals[1:]

    # Backwards compatibility for httplib
    getheaders = getlist
    getallmatchingheaders = getlist
    iget = getlist

    # Backwards compatibility for http.cookiejar
    get_all = getlist

    def __repr__(self):
        return "%s(%s)" % (type(self).__name__, dict(self.itermerged()))

    def _copy_from(self, other):
        for key in other:
            val = other.getlist(key)
            if isinstance(val, list):
                # Don't need to convert tuples
                val = list(val)
            self._container[key.lower()] = [key] + val

    def copy(self):
        clone = type(self)()
        clone._copy_from(self)
        return clone

    def iteritems(self):
        """Iterate over all header lines, including duplicate ones."""
        for key in self:
            vals = self._container[key.lower()]
            for val in vals[1:]:
                yield vals[0], val

    def itermerged(self):
        """Iterate over all headers, merging duplicate ones together."""
        for key in self:
            val = self._container[key.lower()]
            yield val[0], ", ".join(val[1:])

    def items(self):
        return list(self.iteritems())

    @classmethod
    def from_httplib(cls, message):  # Python 2
        """Read headers from a Python 2 httplib message object."""
        # python2.7 does not expose a proper API for exporting multiheaders
        # efficiently. This function re-reads raw lines from the message
        # object and extracts the multiheaders properly.
        obs_fold_continued_leaders = (" ", "\t")
        headers = []

        for line in message.headers:
            if line.startswith(obs_fold_continued_leaders):
                if not headers:
                    # We received a header line that starts with OWS as described
                    # in RFC-7230 S3.2.4. This indicates a multiline header, but
                    # there exists no previous header to which we can attach it.
                    raise InvalidHeader(
                        "Header continuation with no previous header: %s" % line
                    )
                else:
                    key, value = headers[-1]
                    headers[-1] = (key, value + " " + line.strip())
                    continue

            key, value = line.split(":", 1)
            headers.append((key, value.strip()))

        return cls(headers)




############################################################
### File: _common.py
############################################################
"""
Common code used in multiple modules.
"""


class weekday(object):
    __slots__ = ["weekday", "n"]

    def __init__(self, weekday, n=None):
        self.weekday = weekday
        self.n = n

    def __call__(self, n):
        if n == self.n:
            return self
        else:
            return self.__class__(self.weekday, n)

    def __eq__(self, other):
        try:
            if self.weekday != other.weekday or self.n != other.n:
                return False
        except AttributeError:
            return False
        return True

    def __hash__(self):
        return hash((
          self.weekday,
          self.n,
        ))

    def __ne__(self, other):
        return not (self == other)

    def __repr__(self):
        s = ("MO", "TU", "WE", "TH", "FR", "SA", "SU")[self.weekday]
        if not self.n:
            return s
        else:
            return "%s(%+d)" % (s, self.n)

# vim:ts=4:sw=4:et




############################################################
### File: _compat.py
############################################################
import sys
import decimal
from decimal import Context

PY3 = sys.version_info[0] == 3
PY2 = sys.version_info[0] == 2


if PY3:
    long = int
    xrange = range
else:
    long = long  # pylint: disable=long-builtin
    xrange = xrange  # pylint: disable=xrange-builtin

# unicode / binary types
if PY3:
    text_type = str
    binary_type = bytes
    string_types = (str,)
    unichr = chr
    def maybe_decode(x):
        return x.decode()
    def maybe_encode(x):
        return x.encode()
    def maybe_chr(x):
        return x
    def maybe_ord(x):
        return x
else:
    text_type = unicode  # pylint: disable=unicode-builtin, undefined-variable
    binary_type = str
    string_types = (
        basestring,  # pylint: disable=basestring-builtin, undefined-variable
    )
    unichr = unichr  # pylint: disable=unichr-builtin
    def maybe_decode(x):
        return x
    def maybe_encode(x):
        return x
    def maybe_chr(x):
        return chr(x)
    def maybe_ord(x):
        return ord(x)


def round_py2_compat(what):
    """
    Python 2 and Python 3 use different rounding strategies in round(). This
    function ensures that results are python2/3 compatible and backward
    compatible with previous py2 releases
    :param what: float
    :return: rounded long
    """
    d = Context(
        prec=len(str(long(what))),  # round to integer with max precision
        rounding=decimal.ROUND_HALF_UP
    ).create_decimal(str(what))  # str(): python 2.6 compat
    return long(d)




############################################################
### File: _cookiejar.py
############################################################
try:
    import Cookie
except:
    import http.cookies as Cookie


class SimpleCookieJar(object):
    def __init__(self):
        self.jar = dict()

    def add(self, set_cookie):
        if set_cookie:
            try:
                simpleCookie = Cookie.SimpleCookie(set_cookie)
            except:
                simpleCookie = Cookie.SimpleCookie(set_cookie.encode('ascii', 'ignore'))

            for k, v in simpleCookie.items():
                domain = v.get("domain")
                if domain:
                    if not domain.startswith("."):
                        domain = "." + domain
                    cookie = self.jar.get(domain) if self.jar.get(domain) else Cookie.SimpleCookie()
                    cookie.update(simpleCookie)
                    self.jar[domain.lower()] = cookie

    def set(self, set_cookie):
        if set_cookie:
            try:
                simpleCookie = Cookie.SimpleCookie(set_cookie)
            except:
                simpleCookie = Cookie.SimpleCookie(set_cookie.encode('ascii', 'ignore'))

            for k, v in simpleCookie.items():
                domain = v.get("domain")
                if domain:
                    if not domain.startswith("."):
                        domain = "." + domain
                    self.jar[domain.lower()] = simpleCookie

    def get(self, host):
        if not host:
            return ""

        cookies = []
        for domain, simpleCookie in self.jar.items():
            host = host.lower()
            if host.endswith(domain) or host == domain[1:]:
                cookies.append(self.jar.get(domain))

        return "; ".join(filter(None, ["%s=%s" % (k, v.value) for cookie in filter(None, sorted(cookies)) for k, v in
                                       sorted(cookie.items())]))




############################################################
### File: _core.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA  02110-1335  USA

"""
from __future__ import print_function

import socket
import struct
import threading
import time

import six

# websocket modules
from ._abnf import *
from ._exceptions import *
from ._handshake import *
from ._http import *
from ._logging import *
from ._socket import *
from ._ssl_compat import *
from ._utils import *

__all__ = ['WebSocket', 'create_connection']

"""
websocket python client.
=========================

This version support only hybi-13.
Please see http://tools.ietf.org/html/rfc6455 for protocol.
"""


class WebSocket(object):
    """
    Low level WebSocket interface.
    This class is based on
      The WebSocket protocol draft-hixie-thewebsocketprotocol-76
      http://tools.ietf.org/html/draft-hixie-thewebsocketprotocol-76

    We can connect to the websocket server and send/receive data.
    The following example is an echo client.

    >>> import websocket
    >>> ws = websocket.WebSocket()
    >>> ws.connect("ws://echo.websocket.org")
    >>> ws.send("Hello, Server")
    >>> ws.recv()
    'Hello, Server'
    >>> ws.close()

    get_mask_key: a callable to produce new mask keys, see the set_mask_key
      function's docstring for more details
    sockopt: values for socket.setsockopt.
        sockopt must be tuple and each element is argument of sock.setsockopt.
    sslopt: dict object for ssl socket option.
    fire_cont_frame: fire recv event for each cont frame. default is False
    enable_multithread: if set to True, lock send method.
    skip_utf8_validation: skip utf8 validation.
    """

    def __init__(self, get_mask_key=None, sockopt=None, sslopt=None,
                 fire_cont_frame=False, enable_multithread=False,
                 skip_utf8_validation=False, **_):
        """
        Initialize WebSocket object.
        """
        self.sock_opt = sock_opt(sockopt, sslopt)
        self.handshake_response = None
        self.sock = None

        self.connected = False
        self.get_mask_key = get_mask_key
        # These buffer over the build-up of a single frame.
        self.frame_buffer = frame_buffer(self._recv, skip_utf8_validation)
        self.cont_frame = continuous_frame(
            fire_cont_frame, skip_utf8_validation)

        if enable_multithread:
            self.lock = threading.Lock()
            self.readlock = threading.Lock()
        else:
            self.lock = NoLock()
            self.readlock = NoLock()

    def __iter__(self):
        """
        Allow iteration over websocket, implying sequential `recv` executions.
        """
        while True:
            yield self.recv()

    def __next__(self):
        return self.recv()

    def next(self):
        return self.__next__()

    def fileno(self):
        return self.sock.fileno()

    def set_mask_key(self, func):
        """
        set function to create musk key. You can customize mask key generator.
        Mainly, this is for testing purpose.

        func: callable object. the func takes 1 argument as integer.
              The argument means length of mask key.
              This func must return string(byte array),
              which length is argument specified.
        """
        self.get_mask_key = func

    def gettimeout(self):
        """
        Get the websocket timeout(second).
        """
        return self.sock_opt.timeout

    def settimeout(self, timeout):
        """
        Set the timeout to the websocket.

        timeout: timeout time(second).
        """
        self.sock_opt.timeout = timeout
        if self.sock:
            self.sock.settimeout(timeout)

    timeout = property(gettimeout, settimeout)

    def getsubprotocol(self):
        """
        get subprotocol
        """
        if self.handshake_response:
            return self.handshake_response.subprotocol
        else:
            return None

    subprotocol = property(getsubprotocol)

    def getstatus(self):
        """
        get handshake status
        """
        if self.handshake_response:
            return self.handshake_response.status
        else:
            return None

    status = property(getstatus)

    def getheaders(self):
        """
        get handshake response header
        """
        if self.handshake_response:
            return self.handshake_response.headers
        else:
            return None

    def is_ssl(self):
        return isinstance(self.sock, ssl.SSLSocket)

    headers = property(getheaders)

    def connect(self, url, **options):
        """
        Connect to url. url is websocket url scheme.
        ie. ws://host:port/resource
        You can customize using 'options'.
        If you set "header" list object, you can set your own custom header.

        >>> ws = WebSocket()
        >>> ws.connect("ws://echo.websocket.org/",
                ...     header=["User-Agent: MyProgram",
                ...             "x-custom: header"])

        timeout: socket timeout time. This value is integer.
                 if you set None for this value,
                 it means "use default_timeout value"

        options: "header" -> custom http header list or dict.
                 "cookie" -> cookie value.
                 "origin" -> custom origin url.
                 "suppress_origin" -> suppress outputting origin header.
                 "host"   -> custom host header string.
                 "http_proxy_host" - http proxy host name.
                 "http_proxy_port" - http proxy port. If not set, set to 80.
                 "http_no_proxy"   - host names, which doesn't use proxy.
                 "http_proxy_auth" - http proxy auth information.
                                     tuple of username and password.
                                     default is None
                 "redirect_limit" -> number of redirects to follow.
                 "subprotocols" - array of available sub protocols.
                                  default is None.
                 "socket" - pre-initialized stream socket.

        """
        # FIXME: "subprotocols" are getting lost, not passed down
        # FIXME: "header", "cookie", "origin" and "host" too
        self.sock_opt.timeout = options.get('timeout', self.sock_opt.timeout)
        self.sock, addrs = connect(url, self.sock_opt, proxy_info(**options),
                                   options.pop('socket', None))

        try:
            self.handshake_response = handshake(self.sock, *addrs, **options)
            for attempt in range(options.pop('redirect_limit', 3)):
                if self.handshake_response.status in SUPPORTED_REDIRECT_STATUSES:
                    url = self.handshake_response.headers['location']
                    self.sock.close()
                    self.sock, addrs =  connect(url, self.sock_opt, proxy_info(**options),
                                                options.pop('socket', None))
                    self.handshake_response = handshake(self.sock, *addrs, **options)
            self.connected = True
        except:
            if self.sock:
                self.sock.close()
                self.sock = None
            raise

    def send(self, payload, opcode=ABNF.OPCODE_TEXT):
        """
        Send the data as string.

        payload: Payload must be utf-8 string or unicode,
                  if the opcode is OPCODE_TEXT.
                  Otherwise, it must be string(byte array)

        opcode: operation code to send. Please see OPCODE_XXX.
        """

        frame = ABNF.create_frame(payload, opcode)
        return self.send_frame(frame)

    def send_frame(self, frame):
        """
        Send the data frame.

        frame: frame data created  by ABNF.create_frame

        >>> ws = create_connection("ws://echo.websocket.org/")
        >>> frame = ABNF.create_frame("Hello", ABNF.OPCODE_TEXT)
        >>> ws.send_frame(frame)
        >>> cont_frame = ABNF.create_frame("My name is ", ABNF.OPCODE_CONT, 0)
        >>> ws.send_frame(frame)
        >>> cont_frame = ABNF.create_frame("Foo Bar", ABNF.OPCODE_CONT, 1)
        >>> ws.send_frame(frame)

        """
        if self.get_mask_key:
            frame.get_mask_key = self.get_mask_key
        data = frame.format()
        length = len(data)
        if (isEnabledForTrace()):
            trace("send: " + repr(data))

        with self.lock:
            while data:
                l = self._send(data)
                data = data[l:]

        return length

    def send_binary(self, payload):
        return self.send(payload, ABNF.OPCODE_BINARY)

    def ping(self, payload=""):
        """
        send ping data.

        payload: data payload to send server.
        """
        if isinstance(payload, six.text_type):
            payload = payload.encode("utf-8")
        self.send(payload, ABNF.OPCODE_PING)

    def pong(self, payload):
        """
        send pong data.

        payload: data payload to send server.
        """
        if isinstance(payload, six.text_type):
            payload = payload.encode("utf-8")
        self.send(payload, ABNF.OPCODE_PONG)

    def recv(self):
        """
        Receive string data(byte array) from the server.

        return value: string(byte array) value.
        """
        with self.readlock:
            opcode, data = self.recv_data()
        if six.PY3 and opcode == ABNF.OPCODE_TEXT:
            return data.decode("utf-8")
        elif opcode == ABNF.OPCODE_TEXT or opcode == ABNF.OPCODE_BINARY:
            return data
        else:
            return ''

    def recv_data(self, control_frame=False):
        """
        Receive data with operation code.

        control_frame: a boolean flag indicating whether to return control frame
        data, defaults to False

        return  value: tuple of operation code and string(byte array) value.
        """
        opcode, frame = self.recv_data_frame(control_frame)
        return opcode, frame.data

    def recv_data_frame(self, control_frame=False):
        """
        Receive data with operation code.

        control_frame: a boolean flag indicating whether to return control frame
        data, defaults to False

        return  value: tuple of operation code and string(byte array) value.
        """
        while True:
            frame = self.recv_frame()
            if not frame:
                # handle error:
                # 'NoneType' object has no attribute 'opcode'
                raise WebSocketProtocolException(
                    "Not a valid frame %s" % frame)
            elif frame.opcode in (ABNF.OPCODE_TEXT, ABNF.OPCODE_BINARY, ABNF.OPCODE_CONT):
                self.cont_frame.validate(frame)
                self.cont_frame.add(frame)

                if self.cont_frame.is_fire(frame):
                    return self.cont_frame.extract(frame)

            elif frame.opcode == ABNF.OPCODE_CLOSE:
                self.send_close()
                return frame.opcode, frame
            elif frame.opcode == ABNF.OPCODE_PING:
                if len(frame.data) < 126:
                    self.pong(frame.data)
                else:
                    raise WebSocketProtocolException(
                        "Ping message is too long")
                if control_frame:
                    return frame.opcode, frame
            elif frame.opcode == ABNF.OPCODE_PONG:
                if control_frame:
                    return frame.opcode, frame

    def recv_frame(self):
        """
        receive data as frame from server.

        return value: ABNF frame object.
        """
        return self.frame_buffer.recv_frame()

    def send_close(self, status=STATUS_NORMAL, reason=six.b("")):
        """
        send close data to the server.

        status: status code to send. see STATUS_XXX.

        reason: the reason to close. This must be string or bytes.
        """
        if status < 0 or status >= ABNF.LENGTH_16:
            raise ValueError("code is invalid range")
        self.connected = False
        self.send(struct.pack('!H', status) + reason, ABNF.OPCODE_CLOSE)

    def close(self, status=STATUS_NORMAL, reason=six.b(""), timeout=3):
        """
        Close Websocket object

        status: status code to send. see STATUS_XXX.

        reason: the reason to close. This must be string.

        timeout: timeout until receive a close frame.
            If None, it will wait forever until receive a close frame.
        """
        if self.connected:
            if status < 0 or status >= ABNF.LENGTH_16:
                raise ValueError("code is invalid range")

            try:
                self.connected = False
                self.send(struct.pack('!H', status) +
                          reason, ABNF.OPCODE_CLOSE)
                sock_timeout = self.sock.gettimeout()
                self.sock.settimeout(timeout)
                start_time = time.time()
                while timeout is None or time.time() - start_time < timeout:
                    try:
                        frame = self.recv_frame()
                        if frame.opcode != ABNF.OPCODE_CLOSE:
                            continue
                        if isEnabledForError():
                            recv_status = struct.unpack("!H", frame.data[0:2])[0]
                            if recv_status != STATUS_NORMAL:
                                error("close status: " + repr(recv_status))
                        break
                    except:
                        break
                self.sock.settimeout(sock_timeout)
                self.sock.shutdown(socket.SHUT_RDWR)
            except:
                pass

            self.shutdown()

    def abort(self):
        """
        Low-level asynchronous abort, wakes up other threads that are waiting in recv_*
        """
        if self.connected:
            self.sock.shutdown(socket.SHUT_RDWR)

    def shutdown(self):
        """close socket, immediately."""
        if self.sock:
            self.sock.close()
            self.sock = None
            self.connected = False

    def _send(self, data):
        return send(self.sock, data)

    def _recv(self, bufsize):
        try:
            return recv(self.sock, bufsize)
        except WebSocketConnectionClosedException:
            if self.sock:
                self.sock.close()
            self.sock = None
            self.connected = False
            raise


def create_connection(url, timeout=None, class_=WebSocket, **options):
    """
    connect to url and return websocket object.

    Connect to url and return the WebSocket object.
    Passing optional timeout parameter will set the timeout on the socket.
    If no timeout is supplied,
    the global default timeout setting returned by getdefauttimeout() is used.
    You can customize using 'options'.
    If you set "header" list object, you can set your own custom header.

    >>> conn = create_connection("ws://echo.websocket.org/",
         ...     header=["User-Agent: MyProgram",
         ...             "x-custom: header"])


    timeout: socket timeout time. This value is integer.
             if you set None for this value,
             it means "use default_timeout value"

    class_: class to instantiate when creating the connection. It has to implement
            settimeout and connect. It's __init__ should be compatible with
            WebSocket.__init__, i.e. accept all of it's kwargs.
    options: "header" -> custom http header list or dict.
             "cookie" -> cookie value.
             "origin" -> custom origin url.
             "suppress_origin" -> suppress outputting origin header.
             "host"   -> custom host header string.
             "http_proxy_host" - http proxy host name.
             "http_proxy_port" - http proxy port. If not set, set to 80.
             "http_no_proxy"   - host names, which doesn't use proxy.
             "http_proxy_auth" - http proxy auth information.
                                    tuple of username and password.
                                    default is None
             "enable_multithread" -> enable lock for multithread.
             "redirect_limit" -> number of redirects to follow.
             "sockopt" -> socket options
             "sslopt" -> ssl option
             "subprotocols" - array of available sub protocols.
                              default is None.
             "skip_utf8_validation" - skip utf8 validation.
             "socket" - pre-initialized stream socket.
    """
    sockopt = options.pop("sockopt", [])
    sslopt = options.pop("sslopt", {})
    fire_cont_frame = options.pop("fire_cont_frame", False)
    enable_multithread = options.pop("enable_multithread", False)
    skip_utf8_validation = options.pop("skip_utf8_validation", False)
    websock = class_(sockopt=sockopt, sslopt=sslopt,
                     fire_cont_frame=fire_cont_frame,
                     enable_multithread=enable_multithread,
                     skip_utf8_validation=skip_utf8_validation, **options)
    websock.settimeout(timeout if timeout is not None else getdefaulttimeout())
    websock.connect(url, **options)
    return websock




############################################################
### File: _exceptions.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA  02110-1335  USA

"""


"""
define websocket exceptions
"""


class WebSocketException(Exception):
    """
    websocket exception class.
    """
    pass


class WebSocketProtocolException(WebSocketException):
    """
    If the websocket protocol is invalid, this exception will be raised.
    """
    pass


class WebSocketPayloadException(WebSocketException):
    """
    If the websocket payload is invalid, this exception will be raised.
    """
    pass


class WebSocketConnectionClosedException(WebSocketException):
    """
    If remote host closed the connection or some network error happened,
    this exception will be raised.
    """
    pass


class WebSocketTimeoutException(WebSocketException):
    """
    WebSocketTimeoutException will be raised at socket timeout during read/write data.
    """
    pass


class WebSocketProxyException(WebSocketException):
    """
    WebSocketProxyException will be raised when proxy error occurred.
    """
    pass


class WebSocketBadStatusException(WebSocketException):
    """
    WebSocketBadStatusException will be raised when we get bad handshake status code.
    """

    def __init__(self, message, status_code, status_message=None, resp_headers=None):
        msg = message % (status_code, status_message)
        super(WebSocketBadStatusException, self).__init__(msg)
        self.status_code = status_code
        self.resp_headers = resp_headers


class WebSocketAddressException(WebSocketException):
    """
    If the websocket address info cannot be found, this exception will be raised.
    """
    pass




############################################################
### File: _handshake.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA  02110-1335  USA

"""
import hashlib
import hmac
import os

import six

from ._cookiejar import SimpleCookieJar
from ._exceptions import *
from ._http import *
from ._logging import *
from ._socket import *

if hasattr(six, 'PY3') and six.PY3:
    from base64 import encodebytes as base64encode
else:
    from base64 import encodestring as base64encode

if hasattr(six, 'PY3') and six.PY3:
    if hasattr(six, 'PY34') and six.PY34:
        from http import client as HTTPStatus
    else:
        from http import HTTPStatus
else:
    import httplib as HTTPStatus

__all__ = ["handshake_response", "handshake", "SUPPORTED_REDIRECT_STATUSES"]

if hasattr(hmac, "compare_digest"):
    compare_digest = hmac.compare_digest
else:
    def compare_digest(s1, s2):
        return s1 == s2

# websocket supported version.
VERSION = 13

SUPPORTED_REDIRECT_STATUSES = (HTTPStatus.MOVED_PERMANENTLY, HTTPStatus.FOUND, HTTPStatus.SEE_OTHER,)
SUCCESS_STATUSES = SUPPORTED_REDIRECT_STATUSES + (HTTPStatus.SWITCHING_PROTOCOLS,)

CookieJar = SimpleCookieJar()


class handshake_response(object):

    def __init__(self, status, headers, subprotocol):
        self.status = status
        self.headers = headers
        self.subprotocol = subprotocol
        CookieJar.add(headers.get("set-cookie"))


def handshake(sock, hostname, port, resource, **options):
    headers, key = _get_handshake_headers(resource, hostname, port, options)

    header_str = "\r\n".join(headers)
    send(sock, header_str)
    dump("request header", header_str)

    status, resp = _get_resp_headers(sock)
    if status in SUPPORTED_REDIRECT_STATUSES:
        return handshake_response(status, resp, None)
    success, subproto = _validate(resp, key, options.get("subprotocols"))
    if not success:
        raise WebSocketException("Invalid WebSocket Header")

    return handshake_response(status, resp, subproto)


def _pack_hostname(hostname):
    # IPv6 address
    if ':' in hostname:
        return '[' + hostname + ']'

    return hostname

def _get_handshake_headers(resource, host, port, options):
    headers = [
        "GET %s HTTP/1.1" % resource,
        "Upgrade: websocket"
    ]
    if port == 80 or port == 443:
        hostport = _pack_hostname(host)
    else:
        hostport = "%s:%d" % (_pack_hostname(host), port)
    if "host" in options and options["host"] is not None:
        headers.append("Host: %s" % options["host"])
    else:
        headers.append("Host: %s" % hostport)

    if "suppress_origin" not in options or not options["suppress_origin"]:
        if "origin" in options and options["origin"] is not None:
            headers.append("Origin: %s" % options["origin"])
        else:
            headers.append("Origin: http://%s" % hostport)

    key = _create_sec_websocket_key()
    
    # Append Sec-WebSocket-Key & Sec-WebSocket-Version if not manually specified
    if not 'header' in options or 'Sec-WebSocket-Key' not in options['header']:
        key = _create_sec_websocket_key()
        headers.append("Sec-WebSocket-Key: %s" % key)
    else:
        key = options['header']['Sec-WebSocket-Key']

    if not 'header' in options or 'Sec-WebSocket-Version' not in options['header']:
        headers.append("Sec-WebSocket-Version: %s" % VERSION)

    if not 'connection' in options or options['connection'] is None:
        headers.append('Connection: upgrade')
    else:
        headers.append(options['connection'])

    subprotocols = options.get("subprotocols")
    if subprotocols:
        headers.append("Sec-WebSocket-Protocol: %s" % ",".join(subprotocols))

    if "header" in options:
        header = options["header"]
        if isinstance(header, dict):
            header = [
                ": ".join([k, v])
                for k, v in header.items()
                if v is not None
            ]
        headers.extend(header)

    server_cookie = CookieJar.get(host)
    client_cookie = options.get("cookie", None)

    cookie = "; ".join(filter(None, [server_cookie, client_cookie]))

    if cookie:
        headers.append("Cookie: %s" % cookie)

    headers.append("")
    headers.append("")

    return headers, key


def _get_resp_headers(sock, success_statuses=SUCCESS_STATUSES):
    status, resp_headers, status_message = read_headers(sock)
    if status not in success_statuses:
        raise WebSocketBadStatusException("Handshake status %d %s", status, status_message, resp_headers)
    return status, resp_headers


_HEADERS_TO_CHECK = {
    "upgrade": "websocket",
    "connection": "upgrade",
}


def _validate(headers, key, subprotocols):
    subproto = None
    for k, v in _HEADERS_TO_CHECK.items():
        r = headers.get(k, None)
        if not r:
            return False, None
        r = r.lower()
        if v != r:
            return False, None

    if subprotocols:
        subproto = headers.get("sec-websocket-protocol", None).lower()
        if not subproto or subproto not in [s.lower() for s in subprotocols]:
            error("Invalid subprotocol: " + str(subprotocols))
            return False, None

    result = headers.get("sec-websocket-accept", None)
    if not result:
        return False, None
    result = result.lower()

    if isinstance(result, six.text_type):
        result = result.encode('utf-8')

    value = (key + "258EAFA5-E914-47DA-95CA-C5AB0DC85B11").encode('utf-8')
    hashed = base64encode(hashlib.sha1(value).digest()).strip().lower()
    success = compare_digest(hashed, result)

    if success:
        return True, subproto
    else:
        return False, None


def _create_sec_websocket_key():
    randomness = os.urandom(16)
    return base64encode(randomness).decode('utf-8').strip()




############################################################
### File: _http.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA  02110-1335  USA

"""
import errno
import os
import socket
import sys

import six

from ._exceptions import *
from ._logging import *
from ._socket import*
from ._ssl_compat import *
from ._url import *

if six.PY3:
    from base64 import encodebytes as base64encode
else:
    from base64 import encodestring as base64encode

__all__ = ["proxy_info", "connect", "read_headers"]

try:
    import socks
    ProxyConnectionError = socks.ProxyConnectionError
    HAS_PYSOCKS = True
except:
    class ProxyConnectionError(BaseException):
        pass
    HAS_PYSOCKS = False

class proxy_info(object):

    def __init__(self, **options):
        self.type = options.get("proxy_type") or "http"
        if not(self.type in ['http', 'socks4', 'socks5', 'socks5h']):
            raise ValueError("proxy_type must be 'http', 'socks4', 'socks5' or 'socks5h'")
        self.host = options.get("http_proxy_host", None)
        if self.host:
            self.port = options.get("http_proxy_port", 0)
            self.auth = options.get("http_proxy_auth", None)
            self.no_proxy = options.get("http_no_proxy", None)
        else:
            self.port = 0
            self.auth = None
            self.no_proxy = None


def _open_proxied_socket(url, options, proxy):
    hostname, port, resource, is_secure = parse_url(url)

    if not HAS_PYSOCKS:
        raise WebSocketException("PySocks module not found.")

    ptype = socks.SOCKS5
    rdns = False
    if proxy.type == "socks4":
        ptype = socks.SOCKS4
    if proxy.type == "http":
        ptype = socks.HTTP
    if proxy.type[-1] == "h":
        rdns = True

    sock = socks.create_connection(
            (hostname, port),
            proxy_type = ptype,
            proxy_addr = proxy.host,
            proxy_port = proxy.port,
            proxy_rdns = rdns,
            proxy_username = proxy.auth[0] if proxy.auth else None,
            proxy_password = proxy.auth[1] if proxy.auth else None,
            timeout = options.timeout,
            socket_options = DEFAULT_SOCKET_OPTION + options.sockopt
    )

    if is_secure:
        if HAVE_SSL:
            sock = _ssl_socket(sock, options.sslopt, hostname)
        else:
            raise WebSocketException("SSL not available.")

    return sock, (hostname, port, resource)


def connect(url, options, proxy, socket):
    if proxy.host and not socket and not (proxy.type == 'http'):
        return _open_proxied_socket(url, options, proxy)

    hostname, port, resource, is_secure = parse_url(url)

    if socket:
        return socket, (hostname, port, resource)

    addrinfo_list, need_tunnel, auth = _get_addrinfo_list(
        hostname, port, is_secure, proxy)
    if not addrinfo_list:
        raise WebSocketException(
            "Host not found.: " + hostname + ":" + str(port))

    sock = None
    try:
        sock = _open_socket(addrinfo_list, options.sockopt, options.timeout)
        if need_tunnel:
            sock = _tunnel(sock, hostname, port, auth)

        if is_secure:
            if HAVE_SSL:
                sock = _ssl_socket(sock, options.sslopt, hostname)
            else:
                raise WebSocketException("SSL not available.")

        return sock, (hostname, port, resource)
    except:
        if sock:
            sock.close()
        raise


def _get_addrinfo_list(hostname, port, is_secure, proxy):
    phost, pport, pauth = get_proxy_info(
        hostname, is_secure, proxy.host, proxy.port, proxy.auth, proxy.no_proxy)
    try:
        # when running on windows 10, getaddrinfo without socktype returns a socktype 0.
        # This generates an error exception: `_on_error: exception Socket type must be stream or datagram, not 0`
        # or `OSError: [Errno 22] Invalid argument` when creating socket. Force the socket type to SOCK_STREAM.
        if not phost:
            addrinfo_list = socket.getaddrinfo(
                hostname, port, 0, socket.SOCK_STREAM, socket.SOL_TCP)
            return addrinfo_list, False, None
        else:
            pport = pport and pport or 80
            # when running on windows 10, the getaddrinfo used above
            # returns a socktype 0. This generates an error exception:
            # _on_error: exception Socket type must be stream or datagram, not 0
            # Force the socket type to SOCK_STREAM
            addrinfo_list = socket.getaddrinfo(phost, pport, 0, socket.SOCK_STREAM, socket.SOL_TCP)
            return addrinfo_list, True, pauth
    except socket.gaierror as e:
        raise WebSocketAddressException(e)


def _open_socket(addrinfo_list, sockopt, timeout):
    err = None
    for addrinfo in addrinfo_list:
        family, socktype, proto = addrinfo[:3]
        sock = socket.socket(family, socktype, proto)
        sock.settimeout(timeout)
        for opts in DEFAULT_SOCKET_OPTION:
            sock.setsockopt(*opts)
        for opts in sockopt:
            sock.setsockopt(*opts)

        address = addrinfo[4]
        err = None
        while not err:
            try:
                sock.connect(address)
            except ProxyConnectionError as error:
                err = WebSocketProxyException(str(error))
                err.remote_ip = str(address[0])
                continue
            except socket.error as error:
                error.remote_ip = str(address[0])
                try:
                    eConnRefused = (errno.ECONNREFUSED, errno.WSAECONNREFUSED)
                except:
                    eConnRefused = (errno.ECONNREFUSED, )
                if error.errno == errno.EINTR:
                    continue
                elif error.errno in eConnRefused:
                    err = error
                    continue
                else:
                    raise error
            else:
                break
        else:
            continue
        break
    else:
        if err:
            raise err

    return sock


def _can_use_sni():
    return six.PY2 and sys.version_info >= (2, 7, 9) or sys.version_info >= (3, 2)


def _wrap_sni_socket(sock, sslopt, hostname, check_hostname):
    context = ssl.SSLContext(sslopt.get('ssl_version', ssl.PROTOCOL_SSLv23))

    if sslopt.get('cert_reqs', ssl.CERT_NONE) != ssl.CERT_NONE:
        cafile = sslopt.get('ca_certs', None)
        capath = sslopt.get('ca_cert_path', None)
        if cafile or capath:
            context.load_verify_locations(cafile=cafile, capath=capath)
        elif hasattr(context, 'load_default_certs'):
            context.load_default_certs(ssl.Purpose.SERVER_AUTH)
    if sslopt.get('certfile', None):
        context.load_cert_chain(
            sslopt['certfile'],
            sslopt.get('keyfile', None),
            sslopt.get('password', None),
        )
    # see
    # https://github.com/liris/websocket-client/commit/b96a2e8fa765753e82eea531adb19716b52ca3ca#commitcomment-10803153
    context.verify_mode = sslopt['cert_reqs']
    if HAVE_CONTEXT_CHECK_HOSTNAME:
        context.check_hostname = check_hostname
    if 'ciphers' in sslopt:
        context.set_ciphers(sslopt['ciphers'])
    if 'cert_chain' in sslopt:
        certfile, keyfile, password = sslopt['cert_chain']
        context.load_cert_chain(certfile, keyfile, password)
    if 'ecdh_curve' in sslopt:
        context.set_ecdh_curve(sslopt['ecdh_curve'])

    return context.wrap_socket(
        sock,
        do_handshake_on_connect=sslopt.get('do_handshake_on_connect', True),
        suppress_ragged_eofs=sslopt.get('suppress_ragged_eofs', True),
        server_hostname=hostname,
    )


def _ssl_socket(sock, user_sslopt, hostname):
    sslopt = dict(cert_reqs=ssl.CERT_REQUIRED)
    sslopt.update(user_sslopt)

    certPath = os.environ.get('WEBSOCKET_CLIENT_CA_BUNDLE')
    if certPath and os.path.isfile(certPath) \
            and user_sslopt.get('ca_certs', None) is None \
            and user_sslopt.get('ca_cert', None) is None:
        sslopt['ca_certs'] = certPath
    elif certPath and os.path.isdir(certPath) \
            and user_sslopt.get('ca_cert_path', None) is None:
        sslopt['ca_cert_path'] = certPath

    check_hostname = sslopt["cert_reqs"] != ssl.CERT_NONE and sslopt.pop(
        'check_hostname', True)

    if _can_use_sni():
        sock = _wrap_sni_socket(sock, sslopt, hostname, check_hostname)
    else:
        sslopt.pop('check_hostname', True)
        sock = ssl.wrap_socket(sock, **sslopt)

    if not HAVE_CONTEXT_CHECK_HOSTNAME and check_hostname:
        match_hostname(sock.getpeercert(), hostname)

    return sock


def _tunnel(sock, host, port, auth):
    debug("Connecting proxy...")
    connect_header = "CONNECT %s:%d HTTP/1.0\r\n" % (host, port)
    # TODO: support digest auth.
    if auth and auth[0]:
        auth_str = auth[0]
        if auth[1]:
            auth_str += ":" + auth[1]
        encoded_str = base64encode(auth_str.encode()).strip().decode().replace('\n', '')
        connect_header += "Proxy-Authorization: Basic %s\r\n" % encoded_str
    connect_header += "\r\n"
    dump("request header", connect_header)

    send(sock, connect_header)

    try:
        status, resp_headers, status_message = read_headers(sock)
    except Exception as e:
        raise WebSocketProxyException(str(e))

    if status != 200:
        raise WebSocketProxyException(
            "failed CONNECT via proxy status: %r" % status)

    return sock


def read_headers(sock):
    status = None
    status_message = None
    headers = {}
    trace("--- response header ---")

    while True:
        line = recv_line(sock)
        line = line.decode('utf-8').strip()
        if not line:
            break
        trace(line)
        if not status:

            status_info = line.split(" ", 2)
            status = int(status_info[1])
            if len(status_info) > 2:
                status_message = status_info[2]
        else:
            kv = line.split(":", 1)
            if len(kv) == 2:
                key, value = kv
                headers[key.lower()] = value.strip()
            else:
                raise WebSocketException("Invalid header")

    trace("-----------------------")

    return status, headers, status_message




############################################################
### File: _internal_utils.py
############################################################
# -*- coding: utf-8 -*-

"""
requests._internal_utils
~~~~~~~~~~~~~~

Provides utility functions that are consumed internally by Requests
which depend on extremely few external helpers (such as compat)
"""

from .compat import is_py2, builtin_str, str


def to_native_string(string, encoding='ascii'):
    """Given a string object, regardless of type, returns a representation of
    that string in the native string type, encoding and decoding where
    necessary. This assumes ASCII unless told otherwise.
    """
    if isinstance(string, builtin_str):
        out = string
    else:
        if is_py2:
            out = string.encode(encoding)
        else:
            out = string.decode(encoding)

    return out


def unicode_is_ascii(u_string):
    """Determine if unicode string only contains ASCII characters.

    :param str u_string: unicode string to check. Must be unicode
        and not Python 2 `str`.
    :rtype: bool
    """
    assert isinstance(u_string, str)
    try:
        u_string.encode('ascii')
        return True
    except UnicodeEncodeError:
        return False




############################################################
### File: _logging.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA  02110-1335  USA

"""
import logging

_logger = logging.getLogger('websocket')
try:
    from logging import NullHandler
except ImportError:
    class NullHandler(logging.Handler):
        def emit(self, record):
            pass

_logger.addHandler(NullHandler())

_traceEnabled = False

__all__ = ["enableTrace", "dump", "error", "warning", "debug", "trace",
           "isEnabledForError", "isEnabledForDebug", "isEnabledForTrace"]


def enableTrace(traceable, handler = logging.StreamHandler()):
    """
    turn on/off the traceability.

    traceable: boolean value. if set True, traceability is enabled.
    """
    global _traceEnabled
    _traceEnabled = traceable
    if traceable:
        _logger.addHandler(handler)
        _logger.setLevel(logging.DEBUG)

def dump(title, message):
    if _traceEnabled:
        _logger.debug("--- " + title + " ---")
        _logger.debug(message)
        _logger.debug("-----------------------")


def error(msg):
    _logger.error(msg)


def warning(msg):
    _logger.warning(msg)


def debug(msg):
    _logger.debug(msg)


def trace(msg):
    if _traceEnabled:
        _logger.debug(msg)


def isEnabledForError():
    return _logger.isEnabledFor(logging.ERROR)


def isEnabledForDebug():
    return _logger.isEnabledFor(logging.DEBUG)

def isEnabledForTrace():
    return _traceEnabled




############################################################
### File: _socket.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA 02110-1335  USA

"""
import errno
import select
import socket

import six
import sys

from ._exceptions import *
from ._ssl_compat import *
from ._utils import *

DEFAULT_SOCKET_OPTION = [(socket.SOL_TCP, socket.TCP_NODELAY, 1)]
if hasattr(socket, "SO_KEEPALIVE"):
    DEFAULT_SOCKET_OPTION.append((socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1))
if hasattr(socket, "TCP_KEEPIDLE"):
    DEFAULT_SOCKET_OPTION.append((socket.SOL_TCP, socket.TCP_KEEPIDLE, 30))
if hasattr(socket, "TCP_KEEPINTVL"):
    DEFAULT_SOCKET_OPTION.append((socket.SOL_TCP, socket.TCP_KEEPINTVL, 10))
if hasattr(socket, "TCP_KEEPCNT"):
    DEFAULT_SOCKET_OPTION.append((socket.SOL_TCP, socket.TCP_KEEPCNT, 3))

_default_timeout = None

__all__ = ["DEFAULT_SOCKET_OPTION", "sock_opt", "setdefaulttimeout", "getdefaulttimeout",
           "recv", "recv_line", "send"]


class sock_opt(object):

    def __init__(self, sockopt, sslopt):
        if sockopt is None:
            sockopt = []
        if sslopt is None:
            sslopt = {}
        self.sockopt = sockopt
        self.sslopt = sslopt
        self.timeout = None


def setdefaulttimeout(timeout):
    """
    Set the global timeout setting to connect.

    timeout: default socket timeout time. This value is second.
    """
    global _default_timeout
    _default_timeout = timeout


def getdefaulttimeout():
    """
    Return the global timeout setting(second) to connect.
    """
    return _default_timeout


def recv(sock, bufsize):
    if not sock:
        raise WebSocketConnectionClosedException("socket is already closed.")

    def _recv():
        try:
            return sock.recv(bufsize)
        except SSLWantReadError:
            pass
        except socket.error as exc:
            error_code = extract_error_code(exc)
            if error_code is None:
                raise
            if error_code != errno.EAGAIN or error_code != errno.EWOULDBLOCK:
                raise

        r, w, e = select.select((sock, ), (), (), sock.gettimeout())
        if r:
            return sock.recv(bufsize)

    try:
        if sock.gettimeout() == 0:
            bytes_ = sock.recv(bufsize)
        else:
            bytes_ = _recv()
    except socket.timeout as e:
        message = extract_err_message(e)
        raise WebSocketTimeoutException(message)
    except SSLError as e:
        message = extract_err_message(e)
        if isinstance(message, str) and 'timed out' in message:
            raise WebSocketTimeoutException(message)
        else:
            raise

    if not bytes_:
        raise WebSocketConnectionClosedException(
            "Connection is already closed.")

    return bytes_


def recv_line(sock):
    line = []
    while True:
        c = recv(sock, 1)
        line.append(c)
        if c == six.b("\n"):
            break
    return six.b("").join(line)


def send(sock, data):
    if isinstance(data, six.text_type):
        data = data.encode('utf-8')

    if not sock:
        raise WebSocketConnectionClosedException("socket is already closed.")

    def _send():
        try:
            return sock.send(data)
        except SSLWantWriteError:
            pass
        except socket.error as exc:
            error_code = extract_error_code(exc)
            if error_code is None:
                raise
            if error_code != errno.EAGAIN or error_code != errno.EWOULDBLOCK:
                raise

        r, w, e = select.select((), (sock, ), (), sock.gettimeout())
        if w:
            return sock.send(data)

    try:
        if sock.gettimeout() == 0:
            return sock.send(data)
        else:
            return _send()
    except socket.timeout as e:
        message = extract_err_message(e)
        raise WebSocketTimeoutException(message)
    except Exception as e:
        message = extract_err_message(e)
        if isinstance(message, str) and "timed out" in message:
            raise WebSocketTimeoutException(message)
        else:
            raise




############################################################
### File: _ssl_compat.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA 02110-1335  USA

"""
__all__ = ["HAVE_SSL", "ssl", "SSLError", "SSLWantReadError", "SSLWantWriteError"]

try:
    import ssl
    from ssl import SSLError
    from ssl import SSLWantReadError
    from ssl import SSLWantWriteError
    if hasattr(ssl, 'SSLContext') and hasattr(ssl.SSLContext, 'check_hostname'):
        HAVE_CONTEXT_CHECK_HOSTNAME = True
    else:
        HAVE_CONTEXT_CHECK_HOSTNAME = False
        if hasattr(ssl, "match_hostname"):
            from ssl import match_hostname
        else:
            from _backports.ssl_match_hostname import match_hostname
        __all__.append("match_hostname")
    __all__.append("HAVE_CONTEXT_CHECK_HOSTNAME")

    HAVE_SSL = True
except ImportError:
    # dummy class of SSLError for ssl none-support environment.
    class SSLError(Exception):
        pass

    class SSLWantReadError(Exception):
        pass

    class SSLWantWriteError(Exception):
        pass

    ssl = lambda: None

    HAVE_SSL = False




############################################################
### File: _url.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA  02110-1335  USA

"""

import os
import socket
import struct

from six.moves.urllib.parse import urlparse


__all__ = ["parse_url", "get_proxy_info"]


def parse_url(url):
    """
    parse url and the result is tuple of
    (hostname, port, resource path and the flag of secure mode)

    url: url string.
    """
    if ":" not in url:
        raise ValueError("url is invalid")

    scheme, url = url.split(":", 1)

    parsed = urlparse(url, scheme="ws")
    if parsed.hostname:
        hostname = parsed.hostname
    else:
        raise ValueError("hostname is invalid")
    port = 0
    if parsed.port:
        port = parsed.port

    is_secure = False
    if scheme == "ws":
        if not port:
            port = 80
    elif scheme == "wss":
        is_secure = True
        if not port:
            port = 443
    else:
        raise ValueError("scheme %s is invalid" % scheme)

    if parsed.path:
        resource = parsed.path
    else:
        resource = "/"

    if parsed.query:
        resource += "?" + parsed.query

    return hostname, port, resource, is_secure


DEFAULT_NO_PROXY_HOST = ["localhost", "127.0.0.1"]


def _is_ip_address(addr):
    try:
        socket.inet_aton(addr)
    except socket.error:
        return False
    else:
        return True


def _is_subnet_address(hostname):
    try:
        addr, netmask = hostname.split("/")
        return _is_ip_address(addr) and 0 <= int(netmask) < 32
    except ValueError:
        return False


def _is_address_in_network(ip, net):
    ipaddr = struct.unpack('I', socket.inet_aton(ip))[0]
    netaddr, bits = net.split('/')
    netmask = struct.unpack('I', socket.inet_aton(netaddr))[0] & ((2 << int(bits) - 1) - 1)
    return ipaddr & netmask == netmask


def _is_no_proxy_host(hostname, no_proxy):
    if not no_proxy:
        v = os.environ.get("no_proxy", "").replace(" ", "")
        if v:
            no_proxy = v.split(",")
    if not no_proxy:
        no_proxy = DEFAULT_NO_PROXY_HOST

    if hostname in no_proxy:
        return True
    elif _is_ip_address(hostname):
        return any([_is_address_in_network(hostname, subnet) for subnet in no_proxy if _is_subnet_address(subnet)])

    return False


def get_proxy_info(
        hostname, is_secure, proxy_host=None, proxy_port=0, proxy_auth=None,
        no_proxy=None, proxy_type='http'):
    """
    try to retrieve proxy host and port from environment
    if not provided in options.
    result is (proxy_host, proxy_port, proxy_auth).
    proxy_auth is tuple of username and password
     of proxy authentication information.

    hostname: websocket server name.

    is_secure:  is the connection secure? (wss)
                looks for "https_proxy" in env
                before falling back to "http_proxy"

    options:    "http_proxy_host" - http proxy host name.
                "http_proxy_port" - http proxy port.
                "http_no_proxy"   - host names, which doesn't use proxy.
                "http_proxy_auth" - http proxy auth information.
                                    tuple of username and password.
                                    default is None
                "proxy_type"      - if set to "socks5" PySocks wrapper
                                    will be used in place of a http proxy.
                                    default is "http"
    """
    if _is_no_proxy_host(hostname, no_proxy):
        return None, 0, None

    if proxy_host:
        port = proxy_port
        auth = proxy_auth
        return proxy_host, port, auth

    env_keys = ["http_proxy"]
    if is_secure:
        env_keys.insert(0, "https_proxy")

    for key in env_keys:
        value = os.environ.get(key, None)
        if value:
            proxy = urlparse(value)
            auth = (proxy.username, proxy.password) if proxy.username else None
            return proxy.hostname, proxy.port, auth

    return None, 0, None




############################################################
### File: _utils.py
############################################################
"""
websocket - WebSocket client library for Python

Copyright (C) 2010 Hiroki Ohtani(liris)

    This library is free software; you can redistribute it and/or
    modify it under the terms of the GNU Lesser General Public
    License as published by the Free Software Foundation; either
    version 2.1 of the License, or (at your option) any later version.

    This library is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
    Lesser General Public License for more details.

    You should have received a copy of the GNU Lesser General Public
    License along with this library; if not, write to the Free Software
    Foundation, Inc., 51 Franklin Street, Fifth Floor,
    Boston, MA 02110-1335  USA

"""
import six

__all__ = ["NoLock", "validate_utf8", "extract_err_message", "extract_error_code"]


class NoLock(object):

    def __enter__(self):
        pass

    def __exit__(self, exc_type, exc_value, traceback):
        pass


try:
    # If wsaccel is available we use compiled routines to validate UTF-8
    # strings.
    from wsaccel.utf8validator import Utf8Validator

    def _validate_utf8(utfbytes):
        return Utf8Validator().validate(utfbytes)[0]

except ImportError:
    # UTF-8 validator
    # python implementation of http://bjoern.hoehrmann.de/utf-8/decoder/dfa/

    _UTF8_ACCEPT = 0
    _UTF8_REJECT = 12

    _UTF8D = [
        # The first part of the table maps bytes to character classes that
        # to reduce the size of the transition table and create bitmasks.
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
        0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,  0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
        1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,  9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,9,
        7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,  7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,7,
        8,8,2,2,2,2,2,2,2,2,2,2,2,2,2,2,  2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,
        10,3,3,3,3,3,3,3,3,3,3,3,3,4,3,3, 11,6,6,6,5,8,8,8,8,8,8,8,8,8,8,8,

        # The second part is a transition table that maps a combination
        # of a state of the automaton and a character class to a state.
        0,12,24,36,60,96,84,12,12,12,48,72, 12,12,12,12,12,12,12,12,12,12,12,12,
        12, 0,12,12,12,12,12, 0,12, 0,12,12, 12,24,12,12,12,12,12,24,12,24,12,12,
        12,12,12,12,12,12,12,24,12,12,12,12, 12,24,12,12,12,12,12,12,12,24,12,12,
        12,12,12,12,12,12,12,36,12,36,12,12, 12,36,12,12,12,12,12,36,12,36,12,12,
        12,36,12,12,12,12,12,12,12,12,12,12, ]

    def _decode(state, codep, ch):
        tp = _UTF8D[ch]

        codep = (ch & 0x3f) | (codep << 6) if (
            state != _UTF8_ACCEPT) else (0xff >> tp) & ch
        state = _UTF8D[256 + state + tp]

        return state, codep

    def _validate_utf8(utfbytes):
        state = _UTF8_ACCEPT
        codep = 0
        for i in utfbytes:
            if six.PY2:
                i = ord(i)
            state, codep = _decode(state, codep, i)
            if state == _UTF8_REJECT:
                return False

        return True


def validate_utf8(utfbytes):
    """
    validate utf8 byte string.
    utfbytes: utf byte string to check.
    return value: if valid utf8 string, return true. Otherwise, return false.
    """
    return _validate_utf8(utfbytes)


def extract_err_message(exception):
    if exception.args:
        return exception.args[0]
    else:
        return None


def extract_error_code(exception):
    if exception.args and len(exception.args) > 1:
        return exception.args[0] if isinstance(exception.args[0], int) else None




############################################################
### File: _version.py
############################################################
# This file is protected via CODEOWNERS
__version__ = "1.26.9"




############################################################
### File: adapters.py
############################################################
# -*- coding: utf-8 -*-

"""
requests.adapters
~~~~~~~~~~~~~~~~~

This module contains the transport adapters that Requests uses to define
and maintain connections.
"""

import os.path
import socket

from urllib3.poolmanager import PoolManager, proxy_from_url
from urllib3.response import HTTPResponse
from urllib3.util import parse_url
from urllib3.util import Timeout as TimeoutSauce
from urllib3.util.retry import Retry
from urllib3.exceptions import ClosedPoolError
from urllib3.exceptions import ConnectTimeoutError
from urllib3.exceptions import HTTPError as _HTTPError
from urllib3.exceptions import InvalidHeader as _InvalidHeader
from urllib3.exceptions import MaxRetryError
from urllib3.exceptions import NewConnectionError
from urllib3.exceptions import ProxyError as _ProxyError
from urllib3.exceptions import ProtocolError
from urllib3.exceptions import ReadTimeoutError
from urllib3.exceptions import SSLError as _SSLError
from urllib3.exceptions import ResponseError
from urllib3.exceptions import LocationValueError

from .models import Response
from .compat import urlparse, basestring
from .utils import (DEFAULT_CA_BUNDLE_PATH, extract_zipped_paths,
                    get_encoding_from_headers, prepend_scheme_if_needed,
                    get_auth_from_url, urldefragauth, select_proxy)
from .structures import CaseInsensitiveDict
from .cookies import extract_cookies_to_jar
from .exceptions import (ConnectionError, ConnectTimeout, ReadTimeout, SSLError,
                         ProxyError, RetryError, InvalidSchema, InvalidProxyURL,
                         InvalidURL, InvalidHeader)
from .auth import _basic_auth_str

try:
    from urllib3.contrib.socks import SOCKSProxyManager
except ImportError:
    def SOCKSProxyManager(*args, **kwargs):
        raise InvalidSchema("Missing dependencies for SOCKS support.")

DEFAULT_POOLBLOCK = False
DEFAULT_POOLSIZE = 10
DEFAULT_RETRIES = 0
DEFAULT_POOL_TIMEOUT = None


class BaseAdapter(object):
    """The Base Transport Adapter"""

    def __init__(self):
        super(BaseAdapter, self).__init__()

    def send(self, request, stream=False, timeout=None, verify=True,
             cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        """
        raise NotImplementedError

    def close(self):
        """Cleans up adapter specific items."""
        raise NotImplementedError


class HTTPAdapter(BaseAdapter):
    """The built-in HTTP Adapter for urllib3.

    Provides a general-case interface for Requests sessions to contact HTTP and
    HTTPS urls by implementing the Transport Adapter interface. This class will
    usually be created by the :class:`Session <Session>` class under the
    covers.

    :param pool_connections: The number of urllib3 connection pools to cache.
    :param pool_maxsize: The maximum number of connections to save in the pool.
    :param max_retries: The maximum number of retries each connection
        should attempt. Note, this applies only to failed DNS lookups, socket
        connections and connection timeouts, never to requests where data has
        made it to the server. By default, Requests does not retry failed
        connections. If you need granular control over the conditions under
        which we retry a request, import urllib3's ``Retry`` class and pass
        that instead.
    :param pool_block: Whether the connection pool should block for connections.

    Usage::

      >>> import requests
      >>> s = requests.Session()
      >>> a = requests.adapters.HTTPAdapter(max_retries=3)
      >>> s.mount('http://', a)
    """
    __attrs__ = ['max_retries', 'config', '_pool_connections', '_pool_maxsize',
                 '_pool_block']

    def __init__(self, pool_connections=DEFAULT_POOLSIZE,
                 pool_maxsize=DEFAULT_POOLSIZE, max_retries=DEFAULT_RETRIES,
                 pool_block=DEFAULT_POOLBLOCK):
        if max_retries == DEFAULT_RETRIES:
            self.max_retries = Retry(0, read=False)
        else:
            self.max_retries = Retry.from_int(max_retries)
        self.config = {}
        self.proxy_manager = {}

        super(HTTPAdapter, self).__init__()

        self._pool_connections = pool_connections
        self._pool_maxsize = pool_maxsize
        self._pool_block = pool_block

        self.init_poolmanager(pool_connections, pool_maxsize, block=pool_block)

    def __getstate__(self):
        return {attr: getattr(self, attr, None) for attr in self.__attrs__}

    def __setstate__(self, state):
        # Can't handle by adding 'proxy_manager' to self.__attrs__ because
        # self.poolmanager uses a lambda function, which isn't pickleable.
        self.proxy_manager = {}
        self.config = {}

        for attr, value in state.items():
            setattr(self, attr, value)

        self.init_poolmanager(self._pool_connections, self._pool_maxsize,
                              block=self._pool_block)

    def init_poolmanager(self, connections, maxsize, block=DEFAULT_POOLBLOCK, **pool_kwargs):
        """Initializes a urllib3 PoolManager.

        This method should not be called from user code, and is only
        exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param connections: The number of urllib3 connection pools to cache.
        :param maxsize: The maximum number of connections to save in the pool.
        :param block: Block when no free connections are available.
        :param pool_kwargs: Extra keyword arguments used to initialize the Pool Manager.
        """
        # save these values for pickling
        self._pool_connections = connections
        self._pool_maxsize = maxsize
        self._pool_block = block

        self.poolmanager = PoolManager(num_pools=connections, maxsize=maxsize,
                                       block=block, strict=True, **pool_kwargs)

    def proxy_manager_for(self, proxy, **proxy_kwargs):
        """Return urllib3 ProxyManager for the given proxy.

        This method should not be called from user code, and is only
        exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param proxy: The proxy to return a urllib3 ProxyManager for.
        :param proxy_kwargs: Extra keyword arguments used to configure the Proxy Manager.
        :returns: ProxyManager
        :rtype: urllib3.ProxyManager
        """
        if proxy in self.proxy_manager:
            manager = self.proxy_manager[proxy]
        elif proxy.lower().startswith('socks'):
            username, password = get_auth_from_url(proxy)
            manager = self.proxy_manager[proxy] = SOCKSProxyManager(
                proxy,
                username=username,
                password=password,
                num_pools=self._pool_connections,
                maxsize=self._pool_maxsize,
                block=self._pool_block,
                **proxy_kwargs
            )
        else:
            proxy_headers = self.proxy_headers(proxy)
            manager = self.proxy_manager[proxy] = proxy_from_url(
                proxy,
                proxy_headers=proxy_headers,
                num_pools=self._pool_connections,
                maxsize=self._pool_maxsize,
                block=self._pool_block,
                **proxy_kwargs)

        return manager

    def cert_verify(self, conn, url, verify, cert):
        """Verify a SSL certificate. This method should not be called from user
        code, and is only exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param conn: The urllib3 connection object associated with the cert.
        :param url: The requested URL.
        :param verify: Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use
        :param cert: The SSL certificate to verify.
        """
        if url.lower().startswith('https') and verify:

            cert_loc = None

            # Allow self-specified cert location.
            if verify is not True:
                cert_loc = verify

            if not cert_loc:
                cert_loc = extract_zipped_paths(DEFAULT_CA_BUNDLE_PATH)

            if not cert_loc or not os.path.exists(cert_loc):
                raise IOError("Could not find a suitable TLS CA certificate bundle, "
                              "invalid path: {}".format(cert_loc))

            conn.cert_reqs = 'CERT_REQUIRED'

            if not os.path.isdir(cert_loc):
                conn.ca_certs = cert_loc
            else:
                conn.ca_cert_dir = cert_loc
        else:
            conn.cert_reqs = 'CERT_NONE'
            conn.ca_certs = None
            conn.ca_cert_dir = None

        if cert:
            if not isinstance(cert, basestring):
                conn.cert_file = cert[0]
                conn.key_file = cert[1]
            else:
                conn.cert_file = cert
                conn.key_file = None
            if conn.cert_file and not os.path.exists(conn.cert_file):
                raise IOError("Could not find the TLS certificate file, "
                              "invalid path: {}".format(conn.cert_file))
            if conn.key_file and not os.path.exists(conn.key_file):
                raise IOError("Could not find the TLS key file, "
                              "invalid path: {}".format(conn.key_file))

    def build_response(self, req, resp):
        """Builds a :class:`Response <requests.Response>` object from a urllib3
        response. This should not be called from user code, and is only exposed
        for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`

        :param req: The :class:`PreparedRequest <PreparedRequest>` used to generate the response.
        :param resp: The urllib3 response object.
        :rtype: requests.Response
        """
        response = Response()

        # Fallback to None if there's no status_code, for whatever reason.
        response.status_code = getattr(resp, 'status', None)

        # Make headers case-insensitive.
        response.headers = CaseInsensitiveDict(getattr(resp, 'headers', {}))

        # Set encoding.
        response.encoding = get_encoding_from_headers(response.headers)
        response.raw = resp
        response.reason = response.raw.reason

        if isinstance(req.url, bytes):
            response.url = req.url.decode('utf-8')
        else:
            response.url = req.url

        # Add new cookies from the server.
        extract_cookies_to_jar(response.cookies, req, resp)

        # Give the Response some context.
        response.request = req
        response.connection = self

        return response

    def get_connection(self, url, proxies=None):
        """Returns a urllib3 connection for the given URL. This should not be
        called from user code, and is only exposed for use when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param url: The URL to connect to.
        :param proxies: (optional) A Requests-style dictionary of proxies used on this request.
        :rtype: urllib3.ConnectionPool
        """
        proxy = select_proxy(url, proxies)

        if proxy:
            proxy = prepend_scheme_if_needed(proxy, 'http')
            proxy_url = parse_url(proxy)
            if not proxy_url.host:
                raise InvalidProxyURL("Please check proxy URL. It is malformed"
                                      " and could be missing the host.")
            proxy_manager = self.proxy_manager_for(proxy)
            conn = proxy_manager.connection_from_url(url)
        else:
            # Only scheme should be lower case
            parsed = urlparse(url)
            url = parsed.geturl()
            conn = self.poolmanager.connection_from_url(url)

        return conn

    def close(self):
        """Disposes of any internal state.

        Currently, this closes the PoolManager and any active ProxyManager,
        which closes any pooled connections.
        """
        self.poolmanager.clear()
        for proxy in self.proxy_manager.values():
            proxy.clear()

    def request_url(self, request, proxies):
        """Obtain the url to use when making the final request.

        If the message is being sent through a HTTP proxy, the full URL has to
        be used. Otherwise, we should only use the path portion of the URL.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param proxies: A dictionary of schemes or schemes and hosts to proxy URLs.
        :rtype: str
        """
        proxy = select_proxy(request.url, proxies)
        scheme = urlparse(request.url).scheme

        is_proxied_http_request = (proxy and scheme != 'https')
        using_socks_proxy = False
        if proxy:
            proxy_scheme = urlparse(proxy).scheme.lower()
            using_socks_proxy = proxy_scheme.startswith('socks')

        url = request.path_url
        if is_proxied_http_request and not using_socks_proxy:
            url = urldefragauth(request.url)

        return url

    def add_headers(self, request, **kwargs):
        """Add any headers needed by the connection. As of v2.0 this does
        nothing by default, but is left for overriding by users that subclass
        the :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param request: The :class:`PreparedRequest <PreparedRequest>` to add headers to.
        :param kwargs: The keyword arguments from the call to send().
        """
        pass

    def proxy_headers(self, proxy):
        """Returns a dictionary of the headers to add to any request sent
        through a proxy. This works with urllib3 magic to ensure that they are
        correctly sent to the proxy, rather than in a tunnelled request if
        CONNECT is being used.

        This should not be called from user code, and is only exposed for use
        when subclassing the
        :class:`HTTPAdapter <requests.adapters.HTTPAdapter>`.

        :param proxy: The url of the proxy being used for this request.
        :rtype: dict
        """
        headers = {}
        username, password = get_auth_from_url(proxy)

        if username:
            headers['Proxy-Authorization'] = _basic_auth_str(username,
                                                             password)

        return headers

    def send(self, request, stream=False, timeout=None, verify=True, cert=None, proxies=None):
        """Sends PreparedRequest object. Returns Response object.

        :param request: The :class:`PreparedRequest <PreparedRequest>` being sent.
        :param stream: (optional) Whether to stream the request content.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple or urllib3 Timeout object
        :param verify: (optional) Either a boolean, in which case it controls whether
            we verify the server's TLS certificate, or a string, in which case it
            must be a path to a CA bundle to use
        :param cert: (optional) Any user-provided SSL certificate to be trusted.
        :param proxies: (optional) The proxies dictionary to apply to the request.
        :rtype: requests.Response
        """

        try:
            conn = self.get_connection(request.url, proxies)
        except LocationValueError as e:
            raise InvalidURL(e, request=request)

        self.cert_verify(conn, request.url, verify, cert)
        url = self.request_url(request, proxies)
        self.add_headers(request, stream=stream, timeout=timeout, verify=verify, cert=cert, proxies=proxies)

        chunked = not (request.body is None or 'Content-Length' in request.headers)

        if isinstance(timeout, tuple):
            try:
                connect, read = timeout
                timeout = TimeoutSauce(connect=connect, read=read)
            except ValueError as e:
                # this may raise a string formatting error.
                err = ("Invalid timeout {}. Pass a (connect, read) "
                       "timeout tuple, or a single float to set "
                       "both timeouts to the same value".format(timeout))
                raise ValueError(err)
        elif isinstance(timeout, TimeoutSauce):
            pass
        else:
            timeout = TimeoutSauce(connect=timeout, read=timeout)

        try:
            if not chunked:
                resp = conn.urlopen(
                    method=request.method,
                    url=url,
                    body=request.body,
                    headers=request.headers,
                    redirect=False,
                    assert_same_host=False,
                    preload_content=False,
                    decode_content=False,
                    retries=self.max_retries,
                    timeout=timeout
                )

            # Send the request.
            else:
                if hasattr(conn, 'proxy_pool'):
                    conn = conn.proxy_pool

                low_conn = conn._get_conn(timeout=DEFAULT_POOL_TIMEOUT)

                try:
                    skip_host = 'Host' in request.headers
                    low_conn.putrequest(request.method,
                                        url,
                                        skip_accept_encoding=True,
                                        skip_host=skip_host)

                    for header, value in request.headers.items():
                        low_conn.putheader(header, value)

                    low_conn.endheaders()

                    for i in request.body:
                        low_conn.send(hex(len(i))[2:].encode('utf-8'))
                        low_conn.send(b'\r\n')
                        low_conn.send(i)
                        low_conn.send(b'\r\n')
                    low_conn.send(b'0\r\n\r\n')

                    # Receive the response from the server
                    try:
                        # For Python 2.7, use buffering of HTTP responses
                        r = low_conn.getresponse(buffering=True)
                    except TypeError:
                        # For compatibility with Python 3.3+
                        r = low_conn.getresponse()

                    resp = HTTPResponse.from_httplib(
                        r,
                        pool=conn,
                        connection=low_conn,
                        preload_content=False,
                        decode_content=False
                    )
                except:
                    # If we hit any problems here, clean up the connection.
                    # Then, reraise so that we can handle the actual exception.
                    low_conn.close()
                    raise

        except (ProtocolError, socket.error) as err:
            raise ConnectionError(err, request=request)

        except MaxRetryError as e:
            if isinstance(e.reason, ConnectTimeoutError):
                # TODO: Remove this in 3.0.0: see #2811
                if not isinstance(e.reason, NewConnectionError):
                    raise ConnectTimeout(e, request=request)

            if isinstance(e.reason, ResponseError):
                raise RetryError(e, request=request)

            if isinstance(e.reason, _ProxyError):
                raise ProxyError(e, request=request)

            if isinstance(e.reason, _SSLError):
                # This branch is for urllib3 v1.22 and later.
                raise SSLError(e, request=request)

            raise ConnectionError(e, request=request)

        except ClosedPoolError as e:
            raise ConnectionError(e, request=request)

        except _ProxyError as e:
            raise ProxyError(e)

        except (_SSLError, _HTTPError) as e:
            if isinstance(e, _SSLError):
                # This branch is for urllib3 versions earlier than v1.22
                raise SSLError(e, request=request)
            elif isinstance(e, ReadTimeoutError):
                raise ReadTimeout(e, request=request)
            elif isinstance(e, _InvalidHeader):
                raise InvalidHeader(e, request=request)
            else:
                raise

        return self.build_response(request, resp)




############################################################
### File: aes.py
############################################################
# The MIT License (MIT)
#
# Copyright (c) 2014 Richard Moore
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.

# This is a pure-Python implementation of the AES algorithm and AES common
# modes of operation.

# See: https://en.wikipedia.org/wiki/Advanced_Encryption_Standard

# Honestly, the best description of the modes of operations are the wonderful
# diagrams on Wikipedia. They explain in moments what my words could never
# achieve. Hence the inline documentation here is sparer than I'd prefer.
# See: https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation

# Also useful, PyCrypto, a crypto library implemented in C with Python bindings:
# https://www.dlitz.net/software/pycrypto/


# Supported key sizes:
#   128-bit
#   192-bit
#   256-bit


# Supported modes of operation:
#   ECB - Electronic Codebook
#   CBC - Cipher-Block Chaining
#   CFB - Cipher Feedback
#   OFB - Output Feedback
#   CTR - Counter


# See the README.md for API details and general information.


import copy
import struct

__all__ = ["AES", "AESModeOfOperationCTR", "AESModeOfOperationCBC", "AESModeOfOperationCFB",
           "AESModeOfOperationECB", "AESModeOfOperationOFB", "AESModesOfOperation", "Counter"]


def _compact_word(word):
    return (word[0] << 24) | (word[1] << 16) | (word[2] << 8) | word[3]

def _string_to_bytes(text):
    return list(ord(c) for c in text)

def _bytes_to_string(binary):
    return "".join(chr(b) for b in binary)

def _concat_list(a, b):
    return a + b


# Python 3 compatibility
try:
    xrange
except Exception:
    xrange = range

    # Python 3 supports bytes, which is already an array of integers
    def _string_to_bytes(text):
        if isinstance(text, bytes):
            return text
        return [ord(c) for c in text]

    # In Python 3, we return bytes
    def _bytes_to_string(binary):
        return bytes(binary)

    # Python 3 cannot concatenate a list onto a bytes, so we bytes-ify it first
    def _concat_list(a, b):
        return a + bytes(b)


# Based *largely* on the Rijndael implementation
# See: http://csrc.nist.gov/publications/fips/fips197/fips-197.pdf
class AES(object):
    '''Encapsulates the AES block cipher.

    You generally should not need this. Use the AESModeOfOperation classes
    below instead.'''

    # Number of rounds by keysize
    number_of_rounds = {16: 10, 24: 12, 32: 14}

    # Round constant words
    rcon = [ 0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1b, 0x36, 0x6c, 0xd8, 0xab, 0x4d, 0x9a, 0x2f, 0x5e, 0xbc, 0x63, 0xc6, 0x97, 0x35, 0x6a, 0xd4, 0xb3, 0x7d, 0xfa, 0xef, 0xc5, 0x91 ]

    # S-box and Inverse S-box (S is for Substitution)
    S = [ 0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5, 0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76, 0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0, 0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0, 0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc, 0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15, 0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a, 0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75, 0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0, 0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84, 0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b, 0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf, 0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85, 0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8, 0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5, 0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2, 0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17, 0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73, 0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88, 0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb, 0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c, 0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79, 0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9, 0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08, 0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6, 0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a, 0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e, 0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e, 0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94, 0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf, 0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68, 0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16 ]
    Si =[ 0x52, 0x09, 0x6a, 0xd5, 0x30, 0x36, 0xa5, 0x38, 0xbf, 0x40, 0xa3, 0x9e, 0x81, 0xf3, 0xd7, 0xfb, 0x7c, 0xe3, 0x39, 0x82, 0x9b, 0x2f, 0xff, 0x87, 0x34, 0x8e, 0x43, 0x44, 0xc4, 0xde, 0xe9, 0xcb, 0x54, 0x7b, 0x94, 0x32, 0xa6, 0xc2, 0x23, 0x3d, 0xee, 0x4c, 0x95, 0x0b, 0x42, 0xfa, 0xc3, 0x4e, 0x08, 0x2e, 0xa1, 0x66, 0x28, 0xd9, 0x24, 0xb2, 0x76, 0x5b, 0xa2, 0x49, 0x6d, 0x8b, 0xd1, 0x25, 0x72, 0xf8, 0xf6, 0x64, 0x86, 0x68, 0x98, 0x16, 0xd4, 0xa4, 0x5c, 0xcc, 0x5d, 0x65, 0xb6, 0x92, 0x6c, 0x70, 0x48, 0x50, 0xfd, 0xed, 0xb9, 0xda, 0x5e, 0x15, 0x46, 0x57, 0xa7, 0x8d, 0x9d, 0x84, 0x90, 0xd8, 0xab, 0x00, 0x8c, 0xbc, 0xd3, 0x0a, 0xf7, 0xe4, 0x58, 0x05, 0xb8, 0xb3, 0x45, 0x06, 0xd0, 0x2c, 0x1e, 0x8f, 0xca, 0x3f, 0x0f, 0x02, 0xc1, 0xaf, 0xbd, 0x03, 0x01, 0x13, 0x8a, 0x6b, 0x3a, 0x91, 0x11, 0x41, 0x4f, 0x67, 0xdc, 0xea, 0x97, 0xf2, 0xcf, 0xce, 0xf0, 0xb4, 0xe6, 0x73, 0x96, 0xac, 0x74, 0x22, 0xe7, 0xad, 0x35, 0x85, 0xe2, 0xf9, 0x37, 0xe8, 0x1c, 0x75, 0xdf, 0x6e, 0x47, 0xf1, 0x1a, 0x71, 0x1d, 0x29, 0xc5, 0x89, 0x6f, 0xb7, 0x62, 0x0e, 0xaa, 0x18, 0xbe, 0x1b, 0xfc, 0x56, 0x3e, 0x4b, 0xc6, 0xd2, 0x79, 0x20, 0x9a, 0xdb, 0xc0, 0xfe, 0x78, 0xcd, 0x5a, 0xf4, 0x1f, 0xdd, 0xa8, 0x33, 0x88, 0x07, 0xc7, 0x31, 0xb1, 0x12, 0x10, 0x59, 0x27, 0x80, 0xec, 0x5f, 0x60, 0x51, 0x7f, 0xa9, 0x19, 0xb5, 0x4a, 0x0d, 0x2d, 0xe5, 0x7a, 0x9f, 0x93, 0xc9, 0x9c, 0xef, 0xa0, 0xe0, 0x3b, 0x4d, 0xae, 0x2a, 0xf5, 0xb0, 0xc8, 0xeb, 0xbb, 0x3c, 0x83, 0x53, 0x99, 0x61, 0x17, 0x2b, 0x04, 0x7e, 0xba, 0x77, 0xd6, 0x26, 0xe1, 0x69, 0x14, 0x63, 0x55, 0x21, 0x0c, 0x7d ] 

    # Transformations for encryption
    T1 = [ 0xc66363a5, 0xf87c7c84, 0xee777799, 0xf67b7b8d, 0xfff2f20d, 0xd66b6bbd, 0xde6f6fb1, 0x91c5c554, 0x60303050, 0x02010103, 0xce6767a9, 0x562b2b7d, 0xe7fefe19, 0xb5d7d762, 0x4dababe6, 0xec76769a, 0x8fcaca45, 0x1f82829d, 0x89c9c940, 0xfa7d7d87, 0xeffafa15, 0xb25959eb, 0x8e4747c9, 0xfbf0f00b, 0x41adadec, 0xb3d4d467, 0x5fa2a2fd, 0x45afafea, 0x239c9cbf, 0x53a4a4f7, 0xe4727296, 0x9bc0c05b, 0x75b7b7c2, 0xe1fdfd1c, 0x3d9393ae, 0x4c26266a, 0x6c36365a, 0x7e3f3f41, 0xf5f7f702, 0x83cccc4f, 0x6834345c, 0x51a5a5f4, 0xd1e5e534, 0xf9f1f108, 0xe2717193, 0xabd8d873, 0x62313153, 0x2a15153f, 0x0804040c, 0x95c7c752, 0x46232365, 0x9dc3c35e, 0x30181828, 0x379696a1, 0x0a05050f, 0x2f9a9ab5, 0x0e070709, 0x24121236, 0x1b80809b, 0xdfe2e23d, 0xcdebeb26, 0x4e272769, 0x7fb2b2cd, 0xea75759f, 0x1209091b, 0x1d83839e, 0x582c2c74, 0x341a1a2e, 0x361b1b2d, 0xdc6e6eb2, 0xb45a5aee, 0x5ba0a0fb, 0xa45252f6, 0x763b3b4d, 0xb7d6d661, 0x7db3b3ce, 0x5229297b, 0xdde3e33e, 0x5e2f2f71, 0x13848497, 0xa65353f5, 0xb9d1d168, 0x00000000, 0xc1eded2c, 0x40202060, 0xe3fcfc1f, 0x79b1b1c8, 0xb65b5bed, 0xd46a6abe, 0x8dcbcb46, 0x67bebed9, 0x7239394b, 0x944a4ade, 0x984c4cd4, 0xb05858e8, 0x85cfcf4a, 0xbbd0d06b, 0xc5efef2a, 0x4faaaae5, 0xedfbfb16, 0x864343c5, 0x9a4d4dd7, 0x66333355, 0x11858594, 0x8a4545cf, 0xe9f9f910, 0x04020206, 0xfe7f7f81, 0xa05050f0, 0x783c3c44, 0x259f9fba, 0x4ba8a8e3, 0xa25151f3, 0x5da3a3fe, 0x804040c0, 0x058f8f8a, 0x3f9292ad, 0x219d9dbc, 0x70383848, 0xf1f5f504, 0x63bcbcdf, 0x77b6b6c1, 0xafdada75, 0x42212163, 0x20101030, 0xe5ffff1a, 0xfdf3f30e, 0xbfd2d26d, 0x81cdcd4c, 0x180c0c14, 0x26131335, 0xc3ecec2f, 0xbe5f5fe1, 0x359797a2, 0x884444cc, 0x2e171739, 0x93c4c457, 0x55a7a7f2, 0xfc7e7e82, 0x7a3d3d47, 0xc86464ac, 0xba5d5de7, 0x3219192b, 0xe6737395, 0xc06060a0, 0x19818198, 0x9e4f4fd1, 0xa3dcdc7f, 0x44222266, 0x542a2a7e, 0x3b9090ab, 0x0b888883, 0x8c4646ca, 0xc7eeee29, 0x6bb8b8d3, 0x2814143c, 0xa7dede79, 0xbc5e5ee2, 0x160b0b1d, 0xaddbdb76, 0xdbe0e03b, 0x64323256, 0x743a3a4e, 0x140a0a1e, 0x924949db, 0x0c06060a, 0x4824246c, 0xb85c5ce4, 0x9fc2c25d, 0xbdd3d36e, 0x43acacef, 0xc46262a6, 0x399191a8, 0x319595a4, 0xd3e4e437, 0xf279798b, 0xd5e7e732, 0x8bc8c843, 0x6e373759, 0xda6d6db7, 0x018d8d8c, 0xb1d5d564, 0x9c4e4ed2, 0x49a9a9e0, 0xd86c6cb4, 0xac5656fa, 0xf3f4f407, 0xcfeaea25, 0xca6565af, 0xf47a7a8e, 0x47aeaee9, 0x10080818, 0x6fbabad5, 0xf0787888, 0x4a25256f, 0x5c2e2e72, 0x381c1c24, 0x57a6a6f1, 0x73b4b4c7, 0x97c6c651, 0xcbe8e823, 0xa1dddd7c, 0xe874749c, 0x3e1f1f21, 0x964b4bdd, 0x61bdbddc, 0x0d8b8b86, 0x0f8a8a85, 0xe0707090, 0x7c3e3e42, 0x71b5b5c4, 0xcc6666aa, 0x904848d8, 0x06030305, 0xf7f6f601, 0x1c0e0e12, 0xc26161a3, 0x6a35355f, 0xae5757f9, 0x69b9b9d0, 0x17868691, 0x99c1c158, 0x3a1d1d27, 0x279e9eb9, 0xd9e1e138, 0xebf8f813, 0x2b9898b3, 0x22111133, 0xd26969bb, 0xa9d9d970, 0x078e8e89, 0x339494a7, 0x2d9b9bb6, 0x3c1e1e22, 0x15878792, 0xc9e9e920, 0x87cece49, 0xaa5555ff, 0x50282878, 0xa5dfdf7a, 0x038c8c8f, 0x59a1a1f8, 0x09898980, 0x1a0d0d17, 0x65bfbfda, 0xd7e6e631, 0x844242c6, 0xd06868b8, 0x824141c3, 0x299999b0, 0x5a2d2d77, 0x1e0f0f11, 0x7bb0b0cb, 0xa85454fc, 0x6dbbbbd6, 0x2c16163a ]
    T2 = [ 0xa5c66363, 0x84f87c7c, 0x99ee7777, 0x8df67b7b, 0x0dfff2f2, 0xbdd66b6b, 0xb1de6f6f, 0x5491c5c5, 0x50603030, 0x03020101, 0xa9ce6767, 0x7d562b2b, 0x19e7fefe, 0x62b5d7d7, 0xe64dabab, 0x9aec7676, 0x458fcaca, 0x9d1f8282, 0x4089c9c9, 0x87fa7d7d, 0x15effafa, 0xebb25959, 0xc98e4747, 0x0bfbf0f0, 0xec41adad, 0x67b3d4d4, 0xfd5fa2a2, 0xea45afaf, 0xbf239c9c, 0xf753a4a4, 0x96e47272, 0x5b9bc0c0, 0xc275b7b7, 0x1ce1fdfd, 0xae3d9393, 0x6a4c2626, 0x5a6c3636, 0x417e3f3f, 0x02f5f7f7, 0x4f83cccc, 0x5c683434, 0xf451a5a5, 0x34d1e5e5, 0x08f9f1f1, 0x93e27171, 0x73abd8d8, 0x53623131, 0x3f2a1515, 0x0c080404, 0x5295c7c7, 0x65462323, 0x5e9dc3c3, 0x28301818, 0xa1379696, 0x0f0a0505, 0xb52f9a9a, 0x090e0707, 0x36241212, 0x9b1b8080, 0x3ddfe2e2, 0x26cdebeb, 0x694e2727, 0xcd7fb2b2, 0x9fea7575, 0x1b120909, 0x9e1d8383, 0x74582c2c, 0x2e341a1a, 0x2d361b1b, 0xb2dc6e6e, 0xeeb45a5a, 0xfb5ba0a0, 0xf6a45252, 0x4d763b3b, 0x61b7d6d6, 0xce7db3b3, 0x7b522929, 0x3edde3e3, 0x715e2f2f, 0x97138484, 0xf5a65353, 0x68b9d1d1, 0x00000000, 0x2cc1eded, 0x60402020, 0x1fe3fcfc, 0xc879b1b1, 0xedb65b5b, 0xbed46a6a, 0x468dcbcb, 0xd967bebe, 0x4b723939, 0xde944a4a, 0xd4984c4c, 0xe8b05858, 0x4a85cfcf, 0x6bbbd0d0, 0x2ac5efef, 0xe54faaaa, 0x16edfbfb, 0xc5864343, 0xd79a4d4d, 0x55663333, 0x94118585, 0xcf8a4545, 0x10e9f9f9, 0x06040202, 0x81fe7f7f, 0xf0a05050, 0x44783c3c, 0xba259f9f, 0xe34ba8a8, 0xf3a25151, 0xfe5da3a3, 0xc0804040, 0x8a058f8f, 0xad3f9292, 0xbc219d9d, 0x48703838, 0x04f1f5f5, 0xdf63bcbc, 0xc177b6b6, 0x75afdada, 0x63422121, 0x30201010, 0x1ae5ffff, 0x0efdf3f3, 0x6dbfd2d2, 0x4c81cdcd, 0x14180c0c, 0x35261313, 0x2fc3ecec, 0xe1be5f5f, 0xa2359797, 0xcc884444, 0x392e1717, 0x5793c4c4, 0xf255a7a7, 0x82fc7e7e, 0x477a3d3d, 0xacc86464, 0xe7ba5d5d, 0x2b321919, 0x95e67373, 0xa0c06060, 0x98198181, 0xd19e4f4f, 0x7fa3dcdc, 0x66442222, 0x7e542a2a, 0xab3b9090, 0x830b8888, 0xca8c4646, 0x29c7eeee, 0xd36bb8b8, 0x3c281414, 0x79a7dede, 0xe2bc5e5e, 0x1d160b0b, 0x76addbdb, 0x3bdbe0e0, 0x56643232, 0x4e743a3a, 0x1e140a0a, 0xdb924949, 0x0a0c0606, 0x6c482424, 0xe4b85c5c, 0x5d9fc2c2, 0x6ebdd3d3, 0xef43acac, 0xa6c46262, 0xa8399191, 0xa4319595, 0x37d3e4e4, 0x8bf27979, 0x32d5e7e7, 0x438bc8c8, 0x596e3737, 0xb7da6d6d, 0x8c018d8d, 0x64b1d5d5, 0xd29c4e4e, 0xe049a9a9, 0xb4d86c6c, 0xfaac5656, 0x07f3f4f4, 0x25cfeaea, 0xafca6565, 0x8ef47a7a, 0xe947aeae, 0x18100808, 0xd56fbaba, 0x88f07878, 0x6f4a2525, 0x725c2e2e, 0x24381c1c, 0xf157a6a6, 0xc773b4b4, 0x5197c6c6, 0x23cbe8e8, 0x7ca1dddd, 0x9ce87474, 0x213e1f1f, 0xdd964b4b, 0xdc61bdbd, 0x860d8b8b, 0x850f8a8a, 0x90e07070, 0x427c3e3e, 0xc471b5b5, 0xaacc6666, 0xd8904848, 0x05060303, 0x01f7f6f6, 0x121c0e0e, 0xa3c26161, 0x5f6a3535, 0xf9ae5757, 0xd069b9b9, 0x91178686, 0x5899c1c1, 0x273a1d1d, 0xb9279e9e, 0x38d9e1e1, 0x13ebf8f8, 0xb32b9898, 0x33221111, 0xbbd26969, 0x70a9d9d9, 0x89078e8e, 0xa7339494, 0xb62d9b9b, 0x223c1e1e, 0x92158787, 0x20c9e9e9, 0x4987cece, 0xffaa5555, 0x78502828, 0x7aa5dfdf, 0x8f038c8c, 0xf859a1a1, 0x80098989, 0x171a0d0d, 0xda65bfbf, 0x31d7e6e6, 0xc6844242, 0xb8d06868, 0xc3824141, 0xb0299999, 0x775a2d2d, 0x111e0f0f, 0xcb7bb0b0, 0xfca85454, 0xd66dbbbb, 0x3a2c1616 ]
    T3 = [ 0x63a5c663, 0x7c84f87c, 0x7799ee77, 0x7b8df67b, 0xf20dfff2, 0x6bbdd66b, 0x6fb1de6f, 0xc55491c5, 0x30506030, 0x01030201, 0x67a9ce67, 0x2b7d562b, 0xfe19e7fe, 0xd762b5d7, 0xabe64dab, 0x769aec76, 0xca458fca, 0x829d1f82, 0xc94089c9, 0x7d87fa7d, 0xfa15effa, 0x59ebb259, 0x47c98e47, 0xf00bfbf0, 0xadec41ad, 0xd467b3d4, 0xa2fd5fa2, 0xafea45af, 0x9cbf239c, 0xa4f753a4, 0x7296e472, 0xc05b9bc0, 0xb7c275b7, 0xfd1ce1fd, 0x93ae3d93, 0x266a4c26, 0x365a6c36, 0x3f417e3f, 0xf702f5f7, 0xcc4f83cc, 0x345c6834, 0xa5f451a5, 0xe534d1e5, 0xf108f9f1, 0x7193e271, 0xd873abd8, 0x31536231, 0x153f2a15, 0x040c0804, 0xc75295c7, 0x23654623, 0xc35e9dc3, 0x18283018, 0x96a13796, 0x050f0a05, 0x9ab52f9a, 0x07090e07, 0x12362412, 0x809b1b80, 0xe23ddfe2, 0xeb26cdeb, 0x27694e27, 0xb2cd7fb2, 0x759fea75, 0x091b1209, 0x839e1d83, 0x2c74582c, 0x1a2e341a, 0x1b2d361b, 0x6eb2dc6e, 0x5aeeb45a, 0xa0fb5ba0, 0x52f6a452, 0x3b4d763b, 0xd661b7d6, 0xb3ce7db3, 0x297b5229, 0xe33edde3, 0x2f715e2f, 0x84971384, 0x53f5a653, 0xd168b9d1, 0x00000000, 0xed2cc1ed, 0x20604020, 0xfc1fe3fc, 0xb1c879b1, 0x5bedb65b, 0x6abed46a, 0xcb468dcb, 0xbed967be, 0x394b7239, 0x4ade944a, 0x4cd4984c, 0x58e8b058, 0xcf4a85cf, 0xd06bbbd0, 0xef2ac5ef, 0xaae54faa, 0xfb16edfb, 0x43c58643, 0x4dd79a4d, 0x33556633, 0x85941185, 0x45cf8a45, 0xf910e9f9, 0x02060402, 0x7f81fe7f, 0x50f0a050, 0x3c44783c, 0x9fba259f, 0xa8e34ba8, 0x51f3a251, 0xa3fe5da3, 0x40c08040, 0x8f8a058f, 0x92ad3f92, 0x9dbc219d, 0x38487038, 0xf504f1f5, 0xbcdf63bc, 0xb6c177b6, 0xda75afda, 0x21634221, 0x10302010, 0xff1ae5ff, 0xf30efdf3, 0xd26dbfd2, 0xcd4c81cd, 0x0c14180c, 0x13352613, 0xec2fc3ec, 0x5fe1be5f, 0x97a23597, 0x44cc8844, 0x17392e17, 0xc45793c4, 0xa7f255a7, 0x7e82fc7e, 0x3d477a3d, 0x64acc864, 0x5de7ba5d, 0x192b3219, 0x7395e673, 0x60a0c060, 0x81981981, 0x4fd19e4f, 0xdc7fa3dc, 0x22664422, 0x2a7e542a, 0x90ab3b90, 0x88830b88, 0x46ca8c46, 0xee29c7ee, 0xb8d36bb8, 0x143c2814, 0xde79a7de, 0x5ee2bc5e, 0x0b1d160b, 0xdb76addb, 0xe03bdbe0, 0x32566432, 0x3a4e743a, 0x0a1e140a, 0x49db9249, 0x060a0c06, 0x246c4824, 0x5ce4b85c, 0xc25d9fc2, 0xd36ebdd3, 0xacef43ac, 0x62a6c462, 0x91a83991, 0x95a43195, 0xe437d3e4, 0x798bf279, 0xe732d5e7, 0xc8438bc8, 0x37596e37, 0x6db7da6d, 0x8d8c018d, 0xd564b1d5, 0x4ed29c4e, 0xa9e049a9, 0x6cb4d86c, 0x56faac56, 0xf407f3f4, 0xea25cfea, 0x65afca65, 0x7a8ef47a, 0xaee947ae, 0x08181008, 0xbad56fba, 0x7888f078, 0x256f4a25, 0x2e725c2e, 0x1c24381c, 0xa6f157a6, 0xb4c773b4, 0xc65197c6, 0xe823cbe8, 0xdd7ca1dd, 0x749ce874, 0x1f213e1f, 0x4bdd964b, 0xbddc61bd, 0x8b860d8b, 0x8a850f8a, 0x7090e070, 0x3e427c3e, 0xb5c471b5, 0x66aacc66, 0x48d89048, 0x03050603, 0xf601f7f6, 0x0e121c0e, 0x61a3c261, 0x355f6a35, 0x57f9ae57, 0xb9d069b9, 0x86911786, 0xc15899c1, 0x1d273a1d, 0x9eb9279e, 0xe138d9e1, 0xf813ebf8, 0x98b32b98, 0x11332211, 0x69bbd269, 0xd970a9d9, 0x8e89078e, 0x94a73394, 0x9bb62d9b, 0x1e223c1e, 0x87921587, 0xe920c9e9, 0xce4987ce, 0x55ffaa55, 0x28785028, 0xdf7aa5df, 0x8c8f038c, 0xa1f859a1, 0x89800989, 0x0d171a0d, 0xbfda65bf, 0xe631d7e6, 0x42c68442, 0x68b8d068, 0x41c38241, 0x99b02999, 0x2d775a2d, 0x0f111e0f, 0xb0cb7bb0, 0x54fca854, 0xbbd66dbb, 0x163a2c16 ]
    T4 = [ 0x6363a5c6, 0x7c7c84f8, 0x777799ee, 0x7b7b8df6, 0xf2f20dff, 0x6b6bbdd6, 0x6f6fb1de, 0xc5c55491, 0x30305060, 0x01010302, 0x6767a9ce, 0x2b2b7d56, 0xfefe19e7, 0xd7d762b5, 0xababe64d, 0x76769aec, 0xcaca458f, 0x82829d1f, 0xc9c94089, 0x7d7d87fa, 0xfafa15ef, 0x5959ebb2, 0x4747c98e, 0xf0f00bfb, 0xadadec41, 0xd4d467b3, 0xa2a2fd5f, 0xafafea45, 0x9c9cbf23, 0xa4a4f753, 0x727296e4, 0xc0c05b9b, 0xb7b7c275, 0xfdfd1ce1, 0x9393ae3d, 0x26266a4c, 0x36365a6c, 0x3f3f417e, 0xf7f702f5, 0xcccc4f83, 0x34345c68, 0xa5a5f451, 0xe5e534d1, 0xf1f108f9, 0x717193e2, 0xd8d873ab, 0x31315362, 0x15153f2a, 0x04040c08, 0xc7c75295, 0x23236546, 0xc3c35e9d, 0x18182830, 0x9696a137, 0x05050f0a, 0x9a9ab52f, 0x0707090e, 0x12123624, 0x80809b1b, 0xe2e23ddf, 0xebeb26cd, 0x2727694e, 0xb2b2cd7f, 0x75759fea, 0x09091b12, 0x83839e1d, 0x2c2c7458, 0x1a1a2e34, 0x1b1b2d36, 0x6e6eb2dc, 0x5a5aeeb4, 0xa0a0fb5b, 0x5252f6a4, 0x3b3b4d76, 0xd6d661b7, 0xb3b3ce7d, 0x29297b52, 0xe3e33edd, 0x2f2f715e, 0x84849713, 0x5353f5a6, 0xd1d168b9, 0x00000000, 0xeded2cc1, 0x20206040, 0xfcfc1fe3, 0xb1b1c879, 0x5b5bedb6, 0x6a6abed4, 0xcbcb468d, 0xbebed967, 0x39394b72, 0x4a4ade94, 0x4c4cd498, 0x5858e8b0, 0xcfcf4a85, 0xd0d06bbb, 0xefef2ac5, 0xaaaae54f, 0xfbfb16ed, 0x4343c586, 0x4d4dd79a, 0x33335566, 0x85859411, 0x4545cf8a, 0xf9f910e9, 0x02020604, 0x7f7f81fe, 0x5050f0a0, 0x3c3c4478, 0x9f9fba25, 0xa8a8e34b, 0x5151f3a2, 0xa3a3fe5d, 0x4040c080, 0x8f8f8a05, 0x9292ad3f, 0x9d9dbc21, 0x38384870, 0xf5f504f1, 0xbcbcdf63, 0xb6b6c177, 0xdada75af, 0x21216342, 0x10103020, 0xffff1ae5, 0xf3f30efd, 0xd2d26dbf, 0xcdcd4c81, 0x0c0c1418, 0x13133526, 0xecec2fc3, 0x5f5fe1be, 0x9797a235, 0x4444cc88, 0x1717392e, 0xc4c45793, 0xa7a7f255, 0x7e7e82fc, 0x3d3d477a, 0x6464acc8, 0x5d5de7ba, 0x19192b32, 0x737395e6, 0x6060a0c0, 0x81819819, 0x4f4fd19e, 0xdcdc7fa3, 0x22226644, 0x2a2a7e54, 0x9090ab3b, 0x8888830b, 0x4646ca8c, 0xeeee29c7, 0xb8b8d36b, 0x14143c28, 0xdede79a7, 0x5e5ee2bc, 0x0b0b1d16, 0xdbdb76ad, 0xe0e03bdb, 0x32325664, 0x3a3a4e74, 0x0a0a1e14, 0x4949db92, 0x06060a0c, 0x24246c48, 0x5c5ce4b8, 0xc2c25d9f, 0xd3d36ebd, 0xacacef43, 0x6262a6c4, 0x9191a839, 0x9595a431, 0xe4e437d3, 0x79798bf2, 0xe7e732d5, 0xc8c8438b, 0x3737596e, 0x6d6db7da, 0x8d8d8c01, 0xd5d564b1, 0x4e4ed29c, 0xa9a9e049, 0x6c6cb4d8, 0x5656faac, 0xf4f407f3, 0xeaea25cf, 0x6565afca, 0x7a7a8ef4, 0xaeaee947, 0x08081810, 0xbabad56f, 0x787888f0, 0x25256f4a, 0x2e2e725c, 0x1c1c2438, 0xa6a6f157, 0xb4b4c773, 0xc6c65197, 0xe8e823cb, 0xdddd7ca1, 0x74749ce8, 0x1f1f213e, 0x4b4bdd96, 0xbdbddc61, 0x8b8b860d, 0x8a8a850f, 0x707090e0, 0x3e3e427c, 0xb5b5c471, 0x6666aacc, 0x4848d890, 0x03030506, 0xf6f601f7, 0x0e0e121c, 0x6161a3c2, 0x35355f6a, 0x5757f9ae, 0xb9b9d069, 0x86869117, 0xc1c15899, 0x1d1d273a, 0x9e9eb927, 0xe1e138d9, 0xf8f813eb, 0x9898b32b, 0x11113322, 0x6969bbd2, 0xd9d970a9, 0x8e8e8907, 0x9494a733, 0x9b9bb62d, 0x1e1e223c, 0x87879215, 0xe9e920c9, 0xcece4987, 0x5555ffaa, 0x28287850, 0xdfdf7aa5, 0x8c8c8f03, 0xa1a1f859, 0x89898009, 0x0d0d171a, 0xbfbfda65, 0xe6e631d7, 0x4242c684, 0x6868b8d0, 0x4141c382, 0x9999b029, 0x2d2d775a, 0x0f0f111e, 0xb0b0cb7b, 0x5454fca8, 0xbbbbd66d, 0x16163a2c ]

    # Transformations for decryption
    T5 = [ 0x51f4a750, 0x7e416553, 0x1a17a4c3, 0x3a275e96, 0x3bab6bcb, 0x1f9d45f1, 0xacfa58ab, 0x4be30393, 0x2030fa55, 0xad766df6, 0x88cc7691, 0xf5024c25, 0x4fe5d7fc, 0xc52acbd7, 0x26354480, 0xb562a38f, 0xdeb15a49, 0x25ba1b67, 0x45ea0e98, 0x5dfec0e1, 0xc32f7502, 0x814cf012, 0x8d4697a3, 0x6bd3f9c6, 0x038f5fe7, 0x15929c95, 0xbf6d7aeb, 0x955259da, 0xd4be832d, 0x587421d3, 0x49e06929, 0x8ec9c844, 0x75c2896a, 0xf48e7978, 0x99583e6b, 0x27b971dd, 0xbee14fb6, 0xf088ad17, 0xc920ac66, 0x7dce3ab4, 0x63df4a18, 0xe51a3182, 0x97513360, 0x62537f45, 0xb16477e0, 0xbb6bae84, 0xfe81a01c, 0xf9082b94, 0x70486858, 0x8f45fd19, 0x94de6c87, 0x527bf8b7, 0xab73d323, 0x724b02e2, 0xe31f8f57, 0x6655ab2a, 0xb2eb2807, 0x2fb5c203, 0x86c57b9a, 0xd33708a5, 0x302887f2, 0x23bfa5b2, 0x02036aba, 0xed16825c, 0x8acf1c2b, 0xa779b492, 0xf307f2f0, 0x4e69e2a1, 0x65daf4cd, 0x0605bed5, 0xd134621f, 0xc4a6fe8a, 0x342e539d, 0xa2f355a0, 0x058ae132, 0xa4f6eb75, 0x0b83ec39, 0x4060efaa, 0x5e719f06, 0xbd6e1051, 0x3e218af9, 0x96dd063d, 0xdd3e05ae, 0x4de6bd46, 0x91548db5, 0x71c45d05, 0x0406d46f, 0x605015ff, 0x1998fb24, 0xd6bde997, 0x894043cc, 0x67d99e77, 0xb0e842bd, 0x07898b88, 0xe7195b38, 0x79c8eedb, 0xa17c0a47, 0x7c420fe9, 0xf8841ec9, 0x00000000, 0x09808683, 0x322bed48, 0x1e1170ac, 0x6c5a724e, 0xfd0efffb, 0x0f853856, 0x3daed51e, 0x362d3927, 0x0a0fd964, 0x685ca621, 0x9b5b54d1, 0x24362e3a, 0x0c0a67b1, 0x9357e70f, 0xb4ee96d2, 0x1b9b919e, 0x80c0c54f, 0x61dc20a2, 0x5a774b69, 0x1c121a16, 0xe293ba0a, 0xc0a02ae5, 0x3c22e043, 0x121b171d, 0x0e090d0b, 0xf28bc7ad, 0x2db6a8b9, 0x141ea9c8, 0x57f11985, 0xaf75074c, 0xee99ddbb, 0xa37f60fd, 0xf701269f, 0x5c72f5bc, 0x44663bc5, 0x5bfb7e34, 0x8b432976, 0xcb23c6dc, 0xb6edfc68, 0xb8e4f163, 0xd731dcca, 0x42638510, 0x13972240, 0x84c61120, 0x854a247d, 0xd2bb3df8, 0xaef93211, 0xc729a16d, 0x1d9e2f4b, 0xdcb230f3, 0x0d8652ec, 0x77c1e3d0, 0x2bb3166c, 0xa970b999, 0x119448fa, 0x47e96422, 0xa8fc8cc4, 0xa0f03f1a, 0x567d2cd8, 0x223390ef, 0x87494ec7, 0xd938d1c1, 0x8ccaa2fe, 0x98d40b36, 0xa6f581cf, 0xa57ade28, 0xdab78e26, 0x3fadbfa4, 0x2c3a9de4, 0x5078920d, 0x6a5fcc9b, 0x547e4662, 0xf68d13c2, 0x90d8b8e8, 0x2e39f75e, 0x82c3aff5, 0x9f5d80be, 0x69d0937c, 0x6fd52da9, 0xcf2512b3, 0xc8ac993b, 0x10187da7, 0xe89c636e, 0xdb3bbb7b, 0xcd267809, 0x6e5918f4, 0xec9ab701, 0x834f9aa8, 0xe6956e65, 0xaaffe67e, 0x21bccf08, 0xef15e8e6, 0xbae79bd9, 0x4a6f36ce, 0xea9f09d4, 0x29b07cd6, 0x31a4b2af, 0x2a3f2331, 0xc6a59430, 0x35a266c0, 0x744ebc37, 0xfc82caa6, 0xe090d0b0, 0x33a7d815, 0xf104984a, 0x41ecdaf7, 0x7fcd500e, 0x1791f62f, 0x764dd68d, 0x43efb04d, 0xccaa4d54, 0xe49604df, 0x9ed1b5e3, 0x4c6a881b, 0xc12c1fb8, 0x4665517f, 0x9d5eea04, 0x018c355d, 0xfa877473, 0xfb0b412e, 0xb3671d5a, 0x92dbd252, 0xe9105633, 0x6dd64713, 0x9ad7618c, 0x37a10c7a, 0x59f8148e, 0xeb133c89, 0xcea927ee, 0xb761c935, 0xe11ce5ed, 0x7a47b13c, 0x9cd2df59, 0x55f2733f, 0x1814ce79, 0x73c737bf, 0x53f7cdea, 0x5ffdaa5b, 0xdf3d6f14, 0x7844db86, 0xcaaff381, 0xb968c43e, 0x3824342c, 0xc2a3405f, 0x161dc372, 0xbce2250c, 0x283c498b, 0xff0d9541, 0x39a80171, 0x080cb3de, 0xd8b4e49c, 0x6456c190, 0x7bcb8461, 0xd532b670, 0x486c5c74, 0xd0b85742 ]
    T6 = [ 0x5051f4a7, 0x537e4165, 0xc31a17a4, 0x963a275e, 0xcb3bab6b, 0xf11f9d45, 0xabacfa58, 0x934be303, 0x552030fa, 0xf6ad766d, 0x9188cc76, 0x25f5024c, 0xfc4fe5d7, 0xd7c52acb, 0x80263544, 0x8fb562a3, 0x49deb15a, 0x6725ba1b, 0x9845ea0e, 0xe15dfec0, 0x02c32f75, 0x12814cf0, 0xa38d4697, 0xc66bd3f9, 0xe7038f5f, 0x9515929c, 0xebbf6d7a, 0xda955259, 0x2dd4be83, 0xd3587421, 0x2949e069, 0x448ec9c8, 0x6a75c289, 0x78f48e79, 0x6b99583e, 0xdd27b971, 0xb6bee14f, 0x17f088ad, 0x66c920ac, 0xb47dce3a, 0x1863df4a, 0x82e51a31, 0x60975133, 0x4562537f, 0xe0b16477, 0x84bb6bae, 0x1cfe81a0, 0x94f9082b, 0x58704868, 0x198f45fd, 0x8794de6c, 0xb7527bf8, 0x23ab73d3, 0xe2724b02, 0x57e31f8f, 0x2a6655ab, 0x07b2eb28, 0x032fb5c2, 0x9a86c57b, 0xa5d33708, 0xf2302887, 0xb223bfa5, 0xba02036a, 0x5ced1682, 0x2b8acf1c, 0x92a779b4, 0xf0f307f2, 0xa14e69e2, 0xcd65daf4, 0xd50605be, 0x1fd13462, 0x8ac4a6fe, 0x9d342e53, 0xa0a2f355, 0x32058ae1, 0x75a4f6eb, 0x390b83ec, 0xaa4060ef, 0x065e719f, 0x51bd6e10, 0xf93e218a, 0x3d96dd06, 0xaedd3e05, 0x464de6bd, 0xb591548d, 0x0571c45d, 0x6f0406d4, 0xff605015, 0x241998fb, 0x97d6bde9, 0xcc894043, 0x7767d99e, 0xbdb0e842, 0x8807898b, 0x38e7195b, 0xdb79c8ee, 0x47a17c0a, 0xe97c420f, 0xc9f8841e, 0x00000000, 0x83098086, 0x48322bed, 0xac1e1170, 0x4e6c5a72, 0xfbfd0eff, 0x560f8538, 0x1e3daed5, 0x27362d39, 0x640a0fd9, 0x21685ca6, 0xd19b5b54, 0x3a24362e, 0xb10c0a67, 0x0f9357e7, 0xd2b4ee96, 0x9e1b9b91, 0x4f80c0c5, 0xa261dc20, 0x695a774b, 0x161c121a, 0x0ae293ba, 0xe5c0a02a, 0x433c22e0, 0x1d121b17, 0x0b0e090d, 0xadf28bc7, 0xb92db6a8, 0xc8141ea9, 0x8557f119, 0x4caf7507, 0xbbee99dd, 0xfda37f60, 0x9ff70126, 0xbc5c72f5, 0xc544663b, 0x345bfb7e, 0x768b4329, 0xdccb23c6, 0x68b6edfc, 0x63b8e4f1, 0xcad731dc, 0x10426385, 0x40139722, 0x2084c611, 0x7d854a24, 0xf8d2bb3d, 0x11aef932, 0x6dc729a1, 0x4b1d9e2f, 0xf3dcb230, 0xec0d8652, 0xd077c1e3, 0x6c2bb316, 0x99a970b9, 0xfa119448, 0x2247e964, 0xc4a8fc8c, 0x1aa0f03f, 0xd8567d2c, 0xef223390, 0xc787494e, 0xc1d938d1, 0xfe8ccaa2, 0x3698d40b, 0xcfa6f581, 0x28a57ade, 0x26dab78e, 0xa43fadbf, 0xe42c3a9d, 0x0d507892, 0x9b6a5fcc, 0x62547e46, 0xc2f68d13, 0xe890d8b8, 0x5e2e39f7, 0xf582c3af, 0xbe9f5d80, 0x7c69d093, 0xa96fd52d, 0xb3cf2512, 0x3bc8ac99, 0xa710187d, 0x6ee89c63, 0x7bdb3bbb, 0x09cd2678, 0xf46e5918, 0x01ec9ab7, 0xa8834f9a, 0x65e6956e, 0x7eaaffe6, 0x0821bccf, 0xe6ef15e8, 0xd9bae79b, 0xce4a6f36, 0xd4ea9f09, 0xd629b07c, 0xaf31a4b2, 0x312a3f23, 0x30c6a594, 0xc035a266, 0x37744ebc, 0xa6fc82ca, 0xb0e090d0, 0x1533a7d8, 0x4af10498, 0xf741ecda, 0x0e7fcd50, 0x2f1791f6, 0x8d764dd6, 0x4d43efb0, 0x54ccaa4d, 0xdfe49604, 0xe39ed1b5, 0x1b4c6a88, 0xb8c12c1f, 0x7f466551, 0x049d5eea, 0x5d018c35, 0x73fa8774, 0x2efb0b41, 0x5ab3671d, 0x5292dbd2, 0x33e91056, 0x136dd647, 0x8c9ad761, 0x7a37a10c, 0x8e59f814, 0x89eb133c, 0xeecea927, 0x35b761c9, 0xede11ce5, 0x3c7a47b1, 0x599cd2df, 0x3f55f273, 0x791814ce, 0xbf73c737, 0xea53f7cd, 0x5b5ffdaa, 0x14df3d6f, 0x867844db, 0x81caaff3, 0x3eb968c4, 0x2c382434, 0x5fc2a340, 0x72161dc3, 0x0cbce225, 0x8b283c49, 0x41ff0d95, 0x7139a801, 0xde080cb3, 0x9cd8b4e4, 0x906456c1, 0x617bcb84, 0x70d532b6, 0x74486c5c, 0x42d0b857 ]
    T7 = [ 0xa75051f4, 0x65537e41, 0xa4c31a17, 0x5e963a27, 0x6bcb3bab, 0x45f11f9d, 0x58abacfa, 0x03934be3, 0xfa552030, 0x6df6ad76, 0x769188cc, 0x4c25f502, 0xd7fc4fe5, 0xcbd7c52a, 0x44802635, 0xa38fb562, 0x5a49deb1, 0x1b6725ba, 0x0e9845ea, 0xc0e15dfe, 0x7502c32f, 0xf012814c, 0x97a38d46, 0xf9c66bd3, 0x5fe7038f, 0x9c951592, 0x7aebbf6d, 0x59da9552, 0x832dd4be, 0x21d35874, 0x692949e0, 0xc8448ec9, 0x896a75c2, 0x7978f48e, 0x3e6b9958, 0x71dd27b9, 0x4fb6bee1, 0xad17f088, 0xac66c920, 0x3ab47dce, 0x4a1863df, 0x3182e51a, 0x33609751, 0x7f456253, 0x77e0b164, 0xae84bb6b, 0xa01cfe81, 0x2b94f908, 0x68587048, 0xfd198f45, 0x6c8794de, 0xf8b7527b, 0xd323ab73, 0x02e2724b, 0x8f57e31f, 0xab2a6655, 0x2807b2eb, 0xc2032fb5, 0x7b9a86c5, 0x08a5d337, 0x87f23028, 0xa5b223bf, 0x6aba0203, 0x825ced16, 0x1c2b8acf, 0xb492a779, 0xf2f0f307, 0xe2a14e69, 0xf4cd65da, 0xbed50605, 0x621fd134, 0xfe8ac4a6, 0x539d342e, 0x55a0a2f3, 0xe132058a, 0xeb75a4f6, 0xec390b83, 0xefaa4060, 0x9f065e71, 0x1051bd6e, 0x8af93e21, 0x063d96dd, 0x05aedd3e, 0xbd464de6, 0x8db59154, 0x5d0571c4, 0xd46f0406, 0x15ff6050, 0xfb241998, 0xe997d6bd, 0x43cc8940, 0x9e7767d9, 0x42bdb0e8, 0x8b880789, 0x5b38e719, 0xeedb79c8, 0x0a47a17c, 0x0fe97c42, 0x1ec9f884, 0x00000000, 0x86830980, 0xed48322b, 0x70ac1e11, 0x724e6c5a, 0xfffbfd0e, 0x38560f85, 0xd51e3dae, 0x3927362d, 0xd9640a0f, 0xa621685c, 0x54d19b5b, 0x2e3a2436, 0x67b10c0a, 0xe70f9357, 0x96d2b4ee, 0x919e1b9b, 0xc54f80c0, 0x20a261dc, 0x4b695a77, 0x1a161c12, 0xba0ae293, 0x2ae5c0a0, 0xe0433c22, 0x171d121b, 0x0d0b0e09, 0xc7adf28b, 0xa8b92db6, 0xa9c8141e, 0x198557f1, 0x074caf75, 0xddbbee99, 0x60fda37f, 0x269ff701, 0xf5bc5c72, 0x3bc54466, 0x7e345bfb, 0x29768b43, 0xc6dccb23, 0xfc68b6ed, 0xf163b8e4, 0xdccad731, 0x85104263, 0x22401397, 0x112084c6, 0x247d854a, 0x3df8d2bb, 0x3211aef9, 0xa16dc729, 0x2f4b1d9e, 0x30f3dcb2, 0x52ec0d86, 0xe3d077c1, 0x166c2bb3, 0xb999a970, 0x48fa1194, 0x642247e9, 0x8cc4a8fc, 0x3f1aa0f0, 0x2cd8567d, 0x90ef2233, 0x4ec78749, 0xd1c1d938, 0xa2fe8cca, 0x0b3698d4, 0x81cfa6f5, 0xde28a57a, 0x8e26dab7, 0xbfa43fad, 0x9de42c3a, 0x920d5078, 0xcc9b6a5f, 0x4662547e, 0x13c2f68d, 0xb8e890d8, 0xf75e2e39, 0xaff582c3, 0x80be9f5d, 0x937c69d0, 0x2da96fd5, 0x12b3cf25, 0x993bc8ac, 0x7da71018, 0x636ee89c, 0xbb7bdb3b, 0x7809cd26, 0x18f46e59, 0xb701ec9a, 0x9aa8834f, 0x6e65e695, 0xe67eaaff, 0xcf0821bc, 0xe8e6ef15, 0x9bd9bae7, 0x36ce4a6f, 0x09d4ea9f, 0x7cd629b0, 0xb2af31a4, 0x23312a3f, 0x9430c6a5, 0x66c035a2, 0xbc37744e, 0xcaa6fc82, 0xd0b0e090, 0xd81533a7, 0x984af104, 0xdaf741ec, 0x500e7fcd, 0xf62f1791, 0xd68d764d, 0xb04d43ef, 0x4d54ccaa, 0x04dfe496, 0xb5e39ed1, 0x881b4c6a, 0x1fb8c12c, 0x517f4665, 0xea049d5e, 0x355d018c, 0x7473fa87, 0x412efb0b, 0x1d5ab367, 0xd25292db, 0x5633e910, 0x47136dd6, 0x618c9ad7, 0x0c7a37a1, 0x148e59f8, 0x3c89eb13, 0x27eecea9, 0xc935b761, 0xe5ede11c, 0xb13c7a47, 0xdf599cd2, 0x733f55f2, 0xce791814, 0x37bf73c7, 0xcdea53f7, 0xaa5b5ffd, 0x6f14df3d, 0xdb867844, 0xf381caaf, 0xc43eb968, 0x342c3824, 0x405fc2a3, 0xc372161d, 0x250cbce2, 0x498b283c, 0x9541ff0d, 0x017139a8, 0xb3de080c, 0xe49cd8b4, 0xc1906456, 0x84617bcb, 0xb670d532, 0x5c74486c, 0x5742d0b8 ]
    T8 = [ 0xf4a75051, 0x4165537e, 0x17a4c31a, 0x275e963a, 0xab6bcb3b, 0x9d45f11f, 0xfa58abac, 0xe303934b, 0x30fa5520, 0x766df6ad, 0xcc769188, 0x024c25f5, 0xe5d7fc4f, 0x2acbd7c5, 0x35448026, 0x62a38fb5, 0xb15a49de, 0xba1b6725, 0xea0e9845, 0xfec0e15d, 0x2f7502c3, 0x4cf01281, 0x4697a38d, 0xd3f9c66b, 0x8f5fe703, 0x929c9515, 0x6d7aebbf, 0x5259da95, 0xbe832dd4, 0x7421d358, 0xe0692949, 0xc9c8448e, 0xc2896a75, 0x8e7978f4, 0x583e6b99, 0xb971dd27, 0xe14fb6be, 0x88ad17f0, 0x20ac66c9, 0xce3ab47d, 0xdf4a1863, 0x1a3182e5, 0x51336097, 0x537f4562, 0x6477e0b1, 0x6bae84bb, 0x81a01cfe, 0x082b94f9, 0x48685870, 0x45fd198f, 0xde6c8794, 0x7bf8b752, 0x73d323ab, 0x4b02e272, 0x1f8f57e3, 0x55ab2a66, 0xeb2807b2, 0xb5c2032f, 0xc57b9a86, 0x3708a5d3, 0x2887f230, 0xbfa5b223, 0x036aba02, 0x16825ced, 0xcf1c2b8a, 0x79b492a7, 0x07f2f0f3, 0x69e2a14e, 0xdaf4cd65, 0x05bed506, 0x34621fd1, 0xa6fe8ac4, 0x2e539d34, 0xf355a0a2, 0x8ae13205, 0xf6eb75a4, 0x83ec390b, 0x60efaa40, 0x719f065e, 0x6e1051bd, 0x218af93e, 0xdd063d96, 0x3e05aedd, 0xe6bd464d, 0x548db591, 0xc45d0571, 0x06d46f04, 0x5015ff60, 0x98fb2419, 0xbde997d6, 0x4043cc89, 0xd99e7767, 0xe842bdb0, 0x898b8807, 0x195b38e7, 0xc8eedb79, 0x7c0a47a1, 0x420fe97c, 0x841ec9f8, 0x00000000, 0x80868309, 0x2bed4832, 0x1170ac1e, 0x5a724e6c, 0x0efffbfd, 0x8538560f, 0xaed51e3d, 0x2d392736, 0x0fd9640a, 0x5ca62168, 0x5b54d19b, 0x362e3a24, 0x0a67b10c, 0x57e70f93, 0xee96d2b4, 0x9b919e1b, 0xc0c54f80, 0xdc20a261, 0x774b695a, 0x121a161c, 0x93ba0ae2, 0xa02ae5c0, 0x22e0433c, 0x1b171d12, 0x090d0b0e, 0x8bc7adf2, 0xb6a8b92d, 0x1ea9c814, 0xf1198557, 0x75074caf, 0x99ddbbee, 0x7f60fda3, 0x01269ff7, 0x72f5bc5c, 0x663bc544, 0xfb7e345b, 0x4329768b, 0x23c6dccb, 0xedfc68b6, 0xe4f163b8, 0x31dccad7, 0x63851042, 0x97224013, 0xc6112084, 0x4a247d85, 0xbb3df8d2, 0xf93211ae, 0x29a16dc7, 0x9e2f4b1d, 0xb230f3dc, 0x8652ec0d, 0xc1e3d077, 0xb3166c2b, 0x70b999a9, 0x9448fa11, 0xe9642247, 0xfc8cc4a8, 0xf03f1aa0, 0x7d2cd856, 0x3390ef22, 0x494ec787, 0x38d1c1d9, 0xcaa2fe8c, 0xd40b3698, 0xf581cfa6, 0x7ade28a5, 0xb78e26da, 0xadbfa43f, 0x3a9de42c, 0x78920d50, 0x5fcc9b6a, 0x7e466254, 0x8d13c2f6, 0xd8b8e890, 0x39f75e2e, 0xc3aff582, 0x5d80be9f, 0xd0937c69, 0xd52da96f, 0x2512b3cf, 0xac993bc8, 0x187da710, 0x9c636ee8, 0x3bbb7bdb, 0x267809cd, 0x5918f46e, 0x9ab701ec, 0x4f9aa883, 0x956e65e6, 0xffe67eaa, 0xbccf0821, 0x15e8e6ef, 0xe79bd9ba, 0x6f36ce4a, 0x9f09d4ea, 0xb07cd629, 0xa4b2af31, 0x3f23312a, 0xa59430c6, 0xa266c035, 0x4ebc3774, 0x82caa6fc, 0x90d0b0e0, 0xa7d81533, 0x04984af1, 0xecdaf741, 0xcd500e7f, 0x91f62f17, 0x4dd68d76, 0xefb04d43, 0xaa4d54cc, 0x9604dfe4, 0xd1b5e39e, 0x6a881b4c, 0x2c1fb8c1, 0x65517f46, 0x5eea049d, 0x8c355d01, 0x877473fa, 0x0b412efb, 0x671d5ab3, 0xdbd25292, 0x105633e9, 0xd647136d, 0xd7618c9a, 0xa10c7a37, 0xf8148e59, 0x133c89eb, 0xa927eece, 0x61c935b7, 0x1ce5ede1, 0x47b13c7a, 0xd2df599c, 0xf2733f55, 0x14ce7918, 0xc737bf73, 0xf7cdea53, 0xfdaa5b5f, 0x3d6f14df, 0x44db8678, 0xaff381ca, 0x68c43eb9, 0x24342c38, 0xa3405fc2, 0x1dc37216, 0xe2250cbc, 0x3c498b28, 0x0d9541ff, 0xa8017139, 0x0cb3de08, 0xb4e49cd8, 0x56c19064, 0xcb84617b, 0x32b670d5, 0x6c5c7448, 0xb85742d0 ]

    # Transformations for decryption key expansion
    U1 = [ 0x00000000, 0x0e090d0b, 0x1c121a16, 0x121b171d, 0x3824342c, 0x362d3927, 0x24362e3a, 0x2a3f2331, 0x70486858, 0x7e416553, 0x6c5a724e, 0x62537f45, 0x486c5c74, 0x4665517f, 0x547e4662, 0x5a774b69, 0xe090d0b0, 0xee99ddbb, 0xfc82caa6, 0xf28bc7ad, 0xd8b4e49c, 0xd6bde997, 0xc4a6fe8a, 0xcaaff381, 0x90d8b8e8, 0x9ed1b5e3, 0x8ccaa2fe, 0x82c3aff5, 0xa8fc8cc4, 0xa6f581cf, 0xb4ee96d2, 0xbae79bd9, 0xdb3bbb7b, 0xd532b670, 0xc729a16d, 0xc920ac66, 0xe31f8f57, 0xed16825c, 0xff0d9541, 0xf104984a, 0xab73d323, 0xa57ade28, 0xb761c935, 0xb968c43e, 0x9357e70f, 0x9d5eea04, 0x8f45fd19, 0x814cf012, 0x3bab6bcb, 0x35a266c0, 0x27b971dd, 0x29b07cd6, 0x038f5fe7, 0x0d8652ec, 0x1f9d45f1, 0x119448fa, 0x4be30393, 0x45ea0e98, 0x57f11985, 0x59f8148e, 0x73c737bf, 0x7dce3ab4, 0x6fd52da9, 0x61dc20a2, 0xad766df6, 0xa37f60fd, 0xb16477e0, 0xbf6d7aeb, 0x955259da, 0x9b5b54d1, 0x894043cc, 0x87494ec7, 0xdd3e05ae, 0xd33708a5, 0xc12c1fb8, 0xcf2512b3, 0xe51a3182, 0xeb133c89, 0xf9082b94, 0xf701269f, 0x4de6bd46, 0x43efb04d, 0x51f4a750, 0x5ffdaa5b, 0x75c2896a, 0x7bcb8461, 0x69d0937c, 0x67d99e77, 0x3daed51e, 0x33a7d815, 0x21bccf08, 0x2fb5c203, 0x058ae132, 0x0b83ec39, 0x1998fb24, 0x1791f62f, 0x764dd68d, 0x7844db86, 0x6a5fcc9b, 0x6456c190, 0x4e69e2a1, 0x4060efaa, 0x527bf8b7, 0x5c72f5bc, 0x0605bed5, 0x080cb3de, 0x1a17a4c3, 0x141ea9c8, 0x3e218af9, 0x302887f2, 0x223390ef, 0x2c3a9de4, 0x96dd063d, 0x98d40b36, 0x8acf1c2b, 0x84c61120, 0xaef93211, 0xa0f03f1a, 0xb2eb2807, 0xbce2250c, 0xe6956e65, 0xe89c636e, 0xfa877473, 0xf48e7978, 0xdeb15a49, 0xd0b85742, 0xc2a3405f, 0xccaa4d54, 0x41ecdaf7, 0x4fe5d7fc, 0x5dfec0e1, 0x53f7cdea, 0x79c8eedb, 0x77c1e3d0, 0x65daf4cd, 0x6bd3f9c6, 0x31a4b2af, 0x3fadbfa4, 0x2db6a8b9, 0x23bfa5b2, 0x09808683, 0x07898b88, 0x15929c95, 0x1b9b919e, 0xa17c0a47, 0xaf75074c, 0xbd6e1051, 0xb3671d5a, 0x99583e6b, 0x97513360, 0x854a247d, 0x8b432976, 0xd134621f, 0xdf3d6f14, 0xcd267809, 0xc32f7502, 0xe9105633, 0xe7195b38, 0xf5024c25, 0xfb0b412e, 0x9ad7618c, 0x94de6c87, 0x86c57b9a, 0x88cc7691, 0xa2f355a0, 0xacfa58ab, 0xbee14fb6, 0xb0e842bd, 0xea9f09d4, 0xe49604df, 0xf68d13c2, 0xf8841ec9, 0xd2bb3df8, 0xdcb230f3, 0xcea927ee, 0xc0a02ae5, 0x7a47b13c, 0x744ebc37, 0x6655ab2a, 0x685ca621, 0x42638510, 0x4c6a881b, 0x5e719f06, 0x5078920d, 0x0a0fd964, 0x0406d46f, 0x161dc372, 0x1814ce79, 0x322bed48, 0x3c22e043, 0x2e39f75e, 0x2030fa55, 0xec9ab701, 0xe293ba0a, 0xf088ad17, 0xfe81a01c, 0xd4be832d, 0xdab78e26, 0xc8ac993b, 0xc6a59430, 0x9cd2df59, 0x92dbd252, 0x80c0c54f, 0x8ec9c844, 0xa4f6eb75, 0xaaffe67e, 0xb8e4f163, 0xb6edfc68, 0x0c0a67b1, 0x02036aba, 0x10187da7, 0x1e1170ac, 0x342e539d, 0x3a275e96, 0x283c498b, 0x26354480, 0x7c420fe9, 0x724b02e2, 0x605015ff, 0x6e5918f4, 0x44663bc5, 0x4a6f36ce, 0x587421d3, 0x567d2cd8, 0x37a10c7a, 0x39a80171, 0x2bb3166c, 0x25ba1b67, 0x0f853856, 0x018c355d, 0x13972240, 0x1d9e2f4b, 0x47e96422, 0x49e06929, 0x5bfb7e34, 0x55f2733f, 0x7fcd500e, 0x71c45d05, 0x63df4a18, 0x6dd64713, 0xd731dcca, 0xd938d1c1, 0xcb23c6dc, 0xc52acbd7, 0xef15e8e6, 0xe11ce5ed, 0xf307f2f0, 0xfd0efffb, 0xa779b492, 0xa970b999, 0xbb6bae84, 0xb562a38f, 0x9f5d80be, 0x91548db5, 0x834f9aa8, 0x8d4697a3 ]
    U2 = [ 0x00000000, 0x0b0e090d, 0x161c121a, 0x1d121b17, 0x2c382434, 0x27362d39, 0x3a24362e, 0x312a3f23, 0x58704868, 0x537e4165, 0x4e6c5a72, 0x4562537f, 0x74486c5c, 0x7f466551, 0x62547e46, 0x695a774b, 0xb0e090d0, 0xbbee99dd, 0xa6fc82ca, 0xadf28bc7, 0x9cd8b4e4, 0x97d6bde9, 0x8ac4a6fe, 0x81caaff3, 0xe890d8b8, 0xe39ed1b5, 0xfe8ccaa2, 0xf582c3af, 0xc4a8fc8c, 0xcfa6f581, 0xd2b4ee96, 0xd9bae79b, 0x7bdb3bbb, 0x70d532b6, 0x6dc729a1, 0x66c920ac, 0x57e31f8f, 0x5ced1682, 0x41ff0d95, 0x4af10498, 0x23ab73d3, 0x28a57ade, 0x35b761c9, 0x3eb968c4, 0x0f9357e7, 0x049d5eea, 0x198f45fd, 0x12814cf0, 0xcb3bab6b, 0xc035a266, 0xdd27b971, 0xd629b07c, 0xe7038f5f, 0xec0d8652, 0xf11f9d45, 0xfa119448, 0x934be303, 0x9845ea0e, 0x8557f119, 0x8e59f814, 0xbf73c737, 0xb47dce3a, 0xa96fd52d, 0xa261dc20, 0xf6ad766d, 0xfda37f60, 0xe0b16477, 0xebbf6d7a, 0xda955259, 0xd19b5b54, 0xcc894043, 0xc787494e, 0xaedd3e05, 0xa5d33708, 0xb8c12c1f, 0xb3cf2512, 0x82e51a31, 0x89eb133c, 0x94f9082b, 0x9ff70126, 0x464de6bd, 0x4d43efb0, 0x5051f4a7, 0x5b5ffdaa, 0x6a75c289, 0x617bcb84, 0x7c69d093, 0x7767d99e, 0x1e3daed5, 0x1533a7d8, 0x0821bccf, 0x032fb5c2, 0x32058ae1, 0x390b83ec, 0x241998fb, 0x2f1791f6, 0x8d764dd6, 0x867844db, 0x9b6a5fcc, 0x906456c1, 0xa14e69e2, 0xaa4060ef, 0xb7527bf8, 0xbc5c72f5, 0xd50605be, 0xde080cb3, 0xc31a17a4, 0xc8141ea9, 0xf93e218a, 0xf2302887, 0xef223390, 0xe42c3a9d, 0x3d96dd06, 0x3698d40b, 0x2b8acf1c, 0x2084c611, 0x11aef932, 0x1aa0f03f, 0x07b2eb28, 0x0cbce225, 0x65e6956e, 0x6ee89c63, 0x73fa8774, 0x78f48e79, 0x49deb15a, 0x42d0b857, 0x5fc2a340, 0x54ccaa4d, 0xf741ecda, 0xfc4fe5d7, 0xe15dfec0, 0xea53f7cd, 0xdb79c8ee, 0xd077c1e3, 0xcd65daf4, 0xc66bd3f9, 0xaf31a4b2, 0xa43fadbf, 0xb92db6a8, 0xb223bfa5, 0x83098086, 0x8807898b, 0x9515929c, 0x9e1b9b91, 0x47a17c0a, 0x4caf7507, 0x51bd6e10, 0x5ab3671d, 0x6b99583e, 0x60975133, 0x7d854a24, 0x768b4329, 0x1fd13462, 0x14df3d6f, 0x09cd2678, 0x02c32f75, 0x33e91056, 0x38e7195b, 0x25f5024c, 0x2efb0b41, 0x8c9ad761, 0x8794de6c, 0x9a86c57b, 0x9188cc76, 0xa0a2f355, 0xabacfa58, 0xb6bee14f, 0xbdb0e842, 0xd4ea9f09, 0xdfe49604, 0xc2f68d13, 0xc9f8841e, 0xf8d2bb3d, 0xf3dcb230, 0xeecea927, 0xe5c0a02a, 0x3c7a47b1, 0x37744ebc, 0x2a6655ab, 0x21685ca6, 0x10426385, 0x1b4c6a88, 0x065e719f, 0x0d507892, 0x640a0fd9, 0x6f0406d4, 0x72161dc3, 0x791814ce, 0x48322bed, 0x433c22e0, 0x5e2e39f7, 0x552030fa, 0x01ec9ab7, 0x0ae293ba, 0x17f088ad, 0x1cfe81a0, 0x2dd4be83, 0x26dab78e, 0x3bc8ac99, 0x30c6a594, 0x599cd2df, 0x5292dbd2, 0x4f80c0c5, 0x448ec9c8, 0x75a4f6eb, 0x7eaaffe6, 0x63b8e4f1, 0x68b6edfc, 0xb10c0a67, 0xba02036a, 0xa710187d, 0xac1e1170, 0x9d342e53, 0x963a275e, 0x8b283c49, 0x80263544, 0xe97c420f, 0xe2724b02, 0xff605015, 0xf46e5918, 0xc544663b, 0xce4a6f36, 0xd3587421, 0xd8567d2c, 0x7a37a10c, 0x7139a801, 0x6c2bb316, 0x6725ba1b, 0x560f8538, 0x5d018c35, 0x40139722, 0x4b1d9e2f, 0x2247e964, 0x2949e069, 0x345bfb7e, 0x3f55f273, 0x0e7fcd50, 0x0571c45d, 0x1863df4a, 0x136dd647, 0xcad731dc, 0xc1d938d1, 0xdccb23c6, 0xd7c52acb, 0xe6ef15e8, 0xede11ce5, 0xf0f307f2, 0xfbfd0eff, 0x92a779b4, 0x99a970b9, 0x84bb6bae, 0x8fb562a3, 0xbe9f5d80, 0xb591548d, 0xa8834f9a, 0xa38d4697 ]
    U3 = [ 0x00000000, 0x0d0b0e09, 0x1a161c12, 0x171d121b, 0x342c3824, 0x3927362d, 0x2e3a2436, 0x23312a3f, 0x68587048, 0x65537e41, 0x724e6c5a, 0x7f456253, 0x5c74486c, 0x517f4665, 0x4662547e, 0x4b695a77, 0xd0b0e090, 0xddbbee99, 0xcaa6fc82, 0xc7adf28b, 0xe49cd8b4, 0xe997d6bd, 0xfe8ac4a6, 0xf381caaf, 0xb8e890d8, 0xb5e39ed1, 0xa2fe8cca, 0xaff582c3, 0x8cc4a8fc, 0x81cfa6f5, 0x96d2b4ee, 0x9bd9bae7, 0xbb7bdb3b, 0xb670d532, 0xa16dc729, 0xac66c920, 0x8f57e31f, 0x825ced16, 0x9541ff0d, 0x984af104, 0xd323ab73, 0xde28a57a, 0xc935b761, 0xc43eb968, 0xe70f9357, 0xea049d5e, 0xfd198f45, 0xf012814c, 0x6bcb3bab, 0x66c035a2, 0x71dd27b9, 0x7cd629b0, 0x5fe7038f, 0x52ec0d86, 0x45f11f9d, 0x48fa1194, 0x03934be3, 0x0e9845ea, 0x198557f1, 0x148e59f8, 0x37bf73c7, 0x3ab47dce, 0x2da96fd5, 0x20a261dc, 0x6df6ad76, 0x60fda37f, 0x77e0b164, 0x7aebbf6d, 0x59da9552, 0x54d19b5b, 0x43cc8940, 0x4ec78749, 0x05aedd3e, 0x08a5d337, 0x1fb8c12c, 0x12b3cf25, 0x3182e51a, 0x3c89eb13, 0x2b94f908, 0x269ff701, 0xbd464de6, 0xb04d43ef, 0xa75051f4, 0xaa5b5ffd, 0x896a75c2, 0x84617bcb, 0x937c69d0, 0x9e7767d9, 0xd51e3dae, 0xd81533a7, 0xcf0821bc, 0xc2032fb5, 0xe132058a, 0xec390b83, 0xfb241998, 0xf62f1791, 0xd68d764d, 0xdb867844, 0xcc9b6a5f, 0xc1906456, 0xe2a14e69, 0xefaa4060, 0xf8b7527b, 0xf5bc5c72, 0xbed50605, 0xb3de080c, 0xa4c31a17, 0xa9c8141e, 0x8af93e21, 0x87f23028, 0x90ef2233, 0x9de42c3a, 0x063d96dd, 0x0b3698d4, 0x1c2b8acf, 0x112084c6, 0x3211aef9, 0x3f1aa0f0, 0x2807b2eb, 0x250cbce2, 0x6e65e695, 0x636ee89c, 0x7473fa87, 0x7978f48e, 0x5a49deb1, 0x5742d0b8, 0x405fc2a3, 0x4d54ccaa, 0xdaf741ec, 0xd7fc4fe5, 0xc0e15dfe, 0xcdea53f7, 0xeedb79c8, 0xe3d077c1, 0xf4cd65da, 0xf9c66bd3, 0xb2af31a4, 0xbfa43fad, 0xa8b92db6, 0xa5b223bf, 0x86830980, 0x8b880789, 0x9c951592, 0x919e1b9b, 0x0a47a17c, 0x074caf75, 0x1051bd6e, 0x1d5ab367, 0x3e6b9958, 0x33609751, 0x247d854a, 0x29768b43, 0x621fd134, 0x6f14df3d, 0x7809cd26, 0x7502c32f, 0x5633e910, 0x5b38e719, 0x4c25f502, 0x412efb0b, 0x618c9ad7, 0x6c8794de, 0x7b9a86c5, 0x769188cc, 0x55a0a2f3, 0x58abacfa, 0x4fb6bee1, 0x42bdb0e8, 0x09d4ea9f, 0x04dfe496, 0x13c2f68d, 0x1ec9f884, 0x3df8d2bb, 0x30f3dcb2, 0x27eecea9, 0x2ae5c0a0, 0xb13c7a47, 0xbc37744e, 0xab2a6655, 0xa621685c, 0x85104263, 0x881b4c6a, 0x9f065e71, 0x920d5078, 0xd9640a0f, 0xd46f0406, 0xc372161d, 0xce791814, 0xed48322b, 0xe0433c22, 0xf75e2e39, 0xfa552030, 0xb701ec9a, 0xba0ae293, 0xad17f088, 0xa01cfe81, 0x832dd4be, 0x8e26dab7, 0x993bc8ac, 0x9430c6a5, 0xdf599cd2, 0xd25292db, 0xc54f80c0, 0xc8448ec9, 0xeb75a4f6, 0xe67eaaff, 0xf163b8e4, 0xfc68b6ed, 0x67b10c0a, 0x6aba0203, 0x7da71018, 0x70ac1e11, 0x539d342e, 0x5e963a27, 0x498b283c, 0x44802635, 0x0fe97c42, 0x02e2724b, 0x15ff6050, 0x18f46e59, 0x3bc54466, 0x36ce4a6f, 0x21d35874, 0x2cd8567d, 0x0c7a37a1, 0x017139a8, 0x166c2bb3, 0x1b6725ba, 0x38560f85, 0x355d018c, 0x22401397, 0x2f4b1d9e, 0x642247e9, 0x692949e0, 0x7e345bfb, 0x733f55f2, 0x500e7fcd, 0x5d0571c4, 0x4a1863df, 0x47136dd6, 0xdccad731, 0xd1c1d938, 0xc6dccb23, 0xcbd7c52a, 0xe8e6ef15, 0xe5ede11c, 0xf2f0f307, 0xfffbfd0e, 0xb492a779, 0xb999a970, 0xae84bb6b, 0xa38fb562, 0x80be9f5d, 0x8db59154, 0x9aa8834f, 0x97a38d46 ]
    U4 = [ 0x00000000, 0x090d0b0e, 0x121a161c, 0x1b171d12, 0x24342c38, 0x2d392736, 0x362e3a24, 0x3f23312a, 0x48685870, 0x4165537e, 0x5a724e6c, 0x537f4562, 0x6c5c7448, 0x65517f46, 0x7e466254, 0x774b695a, 0x90d0b0e0, 0x99ddbbee, 0x82caa6fc, 0x8bc7adf2, 0xb4e49cd8, 0xbde997d6, 0xa6fe8ac4, 0xaff381ca, 0xd8b8e890, 0xd1b5e39e, 0xcaa2fe8c, 0xc3aff582, 0xfc8cc4a8, 0xf581cfa6, 0xee96d2b4, 0xe79bd9ba, 0x3bbb7bdb, 0x32b670d5, 0x29a16dc7, 0x20ac66c9, 0x1f8f57e3, 0x16825ced, 0x0d9541ff, 0x04984af1, 0x73d323ab, 0x7ade28a5, 0x61c935b7, 0x68c43eb9, 0x57e70f93, 0x5eea049d, 0x45fd198f, 0x4cf01281, 0xab6bcb3b, 0xa266c035, 0xb971dd27, 0xb07cd629, 0x8f5fe703, 0x8652ec0d, 0x9d45f11f, 0x9448fa11, 0xe303934b, 0xea0e9845, 0xf1198557, 0xf8148e59, 0xc737bf73, 0xce3ab47d, 0xd52da96f, 0xdc20a261, 0x766df6ad, 0x7f60fda3, 0x6477e0b1, 0x6d7aebbf, 0x5259da95, 0x5b54d19b, 0x4043cc89, 0x494ec787, 0x3e05aedd, 0x3708a5d3, 0x2c1fb8c1, 0x2512b3cf, 0x1a3182e5, 0x133c89eb, 0x082b94f9, 0x01269ff7, 0xe6bd464d, 0xefb04d43, 0xf4a75051, 0xfdaa5b5f, 0xc2896a75, 0xcb84617b, 0xd0937c69, 0xd99e7767, 0xaed51e3d, 0xa7d81533, 0xbccf0821, 0xb5c2032f, 0x8ae13205, 0x83ec390b, 0x98fb2419, 0x91f62f17, 0x4dd68d76, 0x44db8678, 0x5fcc9b6a, 0x56c19064, 0x69e2a14e, 0x60efaa40, 0x7bf8b752, 0x72f5bc5c, 0x05bed506, 0x0cb3de08, 0x17a4c31a, 0x1ea9c814, 0x218af93e, 0x2887f230, 0x3390ef22, 0x3a9de42c, 0xdd063d96, 0xd40b3698, 0xcf1c2b8a, 0xc6112084, 0xf93211ae, 0xf03f1aa0, 0xeb2807b2, 0xe2250cbc, 0x956e65e6, 0x9c636ee8, 0x877473fa, 0x8e7978f4, 0xb15a49de, 0xb85742d0, 0xa3405fc2, 0xaa4d54cc, 0xecdaf741, 0xe5d7fc4f, 0xfec0e15d, 0xf7cdea53, 0xc8eedb79, 0xc1e3d077, 0xdaf4cd65, 0xd3f9c66b, 0xa4b2af31, 0xadbfa43f, 0xb6a8b92d, 0xbfa5b223, 0x80868309, 0x898b8807, 0x929c9515, 0x9b919e1b, 0x7c0a47a1, 0x75074caf, 0x6e1051bd, 0x671d5ab3, 0x583e6b99, 0x51336097, 0x4a247d85, 0x4329768b, 0x34621fd1, 0x3d6f14df, 0x267809cd, 0x2f7502c3, 0x105633e9, 0x195b38e7, 0x024c25f5, 0x0b412efb, 0xd7618c9a, 0xde6c8794, 0xc57b9a86, 0xcc769188, 0xf355a0a2, 0xfa58abac, 0xe14fb6be, 0xe842bdb0, 0x9f09d4ea, 0x9604dfe4, 0x8d13c2f6, 0x841ec9f8, 0xbb3df8d2, 0xb230f3dc, 0xa927eece, 0xa02ae5c0, 0x47b13c7a, 0x4ebc3774, 0x55ab2a66, 0x5ca62168, 0x63851042, 0x6a881b4c, 0x719f065e, 0x78920d50, 0x0fd9640a, 0x06d46f04, 0x1dc37216, 0x14ce7918, 0x2bed4832, 0x22e0433c, 0x39f75e2e, 0x30fa5520, 0x9ab701ec, 0x93ba0ae2, 0x88ad17f0, 0x81a01cfe, 0xbe832dd4, 0xb78e26da, 0xac993bc8, 0xa59430c6, 0xd2df599c, 0xdbd25292, 0xc0c54f80, 0xc9c8448e, 0xf6eb75a4, 0xffe67eaa, 0xe4f163b8, 0xedfc68b6, 0x0a67b10c, 0x036aba02, 0x187da710, 0x1170ac1e, 0x2e539d34, 0x275e963a, 0x3c498b28, 0x35448026, 0x420fe97c, 0x4b02e272, 0x5015ff60, 0x5918f46e, 0x663bc544, 0x6f36ce4a, 0x7421d358, 0x7d2cd856, 0xa10c7a37, 0xa8017139, 0xb3166c2b, 0xba1b6725, 0x8538560f, 0x8c355d01, 0x97224013, 0x9e2f4b1d, 0xe9642247, 0xe0692949, 0xfb7e345b, 0xf2733f55, 0xcd500e7f, 0xc45d0571, 0xdf4a1863, 0xd647136d, 0x31dccad7, 0x38d1c1d9, 0x23c6dccb, 0x2acbd7c5, 0x15e8e6ef, 0x1ce5ede1, 0x07f2f0f3, 0x0efffbfd, 0x79b492a7, 0x70b999a9, 0x6bae84bb, 0x62a38fb5, 0x5d80be9f, 0x548db591, 0x4f9aa883, 0x4697a38d ]

    def __init__(self, key):

        if len(key) not in (16, 24, 32):
            raise ValueError('Invalid key size')

        rounds = self.number_of_rounds[len(key)]

        # Encryption round keys
        self._Ke = [[0] * 4 for i in xrange(rounds + 1)]

        # Decryption round keys
        self._Kd = [[0] * 4 for i in xrange(rounds + 1)]

        round_key_count = (rounds + 1) * 4
        KC = len(key) // 4

        # Convert the key into ints
        tk = [ struct.unpack('>i', key[i:i + 4])[0] for i in xrange(0, len(key), 4) ]

        # Copy values into round key arrays
        for i in xrange(0, KC):
            self._Ke[i // 4][i % 4] = tk[i]
            self._Kd[rounds - (i // 4)][i % 4] = tk[i]

        # Key expansion (fips-197 section 5.2)
        rconpointer = 0
        t = KC
        while t < round_key_count:

            tt = tk[KC - 1]
            tk[0] ^= ((self.S[(tt >> 16) & 0xFF] << 24) ^
                      (self.S[(tt >>  8) & 0xFF] << 16) ^
                      (self.S[ tt        & 0xFF] <<  8) ^
                       self.S[(tt >> 24) & 0xFF]        ^
                      (self.rcon[rconpointer] << 24))
            rconpointer += 1

            if KC != 8:
                for i in xrange(1, KC):
                    tk[i] ^= tk[i - 1]

            # Key expansion for 256-bit keys is "slightly different" (fips-197)
            else:
                for i in xrange(1, KC // 2):
                    tk[i] ^= tk[i - 1]
                tt = tk[KC // 2 - 1]

                tk[KC // 2] ^= (self.S[ tt        & 0xFF]        ^
                               (self.S[(tt >>  8) & 0xFF] <<  8) ^
                               (self.S[(tt >> 16) & 0xFF] << 16) ^
                               (self.S[(tt >> 24) & 0xFF] << 24))

                for i in xrange(KC // 2 + 1, KC):
                    tk[i] ^= tk[i - 1]

            # Copy values into round key arrays
            j = 0
            while j < KC and t < round_key_count:
                self._Ke[t // 4][t % 4] = tk[j]
                self._Kd[rounds - (t // 4)][t % 4] = tk[j]
                j += 1
                t += 1

        # Inverse-Cipher-ify the decryption round key (fips-197 section 5.3)
        for r in xrange(1, rounds):
            for j in xrange(0, 4):
                tt = self._Kd[r][j]
                self._Kd[r][j] = (self.U1[(tt >> 24) & 0xFF] ^
                                  self.U2[(tt >> 16) & 0xFF] ^
                                  self.U3[(tt >>  8) & 0xFF] ^
                                  self.U4[ tt        & 0xFF])

    def encrypt(self, plaintext):
        'Encrypt a block of plain text using the AES block cipher.'

        if len(plaintext) != 16:
            raise ValueError('wrong block length')

        rounds = len(self._Ke) - 1
        (s1, s2, s3) = [1, 2, 3]
        a = [0, 0, 0, 0]

        # Convert plaintext to (ints ^ key)
        t = [(_compact_word(plaintext[4 * i:4 * i + 4]) ^ self._Ke[0][i]) for i in xrange(0, 4)]

        # Apply round transforms
        for r in xrange(1, rounds):
            for i in xrange(0, 4):
                a[i] = (self.T1[(t[ i          ] >> 24) & 0xFF] ^
                        self.T2[(t[(i + s1) % 4] >> 16) & 0xFF] ^
                        self.T3[(t[(i + s2) % 4] >>  8) & 0xFF] ^
                        self.T4[ t[(i + s3) % 4]        & 0xFF] ^
                        self._Ke[r][i])
            t = copy.copy(a)

        # The last round is special
        result = [ ]
        for i in xrange(0, 4):
            tt = self._Ke[rounds][i]
            result.append((self.S[(t[ i           ] >> 24) & 0xFF] ^ (tt >> 24)) & 0xFF)
            result.append((self.S[(t[(i + s1) % 4] >> 16) & 0xFF] ^ (tt >> 16)) & 0xFF)
            result.append((self.S[(t[(i + s2) % 4] >>  8) & 0xFF] ^ (tt >>  8)) & 0xFF)
            result.append((self.S[ t[(i + s3) % 4]        & 0xFF] ^  tt       ) & 0xFF)

        return result

    def decrypt(self, ciphertext):
        'Decrypt a block of cipher text using the AES block cipher.'

        if len(ciphertext) != 16:
            raise ValueError('wrong block length')

        rounds = len(self._Kd) - 1
        (s1, s2, s3) = [3, 2, 1]
        a = [0, 0, 0, 0]

        # Convert ciphertext to (ints ^ key)
        t = [(_compact_word(ciphertext[4 * i:4 * i + 4]) ^ self._Kd[0][i]) for i in xrange(0, 4)]

        # Apply round transforms
        for r in xrange(1, rounds):
            for i in xrange(0, 4):
                a[i] = (self.T5[(t[ i          ] >> 24) & 0xFF] ^
                        self.T6[(t[(i + s1) % 4] >> 16) & 0xFF] ^
                        self.T7[(t[(i + s2) % 4] >>  8) & 0xFF] ^
                        self.T8[ t[(i + s3) % 4]        & 0xFF] ^
                        self._Kd[r][i])
            t = copy.copy(a)

        # The last round is special
        result = [ ]
        for i in xrange(0, 4):
            tt = self._Kd[rounds][i]
            result.append((self.Si[(t[ i           ] >> 24) & 0xFF] ^ (tt >> 24)) & 0xFF)
            result.append((self.Si[(t[(i + s1) % 4] >> 16) & 0xFF] ^ (tt >> 16)) & 0xFF)
            result.append((self.Si[(t[(i + s2) % 4] >>  8) & 0xFF] ^ (tt >>  8)) & 0xFF)
            result.append((self.Si[ t[(i + s3) % 4]        & 0xFF] ^  tt       ) & 0xFF)

        return result


class Counter(object):
    '''A counter object for the Counter (CTR) mode of operation.

       To create a custom counter, you can usually just override the
       increment method.'''

    def __init__(self, initial_value = 1):

        # Convert the value into an array of bytes long
        self._counter = [ ((initial_value >> i) % 256) for i in xrange(128 - 8, -1, -8) ]

    value = property(lambda s: s._counter)

    def increment(self):
        '''Increment the counter (overflow rolls back to 0).'''

        for i in xrange(len(self._counter) - 1, -1, -1):
            self._counter[i] += 1

            if self._counter[i] < 256: break

            # Carry the one
            self._counter[i] = 0

        # Overflow
        else:
            self._counter = [ 0 ] * len(self._counter)


class AESBlockModeOfOperation(object):
    '''Super-class for AES modes of operation that require blocks.'''
    def __init__(self, key):
        self._aes = AES(key)

    def decrypt(self, ciphertext):
        raise Exception('not implemented')

    def encrypt(self, plaintext):
        raise Exception('not implemented')


class AESStreamModeOfOperation(AESBlockModeOfOperation):
    '''Super-class for AES modes of operation that are stream-ciphers.'''

class AESSegmentModeOfOperation(AESStreamModeOfOperation):
    '''Super-class for AES modes of operation that segment data.'''

    segment_bytes = 16



class AESModeOfOperationECB(AESBlockModeOfOperation):
    '''AES Electronic Codebook Mode of Operation.

       o Block-cipher, so data must be padded to 16 byte boundaries

   Security Notes:
       o This mode is not recommended
       o Any two identical blocks produce identical encrypted values,
         exposing data patterns. (See the image of Tux on wikipedia)

   Also see:
       o https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Electronic_codebook_.28ECB.29
       o See NIST SP800-38A (http://csrc.nist.gov/publications/nistpubs/800-38a/sp800-38a.pdf); section 6.1'''


    name = "Electronic Codebook (ECB)"

    def encrypt(self, plaintext):
        if len(plaintext) != 16:
            raise ValueError('plaintext block must be 16 bytes')

        plaintext = _string_to_bytes(plaintext)
        return _bytes_to_string(self._aes.encrypt(plaintext))

    def decrypt(self, ciphertext):
        if len(ciphertext) != 16:
            raise ValueError('ciphertext block must be 16 bytes')

        ciphertext = _string_to_bytes(ciphertext)
        return _bytes_to_string(self._aes.decrypt(ciphertext))



class AESModeOfOperationCBC(AESBlockModeOfOperation):
    '''AES Cipher-Block Chaining Mode of Operation.

       o The Initialization Vector (IV)
       o Block-cipher, so data must be padded to 16 byte boundaries
       o An incorrect initialization vector will only cause the first
         block to be corrupt; all other blocks will be intact
       o A corrupt bit in the cipher text will cause a block to be
         corrupted, and the next block to be inverted, but all other
         blocks will be intact.

   Security Notes:
       o This method (and CTR) ARE recommended.

   Also see:
       o https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher-block_chaining_.28CBC.29
       o See NIST SP800-38A (http://csrc.nist.gov/publications/nistpubs/800-38a/sp800-38a.pdf); section 6.2'''


    name = "Cipher-Block Chaining (CBC)"

    def __init__(self, key, iv = None):
        if iv is None:
            self._last_cipherblock = [ 0 ] * 16
        elif len(iv) != 16:
            raise ValueError('initialization vector must be 16 bytes')
        else:
            self._last_cipherblock = _string_to_bytes(iv)

        AESBlockModeOfOperation.__init__(self, key)

    def encrypt(self, plaintext):
        if len(plaintext) != 16:
            raise ValueError('plaintext block must be 16 bytes')

        plaintext = _string_to_bytes(plaintext)
        precipherblock = [ (p ^ l) for (p, l) in zip(plaintext, self._last_cipherblock) ]
        self._last_cipherblock = self._aes.encrypt(precipherblock)

        return _bytes_to_string(self._last_cipherblock)

    def decrypt(self, ciphertext):
        if len(ciphertext) != 16:
            raise ValueError('ciphertext block must be 16 bytes')

        cipherblock = _string_to_bytes(ciphertext)
        plaintext = [ (p ^ l) for (p, l) in zip(self._aes.decrypt(cipherblock), self._last_cipherblock) ]
        self._last_cipherblock = cipherblock

        return _bytes_to_string(plaintext)



class AESModeOfOperationCFB(AESSegmentModeOfOperation):
    '''AES Cipher Feedback Mode of Operation.

       o A stream-cipher, so input does not need to be padded to blocks,
         but does need to be padded to segment_size

    Also see:
       o https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Cipher_feedback_.28CFB.29
       o See NIST SP800-38A (http://csrc.nist.gov/publications/nistpubs/800-38a/sp800-38a.pdf); section 6.3'''


    name = "Cipher Feedback (CFB)"

    def __init__(self, key, iv, segment_size = 1):
        if segment_size == 0: segment_size = 1

        if iv is None:
            self._shift_register = [ 0 ] * 16
        elif len(iv) != 16:
            raise ValueError('initialization vector must be 16 bytes')
        else:
          self._shift_register = _string_to_bytes(iv)

        self._segment_bytes = segment_size

        AESBlockModeOfOperation.__init__(self, key)

    segment_bytes = property(lambda s: s._segment_bytes)

    def encrypt(self, plaintext):
        if len(plaintext) % self._segment_bytes != 0:
            raise ValueError('plaintext block must be a multiple of segment_size')

        plaintext = _string_to_bytes(plaintext)

        # Break block into segments
        encrypted = [ ]
        for i in xrange(0, len(plaintext), self._segment_bytes):
            plaintext_segment = plaintext[i: i + self._segment_bytes]
            xor_segment = self._aes.encrypt(self._shift_register)[:len(plaintext_segment)]
            cipher_segment = [ (p ^ x) for (p, x) in zip(plaintext_segment, xor_segment) ]

            # Shift the top bits out and the ciphertext in
            self._shift_register = _concat_list(self._shift_register[len(cipher_segment):], cipher_segment)

            encrypted.extend(cipher_segment)

        return _bytes_to_string(encrypted)

    def decrypt(self, ciphertext):
        if len(ciphertext) % self._segment_bytes != 0:
            raise ValueError('ciphertext block must be a multiple of segment_size')

        ciphertext = _string_to_bytes(ciphertext)

        # Break block into segments
        decrypted = [ ]
        for i in xrange(0, len(ciphertext), self._segment_bytes):
            cipher_segment = ciphertext[i: i + self._segment_bytes]
            xor_segment = self._aes.encrypt(self._shift_register)[:len(cipher_segment)]
            plaintext_segment = [ (p ^ x) for (p, x) in zip(cipher_segment, xor_segment) ]

            # Shift the top bits out and the ciphertext in
            self._shift_register = _concat_list(self._shift_register[len(cipher_segment):], cipher_segment)

            decrypted.extend(plaintext_segment)

        return _bytes_to_string(decrypted)



class AESModeOfOperationOFB(AESStreamModeOfOperation):
    '''AES Output Feedback Mode of Operation.

       o A stream-cipher, so input does not need to be padded to blocks,
         allowing arbitrary length data.
       o A bit twiddled in the cipher text, twiddles the same bit in the
         same bit in the plain text, which can be useful for error
         correction techniques.

    Also see:
       o https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Output_feedback_.28OFB.29
       o See NIST SP800-38A (http://csrc.nist.gov/publications/nistpubs/800-38a/sp800-38a.pdf); section 6.4'''


    name = "Output Feedback (OFB)"

    def __init__(self, key, iv = None):
        if iv is None:
            self._last_precipherblock = [ 0 ] * 16
        elif len(iv) != 16:
            raise ValueError('initialization vector must be 16 bytes')
        else:
          self._last_precipherblock = _string_to_bytes(iv)

        self._remaining_block = [ ]

        AESBlockModeOfOperation.__init__(self, key)

    def encrypt(self, plaintext):
        encrypted = [ ]
        for p in _string_to_bytes(plaintext):
            if len(self._remaining_block) == 0:
                self._remaining_block = self._aes.encrypt(self._last_precipherblock)
                self._last_precipherblock = [ ]
            precipherbyte = self._remaining_block.pop(0)
            self._last_precipherblock.append(precipherbyte)
            cipherbyte = p ^ precipherbyte
            encrypted.append(cipherbyte)

        return _bytes_to_string(encrypted)

    def decrypt(self, ciphertext):
        # AES-OFB is symetric
        return self.encrypt(ciphertext)



class AESModeOfOperationCTR(AESStreamModeOfOperation):
    '''AES Counter Mode of Operation.

       o A stream-cipher, so input does not need to be padded to blocks,
         allowing arbitrary length data.
       o The counter must be the same size as the key size (ie. len(key))
       o Each block independant of the other, so a corrupt byte will not
         damage future blocks.
       o Each block has a uniue counter value associated with it, which
         contributes to the encrypted value, so no data patterns are
         leaked.
       o Also known as: Counter Mode (CM), Integer Counter Mode (ICM) and
         Segmented Integer Counter (SIC

   Security Notes:
       o This method (and CBC) ARE recommended.
       o Each message block is associated with a counter value which must be
         unique for ALL messages with the same key. Otherwise security may be
         compromised.

    Also see:

       o https://en.wikipedia.org/wiki/Block_cipher_mode_of_operation#Counter_.28CTR.29
       o See NIST SP800-38A (http://csrc.nist.gov/publications/nistpubs/800-38a/sp800-38a.pdf); section 6.5
         and Appendix B for managing the initial counter'''


    name = "Counter (CTR)"

    def __init__(self, key, counter = None):
        AESBlockModeOfOperation.__init__(self, key)

        if counter is None:
            counter = Counter()

        self._counter = counter
        self._remaining_counter = [ ]

    def encrypt(self, plaintext):
        while len(self._remaining_counter) < len(plaintext):
            self._remaining_counter += self._aes.encrypt(self._counter.value)
            self._counter.increment()

        plaintext = _string_to_bytes(plaintext)

        encrypted = [ (p ^ c) for (p, c) in zip(plaintext, self._remaining_counter) ]
        self._remaining_counter = self._remaining_counter[len(encrypted):]

        return _bytes_to_string(encrypted)

    def decrypt(self, crypttext):
        # AES-CTR is symetric
        return self.encrypt(crypttext)


# Simple lookup table for each mode
AESModesOfOperation = dict(
    ctr = AESModeOfOperationCTR,
    cbc = AESModeOfOperationCBC,
    cfb = AESModeOfOperationCFB,
    ecb = AESModeOfOperationECB,
    ofb = AESModeOfOperationOFB,
)




############################################################
### File: api.py
############################################################
# -*- coding: utf-8 -*-

"""
requests.api
~~~~~~~~~~~~

This module implements the Requests API.

:copyright: (c) 2012 by Kenneth Reitz.
:license: Apache2, see LICENSE for more details.
"""

from . import sessions


def request(method, url, **kwargs):
    """Constructs and sends a :class:`Request <Request>`.

    :param method: method for the new :class:`Request` object: ``GET``, ``OPTIONS``, ``HEAD``, ``POST``, ``PUT``, ``PATCH``, or ``DELETE``.
    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) A JSON serializable Python object to send in the body of the :class:`Request`.
    :param headers: (optional) Dictionary of HTTP Headers to send with the :class:`Request`.
    :param cookies: (optional) Dict or CookieJar object to send with the :class:`Request`.
    :param files: (optional) Dictionary of ``'name': file-like-objects`` (or ``{'name': file-tuple}``) for multipart encoding upload.
        ``file-tuple`` can be a 2-tuple ``('filename', fileobj)``, 3-tuple ``('filename', fileobj, 'content_type')``
        or a 4-tuple ``('filename', fileobj, 'content_type', custom_headers)``, where ``'content-type'`` is a string
        defining the content type of the given file and ``custom_headers`` a dict-like object containing additional headers
        to add for the file.
    :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth.
    :param timeout: (optional) How many seconds to wait for the server to send data
        before giving up, as a float, or a :ref:`(connect timeout, read
        timeout) <timeouts>` tuple.
    :type timeout: float or tuple
    :param allow_redirects: (optional) Boolean. Enable/disable GET/OPTIONS/POST/PUT/PATCH/DELETE/HEAD redirection. Defaults to ``True``.
    :type allow_redirects: bool
    :param proxies: (optional) Dictionary mapping protocol to the URL of the proxy.
    :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``.
    :param stream: (optional) if ``False``, the response content will be immediately downloaded.
    :param cert: (optional) if String, path to ssl client cert file (.pem). If Tuple, ('cert', 'key') pair.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response

    Usage::

      >>> import requests
      >>> req = requests.request('GET', 'https://httpbin.org/get')
      >>> req
      <Response [200]>
    """

    # By using the 'with' statement we are sure the session is closed, thus we
    # avoid leaving sockets open which can trigger a ResourceWarning in some
    # cases, and look like a memory leak in others.
    with sessions.Session() as session:
        return session.request(method=method, url=url, **kwargs)


def get(url, params=None, **kwargs):
    r"""Sends a GET request.

    :param url: URL for the new :class:`Request` object.
    :param params: (optional) Dictionary, list of tuples or bytes to send
        in the query string for the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    """

    return request('get', url, params=params, **kwargs)


def options(url, **kwargs):
    r"""Sends an OPTIONS request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    """

    return request('options', url, **kwargs)


def head(url, **kwargs):
    r"""Sends a HEAD request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes. If
        `allow_redirects` is not provided, it will be set to `False` (as
        opposed to the default :meth:`request` behavior).
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    """

    kwargs.setdefault('allow_redirects', False)
    return request('head', url, **kwargs)


def post(url, data=None, json=None, **kwargs):
    r"""Sends a POST request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    """

    return request('post', url, data=data, json=json, **kwargs)


def put(url, data=None, **kwargs):
    r"""Sends a PUT request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    """

    return request('put', url, data=data, **kwargs)


def patch(url, data=None, **kwargs):
    r"""Sends a PATCH request.

    :param url: URL for the new :class:`Request` object.
    :param data: (optional) Dictionary, list of tuples, bytes, or file-like
        object to send in the body of the :class:`Request`.
    :param json: (optional) json data to send in the body of the :class:`Request`.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    """

    return request('patch', url, data=data, **kwargs)


def delete(url, **kwargs):
    r"""Sends a DELETE request.

    :param url: URL for the new :class:`Request` object.
    :param \*\*kwargs: Optional arguments that ``request`` takes.
    :return: :class:`Response <Response>` object
    :rtype: requests.Response
    """

    return request('delete', url, **kwargs)




############################################################
### File: arrow.py
############################################################
# -*- coding: utf-8 -*-
"""
Provides the :class:`Arrow <arrow.arrow.Arrow>` class, an enhanced ``datetime``
replacement.

"""

from __future__ import absolute_import

import calendar
import sys
from datetime import datetime, timedelta
from datetime import tzinfo as dt_tzinfo
from math import trunc

from dateutil import tz as dateutil_tz
from dateutil.relativedelta import relativedelta

from arrow import formatter, locales, parser, util


class Arrow(object):
    """An :class:`Arrow <arrow.arrow.Arrow>` object.

    Implements the ``datetime`` interface, behaving as an aware ``datetime`` while implementing
    additional functionality.

    :param year: the calendar year.
    :param month: the calendar month.
    :param day: the calendar day.
    :param hour: (optional) the hour. Defaults to 0.
    :param minute: (optional) the minute, Defaults to 0.
    :param second: (optional) the second, Defaults to 0.
    :param microsecond: (optional) the microsecond. Defaults 0.
    :param tzinfo: (optional) A timezone expression.  Defaults to UTC.

    .. _tz-expr:

    Recognized timezone expressions:

        - A ``tzinfo`` object.
        - A ``str`` describing a timezone, similar to 'US/Pacific', or 'Europe/Berlin'.
        - A ``str`` in ISO 8601 style, as in '+07:00'.
        - A ``str``, one of the following:  'local', 'utc', 'UTC'.

    Usage::

        >>> import arrow
        >>> arrow.Arrow(2013, 5, 5, 12, 30, 45)
        <Arrow [2013-05-05T12:30:45+00:00]>

    """

    resolution = datetime.resolution

    _ATTRS = ["year", "month", "day", "hour", "minute", "second", "microsecond"]
    _ATTRS_PLURAL = ["{}s".format(a) for a in _ATTRS]
    _MONTHS_PER_QUARTER = 3
    _SECS_PER_MINUTE = float(60)
    _SECS_PER_HOUR = float(60 * 60)
    _SECS_PER_DAY = float(60 * 60 * 24)
    _SECS_PER_WEEK = float(60 * 60 * 24 * 7)
    _SECS_PER_MONTH = float(60 * 60 * 24 * 30.5)
    _SECS_PER_YEAR = float(60 * 60 * 24 * 365.25)

    def __init__(
        self, year, month, day, hour=0, minute=0, second=0, microsecond=0, tzinfo=None
    ):
        if tzinfo is None:
            tzinfo = dateutil_tz.tzutc()
        # detect that tzinfo is a pytz object (issue #626)
        elif (
            isinstance(tzinfo, dt_tzinfo)
            and hasattr(tzinfo, "localize")
            and hasattr(tzinfo, "zone")
            and tzinfo.zone
        ):
            tzinfo = parser.TzinfoParser.parse(tzinfo.zone)
        elif util.isstr(tzinfo):
            tzinfo = parser.TzinfoParser.parse(tzinfo)

        self._datetime = datetime(
            year, month, day, hour, minute, second, microsecond, tzinfo
        )

    # factories: single object, both original and from datetime.

    @classmethod
    def now(cls, tzinfo=None):
        """Constructs an :class:`Arrow <arrow.arrow.Arrow>` object, representing "now" in the given
        timezone.

        :param tzinfo: (optional) a ``tzinfo`` object. Defaults to local time.

        Usage::

            >>> arrow.now('Asia/Baku')
            <Arrow [2019-01-24T20:26:31.146412+04:00]>

        """

        if tzinfo is None:
            tzinfo = dateutil_tz.tzlocal()
        dt = datetime.now(tzinfo)

        return cls(
            dt.year,
            dt.month,
            dt.day,
            dt.hour,
            dt.minute,
            dt.second,
            dt.microsecond,
            dt.tzinfo,
        )

    @classmethod
    def utcnow(cls):
        """ Constructs an :class:`Arrow <arrow.arrow.Arrow>` object, representing "now" in UTC
        time.

        Usage::

            >>> arrow.utcnow()
            <Arrow [2019-01-24T16:31:40.651108+00:00]>

        """

        dt = datetime.now(dateutil_tz.tzutc())

        return cls(
            dt.year,
            dt.month,
            dt.day,
            dt.hour,
            dt.minute,
            dt.second,
            dt.microsecond,
            dt.tzinfo,
        )

    @classmethod
    def fromtimestamp(cls, timestamp, tzinfo=None):
        """ Constructs an :class:`Arrow <arrow.arrow.Arrow>` object from a timestamp, converted to
        the given timezone.

        :param timestamp: an ``int`` or ``float`` timestamp, or a ``str`` that converts to either.
        :param tzinfo: (optional) a ``tzinfo`` object.  Defaults to local time.
        """

        if tzinfo is None:
            tzinfo = dateutil_tz.tzlocal()
        elif util.isstr(tzinfo):
            tzinfo = parser.TzinfoParser.parse(tzinfo)

        if not util.is_timestamp(timestamp):
            raise ValueError(
                "The provided timestamp '{}' is invalid.".format(timestamp)
            )

        timestamp = util.normalize_timestamp(float(timestamp))
        dt = datetime.fromtimestamp(timestamp, tzinfo)

        return cls(
            dt.year,
            dt.month,
            dt.day,
            dt.hour,
            dt.minute,
            dt.second,
            dt.microsecond,
            dt.tzinfo,
        )

    @classmethod
    def utcfromtimestamp(cls, timestamp):
        """Constructs an :class:`Arrow <arrow.arrow.Arrow>` object from a timestamp, in UTC time.

        :param timestamp: an ``int`` or ``float`` timestamp, or a ``str`` that converts to either.

        """

        if not util.is_timestamp(timestamp):
            raise ValueError(
                "The provided timestamp '{}' is invalid.".format(timestamp)
            )

        timestamp = util.normalize_timestamp(float(timestamp))
        dt = datetime.utcfromtimestamp(timestamp)

        return cls(
            dt.year,
            dt.month,
            dt.day,
            dt.hour,
            dt.minute,
            dt.second,
            dt.microsecond,
            dateutil_tz.tzutc(),
        )

    @classmethod
    def fromdatetime(cls, dt, tzinfo=None):
        """ Constructs an :class:`Arrow <arrow.arrow.Arrow>` object from a ``datetime`` and
        optional replacement timezone.

        :param dt: the ``datetime``
        :param tzinfo: (optional) A :ref:`timezone expression <tz-expr>`.  Defaults to ``dt``'s
            timezone, or UTC if naive.

        If you only want to replace the timezone of naive datetimes::

            >>> dt
            datetime.datetime(2013, 5, 5, 0, 0, tzinfo=tzutc())
            >>> arrow.Arrow.fromdatetime(dt, dt.tzinfo or 'US/Pacific')
            <Arrow [2013-05-05T00:00:00+00:00]>

        """

        if tzinfo is None:
            if dt.tzinfo is None:
                tzinfo = dateutil_tz.tzutc()
            else:
                tzinfo = dt.tzinfo

        return cls(
            dt.year,
            dt.month,
            dt.day,
            dt.hour,
            dt.minute,
            dt.second,
            dt.microsecond,
            tzinfo,
        )

    @classmethod
    def fromdate(cls, date, tzinfo=None):
        """ Constructs an :class:`Arrow <arrow.arrow.Arrow>` object from a ``date`` and optional
        replacement timezone.  Time values are set to 0.

        :param date: the ``date``
        :param tzinfo: (optional) A :ref:`timezone expression <tz-expr>`.  Defaults to UTC.
        """

        if tzinfo is None:
            tzinfo = dateutil_tz.tzutc()

        return cls(date.year, date.month, date.day, tzinfo=tzinfo)

    @classmethod
    def strptime(cls, date_str, fmt, tzinfo=None):
        """ Constructs an :class:`Arrow <arrow.arrow.Arrow>` object from a date string and format,
        in the style of ``datetime.strptime``.  Optionally replaces the parsed timezone.

        :param date_str: the date string.
        :param fmt: the format string.
        :param tzinfo: (optional) A :ref:`timezone expression <tz-expr>`.  Defaults to the parsed
            timezone if ``fmt`` contains a timezone directive, otherwise UTC.

        Usage::

            >>> arrow.Arrow.strptime('20-01-2019 15:49:10', '%d-%m-%Y %H:%M:%S')
            <Arrow [2019-01-20T15:49:10+00:00]>

        """

        dt = datetime.strptime(date_str, fmt)
        if tzinfo is None:
            tzinfo = dt.tzinfo

        return cls(
            dt.year,
            dt.month,
            dt.day,
            dt.hour,
            dt.minute,
            dt.second,
            dt.microsecond,
            tzinfo,
        )

    # factories: ranges and spans

    @classmethod
    def range(cls, frame, start, end=None, tz=None, limit=None):
        """ Returns an iterator of :class:`Arrow <arrow.arrow.Arrow>` objects, representing
        points in time between two inputs.

        :param frame: The timeframe.  Can be any ``datetime`` property (day, hour, minute...).
        :param start: A datetime expression, the start of the range.
        :param end: (optional) A datetime expression, the end of the range.
        :param tz: (optional) A :ref:`timezone expression <tz-expr>`.  Defaults to
            ``start``'s timezone, or UTC if ``start`` is naive.
        :param limit: (optional) A maximum number of tuples to return.

        **NOTE**: The ``end`` or ``limit`` must be provided.  Call with ``end`` alone to
        return the entire range.  Call with ``limit`` alone to return a maximum # of results from
        the start.  Call with both to cap a range at a maximum # of results.

        **NOTE**: ``tz`` internally **replaces** the timezones of both ``start`` and ``end`` before
        iterating.  As such, either call with naive objects and ``tz``, or aware objects from the
        same timezone and no ``tz``.

        Supported frame values: year, quarter, month, week, day, hour, minute, second.

        Recognized datetime expressions:

            - An :class:`Arrow <arrow.arrow.Arrow>` object.
            - A ``datetime`` object.

        Usage::

            >>> start = datetime(2013, 5, 5, 12, 30)
            >>> end = datetime(2013, 5, 5, 17, 15)
            >>> for r in arrow.Arrow.range('hour', start, end):
            ...     print(repr(r))
            ...
            <Arrow [2013-05-05T12:30:00+00:00]>
            <Arrow [2013-05-05T13:30:00+00:00]>
            <Arrow [2013-05-05T14:30:00+00:00]>
            <Arrow [2013-05-05T15:30:00+00:00]>
            <Arrow [2013-05-05T16:30:00+00:00]>

        **NOTE**: Unlike Python's ``range``, ``end`` *may* be included in the returned iterator::

            >>> start = datetime(2013, 5, 5, 12, 30)
            >>> end = datetime(2013, 5, 5, 13, 30)
            >>> for r in arrow.Arrow.range('hour', start, end):
            ...     print(repr(r))
            ...
            <Arrow [2013-05-05T12:30:00+00:00]>
            <Arrow [2013-05-05T13:30:00+00:00]>

        """

        _, frame_relative, relative_steps = cls._get_frames(frame)

        tzinfo = cls._get_tzinfo(start.tzinfo if tz is None else tz)

        start = cls._get_datetime(start).replace(tzinfo=tzinfo)
        end, limit = cls._get_iteration_params(end, limit)
        end = cls._get_datetime(end).replace(tzinfo=tzinfo)

        current = cls.fromdatetime(start)
        i = 0

        while current <= end and i < limit:
            i += 1
            yield current

            values = [getattr(current, f) for f in cls._ATTRS]
            current = cls(*values, tzinfo=tzinfo) + relativedelta(
                **{frame_relative: relative_steps}
            )

    @classmethod
    def span_range(cls, frame, start, end, tz=None, limit=None, bounds="[)"):
        """ Returns an iterator of tuples, each :class:`Arrow <arrow.arrow.Arrow>` objects,
        representing a series of timespans between two inputs.

        :param frame: The timeframe.  Can be any ``datetime`` property (day, hour, minute...).
        :param start: A datetime expression, the start of the range.
        :param end: (optional) A datetime expression, the end of the range.
        :param tz: (optional) A :ref:`timezone expression <tz-expr>`.  Defaults to
            ``start``'s timezone, or UTC if ``start`` is naive.
        :param limit: (optional) A maximum number of tuples to return.
        :param bounds: (optional) a ``str`` of either '()', '(]', '[)', or '[]' that specifies
            whether to include or exclude the start and end values in each span in the range. '(' excludes
            the start, '[' includes the start, ')' excludes the end, and ']' includes the end.
            If the bounds are not specified, the default bound '[)' is used.

        **NOTE**: The ``end`` or ``limit`` must be provided.  Call with ``end`` alone to
        return the entire range.  Call with ``limit`` alone to return a maximum # of results from
        the start.  Call with both to cap a range at a maximum # of results.

        **NOTE**: ``tz`` internally **replaces** the timezones of both ``start`` and ``end`` before
        iterating.  As such, either call with naive objects and ``tz``, or aware objects from the
        same timezone and no ``tz``.

        Supported frame values: year, quarter, month, week, day, hour, minute, second.

        Recognized datetime expressions:

            - An :class:`Arrow <arrow.arrow.Arrow>` object.
            - A ``datetime`` object.

        **NOTE**: Unlike Python's ``range``, ``end`` will *always* be included in the returned
        iterator of timespans.

        Usage:

            >>> start = datetime(2013, 5, 5, 12, 30)
            >>> end = datetime(2013, 5, 5, 17, 15)
            >>> for r in arrow.Arrow.span_range('hour', start, end):
            ...     print(r)
            ...
            (<Arrow [2013-05-05T12:00:00+00:00]>, <Arrow [2013-05-05T12:59:59.999999+00:00]>)
            (<Arrow [2013-05-05T13:00:00+00:00]>, <Arrow [2013-05-05T13:59:59.999999+00:00]>)
            (<Arrow [2013-05-05T14:00:00+00:00]>, <Arrow [2013-05-05T14:59:59.999999+00:00]>)
            (<Arrow [2013-05-05T15:00:00+00:00]>, <Arrow [2013-05-05T15:59:59.999999+00:00]>)
            (<Arrow [2013-05-05T16:00:00+00:00]>, <Arrow [2013-05-05T16:59:59.999999+00:00]>)
            (<Arrow [2013-05-05T17:00:00+00:00]>, <Arrow [2013-05-05T17:59:59.999999+00:00]>)

        """

        tzinfo = cls._get_tzinfo(start.tzinfo if tz is None else tz)
        start = cls.fromdatetime(start, tzinfo).span(frame)[0]
        _range = cls.range(frame, start, end, tz, limit)
        return (r.span(frame, bounds=bounds) for r in _range)

    @classmethod
    def interval(cls, frame, start, end, interval=1, tz=None, bounds="[)"):
        """ Returns an iterator of tuples, each :class:`Arrow <arrow.arrow.Arrow>` objects,
        representing a series of intervals between two inputs.

        :param frame: The timeframe.  Can be any ``datetime`` property (day, hour, minute...).
        :param start: A datetime expression, the start of the range.
        :param end: (optional) A datetime expression, the end of the range.
        :param interval: (optional) Time interval for the given time frame.
        :param tz: (optional) A timezone expression.  Defaults to UTC.
        :param bounds: (optional) a ``str`` of either '()', '(]', '[)', or '[]' that specifies
            whether to include or exclude the start and end values in the intervals. '(' excludes
            the start, '[' includes the start, ')' excludes the end, and ']' includes the end.
            If the bounds are not specified, the default bound '[)' is used.

        Supported frame values: year, quarter, month, week, day, hour, minute, second

        Recognized datetime expressions:

            - An :class:`Arrow <arrow.arrow.Arrow>` object.
            - A ``datetime`` object.

        Recognized timezone expressions:

            - A ``tzinfo`` object.
            - A ``str`` describing a timezone, similar to 'US/Pacific', or 'Europe/Berlin'.
            - A ``str`` in ISO 8601 style, as in '+07:00'.
            - A ``str``, one of the following:  'local', 'utc', 'UTC'.

        Usage:

            >>> start = datetime(2013, 5, 5, 12, 30)
            >>> end = datetime(2013, 5, 5, 17, 15)
            >>> for r in arrow.Arrow.interval('hour', start, end, 2):
            ...     print r
            ...
            (<Arrow [2013-05-05T12:00:00+00:00]>, <Arrow [2013-05-05T13:59:59.999999+00:00]>)
            (<Arrow [2013-05-05T14:00:00+00:00]>, <Arrow [2013-05-05T15:59:59.999999+00:00]>)
            (<Arrow [2013-05-05T16:00:00+00:00]>, <Arrow [2013-05-05T17:59:59.999999+00:0]>)
        """
        if interval < 1:
            raise ValueError("interval has to be a positive integer")

        spanRange = iter(cls.span_range(frame, start, end, tz, bounds=bounds))
        while True:
            try:
                intvlStart, intvlEnd = next(spanRange)
                for _ in range(interval - 1):
                    _, intvlEnd = next(spanRange)
                yield intvlStart, intvlEnd
            except StopIteration:
                return

    # representations

    def __repr__(self):
        return "<{} [{}]>".format(self.__class__.__name__, self.__str__())

    def __str__(self):
        return self._datetime.isoformat()

    def __format__(self, formatstr):

        if len(formatstr) > 0:
            return self.format(formatstr)

        return str(self)

    def __hash__(self):
        return self._datetime.__hash__()

    # attributes & properties

    def __getattr__(self, name):

        if name == "week":
            return self.isocalendar()[1]

        if name == "quarter":
            return int((self.month - 1) / self._MONTHS_PER_QUARTER) + 1

        if not name.startswith("_"):
            value = getattr(self._datetime, name, None)

            if value is not None:
                return value

        return object.__getattribute__(self, name)

    @property
    def tzinfo(self):
        """ Gets the ``tzinfo`` of the :class:`Arrow <arrow.arrow.Arrow>` object.

        Usage::

            >>> arw=arrow.utcnow()
            >>> arw.tzinfo
            tzutc()

        """

        return self._datetime.tzinfo

    @tzinfo.setter
    def tzinfo(self, tzinfo):
        """ Sets the ``tzinfo`` of the :class:`Arrow <arrow.arrow.Arrow>` object. """

        self._datetime = self._datetime.replace(tzinfo=tzinfo)

    @property
    def datetime(self):
        """ Returns a datetime representation of the :class:`Arrow <arrow.arrow.Arrow>` object.

        Usage::

            >>> arw=arrow.utcnow()
            >>> arw.datetime
            datetime.datetime(2019, 1, 24, 16, 35, 27, 276649, tzinfo=tzutc())

        """

        return self._datetime

    @property
    def naive(self):
        """ Returns a naive datetime representation of the :class:`Arrow <arrow.arrow.Arrow>`
        object.

        Usage::

            >>> nairobi = arrow.now('Africa/Nairobi')
            >>> nairobi
            <Arrow [2019-01-23T19:27:12.297999+03:00]>
            >>> nairobi.naive
            datetime.datetime(2019, 1, 23, 19, 27, 12, 297999)

        """

        return self._datetime.replace(tzinfo=None)

    @property
    def timestamp(self):
        """ Returns a timestamp representation of the :class:`Arrow <arrow.arrow.Arrow>` object, in
        UTC time.

        Usage::

            >>> arrow.utcnow().timestamp
            1548260567

        """

        return calendar.timegm(self._datetime.utctimetuple())

    @property
    def float_timestamp(self):
        """ Returns a floating-point representation of the :class:`Arrow <arrow.arrow.Arrow>`
        object, in UTC time.

        Usage::

            >>> arrow.utcnow().float_timestamp
            1548260516.830896

        """

        return self.timestamp + float(self.microsecond) / 1000000

    # mutation and duplication.

    def clone(self):
        """ Returns a new :class:`Arrow <arrow.arrow.Arrow>` object, cloned from the current one.

        Usage:

            >>> arw = arrow.utcnow()
            >>> cloned = arw.clone()

        """

        return self.fromdatetime(self._datetime)

    def replace(self, **kwargs):
        """ Returns a new :class:`Arrow <arrow.arrow.Arrow>` object with attributes updated
        according to inputs.

        Use property names to set their value absolutely::

            >>> import arrow
            >>> arw = arrow.utcnow()
            >>> arw
            <Arrow [2013-05-11T22:27:34.787885+00:00]>
            >>> arw.replace(year=2014, month=6)
            <Arrow [2014-06-11T22:27:34.787885+00:00]>

        You can also replace the timezone without conversion, using a
        :ref:`timezone expression <tz-expr>`::

            >>> arw.replace(tzinfo=tz.tzlocal())
            <Arrow [2013-05-11T22:27:34.787885-07:00]>

        """

        absolute_kwargs = {}

        for key, value in kwargs.items():

            if key in self._ATTRS:
                absolute_kwargs[key] = value
            elif key in ["week", "quarter"]:
                raise AttributeError("setting absolute {} is not supported".format(key))
            elif key != "tzinfo":
                raise AttributeError('unknown attribute: "{}"'.format(key))

        current = self._datetime.replace(**absolute_kwargs)

        tzinfo = kwargs.get("tzinfo")

        if tzinfo is not None:
            tzinfo = self._get_tzinfo(tzinfo)
            current = current.replace(tzinfo=tzinfo)

        return self.fromdatetime(current)

    def shift(self, **kwargs):
        """ Returns a new :class:`Arrow <arrow.arrow.Arrow>` object with attributes updated
        according to inputs.

        Use pluralized property names to relatively shift their current value:

        >>> import arrow
        >>> arw = arrow.utcnow()
        >>> arw
        <Arrow [2013-05-11T22:27:34.787885+00:00]>
        >>> arw.shift(years=1, months=-1)
        <Arrow [2014-04-11T22:27:34.787885+00:00]>

        Day-of-the-week relative shifting can use either Python's weekday numbers
        (Monday = 0, Tuesday = 1 .. Sunday = 6) or using dateutil.relativedelta's
        day instances (MO, TU .. SU).  When using weekday numbers, the returned
        date will always be greater than or equal to the starting date.

        Using the above code (which is a Saturday) and asking it to shift to Saturday:

        >>> arw.shift(weekday=5)
        <Arrow [2013-05-11T22:27:34.787885+00:00]>

        While asking for a Monday:

        >>> arw.shift(weekday=0)
        <Arrow [2013-05-13T22:27:34.787885+00:00]>

        """

        relative_kwargs = {}
        additional_attrs = ["weeks", "quarters", "weekday"]

        for key, value in kwargs.items():

            if key in self._ATTRS_PLURAL or key in additional_attrs:
                relative_kwargs[key] = value
            else:
                raise AttributeError(
                    "Invalid shift time frame. Please select one of the following: {}.".format(
                        ", ".join(self._ATTRS_PLURAL + additional_attrs)
                    )
                )

        # core datetime does not support quarters, translate to months.
        relative_kwargs.setdefault("months", 0)
        relative_kwargs["months"] += (
            relative_kwargs.pop("quarters", 0) * self._MONTHS_PER_QUARTER
        )

        current = self._datetime + relativedelta(**relative_kwargs)

        return self.fromdatetime(current)

    def to(self, tz):
        """ Returns a new :class:`Arrow <arrow.arrow.Arrow>` object, converted
        to the target timezone.

        :param tz: A :ref:`timezone expression <tz-expr>`.

        Usage::

            >>> utc = arrow.utcnow()
            >>> utc
            <Arrow [2013-05-09T03:49:12.311072+00:00]>

            >>> utc.to('US/Pacific')
            <Arrow [2013-05-08T20:49:12.311072-07:00]>

            >>> utc.to(tz.tzlocal())
            <Arrow [2013-05-08T20:49:12.311072-07:00]>

            >>> utc.to('-07:00')
            <Arrow [2013-05-08T20:49:12.311072-07:00]>

            >>> utc.to('local')
            <Arrow [2013-05-08T20:49:12.311072-07:00]>

            >>> utc.to('local').to('utc')
            <Arrow [2013-05-09T03:49:12.311072+00:00]>

        """

        if not isinstance(tz, dt_tzinfo):
            tz = parser.TzinfoParser.parse(tz)

        dt = self._datetime.astimezone(tz)

        return self.__class__(
            dt.year,
            dt.month,
            dt.day,
            dt.hour,
            dt.minute,
            dt.second,
            dt.microsecond,
            dt.tzinfo,
        )

    @classmethod
    def _validate_bounds(cls, bounds):
        if bounds != "()" and bounds != "(]" and bounds != "[)" and bounds != "[]":
            raise AttributeError(
                'Invalid bounds. Please select between "()", "(]", "[)", or "[]".'
            )

    def span(self, frame, count=1, bounds="[)"):
        """ Returns two new :class:`Arrow <arrow.arrow.Arrow>` objects, representing the timespan
        of the :class:`Arrow <arrow.arrow.Arrow>` object in a given timeframe.

        :param frame: the timeframe.  Can be any ``datetime`` property (day, hour, minute...).
        :param count: (optional) the number of frames to span.
        :param bounds: (optional) a ``str`` of either '()', '(]', '[)', or '[]' that specifies
            whether to include or exclude the start and end values in the span. '(' excludes
            the start, '[' includes the start, ')' excludes the end, and ']' includes the end.
            If the bounds are not specified, the default bound '[)' is used.

        Supported frame values: year, quarter, month, week, day, hour, minute, second.

        Usage::

            >>> arrow.utcnow()
            <Arrow [2013-05-09T03:32:36.186203+00:00]>

            >>> arrow.utcnow().span('hour')
            (<Arrow [2013-05-09T03:00:00+00:00]>, <Arrow [2013-05-09T03:59:59.999999+00:00]>)

            >>> arrow.utcnow().span('day')
            (<Arrow [2013-05-09T00:00:00+00:00]>, <Arrow [2013-05-09T23:59:59.999999+00:00]>)

            >>> arrow.utcnow().span('day', count=2)
            (<Arrow [2013-05-09T00:00:00+00:00]>, <Arrow [2013-05-10T23:59:59.999999+00:00]>)

            >>> arrow.utcnow().span('day', bounds='[]')
            (<Arrow [2013-05-09T00:00:00+00:00]>, <Arrow [2013-05-10T00:00:00+00:00]>)

        """

        self._validate_bounds(bounds)

        frame_absolute, frame_relative, relative_steps = self._get_frames(frame)

        if frame_absolute == "week":
            attr = "day"
        elif frame_absolute == "quarter":
            attr = "month"
        else:
            attr = frame_absolute

        index = self._ATTRS.index(attr)
        frames = self._ATTRS[: index + 1]

        values = [getattr(self, f) for f in frames]

        for _ in range(3 - len(values)):
            values.append(1)

        floor = self.__class__(*values, tzinfo=self.tzinfo)

        if frame_absolute == "week":
            floor = floor + relativedelta(days=-(self.isoweekday() - 1))
        elif frame_absolute == "quarter":
            floor = floor + relativedelta(months=-((self.month - 1) % 3))

        ceil = floor + relativedelta(**{frame_relative: count * relative_steps})

        if bounds[0] == "(":
            floor += relativedelta(microseconds=1)

        if bounds[1] == ")":
            ceil += relativedelta(microseconds=-1)

        return floor, ceil

    def floor(self, frame):
        """ Returns a new :class:`Arrow <arrow.arrow.Arrow>` object, representing the "floor"
        of the timespan of the :class:`Arrow <arrow.arrow.Arrow>` object in a given timeframe.
        Equivalent to the first element in the 2-tuple returned by
        :func:`span <arrow.arrow.Arrow.span>`.

        :param frame: the timeframe.  Can be any ``datetime`` property (day, hour, minute...).

        Usage::

            >>> arrow.utcnow().floor('hour')
            <Arrow [2013-05-09T03:00:00+00:00]>
        """

        return self.span(frame)[0]

    def ceil(self, frame):
        """ Returns a new :class:`Arrow <arrow.arrow.Arrow>` object, representing the "ceiling"
        of the timespan of the :class:`Arrow <arrow.arrow.Arrow>` object in a given timeframe.
        Equivalent to the second element in the 2-tuple returned by
        :func:`span <arrow.arrow.Arrow.span>`.

        :param frame: the timeframe.  Can be any ``datetime`` property (day, hour, minute...).

        Usage::

            >>> arrow.utcnow().ceil('hour')
            <Arrow [2013-05-09T03:59:59.999999+00:00]>
        """

        return self.span(frame)[1]

    # string output and formatting.

    def format(self, fmt="YYYY-MM-DD HH:mm:ssZZ", locale="en_us"):
        """ Returns a string representation of the :class:`Arrow <arrow.arrow.Arrow>` object,
        formatted according to a format string.

        :param fmt: the format string.

        Usage::

            >>> arrow.utcnow().format('YYYY-MM-DD HH:mm:ss ZZ')
            '2013-05-09 03:56:47 -00:00'

            >>> arrow.utcnow().format('X')
            '1368071882'

            >>> arrow.utcnow().format('MMMM DD, YYYY')
            'May 09, 2013'

            >>> arrow.utcnow().format()
            '2013-05-09 03:56:47 -00:00'

        """

        return formatter.DateTimeFormatter(locale).format(self._datetime, fmt)

    def humanize(
        self, other=None, locale="en_us", only_distance=False, granularity="auto"
    ):
        """ Returns a localized, humanized representation of a relative difference in time.

        :param other: (optional) an :class:`Arrow <arrow.arrow.Arrow>` or ``datetime`` object.
            Defaults to now in the current :class:`Arrow <arrow.arrow.Arrow>` object's timezone.
        :param locale: (optional) a ``str`` specifying a locale.  Defaults to 'en_us'.
        :param only_distance: (optional) returns only time difference eg: "11 seconds" without "in" or "ago" part.
        :param granularity: (optional) defines the precision of the output. Set it to strings 'second', 'minute',
                           'hour', 'day', 'week', 'month' or 'year' or a list of any combination of these strings

        Usage::

            >>> earlier = arrow.utcnow().shift(hours=-2)
            >>> earlier.humanize()
            '2 hours ago'

            >>> later = earlier.shift(hours=4)
            >>> later.humanize(earlier)
            'in 4 hours'

        """

        locale_name = locale
        locale = locales.get_locale(locale)

        if other is None:
            utc = datetime.utcnow().replace(tzinfo=dateutil_tz.tzutc())
            dt = utc.astimezone(self._datetime.tzinfo)

        elif isinstance(other, Arrow):
            dt = other._datetime

        elif isinstance(other, datetime):
            if other.tzinfo is None:
                dt = other.replace(tzinfo=self._datetime.tzinfo)
            else:
                dt = other.astimezone(self._datetime.tzinfo)

        else:
            raise TypeError(
                "Invalid 'other' argument of type '{}'. "
                "Argument must be of type None, Arrow, or datetime.".format(
                    type(other).__name__
                )
            )

        if isinstance(granularity, list) and len(granularity) == 1:
            granularity = granularity[0]

        delta = int(round(util.total_seconds(self._datetime - dt)))
        sign = -1 if delta < 0 else 1
        diff = abs(delta)
        delta = diff

        try:
            if granularity == "auto":
                if diff < 10:
                    return locale.describe("now", only_distance=only_distance)

                if diff < 45:
                    seconds = sign * delta
                    return locale.describe(
                        "seconds", seconds, only_distance=only_distance
                    )

                elif diff < 90:
                    return locale.describe("minute", sign, only_distance=only_distance)
                elif diff < 2700:
                    minutes = sign * int(max(delta / 60, 2))
                    return locale.describe(
                        "minutes", minutes, only_distance=only_distance
                    )

                elif diff < 5400:
                    return locale.describe("hour", sign, only_distance=only_distance)
                elif diff < 79200:
                    hours = sign * int(max(delta / 3600, 2))
                    return locale.describe("hours", hours, only_distance=only_distance)

                # anything less than 48 hours should be 1 day
                elif diff < 172800:
                    return locale.describe("day", sign, only_distance=only_distance)
                elif diff < 554400:
                    days = sign * int(max(delta / 86400, 2))
                    return locale.describe("days", days, only_distance=only_distance)

                elif diff < 907200:
                    return locale.describe("week", sign, only_distance=only_distance)
                elif diff < 2419200:
                    weeks = sign * int(max(delta / 604800, 2))
                    return locale.describe("weeks", weeks, only_distance=only_distance)

                elif diff < 3888000:
                    return locale.describe("month", sign, only_distance=only_distance)
                elif diff < 29808000:
                    self_months = self._datetime.year * 12 + self._datetime.month
                    other_months = dt.year * 12 + dt.month

                    months = sign * int(max(abs(other_months - self_months), 2))

                    return locale.describe(
                        "months", months, only_distance=only_distance
                    )

                elif diff < 47260800:
                    return locale.describe("year", sign, only_distance=only_distance)
                else:
                    years = sign * int(max(delta / 31536000, 2))
                    return locale.describe("years", years, only_distance=only_distance)

            elif util.isstr(granularity):
                if granularity == "second":
                    delta = sign * delta
                    if abs(delta) < 2:
                        return locale.describe("now", only_distance=only_distance)
                elif granularity == "minute":
                    delta = sign * delta / self._SECS_PER_MINUTE
                elif granularity == "hour":
                    delta = sign * delta / self._SECS_PER_HOUR
                elif granularity == "day":
                    delta = sign * delta / self._SECS_PER_DAY
                elif granularity == "week":
                    delta = sign * delta / self._SECS_PER_WEEK
                elif granularity == "month":
                    delta = sign * delta / self._SECS_PER_MONTH
                elif granularity == "year":
                    delta = sign * delta / self._SECS_PER_YEAR
                else:
                    raise AttributeError(
                        "Invalid level of granularity. Please select between 'second', 'minute', 'hour', 'day', 'week', 'month' or 'year'"
                    )

                if trunc(abs(delta)) != 1:
                    granularity += "s"
                return locale.describe(granularity, delta, only_distance=only_distance)

            else:
                timeframes = []
                if "year" in granularity:
                    years = sign * delta / self._SECS_PER_YEAR
                    delta %= self._SECS_PER_YEAR
                    timeframes.append(["year", years])

                if "month" in granularity:
                    months = sign * delta / self._SECS_PER_MONTH
                    delta %= self._SECS_PER_MONTH
                    timeframes.append(["month", months])

                if "week" in granularity:
                    weeks = sign * delta / self._SECS_PER_WEEK
                    delta %= self._SECS_PER_WEEK
                    timeframes.append(["week", weeks])

                if "day" in granularity:
                    days = sign * delta / self._SECS_PER_DAY
                    delta %= self._SECS_PER_DAY
                    timeframes.append(["day", days])

                if "hour" in granularity:
                    hours = sign * delta / self._SECS_PER_HOUR
                    delta %= self._SECS_PER_HOUR
                    timeframes.append(["hour", hours])

                if "minute" in granularity:
                    minutes = sign * delta / self._SECS_PER_MINUTE
                    delta %= self._SECS_PER_MINUTE
                    timeframes.append(["minute", minutes])

                if "second" in granularity:
                    seconds = sign * delta
                    timeframes.append(["second", seconds])

                if len(timeframes) < len(granularity):
                    raise AttributeError(
                        "Invalid level of granularity. "
                        "Please select between 'second', 'minute', 'hour', 'day', 'week', 'month' or 'year'."
                    )

                for tf in timeframes:
                    # Make granularity plural if the delta is not equal to 1
                    if trunc(abs(tf[1])) != 1:
                        tf[0] += "s"
                return locale.describe_multi(timeframes, only_distance=only_distance)

        except KeyError as e:
            raise ValueError(
                "Humanization of the {} granularity is not currently translated in the '{}' locale. "
                "Please consider making a contribution to this locale.".format(
                    e, locale_name
                )
            )

    # query functions

    def is_between(self, start, end, bounds="()"):
        """ Returns a boolean denoting whether the specified date and time is between
        the start and end dates and times.

        :param start: an :class:`Arrow <arrow.arrow.Arrow>` object.
        :param end: an :class:`Arrow <arrow.arrow.Arrow>` object.
        :param bounds: (optional) a ``str`` of either '()', '(]', '[)', or '[]' that specifies
            whether to include or exclude the start and end values in the range. '(' excludes
            the start, '[' includes the start, ')' excludes the end, and ']' includes the end.
            If the bounds are not specified, the default bound '()' is used.

        Usage::

            >>> start = arrow.get(datetime(2013, 5, 5, 12, 30, 10))
            >>> end = arrow.get(datetime(2013, 5, 5, 12, 30, 36))
            >>> arrow.get(datetime(2013, 5, 5, 12, 30, 27)).is_between(start, end)
            True

            >>> start = arrow.get(datetime(2013, 5, 5))
            >>> end = arrow.get(datetime(2013, 5, 8))
            >>> arrow.get(datetime(2013, 5, 8)).is_between(start, end, '[]')
            True

            >>> start = arrow.get(datetime(2013, 5, 5))
            >>> end = arrow.get(datetime(2013, 5, 8))
            >>> arrow.get(datetime(2013, 5, 8)).is_between(start, end, '[)')
            False

        """

        self._validate_bounds(bounds)

        if not isinstance(start, Arrow):
            raise TypeError(
                "Can't parse start date argument type of '{}'".format(type(start))
            )

        if not isinstance(end, Arrow):
            raise TypeError(
                "Can't parse end date argument type of '{}'".format(type(end))
            )

        include_start = bounds[0] == "["
        include_end = bounds[1] == "]"

        target_timestamp = self.float_timestamp
        start_timestamp = start.float_timestamp
        end_timestamp = end.float_timestamp

        if include_start and include_end:
            return (
                target_timestamp >= start_timestamp
                and target_timestamp <= end_timestamp
            )
        elif include_start and not include_end:
            return (
                target_timestamp >= start_timestamp and target_timestamp < end_timestamp
            )
        elif not include_start and include_end:
            return (
                target_timestamp > start_timestamp and target_timestamp <= end_timestamp
            )
        else:
            return (
                target_timestamp > start_timestamp and target_timestamp < end_timestamp
            )

    # math

    def __add__(self, other):

        if isinstance(other, (timedelta, relativedelta)):
            return self.fromdatetime(self._datetime + other, self._datetime.tzinfo)

        return NotImplemented

    def __radd__(self, other):
        return self.__add__(other)

    def __sub__(self, other):

        if isinstance(other, (timedelta, relativedelta)):
            return self.fromdatetime(self._datetime - other, self._datetime.tzinfo)

        elif isinstance(other, datetime):
            return self._datetime - other

        elif isinstance(other, Arrow):
            return self._datetime - other._datetime

        return NotImplemented

    def __rsub__(self, other):

        if isinstance(other, datetime):
            return other - self._datetime

        return NotImplemented

    # comparisons

    def __eq__(self, other):

        if not isinstance(other, (Arrow, datetime)):
            return False

        return self._datetime == self._get_datetime(other)

    def __ne__(self, other):

        if not isinstance(other, (Arrow, datetime)):
            return True

        return not self.__eq__(other)

    def __gt__(self, other):

        if not isinstance(other, (Arrow, datetime)):
            return NotImplemented

        return self._datetime > self._get_datetime(other)

    def __ge__(self, other):

        if not isinstance(other, (Arrow, datetime)):
            return NotImplemented

        return self._datetime >= self._get_datetime(other)

    def __lt__(self, other):

        if not isinstance(other, (Arrow, datetime)):
            return NotImplemented

        return self._datetime < self._get_datetime(other)

    def __le__(self, other):

        if not isinstance(other, (Arrow, datetime)):
            return NotImplemented

        return self._datetime <= self._get_datetime(other)

    def __cmp__(self, other):
        if sys.version_info[0] < 3:  # pragma: no cover
            if not isinstance(other, (Arrow, datetime)):
                raise TypeError(
                    "can't compare '{}' to '{}'".format(type(self), type(other))
                )

    # datetime methods

    def date(self):
        """ Returns a ``date`` object with the same year, month and day.

        Usage::

            >>> arrow.utcnow().date()
            datetime.date(2019, 1, 23)

        """

        return self._datetime.date()

    def time(self):
        """ Returns a ``time`` object with the same hour, minute, second, microsecond.

        Usage::

            >>> arrow.utcnow().time()
            datetime.time(12, 15, 34, 68352)

        """

        return self._datetime.time()

    def timetz(self):
        """ Returns a ``time`` object with the same hour, minute, second, microsecond and
        tzinfo.

        Usage::

            >>> arrow.utcnow().timetz()
            datetime.time(12, 5, 18, 298893, tzinfo=tzutc())

        """

        return self._datetime.timetz()

    def astimezone(self, tz):
        """ Returns a ``datetime`` object, converted to the specified timezone.

        :param tz: a ``tzinfo`` object.

        Usage::

            >>> pacific=arrow.now('US/Pacific')
            >>> nyc=arrow.now('America/New_York').tzinfo
            >>> pacific.astimezone(nyc)
            datetime.datetime(2019, 1, 20, 10, 24, 22, 328172, tzinfo=tzfile('/usr/share/zoneinfo/America/New_York'))

        """

        return self._datetime.astimezone(tz)

    def utcoffset(self):
        """ Returns a ``timedelta`` object representing the whole number of minutes difference from
        UTC time.

        Usage::

            >>> arrow.now('US/Pacific').utcoffset()
            datetime.timedelta(-1, 57600)

        """

        return self._datetime.utcoffset()

    def dst(self):
        """ Returns the daylight savings time adjustment.

        Usage::

            >>> arrow.utcnow().dst()
            datetime.timedelta(0)

        """

        return self._datetime.dst()

    def timetuple(self):
        """ Returns a ``time.struct_time``, in the current timezone.

        Usage::

            >>> arrow.utcnow().timetuple()
            time.struct_time(tm_year=2019, tm_mon=1, tm_mday=20, tm_hour=15, tm_min=17, tm_sec=8, tm_wday=6, tm_yday=20, tm_isdst=0)

        """

        return self._datetime.timetuple()

    def utctimetuple(self):
        """ Returns a ``time.struct_time``, in UTC time.

        Usage::

            >>> arrow.utcnow().utctimetuple()
            time.struct_time(tm_year=2019, tm_mon=1, tm_mday=19, tm_hour=21, tm_min=41, tm_sec=7, tm_wday=5, tm_yday=19, tm_isdst=0)

        """

        return self._datetime.utctimetuple()

    def toordinal(self):
        """ Returns the proleptic Gregorian ordinal of the date.

        Usage::

            >>> arrow.utcnow().toordinal()
            737078

        """

        return self._datetime.toordinal()

    def weekday(self):
        """ Returns the day of the week as an integer (0-6).

        Usage::

            >>> arrow.utcnow().weekday()
            5

        """

        return self._datetime.weekday()

    def isoweekday(self):
        """ Returns the ISO day of the week as an integer (1-7).

        Usage::

            >>> arrow.utcnow().isoweekday()
            6

        """

        return self._datetime.isoweekday()

    def isocalendar(self):
        """ Returns a 3-tuple, (ISO year, ISO week number, ISO weekday).

        Usage::

            >>> arrow.utcnow().isocalendar()
            (2019, 3, 6)

        """

        return self._datetime.isocalendar()

    def isoformat(self, sep="T"):
        """Returns an ISO 8601 formatted representation of the date and time.

        Usage::

            >>> arrow.utcnow().isoformat()
            '2019-01-19T18:30:52.442118+00:00'

        """

        return self._datetime.isoformat(sep)

    def ctime(self):
        """ Returns a ctime formatted representation of the date and time.

        Usage::

            >>> arrow.utcnow().ctime()
            'Sat Jan 19 18:26:50 2019'

        """

        return self._datetime.ctime()

    def strftime(self, format):
        """ Formats in the style of ``datetime.strftime``.

        :param format: the format string.

        Usage::

            >>> arrow.utcnow().strftime('%d-%m-%Y %H:%M:%S')
            '23-01-2019 12:28:17'

        """

        return self._datetime.strftime(format)

    def for_json(self):
        """Serializes for the ``for_json`` protocol of simplejson.

        Usage::

            >>> arrow.utcnow().for_json()
            '2019-01-19T18:25:36.760079+00:00'

        """

        return self.isoformat()

    # internal tools.

    @staticmethod
    def _get_tzinfo(tz_expr):

        if tz_expr is None:
            return dateutil_tz.tzutc()
        if isinstance(tz_expr, dt_tzinfo):
            return tz_expr
        else:
            try:
                return parser.TzinfoParser.parse(tz_expr)
            except parser.ParserError:
                raise ValueError("'{}' not recognized as a timezone".format(tz_expr))

    @classmethod
    def _get_datetime(cls, expr):
        """Get datetime object for a specified expression."""
        if isinstance(expr, Arrow):
            return expr.datetime
        elif isinstance(expr, datetime):
            return expr
        elif util.is_timestamp(expr):
            timestamp = float(expr)
            return cls.utcfromtimestamp(timestamp).datetime
        else:
            raise ValueError(
                "'{}' not recognized as a datetime or timestamp.".format(expr)
            )

    @classmethod
    def _get_frames(cls, name):

        if name in cls._ATTRS:
            return name, "{}s".format(name), 1
        elif name[-1] == "s" and name[:-1] in cls._ATTRS:
            return name[:-1], name, 1
        elif name in ["week", "weeks"]:
            return "week", "weeks", 1
        elif name in ["quarter", "quarters"]:
            return "quarter", "months", 3

        supported = ", ".join(
            [
                "year(s)",
                "month(s)",
                "day(s)",
                "hour(s)",
                "minute(s)",
                "second(s)",
                "microsecond(s)",
                "week(s)",
                "quarter(s)",
            ]
        )
        raise AttributeError(
            "range/span over frame {} not supported. Supported frames: {}".format(
                name, supported
            )
        )

    @classmethod
    def _get_iteration_params(cls, end, limit):

        if end is None:

            if limit is None:
                raise ValueError("one of 'end' or 'limit' is required")

            return cls.max, limit

        else:
            if limit is None:
                return end, sys.maxsize
            return end, limit




############################################################
### File: auth.py
############################################################
# -*- coding: utf-8 -*-

"""
requests.auth
~~~~~~~~~~~~~

This module contains the authentication handlers for Requests.
"""

import os
import re
import time
import hashlib
import threading
import warnings

from base64 import b64encode

from .compat import urlparse, str, basestring
from .cookies import extract_cookies_to_jar
from ._internal_utils import to_native_string
from .utils import parse_dict_header

CONTENT_TYPE_FORM_URLENCODED = 'application/x-www-form-urlencoded'
CONTENT_TYPE_MULTI_PART = 'multipart/form-data'


def _basic_auth_str(username, password):
    """Returns a Basic Auth string."""

    # "I want us to put a big-ol' comment on top of it that
    # says that this behaviour is dumb but we need to preserve
    # it because people are relying on it."
    #    - Lukasa
    #
    # These are here solely to maintain backwards compatibility
    # for things like ints. This will be removed in 3.0.0.
    if not isinstance(username, basestring):
        warnings.warn(
            "Non-string usernames will no longer be supported in Requests "
            "3.0.0. Please convert the object you've passed in ({!r}) to "
            "a string or bytes object in the near future to avoid "
            "problems.".format(username),
            category=DeprecationWarning,
        )
        username = str(username)

    if not isinstance(password, basestring):
        warnings.warn(
            "Non-string passwords will no longer be supported in Requests "
            "3.0.0. Please convert the object you've passed in ({!r}) to "
            "a string or bytes object in the near future to avoid "
            "problems.".format(type(password)),
            category=DeprecationWarning,
        )
        password = str(password)
    # -- End Removal --

    if isinstance(username, str):
        username = username.encode('latin1')

    if isinstance(password, str):
        password = password.encode('latin1')

    authstr = 'Basic ' + to_native_string(
        b64encode(b':'.join((username, password))).strip()
    )

    return authstr


class AuthBase(object):
    """Base class that all auth implementations derive from"""

    def __call__(self, r):
        raise NotImplementedError('Auth hooks must be callable.')


class HTTPBasicAuth(AuthBase):
    """Attaches HTTP Basic Authentication to the given Request object."""

    def __init__(self, username, password):
        self.username = username
        self.password = password

    def __eq__(self, other):
        return all([
            self.username == getattr(other, 'username', None),
            self.password == getattr(other, 'password', None)
        ])

    def __ne__(self, other):
        return not self == other

    def __call__(self, r):
        r.headers['Authorization'] = _basic_auth_str(self.username, self.password)
        return r


class HTTPProxyAuth(HTTPBasicAuth):
    """Attaches HTTP Proxy Authentication to a given Request object."""

    def __call__(self, r):
        r.headers['Proxy-Authorization'] = _basic_auth_str(self.username, self.password)
        return r


class HTTPDigestAuth(AuthBase):
    """Attaches HTTP Digest Authentication to the given Request object."""

    def __init__(self, username, password):
        self.username = username
        self.password = password
        # Keep state in per-thread local storage
        self._thread_local = threading.local()

    def init_per_thread_state(self):
        # Ensure state is initialized just once per-thread
        if not hasattr(self._thread_local, 'init'):
            self._thread_local.init = True
            self._thread_local.last_nonce = ''
            self._thread_local.nonce_count = 0
            self._thread_local.chal = {}
            self._thread_local.pos = None
            self._thread_local.num_401_calls = None

    def build_digest_header(self, method, url):
        """
        :rtype: str
        """

        realm = self._thread_local.chal['realm']
        nonce = self._thread_local.chal['nonce']
        qop = self._thread_local.chal.get('qop')
        algorithm = self._thread_local.chal.get('algorithm')
        opaque = self._thread_local.chal.get('opaque')
        hash_utf8 = None

        if algorithm is None:
            _algorithm = 'MD5'
        else:
            _algorithm = algorithm.upper()
        # lambdas assume digest modules are imported at the top level
        if _algorithm == 'MD5' or _algorithm == 'MD5-SESS':
            def md5_utf8(x):
                if isinstance(x, str):
                    x = x.encode('utf-8')
                return hashlib.md5(x).hexdigest()
            hash_utf8 = md5_utf8
        elif _algorithm == 'SHA':
            def sha_utf8(x):
                if isinstance(x, str):
                    x = x.encode('utf-8')
                return hashlib.sha1(x).hexdigest()
            hash_utf8 = sha_utf8
        elif _algorithm == 'SHA-256':
            def sha256_utf8(x):
                if isinstance(x, str):
                    x = x.encode('utf-8')
                return hashlib.sha256(x).hexdigest()
            hash_utf8 = sha256_utf8
        elif _algorithm == 'SHA-512':
            def sha512_utf8(x):
                if isinstance(x, str):
                    x = x.encode('utf-8')
                return hashlib.sha512(x).hexdigest()
            hash_utf8 = sha512_utf8

        KD = lambda s, d: hash_utf8("%s:%s" % (s, d))

        if hash_utf8 is None:
            return None

        # XXX not implemented yet
        entdig = None
        p_parsed = urlparse(url)
        #: path is request-uri defined in RFC 2616 which should not be empty
        path = p_parsed.path or "/"
        if p_parsed.query:
            path += '?' + p_parsed.query

        A1 = '%s:%s:%s' % (self.username, realm, self.password)
        A2 = '%s:%s' % (method, path)

        HA1 = hash_utf8(A1)
        HA2 = hash_utf8(A2)

        if nonce == self._thread_local.last_nonce:
            self._thread_local.nonce_count += 1
        else:
            self._thread_local.nonce_count = 1
        ncvalue = '%08x' % self._thread_local.nonce_count
        s = str(self._thread_local.nonce_count).encode('utf-8')
        s += nonce.encode('utf-8')
        s += time.ctime().encode('utf-8')
        s += os.urandom(8)

        cnonce = (hashlib.sha1(s).hexdigest()[:16])
        if _algorithm == 'MD5-SESS':
            HA1 = hash_utf8('%s:%s:%s' % (HA1, nonce, cnonce))

        if not qop:
            respdig = KD(HA1, "%s:%s" % (nonce, HA2))
        elif qop == 'auth' or 'auth' in qop.split(','):
            noncebit = "%s:%s:%s:%s:%s" % (
                nonce, ncvalue, cnonce, 'auth', HA2
            )
            respdig = KD(HA1, noncebit)
        else:
            # XXX handle auth-int.
            return None

        self._thread_local.last_nonce = nonce

        # XXX should the partial digests be encoded too?
        base = 'username="%s", realm="%s", nonce="%s", uri="%s", ' \
               'response="%s"' % (self.username, realm, nonce, path, respdig)
        if opaque:
            base += ', opaque="%s"' % opaque
        if algorithm:
            base += ', algorithm="%s"' % algorithm
        if entdig:
            base += ', digest="%s"' % entdig
        if qop:
            base += ', qop="auth", nc=%s, cnonce="%s"' % (ncvalue, cnonce)

        return 'Digest %s' % (base)

    def handle_redirect(self, r, **kwargs):
        """Reset num_401_calls counter on redirects."""
        if r.is_redirect:
            self._thread_local.num_401_calls = 1

    def handle_401(self, r, **kwargs):
        """
        Takes the given response and tries digest-auth, if needed.

        :rtype: requests.Response
        """

        # If response is not 4xx, do not auth
        # See https://github.com/psf/requests/issues/3772
        if not 400 <= r.status_code < 500:
            self._thread_local.num_401_calls = 1
            return r

        if self._thread_local.pos is not None:
            # Rewind the file position indicator of the body to where
            # it was to resend the request.
            r.request.body.seek(self._thread_local.pos)
        s_auth = r.headers.get('www-authenticate', '')

        if 'digest' in s_auth.lower() and self._thread_local.num_401_calls < 2:

            self._thread_local.num_401_calls += 1
            pat = re.compile(r'digest ', flags=re.IGNORECASE)
            self._thread_local.chal = parse_dict_header(pat.sub('', s_auth, count=1))

            # Consume content and release the original connection
            # to allow our new request to reuse the same one.
            r.content
            r.close()
            prep = r.request.copy()
            extract_cookies_to_jar(prep._cookies, r.request, r.raw)
            prep.prepare_cookies(prep._cookies)

            prep.headers['Authorization'] = self.build_digest_header(
                prep.method, prep.url)
            _r = r.connection.send(prep, **kwargs)
            _r.history.append(r)
            _r.request = prep

            return _r

        self._thread_local.num_401_calls = 1
        return r

    def __call__(self, r):
        # Initialize per-thread state, if needed
        self.init_per_thread_state()
        # If we have a saved nonce, skip the 401
        if self._thread_local.last_nonce:
            r.headers['Authorization'] = self.build_digest_header(r.method, r.url)
        try:
            self._thread_local.pos = r.body.tell()
        except AttributeError:
            # In the case of HTTPDigestAuth being reused and the body of
            # the previous request was a file-like object, pos has the
            # file position of the previous body. Ensure it's set to
            # None.
            self._thread_local.pos = None
        r.register_hook('response', self.handle_401)
        r.register_hook('response', self.handle_redirect)
        self._thread_local.num_401_calls = 1

        return r

    def __eq__(self, other):
        return all([
            self.username == getattr(other, 'username', None),
            self.password == getattr(other, 'password', None)
        ])

    def __ne__(self, other):
        return not self == other




############################################################
### File: base.py
############################################################
from datetime import timedelta
from numbers import Number
from six import text_type

from .exceptions import CaptionReadError, CaptionReadTimingError

DEFAULT_LANGUAGE_CODE = 'en-US'


def force_byte_string(content):
    try:
        return content.encode('UTF-8')
    except UnicodeEncodeError:
        raise RuntimeError('Invalid content encoding')
    except UnicodeDecodeError:
        return content


class CaptionConverter(object):
    def __init__(self, captions=None):
        self.captions = captions if captions else []

    def read(self, content, caption_reader):
        try:
            self.captions = caption_reader.read(content)
        except AttributeError as e:
            raise Exception(e)
        return self

    def write(self, caption_writer):
        try:
            return caption_writer.write(self.captions)
        except AttributeError as e:
            raise Exception(e)


class BaseReader(object):
    def __init__(self, *args, **kwargs):
        pass

    def detect(self, content):
        if content:
            return True
        else:
            return False

    def read(self, content):
        return CaptionSet()


class BaseWriter(object):
    def __init__(self, relativize=True, video_width=None, video_height=None,
                 fit_to_screen=True):
        """
        Initialize writer with the given parameters.

        :param relativize: If True (default), converts absolute positioning
            values (e.g. px) to percentage. ATTENTION: WebVTT does not support
            absolute positioning. If relativize is set to False and it finds
            an absolute positioning parameter for a given caption, it will
            ignore all positioning for that cue and show it in the default
            position.
        :param video_width: The width of the video for which the captions being
            converted were made. This is necessary for relativization.
        :param video_height: The height of the video for which the captions
            being converted were made. This is necessary for relativization.
        :param fit_to_screen: If extent is not set or
            if origin + extent > 100%, (re)calculate it based on origin.
            It is a pycaption fix for caption files that are technically valid
            but contains inconsistent settings that may cause long captions to
            be cut out of the screen.
        """
        self.relativize = relativize
        self.video_width = video_width
        self.video_height = video_height
        self.fit_to_screen = fit_to_screen

    def _relativize_and_fit_to_screen(self, layout_info):
        if layout_info:
            if self.relativize:
                # Transform absolute values (e.g. px) into percentages
                layout_info = layout_info.as_percentage_of(
                    self.video_width, self.video_height)
            if self.fit_to_screen:
                # Make sure origin + extent <= 100%
                layout_info = layout_info.fit_to_screen()
        return layout_info

    def write(self, content):
        return content


class Style(object):
    def __init__(self):
        pass


class CaptionNode(object):
    """
    A single node within a caption, representing either
    text, a style, or a linebreak.

    Rules:
        1. All nodes should have the property layout_info set.
        The value None means specifically that no positioning information
        should be specified. Each reader is to supply its own default
        values (if necessary) when reading their respective formats.
    """

    TEXT = 1
    # When and if this is extended, it might be better to turn it into a
    # property of the node, not a type of node itself.
    STYLE = 2
    BREAK = 3

    def __init__(self, type_, layout_info=None):
        """
        :type type_: int
        :type layout_info: Layout
        """
        self.type_ = type_
        self.content = None

        # Boolean. Marks the beginning/ end of a Style node.
        self.start = None
        self.layout_info = layout_info

    def __repr__(self):
        t = self.type_

        if t == CaptionNode.TEXT:
            return repr(self.content)
        elif t == CaptionNode.BREAK:
            return repr('BREAK')
        elif t == CaptionNode.STYLE:
            return repr('STYLE: %s %s' % (self.start, self.content))
        else:
            raise RuntimeError('Unknown node type: ' + str(t))

    @staticmethod
    def create_text(text, layout_info=None):
        data = CaptionNode(CaptionNode.TEXT, layout_info=layout_info)
        data.content = text
        return data

    @staticmethod
    def create_style(start, content, layout_info=None):
        data = CaptionNode(CaptionNode.STYLE, layout_info=layout_info)
        data.content = content
        data.start = start
        return data

    @staticmethod
    def create_break(layout_info=None):
        return CaptionNode(CaptionNode.BREAK, layout_info=layout_info)


class Caption(object):
    """
    A single caption, including the time and styling information
    for its display.
    """
    def __init__(self, start, end, nodes, style={}, layout_info=None):
        """
        Initialize the Caption object
        :param start: The start time in microseconds
        :type start: Number
        :param end: The end time in microseconds
        :type end: Number
        :param nodes: A list of CaptionNodes
        :type nodes: list
        :param style: A dictionary with CSS-like styling rules
        :type style: dict
        :param layout_info: A Layout object with the necessary positioning
            information
        :type layout_info: Layout
        """
        if not isinstance(start, Number):
            raise CaptionReadTimingError("Captions must be initialized with a"
                                         " valid start time")
        if not isinstance(end, Number):
            raise CaptionReadTimingError("Captions must be initialized with a"
                                         " valid end time")
        if not nodes:
            raise CaptionReadError("Node list cannot be empty")
        self.start = start
        self.end = end
        self.nodes = nodes
        self.style = style
        self.layout_info = layout_info

    def is_empty(self):
        return len(self.nodes) == 0

    def format_start(self, msec_separator=None):
        """
        Format the start time value in milliseconds into a string
        value suitable for some of the supported output formats (ex.
        SRT, DFXP).
        """
        return self._format_timestamp(self.start, msec_separator)

    def format_end(self, msec_separator=None):
        """
        Format the end time value in milliseconds into a string value suitable
        for some of the supported output formats (ex. SRT, DFXP).
        """
        return self._format_timestamp(self.end, msec_separator)

    def __repr__(self):
        return repr(
            '{start} --> {end}\n{text}'.format(
                start=self.format_start(),
                end=self.format_end(),
                text=self.get_text()
            )
        )

    def get_text(self):
        """
        Get the text of the caption.
        """
        def get_text_for_node(node):
            if node.type_ == CaptionNode.TEXT:
                return node.content
            if node.type_ == CaptionNode.BREAK:
                return '\n'
            return ''
        text_nodes = [get_text_for_node(node) for node in self.nodes]
        return ''.join(text_nodes).strip()

    def _format_timestamp(self, value, msec_separator=None):
        datetime_value = timedelta(milliseconds=(int(value / 1000)))

        str_value = text_type(datetime_value)[:11]
        if not datetime_value.microseconds:
            str_value += '.000'

        if msec_separator is not None:
            str_value = str_value.replace(".", msec_separator)

        return '0' + str_value


class CaptionList(list):
    """ A list of captions with a layout object attached to it """
    def __init__(self, iterable=None, layout_info=None):
        """
        :param iterable: An iterator used to populate the caption list
        :param Layout layout_info: A Layout object with the positioning info
        """
        self.layout_info = layout_info
        args = [iterable] if iterable else []
        super(CaptionList, self).__init__(*args)

    def __getslice__(self, i, j):
        return CaptionList(
            list.__getslice__(self, i, j), layout_info=self.layout_info)

    def __getitem__(self, y):
        item = list.__getitem__(self, y)
        if isinstance(item, Caption):
            return item
        return CaptionList(item, layout_info=self.layout_info)

    def __add__(self, other):
        add_is_safe = (
            not hasattr(other, 'layout_info') or
            not other.layout_info or
            self.layout_info == other.layout_info
        )
        if add_is_safe:
            return CaptionList(
                list.__add__(self, other), layout_info=self.layout_info)
        else:
            raise ValueError(
                "Cannot add CaptionList objects with different layout_info")

    def __mul__(self, other):
        return CaptionList(
            list.__mul__(self, other), layout_info=self.layout_info)

    __rmul__ = __mul__


class CaptionSet(object):
    """
    A set of captions in potentially multiple languages,
    all representing the same underlying content.

    The .layout_info attribute, keeps information that should be inherited
    by all the children.
    """
    def __init__(self, captions, styles={}, layout_info=None):
        """
        :param captions: A dictionary of the format {'language': CaptionList}
        :param styles: A dictionary with CSS-like styling rules
        :param Layout layout_info: A Layout object with the positioning info
        """
        self._captions = captions
        self._styles = styles
        self.layout_info = layout_info

    def set_captions(self, lang, captions):
        self._captions[lang] = captions

    def get_languages(self):
        return list(self._captions.keys())

    def get_captions(self, lang):
        return [x for x in self._captions.get(lang, []) if x]

    def add_style(self, selector, rules):
        """
        :param selector: The selector indicating the elements to which the
            rules should be applied.
        :param rules: A dictionary with CSS-like styling rules.
        """
        self._styles[selector] = rules

    def get_style(self, selector):
        """
        Returns a dictionary with CSS-like styling rules for a given selector.
        :param selector: The selector whose rules should be returned (e.g. an
            element or class name).
        """
        return self._styles.get(selector, {})

    def get_styles(self):
        return sorted(self._styles.items())

    def set_styles(self, styles):
        self._styles = styles

    def is_empty(self):
        return all(
            [len(captions) == 0 for captions in list(self._captions.values())]
        )

    def set_layout_info(self, lang, layout_info):
        self._captions[lang].layout_info = layout_info

    def get_layout_info(self, lang):
        caption_list = self._captions.get(lang)
        if caption_list:
            return caption_list.layout_info
        return None

    def adjust_caption_timing(self, offset=0, rate_skew=1.0):
        """
        Adjust the timing according to offset and rate_skew.
        Skew is applied first, then offset.

        e.g. if skew == 1.1, and offset is 5, a caption originally
        displayed from 10-11 seconds would instead be at 16-17.1
        """
        for lang in self.get_languages():
            captions = self.get_captions(lang)
            out_captions = CaptionList()
            for caption in captions:
                caption.start = caption.start * rate_skew + offset
                caption.end = caption.end * rate_skew + offset
                if caption.start >= 0:
                    out_captions.append(caption)
            self.set_captions(lang, out_captions)


# Functions
def merge_concurrent_captions(caption_set):
    """Merge captions that have the same start and end times"""
    for lang in caption_set.get_languages():
        captions = caption_set.get_captions(lang)
        last_caption = None
        concurrent_captions = CaptionList()
        merged_captions = CaptionList()
        for caption in captions:
            if last_caption:
                last_timespan = last_caption.start, last_caption.end
                current_timespan = caption.start, caption.end
                if current_timespan == last_timespan:
                    concurrent_captions.append(caption)
                    last_caption = caption
                    continue
                else:
                    merged_captions.append(merge(concurrent_captions))
            concurrent_captions = [caption]
            last_caption = caption

        if concurrent_captions:
            merged_captions.append(merge(concurrent_captions))
        if merged_captions:
            caption_set.set_captions(lang, merged_captions)
    return caption_set


def merge(captions):
    """
    Merge list of captions into one caption. The start/end times from the first
    caption are kept.
    """
    new_nodes = []
    for caption in captions:
        if new_nodes:
            new_nodes.append(CaptionNode.create_break())
        for node in caption.nodes:
            new_nodes.append(node)
    caption = Caption(
        captions[0].start, captions[0].end, new_nodes, captions[0].style)
    return caption




############################################################
### File: big5freq.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# Big5 frequency table
# by Taiwan's Mandarin Promotion Council
# <http://www.edu.tw:81/mandr/>
#
# 128  --> 0.42261
# 256  --> 0.57851
# 512  --> 0.74851
# 1024 --> 0.89384
# 2048 --> 0.97583
#
# Ideal Distribution Ratio = 0.74851/(1-0.74851) =2.98
# Random Distribution Ration = 512/(5401-512)=0.105
#
# Typical Distribution Ratio about 25% of Ideal one, still much higher than RDR

BIG5_TYPICAL_DISTRIBUTION_RATIO = 0.75

#Char to FreqOrder table
BIG5_TABLE_SIZE = 5376

BIG5_CHAR_TO_FREQ_ORDER = (
   1,1801,1506, 255,1431, 198,   9,  82,   6,5008, 177, 202,3681,1256,2821, 110, #   16
3814,  33,3274, 261,  76,  44,2114,  16,2946,2187,1176, 659,3971,  26,3451,2653, #   32
1198,3972,3350,4202, 410,2215, 302, 590, 361,1964,   8, 204,  58,4510,5009,1932, #   48
  63,5010,5011, 317,1614,  75, 222, 159,4203,2417,1480,5012,3555,3091, 224,2822, #   64
3682,   3,  10,3973,1471,  29,2787,1135,2866,1940, 873, 130,3275,1123, 312,5013, #   80
4511,2052, 507, 252, 682,5014, 142,1915, 124, 206,2947,  34,3556,3204,  64, 604, #   96
5015,2501,1977,1978, 155,1991, 645, 641,1606,5016,3452, 337,  72, 406,5017,  80, #  112
 630, 238,3205,1509, 263, 939,1092,2654, 756,1440,1094,3453, 449,  69,2987, 591, #  128
 179,2096, 471, 115,2035,1844,  60,  50,2988, 134, 806,1869, 734,2036,3454, 180, #  144
 995,1607, 156, 537,2907, 688,5018, 319,1305, 779,2145, 514,2379, 298,4512, 359, #  160
2502,  90,2716,1338, 663,  11, 906,1099,2553,  20,2441, 182, 532,1716,5019, 732, #  176
1376,4204,1311,1420,3206,  25,2317,1056, 113, 399, 382,1950, 242,3455,2474, 529, #  192
3276, 475,1447,3683,5020, 117,  21, 656, 810,1297,2300,2334,3557,5021, 126,4205, #  208
 706, 456, 150, 613,4513,  71,1118,2037,4206, 145,3092,  85, 835, 486,2115,1246, #  224
1426, 428, 727,1285,1015, 800, 106, 623, 303,1281,5022,2128,2359, 347,3815, 221, #  240
3558,3135,5023,1956,1153,4207,  83, 296,1199,3093, 192, 624,  93,5024, 822,1898, #  256
2823,3136, 795,2065, 991,1554,1542,1592,  27,  43,2867, 859, 139,1456, 860,4514, #  272
 437, 712,3974, 164,2397,3137, 695, 211,3037,2097, 195,3975,1608,3559,3560,3684, #  288
3976, 234, 811,2989,2098,3977,2233,1441,3561,1615,2380, 668,2077,1638, 305, 228, #  304
1664,4515, 467, 415,5025, 262,2099,1593, 239, 108, 300, 200,1033, 512,1247,2078, #  320
5026,5027,2176,3207,3685,2682, 593, 845,1062,3277,  88,1723,2038,3978,1951, 212, #  336
 266, 152, 149, 468,1899,4208,4516,  77, 187,5028,3038,  37,   5,2990,5029,3979, #  352
5030,5031,  39,2524,4517,2908,3208,2079,  55, 148,  74,4518, 545, 483,1474,1029, #  368
1665, 217,1870,1531,3138,1104,2655,4209,  24, 172,3562, 900,3980,3563,3564,4519, #  384
  32,1408,2824,1312, 329, 487,2360,2251,2717, 784,2683,   4,3039,3351,1427,1789, #  400
 188, 109, 499,5032,3686,1717,1790, 888,1217,3040,4520,5033,3565,5034,3352,1520, #  416
3687,3981, 196,1034, 775,5035,5036, 929,1816, 249, 439,  38,5037,1063,5038, 794, #  432
3982,1435,2301,  46, 178,3278,2066,5039,2381,5040, 214,1709,4521, 804,  35, 707, #  448
 324,3688,1601,2554, 140, 459,4210,5041,5042,1365, 839, 272, 978,2262,2580,3456, #  464
2129,1363,3689,1423, 697, 100,3094,  48,  70,1231, 495,3139,2196,5043,1294,5044, #  480
2080, 462, 586,1042,3279, 853, 256, 988, 185,2382,3457,1698, 434,1084,5045,3458, #  496
 314,2625,2788,4522,2335,2336, 569,2285, 637,1817,2525, 757,1162,1879,1616,3459, #  512
 287,1577,2116, 768,4523,1671,2868,3566,2526,1321,3816, 909,2418,5046,4211, 933, #  528
3817,4212,2053,2361,1222,4524, 765,2419,1322, 786,4525,5047,1920,1462,1677,2909, #  544
1699,5048,4526,1424,2442,3140,3690,2600,3353,1775,1941,3460,3983,4213, 309,1369, #  560
1130,2825, 364,2234,1653,1299,3984,3567,3985,3986,2656, 525,1085,3041, 902,2001, #  576
1475, 964,4527, 421,1845,1415,1057,2286, 940,1364,3141, 376,4528,4529,1381,   7, #  592
2527, 983,2383, 336,1710,2684,1846, 321,3461, 559,1131,3042,2752,1809,1132,1313, #  608
 265,1481,1858,5049, 352,1203,2826,3280, 167,1089, 420,2827, 776, 792,1724,3568, #  624
4214,2443,3281,5050,4215,5051, 446, 229, 333,2753, 901,3818,1200,1557,4530,2657, #  640
1921, 395,2754,2685,3819,4216,1836, 125, 916,3209,2626,4531,5052,5053,3820,5054, #  656
5055,5056,4532,3142,3691,1133,2555,1757,3462,1510,2318,1409,3569,5057,2146, 438, #  672
2601,2910,2384,3354,1068, 958,3043, 461, 311,2869,2686,4217,1916,3210,4218,1979, #  688
 383, 750,2755,2627,4219, 274, 539, 385,1278,1442,5058,1154,1965, 384, 561, 210, #  704
  98,1295,2556,3570,5059,1711,2420,1482,3463,3987,2911,1257, 129,5060,3821, 642, #  720
 523,2789,2790,2658,5061, 141,2235,1333,  68, 176, 441, 876, 907,4220, 603,2602, #  736
 710, 171,3464, 404, 549,  18,3143,2398,1410,3692,1666,5062,3571,4533,2912,4534, #  752
5063,2991, 368,5064, 146, 366,  99, 871,3693,1543, 748, 807,1586,1185,  22,2263, #  768
 379,3822,3211,5065,3212, 505,1942,2628,1992,1382,2319,5066, 380,2362, 218, 702, #  784
1818,1248,3465,3044,3572,3355,3282,5067,2992,3694, 930,3283,3823,5068,  59,5069, #  800
 585, 601,4221, 497,3466,1112,1314,4535,1802,5070,1223,1472,2177,5071, 749,1837, #  816
 690,1900,3824,1773,3988,1476, 429,1043,1791,2236,2117, 917,4222, 447,1086,1629, #  832
5072, 556,5073,5074,2021,1654, 844,1090, 105, 550, 966,1758,2828,1008,1783, 686, #  848
1095,5075,2287, 793,1602,5076,3573,2603,4536,4223,2948,2302,4537,3825, 980,2503, #  864
 544, 353, 527,4538, 908,2687,2913,5077, 381,2629,1943,1348,5078,1341,1252, 560, #  880
3095,5079,3467,2870,5080,2054, 973, 886,2081, 143,4539,5081,5082, 157,3989, 496, #  896
4224,  57, 840, 540,2039,4540,4541,3468,2118,1445, 970,2264,1748,1966,2082,4225, #  912
3144,1234,1776,3284,2829,3695, 773,1206,2130,1066,2040,1326,3990,1738,1725,4226, #  928
 279,3145,  51,1544,2604, 423,1578,2131,2067, 173,4542,1880,5083,5084,1583, 264, #  944
 610,3696,4543,2444, 280, 154,5085,5086,5087,1739, 338,1282,3096, 693,2871,1411, #  960
1074,3826,2445,5088,4544,5089,5090,1240, 952,2399,5091,2914,1538,2688, 685,1483, #  976
4227,2475,1436, 953,4228,2055,4545, 671,2400,  79,4229,2446,3285, 608, 567,2689, #  992
3469,4230,4231,1691, 393,1261,1792,2401,5092,4546,5093,5094,5095,5096,1383,1672, # 1008
3827,3213,1464, 522,1119, 661,1150, 216, 675,4547,3991,1432,3574, 609,4548,2690, # 1024
2402,5097,5098,5099,4232,3045,   0,5100,2476, 315, 231,2447, 301,3356,4549,2385, # 1040
5101, 233,4233,3697,1819,4550,4551,5102,  96,1777,1315,2083,5103, 257,5104,1810, # 1056
3698,2718,1139,1820,4234,2022,1124,2164,2791,1778,2659,5105,3097, 363,1655,3214, # 1072
5106,2993,5107,5108,5109,3992,1567,3993, 718, 103,3215, 849,1443, 341,3357,2949, # 1088
1484,5110,1712, 127,  67, 339,4235,2403, 679,1412, 821,5111,5112, 834, 738, 351, # 1104
2994,2147, 846, 235,1497,1881, 418,1993,3828,2719, 186,1100,2148,2756,3575,1545, # 1120
1355,2950,2872,1377, 583,3994,4236,2581,2995,5113,1298,3699,1078,2557,3700,2363, # 1136
  78,3829,3830, 267,1289,2100,2002,1594,4237, 348, 369,1274,2197,2178,1838,4552, # 1152
1821,2830,3701,2757,2288,2003,4553,2951,2758, 144,3358, 882,4554,3995,2759,3470, # 1168
4555,2915,5114,4238,1726, 320,5115,3996,3046, 788,2996,5116,2831,1774,1327,2873, # 1184
3997,2832,5117,1306,4556,2004,1700,3831,3576,2364,2660, 787,2023, 506, 824,3702, # 1200
 534, 323,4557,1044,3359,2024,1901, 946,3471,5118,1779,1500,1678,5119,1882,4558, # 1216
 165, 243,4559,3703,2528, 123, 683,4239, 764,4560,  36,3998,1793, 589,2916, 816, # 1232
 626,1667,3047,2237,1639,1555,1622,3832,3999,5120,4000,2874,1370,1228,1933, 891, # 1248
2084,2917, 304,4240,5121, 292,2997,2720,3577, 691,2101,4241,1115,4561, 118, 662, # 1264
5122, 611,1156, 854,2386,1316,2875,   2, 386, 515,2918,5123,5124,3286, 868,2238, # 1280
1486, 855,2661, 785,2216,3048,5125,1040,3216,3578,5126,3146, 448,5127,1525,5128, # 1296
2165,4562,5129,3833,5130,4242,2833,3579,3147, 503, 818,4001,3148,1568, 814, 676, # 1312
1444, 306,1749,5131,3834,1416,1030, 197,1428, 805,2834,1501,4563,5132,5133,5134, # 1328
1994,5135,4564,5136,5137,2198,  13,2792,3704,2998,3149,1229,1917,5138,3835,2132, # 1344
5139,4243,4565,2404,3580,5140,2217,1511,1727,1120,5141,5142, 646,3836,2448, 307, # 1360
5143,5144,1595,3217,5145,5146,5147,3705,1113,1356,4002,1465,2529,2530,5148, 519, # 1376
5149, 128,2133,  92,2289,1980,5150,4003,1512, 342,3150,2199,5151,2793,2218,1981, # 1392
3360,4244, 290,1656,1317, 789, 827,2365,5152,3837,4566, 562, 581,4004,5153, 401, # 1408
4567,2252,  94,4568,5154,1399,2794,5155,1463,2025,4569,3218,1944,5156, 828,1105, # 1424
4245,1262,1394,5157,4246, 605,4570,5158,1784,2876,5159,2835, 819,2102, 578,2200, # 1440
2952,5160,1502, 436,3287,4247,3288,2836,4005,2919,3472,3473,5161,2721,2320,5162, # 1456
5163,2337,2068,  23,4571, 193, 826,3838,2103, 699,1630,4248,3098, 390,1794,1064, # 1472
3581,5164,1579,3099,3100,1400,5165,4249,1839,1640,2877,5166,4572,4573, 137,4250, # 1488
 598,3101,1967, 780, 104, 974,2953,5167, 278, 899, 253, 402, 572, 504, 493,1339, # 1504
5168,4006,1275,4574,2582,2558,5169,3706,3049,3102,2253, 565,1334,2722, 863,  41, # 1520
5170,5171,4575,5172,1657,2338,  19, 463,2760,4251, 606,5173,2999,3289,1087,2085, # 1536
1323,2662,3000,5174,1631,1623,1750,4252,2691,5175,2878, 791,2723,2663,2339, 232, # 1552
2421,5176,3001,1498,5177,2664,2630, 755,1366,3707,3290,3151,2026,1609, 119,1918, # 1568
3474, 862,1026,4253,5178,4007,3839,4576,4008,4577,2265,1952,2477,5179,1125, 817, # 1584
4254,4255,4009,1513,1766,2041,1487,4256,3050,3291,2837,3840,3152,5180,5181,1507, # 1600
5182,2692, 733,  40,1632,1106,2879, 345,4257, 841,2531, 230,4578,3002,1847,3292, # 1616
3475,5183,1263, 986,3476,5184, 735, 879, 254,1137, 857, 622,1300,1180,1388,1562, # 1632
4010,4011,2954, 967,2761,2665,1349, 592,2134,1692,3361,3003,1995,4258,1679,4012, # 1648
1902,2188,5185, 739,3708,2724,1296,1290,5186,4259,2201,2202,1922,1563,2605,2559, # 1664
1871,2762,3004,5187, 435,5188, 343,1108, 596,  17,1751,4579,2239,3477,3709,5189, # 1680
4580, 294,3582,2955,1693, 477, 979, 281,2042,3583, 643,2043,3710,2631,2795,2266, # 1696
1031,2340,2135,2303,3584,4581, 367,1249,2560,5190,3585,5191,4582,1283,3362,2005, # 1712
 240,1762,3363,4583,4584, 836,1069,3153, 474,5192,2149,2532, 268,3586,5193,3219, # 1728
1521,1284,5194,1658,1546,4260,5195,3587,3588,5196,4261,3364,2693,1685,4262, 961, # 1744
1673,2632, 190,2006,2203,3841,4585,4586,5197, 570,2504,3711,1490,5198,4587,2633, # 1760
3293,1957,4588, 584,1514, 396,1045,1945,5199,4589,1968,2449,5200,5201,4590,4013, # 1776
 619,5202,3154,3294, 215,2007,2796,2561,3220,4591,3221,4592, 763,4263,3842,4593, # 1792
5203,5204,1958,1767,2956,3365,3712,1174, 452,1477,4594,3366,3155,5205,2838,1253, # 1808
2387,2189,1091,2290,4264, 492,5206, 638,1169,1825,2136,1752,4014, 648, 926,1021, # 1824
1324,4595, 520,4596, 997, 847,1007, 892,4597,3843,2267,1872,3713,2405,1785,4598, # 1840
1953,2957,3103,3222,1728,4265,2044,3714,4599,2008,1701,3156,1551,  30,2268,4266, # 1856
5207,2027,4600,3589,5208, 501,5209,4267, 594,3478,2166,1822,3590,3479,3591,3223, # 1872
 829,2839,4268,5210,1680,3157,1225,4269,5211,3295,4601,4270,3158,2341,5212,4602, # 1888
4271,5213,4015,4016,5214,1848,2388,2606,3367,5215,4603, 374,4017, 652,4272,4273, # 1904
 375,1140, 798,5216,5217,5218,2366,4604,2269, 546,1659, 138,3051,2450,4605,5219, # 1920
2254, 612,1849, 910, 796,3844,1740,1371, 825,3845,3846,5220,2920,2562,5221, 692, # 1936
 444,3052,2634, 801,4606,4274,5222,1491, 244,1053,3053,4275,4276, 340,5223,4018, # 1952
1041,3005, 293,1168,  87,1357,5224,1539, 959,5225,2240, 721, 694,4277,3847, 219, # 1968
1478, 644,1417,3368,2666,1413,1401,1335,1389,4019,5226,5227,3006,2367,3159,1826, # 1984
 730,1515, 184,2840,  66,4607,5228,1660,2958, 246,3369, 378,1457, 226,3480, 975, # 2000
4020,2959,1264,3592, 674, 696,5229, 163,5230,1141,2422,2167, 713,3593,3370,4608, # 2016
4021,5231,5232,1186,  15,5233,1079,1070,5234,1522,3224,3594, 276,1050,2725, 758, # 2032
1126, 653,2960,3296,5235,2342, 889,3595,4022,3104,3007, 903,1250,4609,4023,3481, # 2048
3596,1342,1681,1718, 766,3297, 286,  89,2961,3715,5236,1713,5237,2607,3371,3008, # 2064
5238,2962,2219,3225,2880,5239,4610,2505,2533, 181, 387,1075,4024, 731,2190,3372, # 2080
5240,3298, 310, 313,3482,2304, 770,4278,  54,3054, 189,4611,3105,3848,4025,5241, # 2096
1230,1617,1850, 355,3597,4279,4612,3373, 111,4280,3716,1350,3160,3483,3055,4281, # 2112
2150,3299,3598,5242,2797,4026,4027,3009, 722,2009,5243,1071, 247,1207,2343,2478, # 2128
1378,4613,2010, 864,1437,1214,4614, 373,3849,1142,2220, 667,4615, 442,2763,2563, # 2144
3850,4028,1969,4282,3300,1840, 837, 170,1107, 934,1336,1883,5244,5245,2119,4283, # 2160
2841, 743,1569,5246,4616,4284, 582,2389,1418,3484,5247,1803,5248, 357,1395,1729, # 2176
3717,3301,2423,1564,2241,5249,3106,3851,1633,4617,1114,2086,4285,1532,5250, 482, # 2192
2451,4618,5251,5252,1492, 833,1466,5253,2726,3599,1641,2842,5254,1526,1272,3718, # 2208
4286,1686,1795, 416,2564,1903,1954,1804,5255,3852,2798,3853,1159,2321,5256,2881, # 2224
4619,1610,1584,3056,2424,2764, 443,3302,1163,3161,5257,5258,4029,5259,4287,2506, # 2240
3057,4620,4030,3162,2104,1647,3600,2011,1873,4288,5260,4289, 431,3485,5261, 250, # 2256
  97,  81,4290,5262,1648,1851,1558, 160, 848,5263, 866, 740,1694,5264,2204,2843, # 2272
3226,4291,4621,3719,1687, 950,2479, 426, 469,3227,3720,3721,4031,5265,5266,1188, # 2288
 424,1996, 861,3601,4292,3854,2205,2694, 168,1235,3602,4293,5267,2087,1674,4622, # 2304
3374,3303, 220,2565,1009,5268,3855, 670,3010, 332,1208, 717,5269,5270,3603,2452, # 2320
4032,3375,5271, 513,5272,1209,2882,3376,3163,4623,1080,5273,5274,5275,5276,2534, # 2336
3722,3604, 815,1587,4033,4034,5277,3605,3486,3856,1254,4624,1328,3058,1390,4035, # 2352
1741,4036,3857,4037,5278, 236,3858,2453,3304,5279,5280,3723,3859,1273,3860,4625, # 2368
5281, 308,5282,4626, 245,4627,1852,2480,1307,2583, 430, 715,2137,2454,5283, 270, # 2384
 199,2883,4038,5284,3606,2727,1753, 761,1754, 725,1661,1841,4628,3487,3724,5285, # 2400
5286, 587,  14,3305, 227,2608, 326, 480,2270, 943,2765,3607, 291, 650,1884,5287, # 2416
1702,1226, 102,1547,  62,3488, 904,4629,3489,1164,4294,5288,5289,1224,1548,2766, # 2432
 391, 498,1493,5290,1386,1419,5291,2056,1177,4630, 813, 880,1081,2368, 566,1145, # 2448
4631,2291,1001,1035,2566,2609,2242, 394,1286,5292,5293,2069,5294,  86,1494,1730, # 2464
4039, 491,1588, 745, 897,2963, 843,3377,4040,2767,2884,3306,1768, 998,2221,2070, # 2480
 397,1827,1195,1970,3725,3011,3378, 284,5295,3861,2507,2138,2120,1904,5296,4041, # 2496
2151,4042,4295,1036,3490,1905, 114,2567,4296, 209,1527,5297,5298,2964,2844,2635, # 2512
2390,2728,3164, 812,2568,5299,3307,5300,1559, 737,1885,3726,1210, 885,  28,2695, # 2528
3608,3862,5301,4297,1004,1780,4632,5302, 346,1982,2222,2696,4633,3863,1742, 797, # 2544
1642,4043,1934,1072,1384,2152, 896,4044,3308,3727,3228,2885,3609,5303,2569,1959, # 2560
4634,2455,1786,5304,5305,5306,4045,4298,1005,1308,3728,4299,2729,4635,4636,1528, # 2576
2610, 161,1178,4300,1983, 987,4637,1101,4301, 631,4046,1157,3229,2425,1343,1241, # 2592
1016,2243,2570, 372, 877,2344,2508,1160, 555,1935, 911,4047,5307, 466,1170, 169, # 2608
1051,2921,2697,3729,2481,3012,1182,2012,2571,1251,2636,5308, 992,2345,3491,1540, # 2624
2730,1201,2071,2406,1997,2482,5309,4638, 528,1923,2191,1503,1874,1570,2369,3379, # 2640
3309,5310, 557,1073,5311,1828,3492,2088,2271,3165,3059,3107, 767,3108,2799,4639, # 2656
1006,4302,4640,2346,1267,2179,3730,3230, 778,4048,3231,2731,1597,2667,5312,4641, # 2672
5313,3493,5314,5315,5316,3310,2698,1433,3311, 131,  95,1504,4049, 723,4303,3166, # 2688
1842,3610,2768,2192,4050,2028,2105,3731,5317,3013,4051,1218,5318,3380,3232,4052, # 2704
4304,2584, 248,1634,3864, 912,5319,2845,3732,3060,3865, 654,  53,5320,3014,5321, # 2720
1688,4642, 777,3494,1032,4053,1425,5322, 191, 820,2121,2846, 971,4643, 931,3233, # 2736
 135, 664, 783,3866,1998, 772,2922,1936,4054,3867,4644,2923,3234, 282,2732, 640, # 2752
1372,3495,1127, 922, 325,3381,5323,5324, 711,2045,5325,5326,4055,2223,2800,1937, # 2768
4056,3382,2224,2255,3868,2305,5327,4645,3869,1258,3312,4057,3235,2139,2965,4058, # 2784
4059,5328,2225, 258,3236,4646, 101,1227,5329,3313,1755,5330,1391,3314,5331,2924, # 2800
2057, 893,5332,5333,5334,1402,4305,2347,5335,5336,3237,3611,5337,5338, 878,1325, # 2816
1781,2801,4647, 259,1385,2585, 744,1183,2272,4648,5339,4060,2509,5340, 684,1024, # 2832
4306,5341, 472,3612,3496,1165,3315,4061,4062, 322,2153, 881, 455,1695,1152,1340, # 2848
 660, 554,2154,4649,1058,4650,4307, 830,1065,3383,4063,4651,1924,5342,1703,1919, # 2864
5343, 932,2273, 122,5344,4652, 947, 677,5345,3870,2637, 297,1906,1925,2274,4653, # 2880
2322,3316,5346,5347,4308,5348,4309,  84,4310, 112, 989,5349, 547,1059,4064, 701, # 2896
3613,1019,5350,4311,5351,3497, 942, 639, 457,2306,2456, 993,2966, 407, 851, 494, # 2912
4654,3384, 927,5352,1237,5353,2426,3385, 573,4312, 680, 921,2925,1279,1875, 285, # 2928
 790,1448,1984, 719,2168,5354,5355,4655,4065,4066,1649,5356,1541, 563,5357,1077, # 2944
5358,3386,3061,3498, 511,3015,4067,4068,3733,4069,1268,2572,3387,3238,4656,4657, # 2960
5359, 535,1048,1276,1189,2926,2029,3167,1438,1373,2847,2967,1134,2013,5360,4313, # 2976
1238,2586,3109,1259,5361, 700,5362,2968,3168,3734,4314,5363,4315,1146,1876,1907, # 2992
4658,2611,4070, 781,2427, 132,1589, 203, 147, 273,2802,2407, 898,1787,2155,4071, # 3008
4072,5364,3871,2803,5365,5366,4659,4660,5367,3239,5368,1635,3872, 965,5369,1805, # 3024
2699,1516,3614,1121,1082,1329,3317,4073,1449,3873,  65,1128,2848,2927,2769,1590, # 3040
3874,5370,5371,  12,2668,  45, 976,2587,3169,4661, 517,2535,1013,1037,3240,5372, # 3056
3875,2849,5373,3876,5374,3499,5375,2612, 614,1999,2323,3877,3110,2733,2638,5376, # 3072
2588,4316, 599,1269,5377,1811,3735,5378,2700,3111, 759,1060, 489,1806,3388,3318, # 3088
1358,5379,5380,2391,1387,1215,2639,2256, 490,5381,5382,4317,1759,2392,2348,5383, # 3104
4662,3878,1908,4074,2640,1807,3241,4663,3500,3319,2770,2349, 874,5384,5385,3501, # 3120
3736,1859,  91,2928,3737,3062,3879,4664,5386,3170,4075,2669,5387,3502,1202,1403, # 3136
3880,2969,2536,1517,2510,4665,3503,2511,5388,4666,5389,2701,1886,1495,1731,4076, # 3152
2370,4667,5390,2030,5391,5392,4077,2702,1216, 237,2589,4318,2324,4078,3881,4668, # 3168
4669,2703,3615,3504, 445,4670,5393,5394,5395,5396,2771,  61,4079,3738,1823,4080, # 3184
5397, 687,2046, 935, 925, 405,2670, 703,1096,1860,2734,4671,4081,1877,1367,2704, # 3200
3389, 918,2106,1782,2483, 334,3320,1611,1093,4672, 564,3171,3505,3739,3390, 945, # 3216
2641,2058,4673,5398,1926, 872,4319,5399,3506,2705,3112, 349,4320,3740,4082,4674, # 3232
3882,4321,3741,2156,4083,4675,4676,4322,4677,2408,2047, 782,4084, 400, 251,4323, # 3248
1624,5400,5401, 277,3742, 299,1265, 476,1191,3883,2122,4324,4325,1109, 205,5402, # 3264
2590,1000,2157,3616,1861,5403,5404,5405,4678,5406,4679,2573, 107,2484,2158,4085, # 3280
3507,3172,5407,1533, 541,1301, 158, 753,4326,2886,3617,5408,1696, 370,1088,4327, # 3296
4680,3618, 579, 327, 440, 162,2244, 269,1938,1374,3508, 968,3063,  56,1396,3113, # 3312
2107,3321,3391,5409,1927,2159,4681,3016,5410,3619,5411,5412,3743,4682,2485,5413, # 3328
2804,5414,1650,4683,5415,2613,5416,5417,4086,2671,3392,1149,3393,4087,3884,4088, # 3344
5418,1076,  49,5419, 951,3242,3322,3323, 450,2850, 920,5420,1812,2805,2371,4328, # 3360
1909,1138,2372,3885,3509,5421,3243,4684,1910,1147,1518,2428,4685,3886,5422,4686, # 3376
2393,2614, 260,1796,3244,5423,5424,3887,3324, 708,5425,3620,1704,5426,3621,1351, # 3392
1618,3394,3017,1887, 944,4329,3395,4330,3064,3396,4331,5427,3744, 422, 413,1714, # 3408
3325, 500,2059,2350,4332,2486,5428,1344,1911, 954,5429,1668,5430,5431,4089,2409, # 3424
4333,3622,3888,4334,5432,2307,1318,2512,3114, 133,3115,2887,4687, 629,  31,2851, # 3440
2706,3889,4688, 850, 949,4689,4090,2970,1732,2089,4335,1496,1853,5433,4091, 620, # 3456
3245, 981,1242,3745,3397,1619,3746,1643,3326,2140,2457,1971,1719,3510,2169,5434, # 3472
3246,5435,5436,3398,1829,5437,1277,4690,1565,2048,5438,1636,3623,3116,5439, 869, # 3488
2852, 655,3890,3891,3117,4092,3018,3892,1310,3624,4691,5440,5441,5442,1733, 558, # 3504
4692,3747, 335,1549,3065,1756,4336,3748,1946,3511,1830,1291,1192, 470,2735,2108, # 3520
2806, 913,1054,4093,5443,1027,5444,3066,4094,4693, 982,2672,3399,3173,3512,3247, # 3536
3248,1947,2807,5445, 571,4694,5446,1831,5447,3625,2591,1523,2429,5448,2090, 984, # 3552
4695,3749,1960,5449,3750, 852, 923,2808,3513,3751, 969,1519, 999,2049,2325,1705, # 3568
5450,3118, 615,1662, 151, 597,4095,2410,2326,1049, 275,4696,3752,4337, 568,3753, # 3584
3626,2487,4338,3754,5451,2430,2275, 409,3249,5452,1566,2888,3514,1002, 769,2853, # 3600
 194,2091,3174,3755,2226,3327,4339, 628,1505,5453,5454,1763,2180,3019,4096, 521, # 3616
1161,2592,1788,2206,2411,4697,4097,1625,4340,4341, 412,  42,3119, 464,5455,2642, # 3632
4698,3400,1760,1571,2889,3515,2537,1219,2207,3893,2643,2141,2373,4699,4700,3328, # 3648
1651,3401,3627,5456,5457,3628,2488,3516,5458,3756,5459,5460,2276,2092, 460,5461, # 3664
4701,5462,3020, 962, 588,3629, 289,3250,2644,1116,  52,5463,3067,1797,5464,5465, # 3680
5466,1467,5467,1598,1143,3757,4342,1985,1734,1067,4702,1280,3402, 465,4703,1572, # 3696
 510,5468,1928,2245,1813,1644,3630,5469,4704,3758,5470,5471,2673,1573,1534,5472, # 3712
5473, 536,1808,1761,3517,3894,3175,2645,5474,5475,5476,4705,3518,2929,1912,2809, # 3728
5477,3329,1122, 377,3251,5478, 360,5479,5480,4343,1529, 551,5481,2060,3759,1769, # 3744
2431,5482,2930,4344,3330,3120,2327,2109,2031,4706,1404, 136,1468,1479, 672,1171, # 3760
3252,2308, 271,3176,5483,2772,5484,2050, 678,2736, 865,1948,4707,5485,2014,4098, # 3776
2971,5486,2737,2227,1397,3068,3760,4708,4709,1735,2931,3403,3631,5487,3895, 509, # 3792
2854,2458,2890,3896,5488,5489,3177,3178,4710,4345,2538,4711,2309,1166,1010, 552, # 3808
 681,1888,5490,5491,2972,2973,4099,1287,1596,1862,3179, 358, 453, 736, 175, 478, # 3824
1117, 905,1167,1097,5492,1854,1530,5493,1706,5494,2181,3519,2292,3761,3520,3632, # 3840
4346,2093,4347,5495,3404,1193,2489,4348,1458,2193,2208,1863,1889,1421,3331,2932, # 3856
3069,2182,3521, 595,2123,5496,4100,5497,5498,4349,1707,2646, 223,3762,1359, 751, # 3872
3121, 183,3522,5499,2810,3021, 419,2374, 633, 704,3897,2394, 241,5500,5501,5502, # 3888
 838,3022,3763,2277,2773,2459,3898,1939,2051,4101,1309,3122,2246,1181,5503,1136, # 3904
2209,3899,2375,1446,4350,2310,4712,5504,5505,4351,1055,2615, 484,3764,5506,4102, # 3920
 625,4352,2278,3405,1499,4353,4103,5507,4104,4354,3253,2279,2280,3523,5508,5509, # 3936
2774, 808,2616,3765,3406,4105,4355,3123,2539, 526,3407,3900,4356, 955,5510,1620, # 3952
4357,2647,2432,5511,1429,3766,1669,1832, 994, 928,5512,3633,1260,5513,5514,5515, # 3968
1949,2293, 741,2933,1626,4358,2738,2460, 867,1184, 362,3408,1392,5516,5517,4106, # 3984
4359,1770,1736,3254,2934,4713,4714,1929,2707,1459,1158,5518,3070,3409,2891,1292, # 4000
1930,2513,2855,3767,1986,1187,2072,2015,2617,4360,5519,2574,2514,2170,3768,2490, # 4016
3332,5520,3769,4715,5521,5522, 666,1003,3023,1022,3634,4361,5523,4716,1814,2257, # 4032
 574,3901,1603, 295,1535, 705,3902,4362, 283, 858, 417,5524,5525,3255,4717,4718, # 4048
3071,1220,1890,1046,2281,2461,4107,1393,1599, 689,2575, 388,4363,5526,2491, 802, # 4064
5527,2811,3903,2061,1405,2258,5528,4719,3904,2110,1052,1345,3256,1585,5529, 809, # 4080
5530,5531,5532, 575,2739,3524, 956,1552,1469,1144,2328,5533,2329,1560,2462,3635, # 4096
3257,4108, 616,2210,4364,3180,2183,2294,5534,1833,5535,3525,4720,5536,1319,3770, # 4112
3771,1211,3636,1023,3258,1293,2812,5537,5538,5539,3905, 607,2311,3906, 762,2892, # 4128
1439,4365,1360,4721,1485,3072,5540,4722,1038,4366,1450,2062,2648,4367,1379,4723, # 4144
2593,5541,5542,4368,1352,1414,2330,2935,1172,5543,5544,3907,3908,4724,1798,1451, # 4160
5545,5546,5547,5548,2936,4109,4110,2492,2351, 411,4111,4112,3637,3333,3124,4725, # 4176
1561,2674,1452,4113,1375,5549,5550,  47,2974, 316,5551,1406,1591,2937,3181,5552, # 4192
1025,2142,3125,3182, 354,2740, 884,2228,4369,2412, 508,3772, 726,3638, 996,2433, # 4208
3639, 729,5553, 392,2194,1453,4114,4726,3773,5554,5555,2463,3640,2618,1675,2813, # 4224
 919,2352,2975,2353,1270,4727,4115,  73,5556,5557, 647,5558,3259,2856,2259,1550, # 4240
1346,3024,5559,1332, 883,3526,5560,5561,5562,5563,3334,2775,5564,1212, 831,1347, # 4256
4370,4728,2331,3909,1864,3073, 720,3910,4729,4730,3911,5565,4371,5566,5567,4731, # 4272
5568,5569,1799,4732,3774,2619,4733,3641,1645,2376,4734,5570,2938, 669,2211,2675, # 4288
2434,5571,2893,5572,5573,1028,3260,5574,4372,2413,5575,2260,1353,5576,5577,4735, # 4304
3183, 518,5578,4116,5579,4373,1961,5580,2143,4374,5581,5582,3025,2354,2355,3912, # 4320
 516,1834,1454,4117,2708,4375,4736,2229,2620,1972,1129,3642,5583,2776,5584,2976, # 4336
1422, 577,1470,3026,1524,3410,5585,5586, 432,4376,3074,3527,5587,2594,1455,2515, # 4352
2230,1973,1175,5588,1020,2741,4118,3528,4737,5589,2742,5590,1743,1361,3075,3529, # 4368
2649,4119,4377,4738,2295, 895, 924,4378,2171, 331,2247,3076, 166,1627,3077,1098, # 4384
5591,1232,2894,2231,3411,4739, 657, 403,1196,2377, 542,3775,3412,1600,4379,3530, # 4400
5592,4740,2777,3261, 576, 530,1362,4741,4742,2540,2676,3776,4120,5593, 842,3913, # 4416
5594,2814,2032,1014,4121, 213,2709,3413, 665, 621,4380,5595,3777,2939,2435,5596, # 4432
2436,3335,3643,3414,4743,4381,2541,4382,4744,3644,1682,4383,3531,1380,5597, 724, # 4448
2282, 600,1670,5598,1337,1233,4745,3126,2248,5599,1621,4746,5600, 651,4384,5601, # 4464
1612,4385,2621,5602,2857,5603,2743,2312,3078,5604, 716,2464,3079, 174,1255,2710, # 4480
4122,3645, 548,1320,1398, 728,4123,1574,5605,1891,1197,3080,4124,5606,3081,3082, # 4496
3778,3646,3779, 747,5607, 635,4386,4747,5608,5609,5610,4387,5611,5612,4748,5613, # 4512
3415,4749,2437, 451,5614,3780,2542,2073,4388,2744,4389,4125,5615,1764,4750,5616, # 4528
4390, 350,4751,2283,2395,2493,5617,4391,4126,2249,1434,4127, 488,4752, 458,4392, # 4544
4128,3781, 771,1330,2396,3914,2576,3184,2160,2414,1553,2677,3185,4393,5618,2494, # 4560
2895,2622,1720,2711,4394,3416,4753,5619,2543,4395,5620,3262,4396,2778,5621,2016, # 4576
2745,5622,1155,1017,3782,3915,5623,3336,2313, 201,1865,4397,1430,5624,4129,5625, # 4592
5626,5627,5628,5629,4398,1604,5630, 414,1866, 371,2595,4754,4755,3532,2017,3127, # 4608
4756,1708, 960,4399, 887, 389,2172,1536,1663,1721,5631,2232,4130,2356,2940,1580, # 4624
5632,5633,1744,4757,2544,4758,4759,5634,4760,5635,2074,5636,4761,3647,3417,2896, # 4640
4400,5637,4401,2650,3418,2815, 673,2712,2465, 709,3533,4131,3648,4402,5638,1148, # 4656
 502, 634,5639,5640,1204,4762,3649,1575,4763,2623,3783,5641,3784,3128, 948,3263, # 4672
 121,1745,3916,1110,5642,4403,3083,2516,3027,4132,3785,1151,1771,3917,1488,4133, # 4688
1987,5643,2438,3534,5644,5645,2094,5646,4404,3918,1213,1407,2816, 531,2746,2545, # 4704
3264,1011,1537,4764,2779,4405,3129,1061,5647,3786,3787,1867,2897,5648,2018, 120, # 4720
4406,4407,2063,3650,3265,2314,3919,2678,3419,1955,4765,4134,5649,3535,1047,2713, # 4736
1266,5650,1368,4766,2858, 649,3420,3920,2546,2747,1102,2859,2679,5651,5652,2000, # 4752
5653,1111,3651,2977,5654,2495,3921,3652,2817,1855,3421,3788,5655,5656,3422,2415, # 4768
2898,3337,3266,3653,5657,2577,5658,3654,2818,4135,1460, 856,5659,3655,5660,2899, # 4784
2978,5661,2900,3922,5662,4408, 632,2517, 875,3923,1697,3924,2296,5663,5664,4767, # 4800
3028,1239, 580,4768,4409,5665, 914, 936,2075,1190,4136,1039,2124,5666,5667,5668, # 4816
5669,3423,1473,5670,1354,4410,3925,4769,2173,3084,4137, 915,3338,4411,4412,3339, # 4832
1605,1835,5671,2748, 398,3656,4413,3926,4138, 328,1913,2860,4139,3927,1331,4414, # 4848
3029, 937,4415,5672,3657,4140,4141,3424,2161,4770,3425, 524, 742, 538,3085,1012, # 4864
5673,5674,3928,2466,5675, 658,1103, 225,3929,5676,5677,4771,5678,4772,5679,3267, # 4880
1243,5680,4142, 963,2250,4773,5681,2714,3658,3186,5682,5683,2596,2332,5684,4774, # 4896
5685,5686,5687,3536, 957,3426,2547,2033,1931,2941,2467, 870,2019,3659,1746,2780, # 4912
2781,2439,2468,5688,3930,5689,3789,3130,3790,3537,3427,3791,5690,1179,3086,5691, # 4928
3187,2378,4416,3792,2548,3188,3131,2749,4143,5692,3428,1556,2549,2297, 977,2901, # 4944
2034,4144,1205,3429,5693,1765,3430,3189,2125,1271, 714,1689,4775,3538,5694,2333, # 4960
3931, 533,4417,3660,2184, 617,5695,2469,3340,3539,2315,5696,5697,3190,5698,5699, # 4976
3932,1988, 618, 427,2651,3540,3431,5700,5701,1244,1690,5702,2819,4418,4776,5703, # 4992
3541,4777,5704,2284,1576, 473,3661,4419,3432, 972,5705,3662,5706,3087,5707,5708, # 5008
4778,4779,5709,3793,4145,4146,5710, 153,4780, 356,5711,1892,2902,4420,2144, 408, # 5024
 803,2357,5712,3933,5713,4421,1646,2578,2518,4781,4782,3934,5714,3935,4422,5715, # 5040
2416,3433, 752,5716,5717,1962,3341,2979,5718, 746,3030,2470,4783,4423,3794, 698, # 5056
4784,1893,4424,3663,2550,4785,3664,3936,5719,3191,3434,5720,1824,1302,4147,2715, # 5072
3937,1974,4425,5721,4426,3192, 823,1303,1288,1236,2861,3542,4148,3435, 774,3938, # 5088
5722,1581,4786,1304,2862,3939,4787,5723,2440,2162,1083,3268,4427,4149,4428, 344, # 5104
1173, 288,2316, 454,1683,5724,5725,1461,4788,4150,2597,5726,5727,4789, 985, 894, # 5120
5728,3436,3193,5729,1914,2942,3795,1989,5730,2111,1975,5731,4151,5732,2579,1194, # 5136
 425,5733,4790,3194,1245,3796,4429,5734,5735,2863,5736, 636,4791,1856,3940, 760, # 5152
1800,5737,4430,2212,1508,4792,4152,1894,1684,2298,5738,5739,4793,4431,4432,2213, # 5168
 479,5740,5741, 832,5742,4153,2496,5743,2980,2497,3797, 990,3132, 627,1815,2652, # 5184
4433,1582,4434,2126,2112,3543,4794,5744, 799,4435,3195,5745,4795,2113,1737,3031, # 5200
1018, 543, 754,4436,3342,1676,4796,4797,4154,4798,1489,5746,3544,5747,2624,2903, # 5216
4155,5748,5749,2981,5750,5751,5752,5753,3196,4799,4800,2185,1722,5754,3269,3270, # 5232
1843,3665,1715, 481, 365,1976,1857,5755,5756,1963,2498,4801,5757,2127,3666,3271, # 5248
 433,1895,2064,2076,5758, 602,2750,5759,5760,5761,5762,5763,3032,1628,3437,5764, # 5264
3197,4802,4156,2904,4803,2519,5765,2551,2782,5766,5767,5768,3343,4804,2905,5769, # 5280
4805,5770,2864,4806,4807,1221,2982,4157,2520,5771,5772,5773,1868,1990,5774,5775, # 5296
5776,1896,5777,5778,4808,1897,4158, 318,5779,2095,4159,4437,5780,5781, 485,5782, # 5312
 938,3941, 553,2680, 116,5783,3942,3667,5784,3545,2681,2783,3438,3344,2820,5785, # 5328
3668,2943,4160,1747,2944,2983,5786,5787, 207,5788,4809,5789,4810,2521,5790,3033, # 5344
 890,3669,3943,5791,1878,3798,3439,5792,2186,2358,3440,1652,5793,5794,5795, 941, # 5360
2299, 208,3546,4161,2020, 330,4438,3944,2906,2499,3799,4439,4811,5796,5797,5798, # 5376
)





############################################################
### File: big5prober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import Big5DistributionAnalysis
from .mbcssm import BIG5_SM_MODEL


class Big5Prober(MultiByteCharSetProber):
    def __init__(self):
        super(Big5Prober, self).__init__()
        self.coding_sm = CodingStateMachine(BIG5_SM_MODEL)
        self.distribution_analyzer = Big5DistributionAnalysis()
        self.reset()

    @property
    def charset_name(self):
        return "Big5"

    @property
    def language(self):
        return "Chinese"




############################################################
### File: blockfeeder.py
############################################################
# The MIT License (MIT)
#
# Copyright (c) 2014 Richard Moore
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.


from .aes import AESBlockModeOfOperation, AESSegmentModeOfOperation, AESStreamModeOfOperation
from .util import append_PKCS7_padding, strip_PKCS7_padding, to_bufferable


# First we inject three functions to each of the modes of operations
#
#    _can_consume(size)
#       - Given a size, determine how many bytes could be consumed in
#         a single call to either the decrypt or encrypt method
#
#    _final_encrypt(data, padding = PADDING_DEFAULT)
#       - call and return encrypt on this (last) chunk of data,
#         padding as necessary; this will always be at least 16
#         bytes unless the total incoming input was less than 16
#         bytes
#
#    _final_decrypt(data, padding = PADDING_DEFAULT)
#       - same as _final_encrypt except for decrypt, for
#         stripping off padding
#

PADDING_NONE       = 'none'
PADDING_DEFAULT    = 'default'

# @TODO: Ciphertext stealing and explicit PKCS#7
# PADDING_CIPHERTEXT_STEALING
# PADDING_PKCS7

# ECB and CBC are block-only ciphers

def _block_can_consume(self, size):
    if size >= 16: return 16
    return 0

# After padding, we may have more than one block
def _block_final_encrypt(self, data, padding = PADDING_DEFAULT):
    if padding == PADDING_DEFAULT:
        data = append_PKCS7_padding(data)

    elif padding == PADDING_NONE:
        if len(data) != 16:
            raise Exception('invalid data length for final block')
    else:
        raise Exception('invalid padding option')

    if len(data) == 32:
        return self.encrypt(data[:16]) + self.encrypt(data[16:])

    return self.encrypt(data)


def _block_final_decrypt(self, data, padding = PADDING_DEFAULT):
    if padding == PADDING_DEFAULT:
        return strip_PKCS7_padding(self.decrypt(data))

    if padding == PADDING_NONE:
        if len(data) != 16:
            raise Exception('invalid data length for final block')
        return self.decrypt(data)

    raise Exception('invalid padding option')

AESBlockModeOfOperation._can_consume = _block_can_consume
AESBlockModeOfOperation._final_encrypt = _block_final_encrypt
AESBlockModeOfOperation._final_decrypt = _block_final_decrypt



# CFB is a segment cipher

def _segment_can_consume(self, size):
    return self.segment_bytes * int(size // self.segment_bytes)

# CFB can handle a non-segment-sized block at the end using the remaining cipherblock
def _segment_final_encrypt(self, data, padding = PADDING_DEFAULT):
    if padding != PADDING_DEFAULT:
        raise Exception('invalid padding option')

    faux_padding = (chr(0) * (self.segment_bytes - (len(data) % self.segment_bytes)))
    padded = data + to_bufferable(faux_padding)
    return self.encrypt(padded)[:len(data)]

# CFB can handle a non-segment-sized block at the end using the remaining cipherblock
def _segment_final_decrypt(self, data, padding = PADDING_DEFAULT):
    if padding != PADDING_DEFAULT:
        raise Exception('invalid padding option')

    faux_padding = (chr(0) * (self.segment_bytes - (len(data) % self.segment_bytes)))
    padded = data + to_bufferable(faux_padding)
    return self.decrypt(padded)[:len(data)]

AESSegmentModeOfOperation._can_consume = _segment_can_consume
AESSegmentModeOfOperation._final_encrypt = _segment_final_encrypt
AESSegmentModeOfOperation._final_decrypt = _segment_final_decrypt



# OFB and CTR are stream ciphers

def _stream_can_consume(self, size):
    return size

def _stream_final_encrypt(self, data, padding = PADDING_DEFAULT):
    if padding not in [PADDING_NONE, PADDING_DEFAULT]:
        raise Exception('invalid padding option')

    return self.encrypt(data)

def _stream_final_decrypt(self, data, padding = PADDING_DEFAULT):
    if padding not in [PADDING_NONE, PADDING_DEFAULT]:
        raise Exception('invalid padding option')

    return self.decrypt(data)

AESStreamModeOfOperation._can_consume = _stream_can_consume
AESStreamModeOfOperation._final_encrypt = _stream_final_encrypt
AESStreamModeOfOperation._final_decrypt = _stream_final_decrypt



class BlockFeeder(object):
    '''The super-class for objects to handle chunking a stream of bytes
       into the appropriate block size for the underlying mode of operation
       and applying (or stripping) padding, as necessary.'''

    def __init__(self, mode, feed, final, padding = PADDING_DEFAULT):
        self._mode = mode
        self._feed = feed
        self._final = final
        self._buffer = to_bufferable("")
        self._padding = padding

    def feed(self, data = None):
        '''Provide bytes to encrypt (or decrypt), returning any bytes
           possible from this or any previous calls to feed.

           Call with None or an empty string to flush the mode of
           operation and return any final bytes; no further calls to
           feed may be made.'''

        if self._buffer is None:
            raise ValueError('already finished feeder')

        # Finalize; process the spare bytes we were keeping
        if data is None:
            result = self._final(self._buffer, self._padding)
            self._buffer = None
            return result

        self._buffer += to_bufferable(data)

        # We keep 16 bytes around so we can determine padding
        result = to_bufferable('')
        while len(self._buffer) > 16:
            can_consume = self._mode._can_consume(len(self._buffer) - 16)
            if can_consume == 0: break
            result += self._feed(self._buffer[:can_consume])
            self._buffer = self._buffer[can_consume:]

        return result


class Encrypter(BlockFeeder):
    'Accepts bytes of plaintext and returns encrypted ciphertext.'

    def __init__(self, mode, padding = PADDING_DEFAULT):
        BlockFeeder.__init__(self, mode, mode.encrypt, mode._final_encrypt, padding)


class Decrypter(BlockFeeder):
    'Accepts bytes of ciphertext and returns decrypted plaintext.'

    def __init__(self, mode, padding = PADDING_DEFAULT):
        BlockFeeder.__init__(self, mode, mode.decrypt, mode._final_decrypt, padding)


# 8kb blocks
BLOCK_SIZE = (1 << 13)

def _feed_stream(feeder, in_stream, out_stream, block_size = BLOCK_SIZE):
    'Uses feeder to read and convert from in_stream and write to out_stream.'

    while True:
        chunk = in_stream.read(block_size)
        if not chunk:
            break
        converted = feeder.feed(chunk)
        out_stream.write(converted)
    converted = feeder.feed()
    out_stream.write(converted)


def encrypt_stream(mode, in_stream, out_stream, block_size = BLOCK_SIZE, padding = PADDING_DEFAULT):
    'Encrypts a stream of bytes from in_stream to out_stream using mode.'

    encrypter = Encrypter(mode, padding = padding)
    _feed_stream(encrypter, in_stream, out_stream, block_size)


def decrypt_stream(mode, in_stream, out_stream, block_size = BLOCK_SIZE, padding = PADDING_DEFAULT):
    'Decrypts a stream of bytes from in_stream to out_stream using mode.'

    decrypter = Decrypter(mode, padding = padding)
    _feed_stream(decrypter, in_stream, out_stream, block_size)




############################################################
### File: certs.py
############################################################
#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
requests.certs
~~~~~~~~~~~~~~

This module returns the preferred default CA certificate bundle. There is
only one  the one from the certifi package.

If you are packaging Requests, e.g., for a Linux distribution or a managed
environment, you can change the definition of where() to return a separately
packaged CA bundle.
"""
from certifi import where

if __name__ == '__main__':
    print(where())




############################################################
### File: chardistribution.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .euctwfreq import (EUCTW_CHAR_TO_FREQ_ORDER, EUCTW_TABLE_SIZE,
                        EUCTW_TYPICAL_DISTRIBUTION_RATIO)
from .euckrfreq import (EUCKR_CHAR_TO_FREQ_ORDER, EUCKR_TABLE_SIZE,
                        EUCKR_TYPICAL_DISTRIBUTION_RATIO)
from .gb2312freq import (GB2312_CHAR_TO_FREQ_ORDER, GB2312_TABLE_SIZE,
                         GB2312_TYPICAL_DISTRIBUTION_RATIO)
from .big5freq import (BIG5_CHAR_TO_FREQ_ORDER, BIG5_TABLE_SIZE,
                       BIG5_TYPICAL_DISTRIBUTION_RATIO)
from .jisfreq import (JIS_CHAR_TO_FREQ_ORDER, JIS_TABLE_SIZE,
                      JIS_TYPICAL_DISTRIBUTION_RATIO)


class CharDistributionAnalysis(object):
    ENOUGH_DATA_THRESHOLD = 1024
    SURE_YES = 0.99
    SURE_NO = 0.01
    MINIMUM_DATA_THRESHOLD = 3

    def __init__(self):
        # Mapping table to get frequency order from char order (get from
        # GetOrder())
        self._char_to_freq_order = None
        self._table_size = None  # Size of above table
        # This is a constant value which varies from language to language,
        # used in calculating confidence.  See
        # http://www.mozilla.org/projects/intl/UniversalCharsetDetection.html
        # for further detail.
        self.typical_distribution_ratio = None
        self._done = None
        self._total_chars = None
        self._freq_chars = None
        self.reset()

    def reset(self):
        """reset analyser, clear any state"""
        # If this flag is set to True, detection is done and conclusion has
        # been made
        self._done = False
        self._total_chars = 0  # Total characters encountered
        # The number of characters whose frequency order is less than 512
        self._freq_chars = 0

    def feed(self, char, char_len):
        """feed a character with known length"""
        if char_len == 2:
            # we only care about 2-bytes character in our distribution analysis
            order = self.get_order(char)
        else:
            order = -1
        if order >= 0:
            self._total_chars += 1
            # order is valid
            if order < self._table_size:
                if 512 > self._char_to_freq_order[order]:
                    self._freq_chars += 1

    def get_confidence(self):
        """return confidence based on existing data"""
        # if we didn't receive any character in our consideration range,
        # return negative answer
        if self._total_chars <= 0 or self._freq_chars <= self.MINIMUM_DATA_THRESHOLD:
            return self.SURE_NO

        if self._total_chars != self._freq_chars:
            r = (self._freq_chars / ((self._total_chars - self._freq_chars)
                 * self.typical_distribution_ratio))
            if r < self.SURE_YES:
                return r

        # normalize confidence (we don't want to be 100% sure)
        return self.SURE_YES

    def got_enough_data(self):
        # It is not necessary to receive all data to draw conclusion.
        # For charset detection, certain amount of data is enough
        return self._total_chars > self.ENOUGH_DATA_THRESHOLD

    def get_order(self, byte_str):
        # We do not handle characters based on the original encoding string,
        # but convert this encoding string to a number, here called order.
        # This allows multiple encodings of a language to share one frequency
        # table.
        return -1


class EUCTWDistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        super(EUCTWDistributionAnalysis, self).__init__()
        self._char_to_freq_order = EUCTW_CHAR_TO_FREQ_ORDER
        self._table_size = EUCTW_TABLE_SIZE
        self.typical_distribution_ratio = EUCTW_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, byte_str):
        # for euc-TW encoding, we are interested
        #   first  byte range: 0xc4 -- 0xfe
        #   second byte range: 0xa1 -- 0xfe
        # no validation needed here. State machine has done that
        first_char = byte_str[0]
        if first_char >= 0xC4:
            return 94 * (first_char - 0xC4) + byte_str[1] - 0xA1
        else:
            return -1


class EUCKRDistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        super(EUCKRDistributionAnalysis, self).__init__()
        self._char_to_freq_order = EUCKR_CHAR_TO_FREQ_ORDER
        self._table_size = EUCKR_TABLE_SIZE
        self.typical_distribution_ratio = EUCKR_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, byte_str):
        # for euc-KR encoding, we are interested
        #   first  byte range: 0xb0 -- 0xfe
        #   second byte range: 0xa1 -- 0xfe
        # no validation needed here. State machine has done that
        first_char = byte_str[0]
        if first_char >= 0xB0:
            return 94 * (first_char - 0xB0) + byte_str[1] - 0xA1
        else:
            return -1


class GB2312DistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        super(GB2312DistributionAnalysis, self).__init__()
        self._char_to_freq_order = GB2312_CHAR_TO_FREQ_ORDER
        self._table_size = GB2312_TABLE_SIZE
        self.typical_distribution_ratio = GB2312_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, byte_str):
        # for GB2312 encoding, we are interested
        #  first  byte range: 0xb0 -- 0xfe
        #  second byte range: 0xa1 -- 0xfe
        # no validation needed here. State machine has done that
        first_char, second_char = byte_str[0], byte_str[1]
        if (first_char >= 0xB0) and (second_char >= 0xA1):
            return 94 * (first_char - 0xB0) + second_char - 0xA1
        else:
            return -1


class Big5DistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        super(Big5DistributionAnalysis, self).__init__()
        self._char_to_freq_order = BIG5_CHAR_TO_FREQ_ORDER
        self._table_size = BIG5_TABLE_SIZE
        self.typical_distribution_ratio = BIG5_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, byte_str):
        # for big5 encoding, we are interested
        #   first  byte range: 0xa4 -- 0xfe
        #   second byte range: 0x40 -- 0x7e , 0xa1 -- 0xfe
        # no validation needed here. State machine has done that
        first_char, second_char = byte_str[0], byte_str[1]
        if first_char >= 0xA4:
            if second_char >= 0xA1:
                return 157 * (first_char - 0xA4) + second_char - 0xA1 + 63
            else:
                return 157 * (first_char - 0xA4) + second_char - 0x40
        else:
            return -1


class SJISDistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        super(SJISDistributionAnalysis, self).__init__()
        self._char_to_freq_order = JIS_CHAR_TO_FREQ_ORDER
        self._table_size = JIS_TABLE_SIZE
        self.typical_distribution_ratio = JIS_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, byte_str):
        # for sjis encoding, we are interested
        #   first  byte range: 0x81 -- 0x9f , 0xe0 -- 0xfe
        #   second byte range: 0x40 -- 0x7e,  0x81 -- oxfe
        # no validation needed here. State machine has done that
        first_char, second_char = byte_str[0], byte_str[1]
        if (first_char >= 0x81) and (first_char <= 0x9F):
            order = 188 * (first_char - 0x81)
        elif (first_char >= 0xE0) and (first_char <= 0xEF):
            order = 188 * (first_char - 0xE0 + 31)
        else:
            return -1
        order = order + second_char - 0x40
        if second_char > 0x7F:
            order = -1
        return order


class EUCJPDistributionAnalysis(CharDistributionAnalysis):
    def __init__(self):
        super(EUCJPDistributionAnalysis, self).__init__()
        self._char_to_freq_order = JIS_CHAR_TO_FREQ_ORDER
        self._table_size = JIS_TABLE_SIZE
        self.typical_distribution_ratio = JIS_TYPICAL_DISTRIBUTION_RATIO

    def get_order(self, byte_str):
        # for euc-JP encoding, we are interested
        #   first  byte range: 0xa0 -- 0xfe
        #   second byte range: 0xa1 -- 0xfe
        # no validation needed here. State machine has done that
        char = byte_str[0]
        if char >= 0xA0:
            return 94 * (char - 0xA1) + byte_str[1] - 0xa1
        else:
            return -1




############################################################
### File: charsetgroupprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .enums import ProbingState
from .charsetprober import CharSetProber


class CharSetGroupProber(CharSetProber):
    def __init__(self, lang_filter=None):
        super(CharSetGroupProber, self).__init__(lang_filter=lang_filter)
        self._active_num = 0
        self.probers = []
        self._best_guess_prober = None

    def reset(self):
        super(CharSetGroupProber, self).reset()
        self._active_num = 0
        for prober in self.probers:
            if prober:
                prober.reset()
                prober.active = True
                self._active_num += 1
        self._best_guess_prober = None

    @property
    def charset_name(self):
        if not self._best_guess_prober:
            self.get_confidence()
            if not self._best_guess_prober:
                return None
        return self._best_guess_prober.charset_name

    @property
    def language(self):
        if not self._best_guess_prober:
            self.get_confidence()
            if not self._best_guess_prober:
                return None
        return self._best_guess_prober.language

    def feed(self, byte_str):
        for prober in self.probers:
            if not prober:
                continue
            if not prober.active:
                continue
            state = prober.feed(byte_str)
            if not state:
                continue
            if state == ProbingState.FOUND_IT:
                self._best_guess_prober = prober
                self._state = ProbingState.FOUND_IT
                return self.state
            elif state == ProbingState.NOT_ME:
                prober.active = False
                self._active_num -= 1
                if self._active_num <= 0:
                    self._state = ProbingState.NOT_ME
                    return self.state
        return self.state

    def get_confidence(self):
        state = self.state
        if state == ProbingState.FOUND_IT:
            return 0.99
        elif state == ProbingState.NOT_ME:
            return 0.01
        best_conf = 0.0
        self._best_guess_prober = None
        for prober in self.probers:
            if not prober:
                continue
            if not prober.active:
                self.logger.debug('%s not active', prober.charset_name)
                continue
            conf = prober.get_confidence()
            self.logger.debug('%s %s confidence = %s', prober.charset_name, prober.language, conf)
            if best_conf < conf:
                best_conf = conf
                self._best_guess_prober = prober
        if not self._best_guess_prober:
            return 0.0
        return best_conf




############################################################
### File: charsetprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import logging
import re

from .enums import ProbingState


class CharSetProber(object):

    SHORTCUT_THRESHOLD = 0.95

    def __init__(self, lang_filter=None):
        self._state = None
        self.lang_filter = lang_filter
        self.logger = logging.getLogger(__name__)

    def reset(self):
        self._state = ProbingState.DETECTING

    @property
    def charset_name(self):
        return None

    def feed(self, buf):
        pass

    @property
    def state(self):
        return self._state

    def get_confidence(self):
        return 0.0

    @staticmethod
    def filter_high_byte_only(buf):
        buf = re.sub(b'([\x00-\x7F])+', b' ', buf)
        return buf

    @staticmethod
    def filter_international_words(buf):
        """
        We define three types of bytes:
        alphabet: english alphabets [a-zA-Z]
        international: international characters [\x80-\xFF]
        marker: everything else [^a-zA-Z\x80-\xFF]

        The input buffer can be thought to contain a series of words delimited
        by markers. This function works to filter all words that contain at
        least one international character. All contiguous sequences of markers
        are replaced by a single space ascii character.

        This filter applies to all scripts which do not use English characters.
        """
        filtered = bytearray()

        # This regex expression filters out only words that have at-least one
        # international character. The word may include one marker character at
        # the end.
        words = re.findall(b'[a-zA-Z]*[\x80-\xFF]+[a-zA-Z]*[^a-zA-Z\x80-\xFF]?',
                           buf)

        for word in words:
            filtered.extend(word[:-1])

            # If the last character in the word is a marker, replace it with a
            # space as markers shouldn't affect our analysis (they are used
            # similarly across all languages and may thus have similar
            # frequencies).
            last_char = word[-1:]
            if not last_char.isalpha() and last_char < b'\x80':
                last_char = b' '
            filtered.extend(last_char)

        return filtered

    @staticmethod
    def filter_with_english_letters(buf):
        """
        Returns a copy of ``buf`` that retains only the sequences of English
        alphabet and high byte characters that are not between <> characters.
        Also retains English alphabet and high byte characters immediately
        before occurrences of >.

        This filter can be applied to all scripts which contain both English
        characters and extended ASCII characters, but is currently only used by
        ``Latin1Prober``.
        """
        filtered = bytearray()
        in_tag = False
        prev = 0

        for curr in range(len(buf)):
            # Slice here to get bytes instead of an int with Python 3
            buf_char = buf[curr:curr + 1]
            # Check if we're coming out of or entering an HTML tag
            if buf_char == b'>':
                in_tag = False
            elif buf_char == b'<':
                in_tag = True

            # If current character is not extended-ASCII and not alphabetic...
            if buf_char < b'\x80' and not buf_char.isalpha():
                # ...and we're not in a tag
                if curr > prev and not in_tag:
                    # Keep everything after last non-extended-ASCII,
                    # non-alphabetic character
                    filtered.extend(buf[prev:curr])
                    # Output a space to delimit stretch we kept
                    filtered.extend(b' ')
                prev = curr + 1

        # If we're not in a tag...
        if not in_tag:
            # Keep everything after last non-extended-ASCII, non-alphabetic
            # character
            filtered.extend(buf[prev:])

        return filtered




############################################################
### File: client.py
############################################################
# -*- coding: utf-8 -*-
"""
A Translation module.

You can translate text using this module.
"""
import random
import json

import requests

from six import PY3
from googletrans import urls, utils
from googletrans.gtoken import TokenAcquirer
from googletrans.constants import (
    DEFAULT_CLIENT_SERVICE_URLS,
    DEFAULT_FALLBACK_SERVICE_URLS,
    DEFAULT_USER_AGENT, LANGCODES, LANGUAGES, SPECIAL_CASES,
    DEFAULT_RAISE_EXCEPTION, DUMMY_DATA
)
from googletrans.models import Translated, Detected, TranslatedPart

EXCLUDES = ('en', 'ca', 'fr')

RPC_ID = 'MkEWBc'

class Translator(object):
    """Google Translate ajax API implementation class

    You have to create an instance of Translator to use this API

    :param service_urls: google translate url list. URLs will be used randomly.
                         For example ``['translate.google.com', 'translate.google.co.kr']``
                         To preferably use the non webapp api, service url should be translate.googleapis.com
    :type service_urls: a sequence of strings

    :param user_agent: the User-Agent header to send when making requests.
    :type user_agent: :class:`str`

    :param proxies: proxies configuration.
                    Dictionary mapping protocol or protocol and host to the URL of the proxy
                    For example ``{'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}``
    :type proxies: dictionary

    :param timeout: Definition of timeout for httpx library.
                    Will be used for every request.
    :type timeout: number or a double of numbers
    :param proxies: proxies configuration.
                    Dictionary mapping protocol or protocol and host to the URL of the proxy
                    For example ``{'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}``
    :param raise_exception: if `True` then raise exception if smth will go wrong
    :param http2: whether to use HTTP2 (default: True)
    :param use_fallback: use a fallback method
    :type raise_exception: boolean
    """

    def __init__(self, service_urls=DEFAULT_CLIENT_SERVICE_URLS, user_agent=DEFAULT_USER_AGENT,
                 raise_exception=DEFAULT_RAISE_EXCEPTION,
                 use_fallback = False,
                 client = None):

        self.client = client or requests.Session()
        self.client.headers.update({
            'User-Agent': user_agent,
            'Referer': 'https://translate.google.com',
        })

        if use_fallback:
            self.service_urls = DEFAULT_FALLBACK_SERVICE_URLS
            self.client_type = 'gtx'
            pass
        else:
            #default way of working: use the defined values from user app
            self.service_urls = service_urls
            self.client_type = 'tw-ob'
            self.token_acquirer = TokenAcquirer(
                client=self.client, host=self.service_urls[0])

        self.raise_exception = raise_exception

    def _build_rpc_request(self, text, dest, src):
        return json.dumps([[
            [
                RPC_ID,
                json.dumps([[text, src, dest, True],[None]], separators=(',', ':')),
                None,
                'generic',
            ],
        ]], separators=(',', ':'))

    def _pick_service_url(self):
        if len(self.service_urls) == 1:
            return self.service_urls[0]
        return random.choice(self.service_urls)

    def _translate(self, text, dest, src):
        if not PY3 and isinstance(text, str):  # pragma: nocover
            text = text.decode('utf-8')
        
        url = urls.TRANSLATE_RPC.format(host=self._pick_service_url())
        data = {
            'f.req': self._build_rpc_request(text, dest, src),
        }
        params = {
            'rpcids': RPC_ID,
            'bl': 'boq_translate-webserver_20201207.13_p0',
            'soc-app': 1,
            'soc-platform': 1,
            'soc-device': 1,
            'rt': 'c',
        }
        r = self.client.post(url, params=params, data=data)

        if r.status_code != 200 and self.raise_exception:
            raise Exception('Unexpected status code "{}" from {}'.format(
                r.status_code, self.service_urls))

        return r.text, r

    def _translate_legacy(self, text, dest, src, override):
        token = '' #dummy default value here as it is not used by api client
        if self.client_type == 'webapp':
            token = self.token_acquirer.do(text)

        params = utils.build_params(client=self.client_type, query=text, src=src, dest=dest,
                                    token=token, override=override)

        url = urls.TRANSLATE.format(host=self._pick_service_url())
        r = self.client.get(url, params=params)

        if r.status_code == 200:
            data = utils.format_json(r.text)
            return data, r

        if self.raise_exception:
            raise Exception('Unexpected status code "{}" from {}'.format(
                r.status_code, self.service_urls))

        DUMMY_DATA[0][0][0] = text
        return DUMMY_DATA, r

    def _parse_extra_data(self, data):
        response_parts_name_mapping = {
            0: 'translation',
            1: 'all-translations',
            2: 'original-language',
            5: 'possible-translations',
            6: 'confidence',
            7: 'possible-mistakes',
            8: 'language',
            11: 'synonyms',
            12: 'definitions',
            13: 'examples',
            14: 'see-also',
        }

        extra = {}

        for index, category in response_parts_name_mapping.items():
            extra[category] = data[index] if (
                index < len(data) and data[index]) else None

        return extra

    def translate(self, text, dest='en', src='auto'):
        dest = dest.lower().split('_', 1)[0]
        src = src.lower().split('_', 1)[0]

        if src != 'auto' and src not in LANGUAGES:
            if src in SPECIAL_CASES:
                src = SPECIAL_CASES[src]
            elif src in LANGCODES:
                src = LANGCODES[src]
            else:
                raise ValueError('invalid source language')

        if dest not in LANGUAGES:
            if dest in SPECIAL_CASES:
                dest = SPECIAL_CASES[dest]
            elif dest in LANGCODES:
                dest = LANGCODES[dest]
            else:
                raise ValueError('invalid destination language')

        origin = text
        data, response = self._translate(text, dest, src)

        token_found = False
        square_bracket_counts = [0, 0]
        resp = ''
        for line in data.split('\n'):
            token_found = token_found or '"{}"'.format(RPC_ID) in line[:30]
            if not token_found:
                continue

            is_in_string = False
            for index, char in enumerate(line):
                if char == '\"' and line[max(0, index - 1)] != '\\':
                    is_in_string = not is_in_string
                if not is_in_string:
                    if char == '[':
                        square_bracket_counts[0] += 1
                    elif char == ']':
                        square_bracket_counts[1] += 1

            resp += line
            if square_bracket_counts[0] == square_bracket_counts[1]:
                break


        data = json.loads(resp)
        parsed = json.loads(data[0][2])
        # not sure
        should_spacing = parsed[1][0][0][3]
        translated_parts = list(map(lambda part: TranslatedPart(part[0], part[1] if len(part) >= 2 else []), parsed[1][0][0][5]))
        translated = (' ' if should_spacing else '').join(map(lambda part: part.text, translated_parts))

        if src == 'auto':
            try:
                src = parsed[2]
            except:
                pass
        if src == 'auto':
            try:
                src = parsed[0][2]
            except:
                pass

        # currently not available
        confidence = None

        origin_pronunciation = None
        try:
            origin_pronunciation = parsed[0][0]
        except:
            pass

        pronunciation = None
        try:
            pronunciation = parsed[1][0][0][1]
        except:
            pass

        extra_data = {
            'confidence': confidence,
            'parts': translated_parts,
            'origin_pronunciation': origin_pronunciation,
            'parsed': parsed,
        }
        result = Translated(src=src, dest=dest, origin=origin,
                            text=translated, pronunciation=pronunciation,
                            parts=translated_parts,
                            extra_data=extra_data,
                            response=response)
        return result


    def translate_legacy(self, text, dest='en', src='auto', **kwargs):
        """Translate text from source language to destination language

        :param text: The source text(s) to be translated. Batch translation is supported via sequence input.
        :type text: UTF-8 :class:`str`; :class:`unicode`; string sequence (list, tuple, iterator, generator)

        :param dest: The language to translate the source text into.
                     The value should be one of the language codes listed in :const:`googletrans.LANGUAGES`
                     or one of the language names listed in :const:`googletrans.LANGCODES`.
        :param dest: :class:`str`; :class:`unicode`

        :param src: The language of the source text.
                    The value should be one of the language codes listed in :const:`googletrans.LANGUAGES`
                    or one of the language names listed in :const:`googletrans.LANGCODES`.
                    If a language is not specified,
                    the system will attempt to identify the source language automatically.
        :param src: :class:`str`; :class:`unicode`

        :rtype: Translated
        :rtype: :class:`list` (when a list is passed)

        Basic usage:
            >>> from googletrans import Translator
            >>> translator = Translator()
            >>> translator.translate('.')
            <Translated src=ko dest=en text=Good evening. pronunciation=Good evening.>
            >>> translator.translate('.', dest='ja')
            <Translated src=ko dest=ja text= pronunciation=Kon'nichiwa.>
            >>> translator.translate('veritas lux mea', src='la')
            <Translated src=la dest=en text=The truth is my light pronunciation=The truth is my light>

        Advanced usage:
            >>> translations = translator.translate(['The quick brown fox', 'jumps over', 'the lazy dog'], dest='ko')
            >>> for translation in translations:
            ...    print(translation.origin, ' -> ', translation.text)
            The quick brown fox  ->    
            jumps over  ->   
            the lazy dog  ->   
        """
        dest = dest.lower().split('_', 1)[0]
        src = src.lower().split('_', 1)[0]

        if src != 'auto' and src not in LANGUAGES:
            if src in SPECIAL_CASES:
                src = SPECIAL_CASES[src]
            elif src in LANGCODES:
                src = LANGCODES[src]
            else:
                raise ValueError('invalid source language')

        if dest not in LANGUAGES:
            if dest in SPECIAL_CASES:
                dest = SPECIAL_CASES[dest]
            elif dest in LANGCODES:
                dest = LANGCODES[dest]
            else:
                raise ValueError('invalid destination language')

        if isinstance(text, list):
            result = []
            for item in text:
                translated = self.translate_legacy(item, dest=dest, src=src, **kwargs)
                result.append(translated)
            return result

        origin = text
        data, response = self.translate_legacy(text, dest, src)

        # this code will be updated when the format is changed.
        translated = ''.join([d[0] if d[0] else '' for d in data[0]])

        extra_data = self._parse_extra_data(data)

        # actual source language that will be recognized by Google Translator when the
        # src passed is equal to auto.
        try:
            src = data[2]
        except Exception:  # pragma: nocover
            pass

        pron = origin
        try:
            pron = data[0][1][-2]
        except Exception:  # pragma: nocover
            pass
        if not PY3 and isinstance(pron, unicode) and isinstance(origin, str):  # pragma: nocover
            origin = origin.decode('utf-8')

        if pron is None:
            try:
                pron = data[0][1][2]
            except:  # pragma: nocover
                pass

        if dest in EXCLUDES and pron == origin:
            pron = translated

        # for python 2.x compatbillity
        if not PY3:  # pragma: nocover
            if isinstance(src, str):
                src = src.decode('utf-8')
            if isinstance(dest, str):
                dest = dest.decode('utf-8')
            if isinstance(translated, str):
                translated = translated.decode('utf-8')

        # put final values into a new Translated object
        result = Translated(src=src, dest=dest, origin=origin,
                            text=translated, pronunciation=pron,
                            extra_data=extra_data,
                            response=response)

        return result

    def detect(self, text):
        translated = self.translate(text, src='auto', dest='en')
        result = Detected(lang=translated.src, confidence=translated.extra_data.get('confidence', None), response=translated._response)
        return result

    def detect_legacy(self, text, **kwargs):
        """Detect language of the input text

        :param text: The source text(s) whose language you want to identify.
                     Batch detection is supported via sequence input.
        :type text: UTF-8 :class:`str`; :class:`unicode`; string sequence (list, tuple, iterator, generator)

        :rtype: Detected
        :rtype: :class:`list` (when a list is passed)

        Basic usage:
            >>> from googletrans import Translator
            >>> translator = Translator()
            >>> translator.detect('   .')
            <Detected lang=ko confidence=0.27041003>
            >>> translator.detect('')
            <Detected lang=ja confidence=0.64889508>
            >>> translator.detect('This sentence is written in English.')
            <Detected lang=en confidence=0.22348526>
            >>> translator.detect('Tiu frazo estas skribita en Esperanto.')
            <Detected lang=eo confidence=0.10538048>

        Advanced usage:
            >>> langs = translator.detect(['', '', 'English', 'le franais'])
            >>> for lang in langs:
            ...    print(lang.lang, lang.confidence)
            ko 1
            ja 0.92929292
            en 0.96954316
            fr 0.043500196
        """
        if isinstance(text, list):
            result = []
            for item in text:
                lang = self.detect(item)
                result.append(lang)
            return result

        data, response = self._translate_legacy(text, 'en', 'auto', kwargs)

        # actual source language that will be recognized by Google Translator when the
        # src passed is equal to auto.
        src = ''
        confidence = 0.0
        try:
            if len(data[8][0]) > 1:
                src = data[8][0]
                confidence = data[8][-2]
            else:
                src = ''.join(data[8][0])
                confidence = data[8][-2][0]
        except Exception:  # pragma: nocover
            pass
        result = Detected(lang=src, confidence=confidence, response=response)

        return result




############################################################
### File: codec.py
############################################################
from .core import encode, decode, alabel, ulabel, IDNAError
import codecs
import re

_unicode_dots_re = re.compile(u'[\u002e\u3002\uff0e\uff61]')

class Codec(codecs.Codec):

    def encode(self, data, errors='strict'):

        if errors != 'strict':
            raise IDNAError("Unsupported error handling \"{0}\"".format(errors))

        if not data:
            return "", 0

        return encode(data), len(data)

    def decode(self, data, errors='strict'):

        if errors != 'strict':
            raise IDNAError("Unsupported error handling \"{0}\"".format(errors))

        if not data:
            return u"", 0

        return decode(data), len(data)

class IncrementalEncoder(codecs.BufferedIncrementalEncoder):
    def _buffer_encode(self, data, errors, final):
        if errors != 'strict':
            raise IDNAError("Unsupported error handling \"{0}\"".format(errors))

        if not data:
            return ("", 0)

        labels = _unicode_dots_re.split(data)
        trailing_dot = u''
        if labels:
            if not labels[-1]:
                trailing_dot = '.'
                del labels[-1]
            elif not final:
                # Keep potentially unfinished label until the next call
                del labels[-1]
                if labels:
                    trailing_dot = '.'

        result = []
        size = 0
        for label in labels:
            result.append(alabel(label))
            if size:
                size += 1
            size += len(label)

        # Join with U+002E
        result = ".".join(result) + trailing_dot
        size += len(trailing_dot)
        return (result, size)

class IncrementalDecoder(codecs.BufferedIncrementalDecoder):
    def _buffer_decode(self, data, errors, final):
        if errors != 'strict':
            raise IDNAError("Unsupported error handling \"{0}\"".format(errors))

        if not data:
            return (u"", 0)

        # IDNA allows decoding to operate on Unicode strings, too.
        if isinstance(data, unicode):
            labels = _unicode_dots_re.split(data)
        else:
            # Must be ASCII string
            data = str(data)
            unicode(data, "ascii")
            labels = data.split(".")

        trailing_dot = u''
        if labels:
            if not labels[-1]:
                trailing_dot = u'.'
                del labels[-1]
            elif not final:
                # Keep potentially unfinished label until the next call
                del labels[-1]
                if labels:
                    trailing_dot = u'.'

        result = []
        size = 0
        for label in labels:
            result.append(ulabel(label))
            if size:
                size += 1
            size += len(label)

        result = u".".join(result) + trailing_dot
        size += len(trailing_dot)
        return (result, size)


class StreamWriter(Codec, codecs.StreamWriter):
    pass

class StreamReader(Codec, codecs.StreamReader):
    pass

def getregentry():
    return codecs.CodecInfo(
        name='idna',
        encode=Codec().encode,
        decode=Codec().decode,
        incrementalencoder=IncrementalEncoder,
        incrementaldecoder=IncrementalDecoder,
        streamwriter=StreamWriter,
        streamreader=StreamReader,
    )




############################################################
### File: codingstatemachine.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

import logging

from .enums import MachineState


class CodingStateMachine(object):
    """
    A state machine to verify a byte sequence for a particular encoding. For
    each byte the detector receives, it will feed that byte to every active
    state machine available, one byte at a time. The state machine changes its
    state based on its previous state and the byte it receives. There are 3
    states in a state machine that are of interest to an auto-detector:

    START state: This is the state to start with, or a legal byte sequence
                 (i.e. a valid code point) for character has been identified.

    ME state:  This indicates that the state machine identified a byte sequence
               that is specific to the charset it is designed for and that
               there is no other possible encoding which can contain this byte
               sequence. This will to lead to an immediate positive answer for
               the detector.

    ERROR state: This indicates the state machine identified an illegal byte
                 sequence for that encoding. This will lead to an immediate
                 negative answer for this encoding. Detector will exclude this
                 encoding from consideration from here on.
    """
    def __init__(self, sm):
        self._model = sm
        self._curr_byte_pos = 0
        self._curr_char_len = 0
        self._curr_state = None
        self.logger = logging.getLogger(__name__)
        self.reset()

    def reset(self):
        self._curr_state = MachineState.START

    def next_state(self, c):
        # for each byte we get its class
        # if it is first byte, we also get byte length
        byte_class = self._model['class_table'][c]
        if self._curr_state == MachineState.START:
            self._curr_byte_pos = 0
            self._curr_char_len = self._model['char_len_table'][byte_class]
        # from byte's class and state_table, we get its next state
        curr_state = (self._curr_state * self._model['class_factor']
                      + byte_class)
        self._curr_state = self._model['state_table'][curr_state]
        self._curr_byte_pos += 1
        return self._curr_state

    def get_current_charlen(self):
        return self._curr_char_len

    def get_coding_state_machine(self):
        return self._model['name']

    @property
    def language(self):
        return self._model['language']




############################################################
### File: compat.py
############################################################
# -*- coding: utf-8 -*-

"""
requests.compat
~~~~~~~~~~~~~~~

This module handles import compatibility issues between Python 2 and
Python 3.
"""

try:
    import chardet
except ImportError:
    import charset_normalizer as chardet

import sys

# -------
# Pythons
# -------

# Syntax sugar.
_ver = sys.version_info

#: Python 2.x?
is_py2 = (_ver[0] == 2)

#: Python 3.x?
is_py3 = (_ver[0] == 3)

has_simplejson = False
try:
    import simplejson as json
    has_simplejson = True
except ImportError:
    import json

# ---------
# Specifics
# ---------

if is_py2:
    from urllib import (
        quote, unquote, quote_plus, unquote_plus, urlencode, getproxies,
        proxy_bypass, proxy_bypass_environment, getproxies_environment)
    from urlparse import urlparse, urlunparse, urljoin, urlsplit, urldefrag
    from urllib2 import parse_http_list
    import cookielib
    from Cookie import Morsel
    from StringIO import StringIO
    # Keep OrderedDict for backwards compatibility.
    from collections import Callable, Mapping, MutableMapping, OrderedDict

    builtin_str = str
    bytes = str
    str = unicode
    basestring = basestring
    numeric_types = (int, long, float)
    integer_types = (int, long)
    JSONDecodeError = ValueError

elif is_py3:
    from urllib.parse import urlparse, urlunparse, urljoin, urlsplit, urlencode, quote, unquote, quote_plus, unquote_plus, urldefrag
    from urllib.request import parse_http_list, getproxies, proxy_bypass, proxy_bypass_environment, getproxies_environment
    from http import cookiejar as cookielib
    from http.cookies import Morsel
    from io import StringIO
    # Keep OrderedDict for backwards compatibility.
    from collections import OrderedDict
    from collections.abc import Callable, Mapping, MutableMapping
    if has_simplejson:
        from simplejson import JSONDecodeError
    else:
        from json import JSONDecodeError

    builtin_str = str
    str = str
    bytes = bytes
    basestring = (str, bytes)
    numeric_types = (int, float)
    integer_types = (int,)




############################################################
### File: connection.py
############################################################
from __future__ import absolute_import

import datetime
import logging
import os
import re
import socket
import warnings
from socket import error as SocketError
from socket import timeout as SocketTimeout

from .packages import six
from .packages.six.moves.http_client import HTTPConnection as _HTTPConnection
from .packages.six.moves.http_client import HTTPException  # noqa: F401
from .util.proxy import create_proxy_ssl_context

try:  # Compiled with SSL?
    import ssl

    BaseSSLError = ssl.SSLError
except (ImportError, AttributeError):  # Platform-specific: No SSL.
    ssl = None

    class BaseSSLError(BaseException):
        pass


try:
    # Python 3: not a no-op, we're adding this to the namespace so it can be imported.
    ConnectionError = ConnectionError
except NameError:
    # Python 2
    class ConnectionError(Exception):
        pass


try:  # Python 3:
    # Not a no-op, we're adding this to the namespace so it can be imported.
    BrokenPipeError = BrokenPipeError
except NameError:  # Python 2:

    class BrokenPipeError(Exception):
        pass


from ._collections import HTTPHeaderDict  # noqa (historical, removed in v2)
from ._version import __version__
from .exceptions import (
    ConnectTimeoutError,
    NewConnectionError,
    SubjectAltNameWarning,
    SystemTimeWarning,
)
from .util import SKIP_HEADER, SKIPPABLE_HEADERS, connection
from .util.ssl_ import (
    assert_fingerprint,
    create_urllib3_context,
    is_ipaddress,
    resolve_cert_reqs,
    resolve_ssl_version,
    ssl_wrap_socket,
)
from .util.ssl_match_hostname import CertificateError, match_hostname

log = logging.getLogger(__name__)

port_by_scheme = {"http": 80, "https": 443}

# When it comes time to update this value as a part of regular maintenance
# (ie test_recent_date is failing) update it to ~6 months before the current date.
RECENT_DATE = datetime.date(2020, 7, 1)

_CONTAINS_CONTROL_CHAR_RE = re.compile(r"[^-!#$%&'*+.^_`|~0-9a-zA-Z]")


class HTTPConnection(_HTTPConnection, object):
    """
    Based on :class:`http.client.HTTPConnection` but provides an extra constructor
    backwards-compatibility layer between older and newer Pythons.

    Additional keyword parameters are used to configure attributes of the connection.
    Accepted parameters include:

    - ``strict``: See the documentation on :class:`urllib3.connectionpool.HTTPConnectionPool`
    - ``source_address``: Set the source address for the current connection.
    - ``socket_options``: Set specific options on the underlying socket. If not specified, then
      defaults are loaded from ``HTTPConnection.default_socket_options`` which includes disabling
      Nagle's algorithm (sets TCP_NODELAY to 1) unless the connection is behind a proxy.

      For example, if you wish to enable TCP Keep Alive in addition to the defaults,
      you might pass:

      .. code-block:: python

         HTTPConnection.default_socket_options + [
             (socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1),
         ]

      Or you may want to disable the defaults by passing an empty list (e.g., ``[]``).
    """

    default_port = port_by_scheme["http"]

    #: Disable Nagle's algorithm by default.
    #: ``[(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]``
    default_socket_options = [(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)]

    #: Whether this connection verifies the host's certificate.
    is_verified = False

    #: Whether this proxy connection (if used) verifies the proxy host's
    #: certificate.
    proxy_is_verified = None

    def __init__(self, *args, **kw):
        if not six.PY2:
            kw.pop("strict", None)

        # Pre-set source_address.
        self.source_address = kw.get("source_address")

        #: The socket options provided by the user. If no options are
        #: provided, we use the default options.
        self.socket_options = kw.pop("socket_options", self.default_socket_options)
        self.getaddrinfo = socket.getaddrinfo

        # Proxy options provided by the user.
        self.proxy = kw.pop("proxy", None)
        self.proxy_config = kw.pop("proxy_config", None)

        _HTTPConnection.__init__(self, *args, **kw)

    @property
    def host(self):
        """
        Getter method to remove any trailing dots that indicate the hostname is an FQDN.

        In general, SSL certificates don't include the trailing dot indicating a
        fully-qualified domain name, and thus, they don't validate properly when
        checked against a domain name that includes the dot. In addition, some
        servers may not expect to receive the trailing dot when provided.

        However, the hostname with trailing dot is critical to DNS resolution; doing a
        lookup with the trailing dot will properly only resolve the appropriate FQDN,
        whereas a lookup without a trailing dot will search the system's search domain
        list. Thus, it's important to keep the original host around for use only in
        those cases where it's appropriate (i.e., when doing DNS lookup to establish the
        actual TCP connection across which we're going to send HTTP requests).
        """
        return self._dns_host.rstrip(".")

    @host.setter
    def host(self, value):
        """
        Setter for the `host` property.

        We assume that only urllib3 uses the _dns_host attribute; httplib itself
        only uses `host`, and it seems reasonable that other libraries follow suit.
        """
        self._dns_host = value

    def _new_conn(self):
        """Establish a socket connection and set nodelay settings on it.

        :return: New socket connection.
        """
        extra_kw = {}
        if self.source_address:
            extra_kw["source_address"] = self.source_address

        if self.socket_options:
            extra_kw["socket_options"] = self.socket_options

        extra_kw['getaddrinfo'] = self.getaddrinfo

        try:
            conn = connection.create_connection(
                (self._dns_host, self.port), self.timeout, **extra_kw
            )

        except SocketTimeout:
            raise ConnectTimeoutError(
                self,
                "Connection to %s timed out. (connect timeout=%s)"
                % (self.host, self.timeout),
            )

        except SocketError as e:
            raise NewConnectionError(
                self, "Failed to establish a new connection: %s" % e
            )

        return conn

    def _is_using_tunnel(self):
        # Google App Engine's httplib does not define _tunnel_host
        return getattr(self, "_tunnel_host", None)

    def _prepare_conn(self, conn):
        self.sock = conn
        if self._is_using_tunnel():
            # TODO: Fix tunnel so it doesn't depend on self.sock state.
            self._tunnel()
            # Mark this connection as not reusable
            self.auto_open = 0

    def connect(self):
        conn = self._new_conn()
        self._prepare_conn(conn)

    def putrequest(self, method, url, *args, **kwargs):
        """ """
        # Empty docstring because the indentation of CPython's implementation
        # is broken but we don't want this method in our documentation.
        match = _CONTAINS_CONTROL_CHAR_RE.search(method)
        if match:
            raise ValueError(
                "Method cannot contain non-token characters %r (found at least %r)"
                % (method, match.group())
            )

        return _HTTPConnection.putrequest(self, method, url, *args, **kwargs)

    def putheader(self, header, *values):
        """ """
        if not any(isinstance(v, str) and v == SKIP_HEADER for v in values):
            _HTTPConnection.putheader(self, header, *values)
        elif six.ensure_str(header.lower()) not in SKIPPABLE_HEADERS:
            raise ValueError(
                "urllib3.util.SKIP_HEADER only supports '%s'"
                % ("', '".join(map(str.title, sorted(SKIPPABLE_HEADERS))),)
            )

    def request(self, method, url, body=None, headers=None):
        if headers is None:
            headers = {}
        else:
            # Avoid modifying the headers passed into .request()
            headers = headers.copy()
        if "user-agent" not in (six.ensure_str(k.lower()) for k in headers):
            headers["User-Agent"] = _get_default_user_agent()
        super(HTTPConnection, self).request(method, url, body=body, headers=headers)

    def request_chunked(self, method, url, body=None, headers=None):
        """
        Alternative to the common request method, which sends the
        body with chunked encoding and not as one block
        """
        headers = headers or {}
        header_keys = set([six.ensure_str(k.lower()) for k in headers])
        skip_accept_encoding = "accept-encoding" in header_keys
        skip_host = "host" in header_keys
        self.putrequest(
            method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host
        )
        if "user-agent" not in header_keys:
            self.putheader("User-Agent", _get_default_user_agent())
        for header, value in headers.items():
            self.putheader(header, value)
        if "transfer-encoding" not in header_keys:
            self.putheader("Transfer-Encoding", "chunked")
        self.endheaders()

        if body is not None:
            stringish_types = six.string_types + (bytes,)
            if isinstance(body, stringish_types):
                body = (body,)
            for chunk in body:
                if not chunk:
                    continue
                if not isinstance(chunk, bytes):
                    chunk = chunk.encode("utf8")
                len_str = hex(len(chunk))[2:]
                to_send = bytearray(len_str.encode())
                to_send += b"\r\n"
                to_send += chunk
                to_send += b"\r\n"
                self.send(to_send)

        # After the if clause, to always have a closed body
        self.send(b"0\r\n\r\n")


class HTTPSConnection(HTTPConnection):
    """
    Many of the parameters to this constructor are passed to the underlying SSL
    socket by means of :py:func:`urllib3.util.ssl_wrap_socket`.
    """

    default_port = port_by_scheme["https"]

    cert_reqs = None
    ca_certs = None
    ca_cert_dir = None
    ca_cert_data = None
    ssl_version = None
    assert_fingerprint = None
    tls_in_tls_required = False

    def __init__(
        self,
        host,
        port=None,
        key_file=None,
        cert_file=None,
        key_password=None,
        strict=None,
        timeout=socket._GLOBAL_DEFAULT_TIMEOUT,
        ssl_context=None,
        server_hostname=None,
        **kw
    ):

        HTTPConnection.__init__(self, host, port, strict=strict, timeout=timeout, **kw)

        self.key_file = key_file
        self.cert_file = cert_file
        self.key_password = key_password
        self.ssl_context = ssl_context
        self.server_hostname = server_hostname

        # Required property for Google AppEngine 1.9.0 which otherwise causes
        # HTTPS requests to go out as HTTP. (See Issue #356)
        self._protocol = "https"

    def set_cert(
        self,
        key_file=None,
        cert_file=None,
        cert_reqs=None,
        key_password=None,
        ca_certs=None,
        assert_hostname=None,
        assert_fingerprint=None,
        ca_cert_dir=None,
        ca_cert_data=None,
    ):
        """
        This method should only be called once, before the connection is used.
        """
        # If cert_reqs is not provided we'll assume CERT_REQUIRED unless we also
        # have an SSLContext object in which case we'll use its verify_mode.
        if cert_reqs is None:
            if self.ssl_context is not None:
                cert_reqs = self.ssl_context.verify_mode
            else:
                cert_reqs = resolve_cert_reqs(None)

        self.key_file = key_file
        self.cert_file = cert_file
        self.cert_reqs = cert_reqs
        self.key_password = key_password
        self.assert_hostname = assert_hostname
        self.assert_fingerprint = assert_fingerprint
        self.ca_certs = ca_certs and os.path.expanduser(ca_certs)
        self.ca_cert_dir = ca_cert_dir and os.path.expanduser(ca_cert_dir)
        self.ca_cert_data = ca_cert_data

    def connect(self):
        # Add certificate verification
        self.sock = conn = self._new_conn()
        hostname = self.host
        tls_in_tls = False

      #  print(self.sock.cipher())

        if self._is_using_tunnel():
            if self.tls_in_tls_required:
                self.sock = conn = self._connect_tls_proxy(hostname, conn)
                tls_in_tls = True

            # Calls self._set_hostport(), so self.host is
            # self._tunnel_host below.
            self._tunnel()
            # Mark this connection as not reusable
            self.auto_open = 0

            # Override the host with the one we're requesting data from.
            hostname = self._tunnel_host

        server_hostname = hostname
        if self.server_hostname is not None:
            server_hostname = self.server_hostname

        is_time_off = datetime.date.today() < RECENT_DATE
        if is_time_off:
            warnings.warn(
                (
                    "System time is way off (before {0}). This will probably "
                    "lead to SSL verification errors"
                ).format(RECENT_DATE),
                SystemTimeWarning,
            )

        # Wrap socket using verification with the root certs in
        # trusted_root_certs
        default_ssl_context = False
        if self.ssl_context is None:
            default_ssl_context = True
            self.ssl_context = create_urllib3_context(
                ssl_version=resolve_ssl_version(self.ssl_version),
                cert_reqs=resolve_cert_reqs(self.cert_reqs),
            )

        context = self.ssl_context
        context.verify_mode = resolve_cert_reqs(self.cert_reqs)

        # Try to load OS default certs if none are given.
        # Works well on Windows (requires Python3.4+)
        if (
            not self.ca_certs
            and not self.ca_cert_dir
            and not self.ca_cert_data
            and default_ssl_context
            and hasattr(context, "load_default_certs")
        ):
            context.load_default_certs()

        self.sock = ssl_wrap_socket(
            sock=conn,
            keyfile=self.key_file,
            certfile=self.cert_file,
            key_password=self.key_password,
            ca_certs=self.ca_certs,
            ca_cert_dir=self.ca_cert_dir,
            ca_cert_data=self.ca_cert_data,
            server_hostname=server_hostname,
            ssl_context=context,
            tls_in_tls=tls_in_tls,
        )

        # If we're using all defaults and the connection
        # is TLSv1 or TLSv1.1 we throw a DeprecationWarning
        # for the host.
        if (
            default_ssl_context
            and self.ssl_version is None
            and hasattr(self.sock, "version")
            and self.sock.version() in {"TLSv1", "TLSv1.1"}
        ):
            warnings.warn(
                "Negotiating TLSv1/TLSv1.1 by default is deprecated "
                "and will be disabled in urllib3 v2.0.0. Connecting to "
                "'%s' with '%s' can be enabled by explicitly opting-in "
                "with 'ssl_version'" % (self.host, self.sock.version()),
                DeprecationWarning,
            )

        if self.assert_fingerprint:
            assert_fingerprint(
                self.sock.getpeercert(binary_form=True), self.assert_fingerprint
            )
        elif (
            context.verify_mode != ssl.CERT_NONE
            and not getattr(context, "check_hostname", False)
            and self.assert_hostname is not False
        ):
            # While urllib3 attempts to always turn off hostname matching from
            # the TLS library, this cannot always be done. So we check whether
            # the TLS Library still thinks it's matching hostnames.
            cert = self.sock.getpeercert()
            if not cert.get("subjectAltName", ()):
                warnings.warn(
                    (
                        "Certificate for {0} has no `subjectAltName`, falling back to check for a "
                        "`commonName` for now. This feature is being removed by major browsers and "
                        "deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 "
                        "for details.)".format(hostname)
                    ),
                    SubjectAltNameWarning,
                )
            _match_hostname(cert, self.assert_hostname or server_hostname)

        self.is_verified = (
            context.verify_mode == ssl.CERT_REQUIRED
            or self.assert_fingerprint is not None
        )

    def _connect_tls_proxy(self, hostname, conn):
        """
        Establish a TLS connection to the proxy using the provided SSL context.
        """
        proxy_config = self.proxy_config
        ssl_context = proxy_config.ssl_context
        if ssl_context:
            # If the user provided a proxy context, we assume CA and client
            # certificates have already been set
            return ssl_wrap_socket(
                sock=conn,
                server_hostname=hostname,
                ssl_context=ssl_context,
            )

        ssl_context = create_proxy_ssl_context(
            self.ssl_version,
            self.cert_reqs,
            self.ca_certs,
            self.ca_cert_dir,
            self.ca_cert_data,
        )

        # If no cert was provided, use only the default options for server
        # certificate validation
        socket = ssl_wrap_socket(
            sock=conn,
            ca_certs=self.ca_certs,
            ca_cert_dir=self.ca_cert_dir,
            ca_cert_data=self.ca_cert_data,
            server_hostname=hostname,
            ssl_context=ssl_context,
        )

        if ssl_context.verify_mode != ssl.CERT_NONE and not getattr(
            ssl_context, "check_hostname", False
        ):
            # While urllib3 attempts to always turn off hostname matching from
            # the TLS library, this cannot always be done. So we check whether
            # the TLS Library still thinks it's matching hostnames.
            cert = socket.getpeercert()
            if not cert.get("subjectAltName", ()):
                warnings.warn(
                    (
                        "Certificate for {0} has no `subjectAltName`, falling back to check for a "
                        "`commonName` for now. This feature is being removed by major browsers and "
                        "deprecated by RFC 2818. (See https://github.com/urllib3/urllib3/issues/497 "
                        "for details.)".format(hostname)
                    ),
                    SubjectAltNameWarning,
                )
            _match_hostname(cert, hostname)

        self.proxy_is_verified = ssl_context.verify_mode == ssl.CERT_REQUIRED
        return socket


def _match_hostname(cert, asserted_hostname):
    # Our upstream implementation of ssl.match_hostname()
    # only applies this normalization to IP addresses so it doesn't
    # match DNS SANs so we do the same thing!
    stripped_hostname = asserted_hostname.strip("u[]")
    if is_ipaddress(stripped_hostname):
        asserted_hostname = stripped_hostname

    try:
        match_hostname(cert, asserted_hostname)
    except CertificateError as e:
        log.warning(
            "Certificate did not match expected hostname: %s. Certificate: %s",
            asserted_hostname,
            cert,
        )
        # Add cert to exception and reraise so client code can inspect
        # the cert when catching the exception, if they want to
        e._peer_cert = cert
        raise


def _get_default_user_agent():
    return "python-urllib3/%s" % __version__


class DummyConnection(object):
    """Used to detect a failed ConnectionCls import."""

    pass


if not ssl:
    HTTPSConnection = DummyConnection  # noqa: F811


VerifiedHTTPSConnection = HTTPSConnection




############################################################
### File: connectionpool.py
############################################################
from __future__ import absolute_import

import errno
import logging
import re
import socket
import sys
import warnings
from socket import error as SocketError
from socket import timeout as SocketTimeout

from .connection import (
    BaseSSLError,
    BrokenPipeError,
    DummyConnection,
    HTTPConnection,
    HTTPException,
    HTTPSConnection,
    VerifiedHTTPSConnection,
    port_by_scheme,
)
from .exceptions import (
    ClosedPoolError,
    EmptyPoolError,
    HeaderParsingError,
    HostChangedError,
    InsecureRequestWarning,
    LocationValueError,
    MaxRetryError,
    NewConnectionError,
    ProtocolError,
    ProxyError,
    ReadTimeoutError,
    SSLError,
    TimeoutError,
)
from .packages import six
from .packages.six.moves import queue
from .request import RequestMethods
from .response import HTTPResponse
from .util.connection import is_connection_dropped
from .util.proxy import connection_requires_http_tunnel
from .util.queue import LifoQueue
from .util.request import set_file_position
from .util.response import assert_header_parsing
from .util.retry import Retry
from .util.ssl_match_hostname import CertificateError
from .util.timeout import Timeout
from .util.url import Url, _encode_target
from .util.url import _normalize_host as normalize_host
from .util.url import get_host, parse_url

xrange = six.moves.xrange

log = logging.getLogger(__name__)

_Default = object()


# Pool objects
class ConnectionPool(object):
    """
    Base class for all connection pools, such as
    :class:`.HTTPConnectionPool` and :class:`.HTTPSConnectionPool`.

    .. note::
       ConnectionPool.urlopen() does not normalize or percent-encode target URIs
       which is useful if your target server doesn't support percent-encoded
       target URIs.
    """

    scheme = None
    QueueCls = LifoQueue

    def __init__(self, host, port=None):
        if not host:
            raise LocationValueError("No host specified.")

        self.host = _normalize_host(host, scheme=self.scheme)
        self._proxy_host = host.lower()
        self.port = port

    def __str__(self):
        return "%s(host=%r, port=%r)" % (type(self).__name__, self.host, self.port)

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
        # Return False to re-raise any potential exceptions
        return False

    def close(self):
        """
        Close all pooled connections and disable the pool.
        """
        pass


# This is taken from http://hg.python.org/cpython/file/7aaba721ebc0/Lib/socket.py#l252
_blocking_errnos = {errno.EAGAIN, errno.EWOULDBLOCK}


class HTTPConnectionPool(ConnectionPool, RequestMethods):
    """
    Thread-safe connection pool for one host.

    :param host:
        Host used for this HTTP Connection (e.g. "localhost"), passed into
        :class:`http.client.HTTPConnection`.

    :param port:
        Port used for this HTTP Connection (None is equivalent to 80), passed
        into :class:`http.client.HTTPConnection`.

    :param strict:
        Causes BadStatusLine to be raised if the status line can't be parsed
        as a valid HTTP/1.0 or 1.1 status line, passed into
        :class:`http.client.HTTPConnection`.

        .. note::
           Only works in Python 2. This parameter is ignored in Python 3.

    :param timeout:
        Socket timeout in seconds for each individual connection. This can
        be a float or integer, which sets the timeout for the HTTP request,
        or an instance of :class:`urllib3.util.Timeout` which gives you more
        fine-grained control over request timeouts. After the constructor has
        been parsed, this is always a `urllib3.util.Timeout` object.

    :param maxsize:
        Number of connections to save that can be reused. More than 1 is useful
        in multithreaded situations. If ``block`` is set to False, more
        connections will be created but they will not be saved once they've
        been used.

    :param block:
        If set to True, no more than ``maxsize`` connections will be used at
        a time. When no free connections are available, the call will block
        until a connection has been released. This is a useful side effect for
        particular multithreaded situations where one does not want to use more
        than maxsize connections per host to prevent flooding.

    :param headers:
        Headers to include with all requests, unless other headers are given
        explicitly.

    :param retries:
        Retry configuration to use by default with requests in this pool.

    :param _proxy:
        Parsed proxy URL, should not be used directly, instead, see
        :class:`urllib3.ProxyManager`

    :param _proxy_headers:
        A dictionary with proxy headers, should not be used directly,
        instead, see :class:`urllib3.ProxyManager`

    :param \\**conn_kw:
        Additional parameters are used to create fresh :class:`urllib3.connection.HTTPConnection`,
        :class:`urllib3.connection.HTTPSConnection` instances.
    """

    scheme = "http"
    ConnectionCls = HTTPConnection
    ResponseCls = HTTPResponse

    def __init__(
        self,
        host,
        port=None,
        strict=False,
        timeout=Timeout.DEFAULT_TIMEOUT,
        maxsize=1,
        block=False,
        headers=None,
        retries=None,
        _proxy=None,
        _proxy_headers=None,
        _proxy_config=None,
        **conn_kw
    ):
        ConnectionPool.__init__(self, host, port)
        RequestMethods.__init__(self, headers)

        self.strict = strict

        if not isinstance(timeout, Timeout):
            timeout = Timeout.from_float(timeout)

        if retries is None:
            retries = Retry.DEFAULT

        self.timeout = timeout
        self.retries = retries

        self.pool = self.QueueCls(maxsize)
        self.block = block

        self.proxy = _proxy
        self.proxy_headers = _proxy_headers or {}
        self.proxy_config = _proxy_config

        # Fill the queue up so that doing get() on it will block properly
        for _ in xrange(maxsize):
            self.pool.put(None)

        # These are mostly for testing and debugging purposes.
        self.num_connections = 0
        self.num_requests = 0
        self.conn_kw = conn_kw

        if self.proxy:
            # Enable Nagle's algorithm for proxies, to avoid packet fragmentation.
            # We cannot know if the user has added default socket options, so we cannot replace the
            # list.
            self.conn_kw.setdefault("socket_options", [])

            self.conn_kw["proxy"] = self.proxy
            self.conn_kw["proxy_config"] = self.proxy_config

    def _new_conn(self):
        """
        Return a fresh :class:`HTTPConnection`.
        """
        self.num_connections += 1
        log.debug(
            "Starting new HTTP connection (%d): %s:%s",
            self.num_connections,
            self.host,
            self.port or "80",
        )

        conn = self.ConnectionCls(
            host=self.host,
            port=self.port,
            timeout=self.timeout.connect_timeout,
            strict=self.strict,
            **self.conn_kw
        )
        return conn

    def _get_conn(self, timeout=None):
        """
        Get a connection. Will return a pooled connection if one is available.

        If no connections are available and :prop:`.block` is ``False``, then a
        fresh connection is returned.

        :param timeout:
            Seconds to wait before giving up and raising
            :class:`urllib3.exceptions.EmptyPoolError` if the pool is empty and
            :prop:`.block` is ``True``.
        """
        conn = None
        try:
            conn = self.pool.get(block=self.block, timeout=timeout)

        except AttributeError:  # self.pool is None
            raise ClosedPoolError(self, "Pool is closed.")

        except queue.Empty:
            if self.block:
                raise EmptyPoolError(
                    self,
                    "Pool reached maximum size and no more connections are allowed.",
                )
            pass  # Oh well, we'll create a new connection then

        # If this is a persistent connection, check if it got disconnected
        if conn and is_connection_dropped(conn):
            log.debug("Resetting dropped connection: %s", self.host)
            conn.close()
            if getattr(conn, "auto_open", 1) == 0:
                # This is a proxied connection that has been mutated by
                # http.client._tunnel() and cannot be reused (since it would
                # attempt to bypass the proxy)
                conn = None

        return conn or self._new_conn()

    def _put_conn(self, conn):
        """
        Put a connection back into the pool.

        :param conn:
            Connection object for the current host and port as returned by
            :meth:`._new_conn` or :meth:`._get_conn`.

        If the pool is already full, the connection is closed and discarded
        because we exceeded maxsize. If connections are discarded frequently,
        then maxsize should be increased.

        If the pool is closed, then the connection will be closed and discarded.
        """
        try:
            self.pool.put(conn, block=False)
            return  # Everything is dandy, done.
        except AttributeError:
            # self.pool is None.
            pass
        except queue.Full:
            # This should never happen if self.block == True
            log.warning(
                "Connection pool is full, discarding connection: %s. Connection pool size: %s",
                self.host,
                self.pool.qsize(),
            )
        # Connection never got put back into the pool, close it.
        if conn:
            conn.close()

    def _validate_conn(self, conn):
        """
        Called right before a request is made, after the socket is created.
        """
        pass

    def _prepare_proxy(self, conn):
        # Nothing to do for HTTP connections.
        pass

    def _get_timeout(self, timeout):
        """Helper that always returns a :class:`urllib3.util.Timeout`"""
        if timeout is _Default:
            return self.timeout.clone()

        if isinstance(timeout, Timeout):
            return timeout.clone()
        else:
            # User passed us an int/float. This is for backwards compatibility,
            # can be removed later
            return Timeout.from_float(timeout)

    def _raise_timeout(self, err, url, timeout_value):
        """Is the error actually a timeout? Will raise a ReadTimeout or pass"""

        if isinstance(err, SocketTimeout):
            raise ReadTimeoutError(
                self, url, "Read timed out. (read timeout=%s)" % timeout_value
            )

        # See the above comment about EAGAIN in Python 3. In Python 2 we have
        # to specifically catch it and throw the timeout error
        if hasattr(err, "errno") and err.errno in _blocking_errnos:
            raise ReadTimeoutError(
                self, url, "Read timed out. (read timeout=%s)" % timeout_value
            )

        # Catch possible read timeouts thrown as SSL errors. If not the
        # case, rethrow the original. We need to do this because of:
        # http://bugs.python.org/issue10272
        if "timed out" in str(err) or "did not complete (read)" in str(
            err
        ):  # Python < 2.7.4
            raise ReadTimeoutError(
                self, url, "Read timed out. (read timeout=%s)" % timeout_value
            )

    def _make_request(
        self, conn, method, url, timeout=_Default, chunked=False, **httplib_request_kw
    ):
        """
        Perform a request on a given urllib connection object taken from our
        pool.

        :param conn:
            a connection from one of our connection pools

        :param timeout:
            Socket timeout in seconds for the request. This can be a
            float or integer, which will set the same timeout value for
            the socket connect and the socket read, or an instance of
            :class:`urllib3.util.Timeout`, which gives you more fine-grained
            control over your timeouts.
        """
        self.num_requests += 1

        timeout_obj = self._get_timeout(timeout)
        timeout_obj.start_connect()
        conn.timeout = timeout_obj.connect_timeout

        # Trigger any extra validation we need to do.
        try:
            self._validate_conn(conn)
        except (SocketTimeout, BaseSSLError) as e:
            # Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.
            self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)
            raise

        # conn.request() calls http.client.*.request, not the method in
        # urllib3.request. It also calls makefile (recv) on the socket.
        try:
            if chunked:
                conn.request_chunked(method, url, **httplib_request_kw)
            else:
                conn.request(method, url, **httplib_request_kw)

        # We are swallowing BrokenPipeError (errno.EPIPE) since the server is
        # legitimately able to close the connection after sending a valid response.
        # With this behaviour, the received response is still readable.
        except BrokenPipeError:
            # Python 3
            pass
        except IOError as e:
            # Python 2 and macOS/Linux
            # EPIPE and ESHUTDOWN are BrokenPipeError on Python 2, and EPROTOTYPE is needed on macOS
            # https://erickt.github.io/blog/2014/11/19/adventures-in-debugging-a-potential-osx-kernel-bug/
            if e.errno not in {
                errno.EPIPE,
                errno.ESHUTDOWN,
                errno.EPROTOTYPE,
            }:
                raise

        # Reset the timeout for the recv() on the socket
        read_timeout = timeout_obj.read_timeout

        # App Engine doesn't have a sock attr
        if getattr(conn, "sock", None):
            # In Python 3 socket.py will catch EAGAIN and return None when you
            # try and read into the file pointer created by http.client, which
            # instead raises a BadStatusLine exception. Instead of catching
            # the exception and assuming all BadStatusLine exceptions are read
            # timeouts, check for a zero timeout before making the request.
            if read_timeout == 0:
                raise ReadTimeoutError(
                    self, url, "Read timed out. (read timeout=%s)" % read_timeout
                )
            if read_timeout is Timeout.DEFAULT_TIMEOUT:
                conn.sock.settimeout(socket.getdefaulttimeout())
            else:  # None or a value
                conn.sock.settimeout(read_timeout)

        # Receive the response from the server
        try:
            try:
                # Python 2.7, use buffering of HTTP responses
                httplib_response = conn.getresponse(buffering=True)
            except TypeError:
                # Python 3
                try:
                    httplib_response = conn.getresponse()
                except BaseException as e:
                    # Remove the TypeError from the exception chain in
                    # Python 3 (including for exceptions like SystemExit).
                    # Otherwise it looks like a bug in the code.
                    six.raise_from(e, None)
        except (SocketTimeout, BaseSSLError, SocketError) as e:
            self._raise_timeout(err=e, url=url, timeout_value=read_timeout)
            raise

        # AppEngine doesn't have a version attr.
        http_version = getattr(conn, "_http_vsn_str", "HTTP/?")
        log.debug(
            '%s://%s:%s "%s %s %s" %s %s',
            self.scheme,
            self.host,
            self.port,
            method,
            url,
            http_version,
            httplib_response.status,
            httplib_response.length,
        )

        try:
            assert_header_parsing(httplib_response.msg)
        except (HeaderParsingError, TypeError) as hpe:  # Platform-specific: Python 3
            log.warning(
                "Failed to parse headers (url=%s): %s",
                self._absolute_url(url),
                hpe,
                exc_info=True,
            )

        return httplib_response

    def _absolute_url(self, path):
        return Url(scheme=self.scheme, host=self.host, port=self.port, path=path).url

    def close(self):
        """
        Close all pooled connections and disable the pool.
        """
        if self.pool is None:
            return
        # Disable access to the pool
        old_pool, self.pool = self.pool, None

        try:
            while True:
                conn = old_pool.get(block=False)
                if conn:
                    conn.close()

        except queue.Empty:
            pass  # Done.

    def is_same_host(self, url):
        """
        Check if the given ``url`` is a member of the same host as this
        connection pool.
        """
        if url.startswith("/"):
            return True

        # TODO: Add optional support for socket.gethostbyname checking.
        scheme, host, port = get_host(url)
        if host is not None:
            host = _normalize_host(host, scheme=scheme)

        # Use explicit default port for comparison when none is given
        if self.port and not port:
            port = port_by_scheme.get(scheme)
        elif not self.port and port == port_by_scheme.get(scheme):
            port = None

        return (scheme, host, port) == (self.scheme, self.host, self.port)

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        retries=None,
        redirect=True,
        assert_same_host=True,
        timeout=_Default,
        pool_timeout=None,
        release_conn=None,
        chunked=False,
        body_pos=None,
        **response_kw
    ):
        """
        Get a connection from the pool and perform an HTTP request. This is the
        lowest level call for making a request, so you'll need to specify all
        the raw details.

        .. note::

           More commonly, it's appropriate to use a convenience method provided
           by :class:`.RequestMethods`, such as :meth:`request`.

        .. note::

           `release_conn` will only behave as expected if
           `preload_content=False` because we want to make
           `preload_content=False` the default behaviour someday soon without
           breaking backwards compatibility.

        :param method:
            HTTP request method (such as GET, POST, PUT, etc.)

        :param url:
            The URL to perform the request on.

        :param body:
            Data to send in the request body, either :class:`str`, :class:`bytes`,
            an iterable of :class:`str`/:class:`bytes`, or a file-like object.

        :param headers:
            Dictionary of custom headers to send, such as User-Agent,
            If-None-Match, etc. If None, pool headers are used. If provided,
            these headers completely replace any pool-specific headers.

        :param retries:
            Configure the number of retries to allow before raising a
            :class:`~urllib3.exceptions.MaxRetryError` exception.

            Pass ``None`` to retry until you receive a response. Pass a
            :class:`~urllib3.util.retry.Retry` object for fine-grained control
            over different types of retries.
            Pass an integer number to retry connection errors that many times,
            but no other types of errors. Pass zero to never retry.

            If ``False``, then retries are disabled and any exception is raised
            immediately. Also, instead of raising a MaxRetryError on redirects,
            the redirect response will be returned.

        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.

        :param redirect:
            If True, automatically handle redirects (status codes 301, 302,
            303, 307, 308). Each redirect counts as a retry. Disabling retries
            will disable redirect, too.

        :param assert_same_host:
            If ``True``, will make sure that the host of the pool requests is
            consistent else will raise HostChangedError. When ``False``, you can
            use the pool on an HTTP proxy and request foreign hosts.

        :param timeout:
            If specified, overrides the default timeout for this one
            request. It may be a float (in seconds) or an instance of
            :class:`urllib3.util.Timeout`.

        :param pool_timeout:
            If set and the pool is set to block=True, then this method will
            block for ``pool_timeout`` seconds and raise EmptyPoolError if no
            connection is available within the time period.

        :param release_conn:
            If False, then the urlopen call will not release the connection
            back into the pool once a response is received (but will release if
            you read the entire contents of the response such as when
            `preload_content=True`). This is useful if you're not preloading
            the response's content immediately. You will need to call
            ``r.release_conn()`` on the response ``r`` to return the connection
            back into the pool. If None, it takes the value of
            ``response_kw.get('preload_content', True)``.

        :param chunked:
            If True, urllib3 will send the body using chunked transfer
            encoding. Otherwise, urllib3 will send the body using the standard
            content-length form. Defaults to False.

        :param int body_pos:
            Position to seek to in file-like body in the event of a retry or
            redirect. Typically this won't need to be set because urllib3 will
            auto-populate the value when needed.

        :param \\**response_kw:
            Additional parameters are passed to
            :meth:`urllib3.response.HTTPResponse.from_httplib`
        """

        parsed_url = parse_url(url)
        destination_scheme = parsed_url.scheme

        if headers is None:
            headers = self.headers

        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)

        if release_conn is None:
            release_conn = response_kw.get("preload_content", True)

        # Check host
        if assert_same_host and not self.is_same_host(url):
            raise HostChangedError(self, url, retries)

        # Ensure that the URL we're connecting to is properly encoded
        if url.startswith("/"):
            url = six.ensure_str(_encode_target(url))
        else:
            url = six.ensure_str(parsed_url.url)

        conn = None

        # Track whether `conn` needs to be released before
        # returning/raising/recursing. Update this variable if necessary, and
        # leave `release_conn` constant throughout the function. That way, if
        # the function recurses, the original value of `release_conn` will be
        # passed down into the recursive call, and its value will be respected.
        #
        # See issue #651 [1] for details.
        #
        # [1] <https://github.com/urllib3/urllib3/issues/651>
        release_this_conn = release_conn

        http_tunnel_required = connection_requires_http_tunnel(
            self.proxy, self.proxy_config, destination_scheme
        )

        # Merge the proxy headers. Only done when not using HTTP CONNECT. We
        # have to copy the headers dict so we can safely change it without those
        # changes being reflected in anyone else's copy.
        if not http_tunnel_required:
            headers = headers.copy()
            headers.update(self.proxy_headers)

        # Must keep the exception bound to a separate variable or else Python 3
        # complains about UnboundLocalError.
        err = None

        # Keep track of whether we cleanly exited the except block. This
        # ensures we do proper cleanup in finally.
        clean_exit = False

        # Rewind body position, if needed. Record current position
        # for future rewinds in the event of a redirect/retry.
        body_pos = set_file_position(body, body_pos)

        try:
            # Request a connection from the queue.
            timeout_obj = self._get_timeout(timeout)
            conn = self._get_conn(timeout=pool_timeout)


            conn.timeout = timeout_obj.connect_timeout

            is_new_proxy_conn = self.proxy is not None and not getattr(
                conn, "sock", None
            )
            if is_new_proxy_conn and http_tunnel_required:
                self._prepare_proxy(conn)

            # Make the request on the httplib connection object.
            httplib_response = self._make_request(
                conn,
                method,
                url,
                timeout=timeout_obj,
                body=body,
                headers=headers,
                chunked=chunked,
            )
            
            # If we're going to release the connection in ``finally:``, then
            # the response doesn't need to know about the connection. Otherwise
            # it will also try to release it and we'll have a double-release
            # mess.
            response_conn = conn if not release_conn else None

            # Pass method to Response for length checking
            response_kw["request_method"] = method

            # Import httplib's response into our own wrapper object
            response = self.ResponseCls.from_httplib(
                httplib_response,
                pool=self,
                connection=response_conn,
                retries=retries,
                **response_kw
            )

            # Everything went great!
            clean_exit = True

        except EmptyPoolError:
            # Didn't get a connection from the pool, no need to clean up
            clean_exit = True
            release_this_conn = False
            raise

        except (
            TimeoutError,
            HTTPException,
            SocketError,
            ProtocolError,
            BaseSSLError,
            SSLError,
            CertificateError,
        ) as e:
            # Discard the connection for these exceptions. It will be
            # replaced during the next _get_conn() call.
            clean_exit = False

            def _is_ssl_error_message_from_http_proxy(ssl_error):
                # We're trying to detect the message 'WRONG_VERSION_NUMBER' but
                # SSLErrors are kinda all over the place when it comes to the message,
                # so we try to cover our bases here!
                message = " ".join(re.split("[^a-z]", str(ssl_error).lower()))
                return (
                    "wrong version number" in message or "unknown protocol" in message
                )

            # Try to detect a common user error with proxies which is to
            # set an HTTP proxy to be HTTPS when it should be 'http://'
            # (ie {'http': 'http://proxy', 'https': 'https://proxy'})
            # Instead we add a nice error message and point to a URL.
            if (
                isinstance(e, BaseSSLError)
                and self.proxy
                and _is_ssl_error_message_from_http_proxy(e)
            ):
                e = ProxyError(
                    "Your proxy appears to only use HTTP and not HTTPS, "
                    "try changing your proxy URL to be HTTP. See: "
                    "https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html"
                    "#https-proxy-error-http-proxy",
                    SSLError(e),
                )
            elif isinstance(e, (BaseSSLError, CertificateError)):
                e = SSLError(e)
            elif isinstance(e, (SocketError, NewConnectionError)) and self.proxy:
                e = ProxyError("Cannot connect to proxy.", e)
            elif isinstance(e, (SocketError, HTTPException)):
                e = ProtocolError("Connection aborted.", e)

            retries = retries.increment(
                method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]
            )
            retries.sleep()

            # Keep track of the error for the retry warning.
            err = e

        finally:
            if not clean_exit:
                # We hit some kind of exception, handled or otherwise. We need
                # to throw the connection away unless explicitly told not to.
                # Close the connection, set the variable to None, and make sure
                # we put the None back in the pool to avoid leaking it.
                conn = conn and conn.close()
                release_this_conn = True

            if release_this_conn:
                # Put the connection back to be reused. If the connection is
                # expired then it will be None, which will get replaced with a
                # fresh connection during _get_conn.
                self._put_conn(conn)

        if not conn:
            # Try again
            log.warning(
                "Retrying (%r) after connection broken by '%r': %s", retries, err, url
            )
            return self.urlopen(
                method,
                url,
                body,
                headers,
                retries,
                redirect,
                assert_same_host,
                timeout=timeout,
                pool_timeout=pool_timeout,
                release_conn=release_conn,
                chunked=chunked,
                body_pos=body_pos,
                **response_kw
            )

        # Handle redirect?
        redirect_location = redirect and response.get_redirect_location()
        if redirect_location:
            if response.status == 303:
                method = "GET"

            try:
                retries = retries.increment(method, url, response=response, _pool=self)
            except MaxRetryError:
                if retries.raise_on_redirect:
                    response.drain_conn()
                    raise
                return response

            response.drain_conn()
            retries.sleep_for_retry(response)
            log.debug("Redirecting %s -> %s", url, redirect_location)
            return self.urlopen(
                method,
                redirect_location,
                body,
                headers,
                retries=retries,
                redirect=redirect,
                assert_same_host=assert_same_host,
                timeout=timeout,
                pool_timeout=pool_timeout,
                release_conn=release_conn,
                chunked=chunked,
                body_pos=body_pos,
                **response_kw
            )

        # Check if we should retry the HTTP response.
        has_retry_after = bool(response.getheader("Retry-After"))
        if retries.is_retry(method, response.status, has_retry_after):
            try:
                retries = retries.increment(method, url, response=response, _pool=self)
            except MaxRetryError:
                if retries.raise_on_status:
                    response.drain_conn()
                    raise
                return response

            response.drain_conn()
            retries.sleep(response)
            log.debug("Retry: %s", url)
            return self.urlopen(
                method,
                url,
                body,
                headers,
                retries=retries,
                redirect=redirect,
                assert_same_host=assert_same_host,
                timeout=timeout,
                pool_timeout=pool_timeout,
                release_conn=release_conn,
                chunked=chunked,
                body_pos=body_pos,
                **response_kw
            )

        return response


class HTTPSConnectionPool(HTTPConnectionPool):
    """
    Same as :class:`.HTTPConnectionPool`, but HTTPS.

    :class:`.HTTPSConnection` uses one of ``assert_fingerprint``,
    ``assert_hostname`` and ``host`` in this order to verify connections.
    If ``assert_hostname`` is False, no verification is done.

    The ``key_file``, ``cert_file``, ``cert_reqs``, ``ca_certs``,
    ``ca_cert_dir``, ``ssl_version``, ``key_password`` are only used if :mod:`ssl`
    is available and are fed into :meth:`urllib3.util.ssl_wrap_socket` to upgrade
    the connection socket into an SSL socket.
    """

    scheme = "https"
    ConnectionCls = HTTPSConnection

    def __init__(
        self,
        host,
        port=None,
        strict=False,
        timeout=Timeout.DEFAULT_TIMEOUT,
        maxsize=1,
        block=False,
        headers=None,
        retries=None,
        _proxy=None,
        _proxy_headers=None,
        key_file=None,
        cert_file=None,
        cert_reqs=None,
        key_password=None,
        ca_certs=None,
        ssl_version=None,
        assert_hostname=None,
        assert_fingerprint=None,
        ca_cert_dir=None,
        **conn_kw
    ):

        HTTPConnectionPool.__init__(
            self,
            host,
            port,
            strict,
            timeout,
            maxsize,
            block,
            headers,
            retries,
            _proxy,
            _proxy_headers,
            **conn_kw
        )

        self.key_file = key_file
        self.cert_file = cert_file
        self.cert_reqs = cert_reqs
        self.key_password = key_password
        self.ca_certs = ca_certs
        self.ca_cert_dir = ca_cert_dir
        self.ssl_version = ssl_version
        self.assert_hostname = assert_hostname
        self.assert_fingerprint = assert_fingerprint

    def _prepare_conn(self, conn):
        """
        Prepare the ``connection`` for :meth:`urllib3.util.ssl_wrap_socket`
        and establish the tunnel if proxy is used.
        """

        if isinstance(conn, VerifiedHTTPSConnection):
            conn.set_cert(
                key_file=self.key_file,
                key_password=self.key_password,
                cert_file=self.cert_file,
                cert_reqs=self.cert_reqs,
                ca_certs=self.ca_certs,
                ca_cert_dir=self.ca_cert_dir,
                assert_hostname=self.assert_hostname,
                assert_fingerprint=self.assert_fingerprint,
            )
            conn.ssl_version = self.ssl_version
        return conn

    def _prepare_proxy(self, conn):
        """
        Establishes a tunnel connection through HTTP CONNECT.

        Tunnel connection is established early because otherwise httplib would
        improperly set Host: header to proxy's IP:port.
        """

        conn.set_tunnel(self._proxy_host, self.port, self.proxy_headers)

        if self.proxy.scheme == "https":
            conn.tls_in_tls_required = True

        conn.connect()

    def _new_conn(self):
        """
        Return a fresh :class:`http.client.HTTPSConnection`.
        """
        self.num_connections += 1
        log.debug(
            "Starting new HTTPS connection (%d): %s:%s",
            self.num_connections,
            self.host,
            self.port or "443",
        )

        if not self.ConnectionCls or self.ConnectionCls is DummyConnection:
            raise SSLError(
                "Can't connect to HTTPS URL because the SSL module is not available."
            )

        actual_host = self.host
        actual_port = self.port
        if self.proxy is not None:
            actual_host = self.proxy.host
            actual_port = self.proxy.port

        conn = self.ConnectionCls(
            host=actual_host,
            port=actual_port,
            timeout=self.timeout.connect_timeout,
            strict=self.strict,
            cert_file=self.cert_file,
            key_file=self.key_file,
            key_password=self.key_password,
            **self.conn_kw
        )

        return self._prepare_conn(conn)

    def _validate_conn(self, conn):
        """
        Called right before a request is made, after the socket is created.
        """
        super(HTTPSConnectionPool, self)._validate_conn(conn)

        # Force connect early to allow us to validate the connection.
        if not getattr(conn, "sock", None):  # AppEngine might not have  `.sock`
            conn.connect()

        if not conn.is_verified:
            warnings.warn(
                (
                    "Unverified HTTPS request is being made to host '%s'. "
                    "Adding certificate verification is strongly advised. See: "
                    "https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html"
                    "#ssl-warnings" % conn.host
                ),
                InsecureRequestWarning,
            )

        if getattr(conn, "proxy_is_verified", None) is False:
            warnings.warn(
                (
                    "Unverified HTTPS connection done to an HTTPS proxy. "
                    "Adding certificate verification is strongly advised. See: "
                    "https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html"
                    "#ssl-warnings"
                ),
                InsecureRequestWarning,
            )


def connection_from_url(url, **kw):
    """
    Given a url, return an :class:`.ConnectionPool` instance of its host.

    This is a shortcut for not having to parse out the scheme, host, and port
    of the url before creating an :class:`.ConnectionPool` instance.

    :param url:
        Absolute URL string that must include the scheme. Port is optional.

    :param \\**kw:
        Passes additional parameters to the constructor of the appropriate
        :class:`.ConnectionPool`. Useful for specifying things like
        timeout, maxsize, headers, etc.

    Example::

        >>> conn = connection_from_url('http://google.com/')
        >>> r = conn.request('GET', '/')
    """
    scheme, host, port = get_host(url)
    port = port or port_by_scheme.get(scheme, 80)
    if scheme == "https":
        return HTTPSConnectionPool(host, port=port, **kw)
    else:
        return HTTPConnectionPool(host, port=port, **kw)


def _normalize_host(host, scheme):
    """
    Normalize hosts for comparisons and use with sockets.
    """

    host = normalize_host(host, scheme)

    # httplib doesn't like it when we include brackets in IPv6 addresses
    # Specifically, if we include brackets but also pass the port then
    # httplib crazily doubles up the square brackets on the Host header.
    # Instead, we need to make sure we never pass ``None`` as the port.
    # However, for backward compatibility reasons we can't actually
    # *assert* that.  See http://bugs.python.org/issue28539
    if host.startswith("[") and host.endswith("]"):
        host = host[1:-1]
    return host




############################################################
### File: constants.py
############################################################
DEFAULT_USER_AGENT = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'

DEFAULT_CLIENT_SERVICE_URLS = (
    'translate.google.com',
)

DEFAULT_FALLBACK_SERVICE_URLS = (
    'translate.googleapis.com',
)

DEFAULT_SERVICE_URLS = ('translate.google.ac', 'translate.google.ad', 'translate.google.ae',
                        'translate.google.al', 'translate.google.am', 'translate.google.as',
                        'translate.google.at', 'translate.google.az', 'translate.google.ba',
                        'translate.google.be', 'translate.google.bf', 'translate.google.bg',
                        'translate.google.bi', 'translate.google.bj', 'translate.google.bs',
                        'translate.google.bt', 'translate.google.by', 'translate.google.ca',
                        'translate.google.cat', 'translate.google.cc', 'translate.google.cd',
                        'translate.google.cf', 'translate.google.cg', 'translate.google.ch',
                        'translate.google.ci', 'translate.google.cl', 'translate.google.cm',
                        'translate.google.cn', 'translate.google.co.ao', 'translate.google.co.bw',
                        'translate.google.co.ck', 'translate.google.co.cr', 'translate.google.co.id',
                        'translate.google.co.il', 'translate.google.co.in', 'translate.google.co.jp',
                        'translate.google.co.ke', 'translate.google.co.kr', 'translate.google.co.ls',
                        'translate.google.co.ma', 'translate.google.co.mz', 'translate.google.co.nz',
                        'translate.google.co.th', 'translate.google.co.tz', 'translate.google.co.ug',
                        'translate.google.co.uk', 'translate.google.co.uz', 'translate.google.co.ve',
                        'translate.google.co.vi', 'translate.google.co.za', 'translate.google.co.zm',
                        'translate.google.co.zw', 'translate.google.com.af', 'translate.google.com.ag',
                        'translate.google.com.ai', 'translate.google.com.ar', 'translate.google.com.au',
                        'translate.google.com.bd', 'translate.google.com.bh', 'translate.google.com.bn',
                        'translate.google.com.bo', 'translate.google.com.br', 'translate.google.com.bz',
                        'translate.google.com.co', 'translate.google.com.cu', 'translate.google.com.cy',
                        'translate.google.com.do', 'translate.google.com.ec', 'translate.google.com.eg',
                        'translate.google.com.et', 'translate.google.com.fj', 'translate.google.com.gh',
                        'translate.google.com.gi', 'translate.google.com.gt', 'translate.google.com.hk',
                        'translate.google.com.jm', 'translate.google.com.kh', 'translate.google.com.kw',
                        'translate.google.com.lb', 'translate.google.com.ly', 'translate.google.com.mm',
                        'translate.google.com.mt', 'translate.google.com.mx', 'translate.google.com.my',
                        'translate.google.com.na', 'translate.google.com.ng', 'translate.google.com.ni',
                        'translate.google.com.np', 'translate.google.com.om', 'translate.google.com.pa',
                        'translate.google.com.pe', 'translate.google.com.pg', 'translate.google.com.ph',
                        'translate.google.com.pk', 'translate.google.com.pr', 'translate.google.com.py',
                        'translate.google.com.qa', 'translate.google.com.sa', 'translate.google.com.sb',
                        'translate.google.com.sg', 'translate.google.com.sl', 'translate.google.com.sv',
                        'translate.google.com.tj', 'translate.google.com.tr', 'translate.google.com.tw',
                        'translate.google.com.ua', 'translate.google.com.uy', 'translate.google.com.vc',
                        'translate.google.com.vn', 'translate.google.com', 'translate.google.cv',
                        'translate.google.cz', 'translate.google.de', 'translate.google.dj',
                        'translate.google.dk', 'translate.google.dm', 'translate.google.dz',
                        'translate.google.ee', 'translate.google.es', 'translate.google.eu',
                        'translate.google.fi', 'translate.google.fm', 'translate.google.fr',
                        'translate.google.ga', 'translate.google.ge', 'translate.google.gf',
                        'translate.google.gg', 'translate.google.gl', 'translate.google.gm',
                        'translate.google.gp', 'translate.google.gr', 'translate.google.gy',
                        'translate.google.hn', 'translate.google.hr', 'translate.google.ht',
                        'translate.google.hu', 'translate.google.ie', 'translate.google.im',
                        'translate.google.io', 'translate.google.iq', 'translate.google.is',
                        'translate.google.it', 'translate.google.je', 'translate.google.jo',
                        'translate.google.kg', 'translate.google.ki', 'translate.google.kz',
                        'translate.google.la', 'translate.google.li', 'translate.google.lk',
                        'translate.google.lt', 'translate.google.lu', 'translate.google.lv',
                        'translate.google.md', 'translate.google.me', 'translate.google.mg',
                        'translate.google.mk', 'translate.google.ml', 'translate.google.mn',
                        'translate.google.ms', 'translate.google.mu', 'translate.google.mv',
                        'translate.google.mw', 'translate.google.ne', 'translate.google.nf',
                        'translate.google.nl', 'translate.google.no', 'translate.google.nr',
                        'translate.google.nu', 'translate.google.pl', 'translate.google.pn',
                        'translate.google.ps', 'translate.google.pt', 'translate.google.ro',
                        'translate.google.rs', 'translate.google.ru', 'translate.google.rw',
                        'translate.google.sc', 'translate.google.se', 'translate.google.sh',
                        'translate.google.si', 'translate.google.sk', 'translate.google.sm',
                        'translate.google.sn', 'translate.google.so', 'translate.google.sr',
                        'translate.google.st', 'translate.google.td', 'translate.google.tg',
                        'translate.google.tk', 'translate.google.tl', 'translate.google.tm',
                        'translate.google.tn', 'translate.google.to', 'translate.google.tt',
                        'translate.google.us', 'translate.google.vg', 'translate.google.vu',
                        'translate.google.ws')

SPECIAL_CASES = {
    'ee': 'et',
}

LANGUAGES = {
    'af': 'afrikaans',
    'sq': 'albanian',
    'am': 'amharic',
    'ar': 'arabic',
    'hy': 'armenian',
    'az': 'azerbaijani',
    'eu': 'basque',
    'be': 'belarusian',
    'bn': 'bengali',
    'bs': 'bosnian',
    'bg': 'bulgarian',
    'ca': 'catalan',
    'ceb': 'cebuano',
    'ny': 'chichewa',
    'zh-cn': 'chinese (simplified)',
    'zh-tw': 'chinese (traditional)',
    'co': 'corsican',
    'hr': 'croatian',
    'cs': 'czech',
    'da': 'danish',
    'nl': 'dutch',
    'en': 'english',
    'eo': 'esperanto',
    'et': 'estonian',
    'tl': 'filipino',
    'fi': 'finnish',
    'fr': 'french',
    'fy': 'frisian',
    'gl': 'galician',
    'ka': 'georgian',
    'de': 'german',
    'el': 'greek',
    'gu': 'gujarati',
    'ht': 'haitian creole',
    'ha': 'hausa',
    'haw': 'hawaiian',
    'iw': 'hebrew',
    'he': 'hebrew',
    'hi': 'hindi',
    'hmn': 'hmong',
    'hu': 'hungarian',
    'is': 'icelandic',
    'ig': 'igbo',
    'id': 'indonesian',
    'ga': 'irish',
    'it': 'italian',
    'ja': 'japanese',
    'jw': 'javanese',
    'kn': 'kannada',
    'kk': 'kazakh',
    'km': 'khmer',
    'ko': 'korean',
    'ku': 'kurdish (kurmanji)',
    'ky': 'kyrgyz',
    'lo': 'lao',
    'la': 'latin',
    'lv': 'latvian',
    'lt': 'lithuanian',
    'lb': 'luxembourgish',
    'mk': 'macedonian',
    'mg': 'malagasy',
    'ms': 'malay',
    'ml': 'malayalam',
    'mt': 'maltese',
    'mi': 'maori',
    'mr': 'marathi',
    'mn': 'mongolian',
    'my': 'myanmar (burmese)',
    'ne': 'nepali',
    'no': 'norwegian',
    'or': 'odia',
    'ps': 'pashto',
    'fa': 'persian',
    'pl': 'polish',
    'pt': 'portuguese',
    'pa': 'punjabi',
    'ro': 'romanian',
    'ru': 'russian',
    'sm': 'samoan',
    'gd': 'scots gaelic',
    'sr': 'serbian',
    'st': 'sesotho',
    'sn': 'shona',
    'sd': 'sindhi',
    'si': 'sinhala',
    'sk': 'slovak',
    'sl': 'slovenian',
    'so': 'somali',
    'es': 'spanish',
    'su': 'sundanese',
    'sw': 'swahili',
    'sv': 'swedish',
    'tg': 'tajik',
    'ta': 'tamil',
    'te': 'telugu',
    'th': 'thai',
    'tr': 'turkish',
    'uk': 'ukrainian',
    'ur': 'urdu',
    'ug': 'uyghur',
    'uz': 'uzbek',
    'vi': 'vietnamese',
    'cy': 'welsh',
    'xh': 'xhosa',
    'yi': 'yiddish',
    'yo': 'yoruba',
    'zu': 'zulu',
}

LANGCODES = dict(map(reversed, LANGUAGES.items()))
DEFAULT_RAISE_EXCEPTION = False
DUMMY_DATA = [[["", None, None, 0]], None, "en", None,
              None, None, 1, None, [["en"], None, [1], ["en"]]]




############################################################
### File: cookies.py
############################################################
# -*- coding: utf-8 -*-

"""
requests.cookies
~~~~~~~~~~~~~~~~

Compatibility code to be able to use `cookielib.CookieJar` with requests.

requests.utils imports from here, so be careful with imports.
"""

import copy
import time
import calendar

from ._internal_utils import to_native_string
from .compat import cookielib, urlparse, urlunparse, Morsel, MutableMapping

try:
    import threading
except ImportError:
    import dummy_threading as threading


class MockRequest(object):
    """Wraps a `requests.Request` to mimic a `urllib2.Request`.

    The code in `cookielib.CookieJar` expects this interface in order to correctly
    manage cookie policies, i.e., determine whether a cookie can be set, given the
    domains of the request and the cookie.

    The original request object is read-only. The client is responsible for collecting
    the new headers via `get_new_headers()` and interpreting them appropriately. You
    probably want `get_cookie_header`, defined below.
    """

    def __init__(self, request):
        self._r = request
        self._new_headers = {}
        self.type = urlparse(self._r.url).scheme

    def get_type(self):
        return self.type

    def get_host(self):
        return urlparse(self._r.url).netloc

    def get_origin_req_host(self):
        return self.get_host()

    def get_full_url(self):
        # Only return the response's URL if the user hadn't set the Host
        # header
        if not self._r.headers.get('Host'):
            return self._r.url
        # If they did set it, retrieve it and reconstruct the expected domain
        host = to_native_string(self._r.headers['Host'], encoding='utf-8')
        parsed = urlparse(self._r.url)
        # Reconstruct the URL as we expect it
        return urlunparse([
            parsed.scheme, host, parsed.path, parsed.params, parsed.query,
            parsed.fragment
        ])

    def is_unverifiable(self):
        return True

    def has_header(self, name):
        return name in self._r.headers or name in self._new_headers

    def get_header(self, name, default=None):
        return self._r.headers.get(name, self._new_headers.get(name, default))

    def add_header(self, key, val):
        """cookielib has no legitimate use for this method; add it back if you find one."""
        raise NotImplementedError("Cookie headers should be added with add_unredirected_header()")

    def add_unredirected_header(self, name, value):
        self._new_headers[name] = value

    def get_new_headers(self):
        return self._new_headers

    @property
    def unverifiable(self):
        return self.is_unverifiable()

    @property
    def origin_req_host(self):
        return self.get_origin_req_host()

    @property
    def host(self):
        return self.get_host()


class MockResponse(object):
    """Wraps a `httplib.HTTPMessage` to mimic a `urllib.addinfourl`.

    ...what? Basically, expose the parsed HTTP headers from the server response
    the way `cookielib` expects to see them.
    """

    def __init__(self, headers):
        """Make a MockResponse for `cookielib` to read.

        :param headers: a httplib.HTTPMessage or analogous carrying the headers
        """
        self._headers = headers

    def info(self):
        return self._headers

    def getheaders(self, name):
        self._headers.getheaders(name)


def extract_cookies_to_jar(jar, request, response):
    """Extract the cookies from the response into a CookieJar.

    :param jar: cookielib.CookieJar (not necessarily a RequestsCookieJar)
    :param request: our own requests.Request object
    :param response: urllib3.HTTPResponse object
    """
    if not (hasattr(response, '_original_response') and
            response._original_response):
        return
    # the _original_response field is the wrapped httplib.HTTPResponse object,
    req = MockRequest(request)
    # pull out the HTTPMessage with the headers and put it in the mock:
    res = MockResponse(response._original_response.msg)
    jar.extract_cookies(res, req)


def get_cookie_header(jar, request):
    """
    Produce an appropriate Cookie header string to be sent with `request`, or None.

    :rtype: str
    """
    r = MockRequest(request)
    jar.add_cookie_header(r)
    return r.get_new_headers().get('Cookie')


def remove_cookie_by_name(cookiejar, name, domain=None, path=None):
    """Unsets a cookie by name, by default over all domains and paths.

    Wraps CookieJar.clear(), is O(n).
    """
    clearables = []
    for cookie in cookiejar:
        if cookie.name != name:
            continue
        if domain is not None and domain != cookie.domain:
            continue
        if path is not None and path != cookie.path:
            continue
        clearables.append((cookie.domain, cookie.path, cookie.name))

    for domain, path, name in clearables:
        cookiejar.clear(domain, path, name)


class CookieConflictError(RuntimeError):
    """There are two cookies that meet the criteria specified in the cookie jar.
    Use .get and .set and include domain and path args in order to be more specific.
    """


class RequestsCookieJar(cookielib.CookieJar, MutableMapping):
    """Compatibility class; is a cookielib.CookieJar, but exposes a dict
    interface.

    This is the CookieJar we create by default for requests and sessions that
    don't specify one, since some clients may expect response.cookies and
    session.cookies to support dict operations.

    Requests does not use the dict interface internally; it's just for
    compatibility with external client code. All requests code should work
    out of the box with externally provided instances of ``CookieJar``, e.g.
    ``LWPCookieJar`` and ``FileCookieJar``.

    Unlike a regular CookieJar, this class is pickleable.

    .. warning:: dictionary operations that are normally O(1) may be O(n).
    """

    def get(self, name, default=None, domain=None, path=None):
        """Dict-like get() that also supports optional domain and path args in
        order to resolve naming collisions from using one cookie jar over
        multiple domains.

        .. warning:: operation is O(n), not O(1).
        """
        try:
            return self._find_no_duplicates(name, domain, path)
        except KeyError:
            return default

    def set(self, name, value, **kwargs):
        """Dict-like set() that also supports optional domain and path args in
        order to resolve naming collisions from using one cookie jar over
        multiple domains.
        """
        # support client code that unsets cookies by assignment of a None value:
        if value is None:
            remove_cookie_by_name(self, name, domain=kwargs.get('domain'), path=kwargs.get('path'))
            return

        if isinstance(value, Morsel):
            c = morsel_to_cookie(value)
        else:
            c = create_cookie(name, value, **kwargs)
        self.set_cookie(c)
        return c

    def iterkeys(self):
        """Dict-like iterkeys() that returns an iterator of names of cookies
        from the jar.

        .. seealso:: itervalues() and iteritems().
        """
        for cookie in iter(self):
            yield cookie.name

    def keys(self):
        """Dict-like keys() that returns a list of names of cookies from the
        jar.

        .. seealso:: values() and items().
        """
        return list(self.iterkeys())

    def itervalues(self):
        """Dict-like itervalues() that returns an iterator of values of cookies
        from the jar.

        .. seealso:: iterkeys() and iteritems().
        """
        for cookie in iter(self):
            yield cookie.value

    def values(self):
        """Dict-like values() that returns a list of values of cookies from the
        jar.

        .. seealso:: keys() and items().
        """
        return list(self.itervalues())

    def iteritems(self):
        """Dict-like iteritems() that returns an iterator of name-value tuples
        from the jar.

        .. seealso:: iterkeys() and itervalues().
        """
        for cookie in iter(self):
            yield cookie.name, cookie.value

    def items(self):
        """Dict-like items() that returns a list of name-value tuples from the
        jar. Allows client-code to call ``dict(RequestsCookieJar)`` and get a
        vanilla python dict of key value pairs.

        .. seealso:: keys() and values().
        """
        return list(self.iteritems())

    def list_domains(self):
        """Utility method to list all the domains in the jar."""
        domains = []
        for cookie in iter(self):
            if cookie.domain not in domains:
                domains.append(cookie.domain)
        return domains

    def list_paths(self):
        """Utility method to list all the paths in the jar."""
        paths = []
        for cookie in iter(self):
            if cookie.path not in paths:
                paths.append(cookie.path)
        return paths

    def multiple_domains(self):
        """Returns True if there are multiple domains in the jar.
        Returns False otherwise.

        :rtype: bool
        """
        domains = []
        for cookie in iter(self):
            if cookie.domain is not None and cookie.domain in domains:
                return True
            domains.append(cookie.domain)
        return False  # there is only one domain in jar

    def get_dict(self, domain=None, path=None):
        """Takes as an argument an optional domain and path and returns a plain
        old Python dict of name-value pairs of cookies that meet the
        requirements.

        :rtype: dict
        """
        dictionary = {}
        for cookie in iter(self):
            if (
                (domain is None or cookie.domain == domain) and
                (path is None or cookie.path == path)
            ):
                dictionary[cookie.name] = cookie.value
        return dictionary

    def __contains__(self, name):
        try:
            return super(RequestsCookieJar, self).__contains__(name)
        except CookieConflictError:
            return True

    def __getitem__(self, name):
        """Dict-like __getitem__() for compatibility with client code. Throws
        exception if there are more than one cookie with name. In that case,
        use the more explicit get() method instead.

        .. warning:: operation is O(n), not O(1).
        """
        return self._find_no_duplicates(name)

    def __setitem__(self, name, value):
        """Dict-like __setitem__ for compatibility with client code. Throws
        exception if there is already a cookie of that name in the jar. In that
        case, use the more explicit set() method instead.
        """
        self.set(name, value)

    def __delitem__(self, name):
        """Deletes a cookie given a name. Wraps ``cookielib.CookieJar``'s
        ``remove_cookie_by_name()``.
        """
        remove_cookie_by_name(self, name)

    def set_cookie(self, cookie, *args, **kwargs):
        if hasattr(cookie.value, 'startswith') and cookie.value.startswith('"') and cookie.value.endswith('"'):
            cookie.value = cookie.value.replace('\\"', '')
        return super(RequestsCookieJar, self).set_cookie(cookie, *args, **kwargs)

    def update(self, other):
        """Updates this jar with cookies from another CookieJar or dict-like"""
        if isinstance(other, cookielib.CookieJar):
            for cookie in other:
                self.set_cookie(copy.copy(cookie))
        else:
            super(RequestsCookieJar, self).update(other)

    def _find(self, name, domain=None, path=None):
        """Requests uses this method internally to get cookie values.

        If there are conflicting cookies, _find arbitrarily chooses one.
        See _find_no_duplicates if you want an exception thrown if there are
        conflicting cookies.

        :param name: a string containing name of cookie
        :param domain: (optional) string containing domain of cookie
        :param path: (optional) string containing path of cookie
        :return: cookie.value
        """
        for cookie in iter(self):
            if cookie.name == name:
                if domain is None or cookie.domain == domain:
                    if path is None or cookie.path == path:
                        return cookie.value

        raise KeyError('name=%r, domain=%r, path=%r' % (name, domain, path))

    def _find_no_duplicates(self, name, domain=None, path=None):
        """Both ``__get_item__`` and ``get`` call this function: it's never
        used elsewhere in Requests.

        :param name: a string containing name of cookie
        :param domain: (optional) string containing domain of cookie
        :param path: (optional) string containing path of cookie
        :raises KeyError: if cookie is not found
        :raises CookieConflictError: if there are multiple cookies
            that match name and optionally domain and path
        :return: cookie.value
        """
        toReturn = None
        for cookie in iter(self):
            if cookie.name == name:
                if domain is None or cookie.domain == domain:
                    if path is None or cookie.path == path:
                        if toReturn is not None:  # if there are multiple cookies that meet passed in criteria
                            raise CookieConflictError('There are multiple cookies with name, %r' % (name))
                        toReturn = cookie.value  # we will eventually return this as long as no cookie conflict

        if toReturn:
            return toReturn
        raise KeyError('name=%r, domain=%r, path=%r' % (name, domain, path))

    def __getstate__(self):
        """Unlike a normal CookieJar, this class is pickleable."""
        state = self.__dict__.copy()
        # remove the unpickleable RLock object
        state.pop('_cookies_lock')
        return state

    def __setstate__(self, state):
        """Unlike a normal CookieJar, this class is pickleable."""
        self.__dict__.update(state)
        if '_cookies_lock' not in self.__dict__:
            self._cookies_lock = threading.RLock()

    def copy(self):
        """Return a copy of this RequestsCookieJar."""
        new_cj = RequestsCookieJar()
        new_cj.set_policy(self.get_policy())
        new_cj.update(self)
        return new_cj

    def get_policy(self):
        """Return the CookiePolicy instance used."""
        return self._policy


def _copy_cookie_jar(jar):
    if jar is None:
        return None

    if hasattr(jar, 'copy'):
        # We're dealing with an instance of RequestsCookieJar
        return jar.copy()
    # We're dealing with a generic CookieJar instance
    new_jar = copy.copy(jar)
    new_jar.clear()
    for cookie in jar:
        new_jar.set_cookie(copy.copy(cookie))
    return new_jar


def create_cookie(name, value, **kwargs):
    """Make a cookie from underspecified parameters.

    By default, the pair of `name` and `value` will be set for the domain ''
    and sent on every request (this is sometimes called a "supercookie").
    """
    result = {
        'version': 0,
        'name': name,
        'value': value,
        'port': None,
        'domain': '',
        'path': '/',
        'secure': False,
        'expires': None,
        'discard': True,
        'comment': None,
        'comment_url': None,
        'rest': {'HttpOnly': None},
        'rfc2109': False,
    }

    badargs = set(kwargs) - set(result)
    if badargs:
        err = 'create_cookie() got unexpected keyword arguments: %s'
        raise TypeError(err % list(badargs))

    result.update(kwargs)
    result['port_specified'] = bool(result['port'])
    result['domain_specified'] = bool(result['domain'])
    result['domain_initial_dot'] = result['domain'].startswith('.')
    result['path_specified'] = bool(result['path'])

    return cookielib.Cookie(**result)


def morsel_to_cookie(morsel):
    """Convert a Morsel object into a Cookie containing the one k/v pair."""

    expires = None
    if morsel['max-age']:
        try:
            expires = int(time.time() + int(morsel['max-age']))
        except ValueError:
            raise TypeError('max-age: %s must be integer' % morsel['max-age'])
    elif morsel['expires']:
        time_template = '%a, %d-%b-%Y %H:%M:%S GMT'
        expires = calendar.timegm(
            time.strptime(morsel['expires'], time_template)
        )
    return create_cookie(
        comment=morsel['comment'],
        comment_url=bool(morsel['comment']),
        discard=False,
        domain=morsel['domain'],
        expires=expires,
        name=morsel.key,
        path=morsel['path'],
        port=None,
        rest={'HttpOnly': morsel['httponly']},
        rfc2109=False,
        secure=bool(morsel['secure']),
        value=morsel.value,
        version=morsel['version'] or 0,
    )


def cookiejar_from_dict(cookie_dict, cookiejar=None, overwrite=True):
    """Returns a CookieJar from a key/value dictionary.

    :param cookie_dict: Dict of key/values to insert into CookieJar.
    :param cookiejar: (optional) A cookiejar to add the cookies to.
    :param overwrite: (optional) If False, will not replace cookies
        already in the jar with new ones.
    :rtype: CookieJar
    """
    if cookiejar is None:
        cookiejar = RequestsCookieJar()

    if cookie_dict is not None:
        names_from_jar = [cookie.name for cookie in cookiejar]
        for name in cookie_dict:
            if overwrite or (name not in names_from_jar):
                cookiejar.set_cookie(create_cookie(name, cookie_dict[name]))

    return cookiejar


def merge_cookies(cookiejar, cookies):
    """Add cookies to cookiejar and returns a merged CookieJar.

    :param cookiejar: CookieJar object to add the cookies to.
    :param cookies: Dictionary or CookieJar object to be added.
    :rtype: CookieJar
    """
    if not isinstance(cookiejar, cookielib.CookieJar):
        raise ValueError('You can only merge into CookieJar')

    if isinstance(cookies, dict):
        cookiejar = cookiejar_from_dict(
            cookies, cookiejar=cookiejar, overwrite=False)
    elif isinstance(cookies, cookielib.CookieJar):
        try:
            cookiejar.update(cookies)
        except AttributeError:
            for cookie_in_jar in cookies:
                cookiejar.set_cookie(cookie_in_jar)

    return cookiejar




############################################################
### File: core.py
############################################################
from . import idnadata
import bisect
import unicodedata
import re
import sys
from .intranges import intranges_contain

_virama_combining_class = 9
_alabel_prefix = b'xn--'
_unicode_dots_re = re.compile(u'[\u002e\u3002\uff0e\uff61]')

if sys.version_info[0] >= 3:
    unicode = str
    unichr = chr

class IDNAError(UnicodeError):
    """ Base exception for all IDNA-encoding related problems """
    pass


class IDNABidiError(IDNAError):
    """ Exception when bidirectional requirements are not satisfied """
    pass


class InvalidCodepoint(IDNAError):
    """ Exception when a disallowed or unallocated codepoint is used """
    pass


class InvalidCodepointContext(IDNAError):
    """ Exception when the codepoint is not valid in the context it is used """
    pass


def _combining_class(cp):
    v = unicodedata.combining(unichr(cp))
    if v == 0:
        if not unicodedata.name(unichr(cp)):
            raise ValueError("Unknown character in unicodedata")
    return v

def _is_script(cp, script):
    return intranges_contain(ord(cp), idnadata.scripts[script])

def _punycode(s):
    return s.encode('punycode')

def _unot(s):
    return 'U+{0:04X}'.format(s)


def valid_label_length(label):

    if len(label) > 63:
        return False
    return True


def valid_string_length(label, trailing_dot):

    if len(label) > (254 if trailing_dot else 253):
        return False
    return True


def check_bidi(label, check_ltr=False):

    # Bidi rules should only be applied if string contains RTL characters
    bidi_label = False
    for (idx, cp) in enumerate(label, 1):
        direction = unicodedata.bidirectional(cp)
        if direction == '':
            # String likely comes from a newer version of Unicode
            raise IDNABidiError('Unknown directionality in label {0} at position {1}'.format(repr(label), idx))
        if direction in ['R', 'AL', 'AN']:
            bidi_label = True
    if not bidi_label and not check_ltr:
        return True

    # Bidi rule 1
    direction = unicodedata.bidirectional(label[0])
    if direction in ['R', 'AL']:
        rtl = True
    elif direction == 'L':
        rtl = False
    else:
        raise IDNABidiError('First codepoint in label {0} must be directionality L, R or AL'.format(repr(label)))

    valid_ending = False
    number_type = False
    for (idx, cp) in enumerate(label, 1):
        direction = unicodedata.bidirectional(cp)

        if rtl:
            # Bidi rule 2
            if not direction in ['R', 'AL', 'AN', 'EN', 'ES', 'CS', 'ET', 'ON', 'BN', 'NSM']:
                raise IDNABidiError('Invalid direction for codepoint at position {0} in a right-to-left label'.format(idx))
            # Bidi rule 3
            if direction in ['R', 'AL', 'EN', 'AN']:
                valid_ending = True
            elif direction != 'NSM':
                valid_ending = False
            # Bidi rule 4
            if direction in ['AN', 'EN']:
                if not number_type:
                    number_type = direction
                else:
                    if number_type != direction:
                        raise IDNABidiError('Can not mix numeral types in a right-to-left label')
        else:
            # Bidi rule 5
            if not direction in ['L', 'EN', 'ES', 'CS', 'ET', 'ON', 'BN', 'NSM']:
                raise IDNABidiError('Invalid direction for codepoint at position {0} in a left-to-right label'.format(idx))
            # Bidi rule 6
            if direction in ['L', 'EN']:
                valid_ending = True
            elif direction != 'NSM':
                valid_ending = False

    if not valid_ending:
        raise IDNABidiError('Label ends with illegal codepoint directionality')

    return True


def check_initial_combiner(label):

    if unicodedata.category(label[0])[0] == 'M':
        raise IDNAError('Label begins with an illegal combining character')
    return True


def check_hyphen_ok(label):

    if label[2:4] == '--':
        raise IDNAError('Label has disallowed hyphens in 3rd and 4th position')
    if label[0] == '-' or label[-1] == '-':
        raise IDNAError('Label must not start or end with a hyphen')
    return True


def check_nfc(label):

    if unicodedata.normalize('NFC', label) != label:
        raise IDNAError('Label must be in Normalization Form C')


def valid_contextj(label, pos):

    cp_value = ord(label[pos])

    if cp_value == 0x200c:

        if pos > 0:
            if _combining_class(ord(label[pos - 1])) == _virama_combining_class:
                return True

        ok = False
        for i in range(pos-1, -1, -1):
            joining_type = idnadata.joining_types.get(ord(label[i]))
            if joining_type == ord('T'):
                continue
            if joining_type in [ord('L'), ord('D')]:
                ok = True
                break

        if not ok:
            return False

        ok = False
        for i in range(pos+1, len(label)):
            joining_type = idnadata.joining_types.get(ord(label[i]))
            if joining_type == ord('T'):
                continue
            if joining_type in [ord('R'), ord('D')]:
                ok = True
                break
        return ok

    if cp_value == 0x200d:

        if pos > 0:
            if _combining_class(ord(label[pos - 1])) == _virama_combining_class:
                return True
        return False

    else:

        return False


def valid_contexto(label, pos, exception=False):

    cp_value = ord(label[pos])

    if cp_value == 0x00b7:
        if 0 < pos < len(label)-1:
            if ord(label[pos - 1]) == 0x006c and ord(label[pos + 1]) == 0x006c:
                return True
        return False

    elif cp_value == 0x0375:
        if pos < len(label)-1 and len(label) > 1:
            return _is_script(label[pos + 1], 'Greek')
        return False

    elif cp_value == 0x05f3 or cp_value == 0x05f4:
        if pos > 0:
            return _is_script(label[pos - 1], 'Hebrew')
        return False

    elif cp_value == 0x30fb:
        for cp in label:
            if cp == u'\u30fb':
                continue
            if _is_script(cp, 'Hiragana') or _is_script(cp, 'Katakana') or _is_script(cp, 'Han'):
                return True
        return False

    elif 0x660 <= cp_value <= 0x669:
        for cp in label:
            if 0x6f0 <= ord(cp) <= 0x06f9:
                return False
        return True

    elif 0x6f0 <= cp_value <= 0x6f9:
        for cp in label:
            if 0x660 <= ord(cp) <= 0x0669:
                return False
        return True


def check_label(label):

    if isinstance(label, (bytes, bytearray)):
        label = label.decode('utf-8')
    if len(label) == 0:
        raise IDNAError('Empty Label')

    check_nfc(label)
    check_hyphen_ok(label)
    check_initial_combiner(label)

    for (pos, cp) in enumerate(label):
        cp_value = ord(cp)
        if intranges_contain(cp_value, idnadata.codepoint_classes['PVALID']):
            continue
        elif intranges_contain(cp_value, idnadata.codepoint_classes['CONTEXTJ']):
            try:
                if not valid_contextj(label, pos):
                    raise InvalidCodepointContext('Joiner {0} not allowed at position {1} in {2}'.format(
                        _unot(cp_value), pos+1, repr(label)))
            except ValueError:
                raise IDNAError('Unknown codepoint adjacent to joiner {0} at position {1} in {2}'.format(
                    _unot(cp_value), pos+1, repr(label)))
        elif intranges_contain(cp_value, idnadata.codepoint_classes['CONTEXTO']):
            if not valid_contexto(label, pos):
                raise InvalidCodepointContext('Codepoint {0} not allowed at position {1} in {2}'.format(_unot(cp_value), pos+1, repr(label)))
        else:
            raise InvalidCodepoint('Codepoint {0} at position {1} of {2} not allowed'.format(_unot(cp_value), pos+1, repr(label)))

    check_bidi(label)


def alabel(label):

    try:
        label = label.encode('ascii')
        ulabel(label)
        if not valid_label_length(label):
            raise IDNAError('Label too long')
        return label
    except UnicodeEncodeError:
        pass

    if not label:
        raise IDNAError('No Input')

    label = unicode(label)
    check_label(label)
    label = _punycode(label)
    label = _alabel_prefix + label

    if not valid_label_length(label):
        raise IDNAError('Label too long')

    return label


def ulabel(label):

    if not isinstance(label, (bytes, bytearray)):
        try:
            label = label.encode('ascii')
        except UnicodeEncodeError:
            check_label(label)
            return label

    label = label.lower()
    if label.startswith(_alabel_prefix):
        label = label[len(_alabel_prefix):]
        if not label:
            raise IDNAError('Malformed A-label, no Punycode eligible content found')
        if label.decode('ascii')[-1] == '-':
            raise IDNAError('A-label must not end with a hyphen')
    else:
        check_label(label)
        return label.decode('ascii')

    label = label.decode('punycode')
    check_label(label)
    return label


def uts46_remap(domain, std3_rules=True, transitional=False):
    """Re-map the characters in the string according to UTS46 processing."""
    from .uts46data import uts46data
    output = u""
    try:
        for pos, char in enumerate(domain):
            code_point = ord(char)
            uts46row = uts46data[code_point if code_point < 256 else
                bisect.bisect_left(uts46data, (code_point, "Z")) - 1]
            status = uts46row[1]
            replacement = uts46row[2] if len(uts46row) == 3 else None
            if (status == "V" or
                    (status == "D" and not transitional) or
                    (status == "3" and not std3_rules and replacement is None)):
                output += char
            elif replacement is not None and (status == "M" or
                    (status == "3" and not std3_rules) or
                    (status == "D" and transitional)):
                output += replacement
            elif status != "I":
                raise IndexError()
        return unicodedata.normalize("NFC", output)
    except IndexError:
        raise InvalidCodepoint(
            "Codepoint {0} not allowed at position {1} in {2}".format(
            _unot(code_point), pos + 1, repr(domain)))


def encode(s, strict=False, uts46=False, std3_rules=False, transitional=False):

    if isinstance(s, (bytes, bytearray)):
        s = s.decode("ascii")
    if uts46:
        s = uts46_remap(s, std3_rules, transitional)
    trailing_dot = False
    result = []
    if strict:
        labels = s.split('.')
    else:
        labels = _unicode_dots_re.split(s)
    if not labels or labels == ['']:
        raise IDNAError('Empty domain')
    if labels[-1] == '':
        del labels[-1]
        trailing_dot = True
    for label in labels:
        s = alabel(label)
        if s:
            result.append(s)
        else:
            raise IDNAError('Empty label')
    if trailing_dot:
        result.append(b'')
    s = b'.'.join(result)
    if not valid_string_length(s, trailing_dot):
        raise IDNAError('Domain too long')
    return s


def decode(s, strict=False, uts46=False, std3_rules=False):

    if isinstance(s, (bytes, bytearray)):
        s = s.decode("ascii")
    if uts46:
        s = uts46_remap(s, std3_rules, False)
    trailing_dot = False
    result = []
    if not strict:
        labels = _unicode_dots_re.split(s)
    else:
        labels = s.split(u'.')
    if not labels or labels == ['']:
        raise IDNAError('Empty domain')
    if not labels[-1]:
        del labels[-1]
        trailing_dot = True
    for label in labels:
        s = ulabel(label)
        if s:
            result.append(s)
        else:
            raise IDNAError('Empty label')
    if trailing_dot:
        result.append(u'')
    return u'.'.join(result)




############################################################
### File: cp949prober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .chardistribution import EUCKRDistributionAnalysis
from .codingstatemachine import CodingStateMachine
from .mbcharsetprober import MultiByteCharSetProber
from .mbcssm import CP949_SM_MODEL


class CP949Prober(MultiByteCharSetProber):
    def __init__(self):
        super(CP949Prober, self).__init__()
        self.coding_sm = CodingStateMachine(CP949_SM_MODEL)
        # NOTE: CP949 is a superset of EUC-KR, so the distribution should be
        #       not different.
        self.distribution_analyzer = EUCKRDistributionAnalysis()
        self.reset()

    @property
    def charset_name(self):
        return "CP949"

    @property
    def language(self):
        return "Korean"




############################################################
### File: dammit.py
############################################################
# -*- coding: utf-8 -*-
"""Beautiful Soup bonus library: Unicode, Dammit

This library converts a bytestream to Unicode through any means
necessary. It is heavily based on code from Mark Pilgrim's Universal
Feed Parser. It works best on XML and HTML, but it does not rewrite the
XML or HTML to reflect a new encoding; that's the tree builder's job.
"""
__license__ = "MIT"

from pdb import set_trace
import codecs
import six
from six.moves.html_entities import codepoint2name
import re
import logging
import string

# Import a library to autodetect character encodings.
chardet_type = None
try:
    # First try the fast C implementation.
    #  PyPI package: cchardet
    import cchardet
    def chardet_dammit(s):
        return cchardet.detect(s)['encoding']
except ImportError:
    try:
        # Fall back to the pure Python implementation
        #  Debian package: python-chardet
        #  PyPI package: chardet
        import chardet
        def chardet_dammit(s):
            return chardet.detect(s)['encoding']
        #import chardet.constants
        #chardet.constants._debug = 1
    except ImportError:
        # No chardet available.
        def chardet_dammit(s):
            return None

# Available from http://cjkpython.i18n.org/.
try:
    import iconv_codec
except ImportError:
    pass

xml_encoding_re = re.compile(
    r'^<\?.*encoding=[\'"](.*?)[\'"].*\?>'.encode(), re.I)
html_meta_re = re.compile(
    r'<\s*meta[^>]+charset\s*=\s*["\']?([^>]*?)[ /;\'">]'.encode(), re.I)

class EntitySubstitution(object):

    """Substitute XML or HTML entities for the corresponding characters."""

    def _populate_class_variables():
        lookup = {}
        reverse_lookup = {}
        characters_for_re = []
        for codepoint, name in list(codepoint2name.items()):
            character = six.unichr(codepoint)
            if codepoint != 34:
                # There's no point in turning the quotation mark into
                # &quot;, unless it happens within an attribute value, which
                # is handled elsewhere.
                characters_for_re.append(character)
                lookup[character] = name
            # But we do want to turn &quot; into the quotation mark.
            reverse_lookup[name] = character
        re_definition = "[%s]" % "".join(characters_for_re)
        return lookup, reverse_lookup, re.compile(re_definition)
    (CHARACTER_TO_HTML_ENTITY, HTML_ENTITY_TO_CHARACTER,
     CHARACTER_TO_HTML_ENTITY_RE) = _populate_class_variables()

    CHARACTER_TO_XML_ENTITY = {
        "'": "apos",
        '"': "quot",
        "&": "amp",
        "<": "lt",
        ">": "gt",
        }

    BARE_AMPERSAND_OR_BRACKET = re.compile("([<>]|"
                                           r"&(?!#\d+;|#x[0-9a-fA-F]+;|\w+;)"
                                           ")")

    AMPERSAND_OR_BRACKET = re.compile("([<>&])")

    @classmethod
    def _substitute_html_entity(cls, matchobj):
        entity = cls.CHARACTER_TO_HTML_ENTITY.get(matchobj.group(0))
        return "&%s;" % entity

    @classmethod
    def _substitute_xml_entity(cls, matchobj):
        """Used with a regular expression to substitute the
        appropriate XML entity for an XML special character."""
        entity = cls.CHARACTER_TO_XML_ENTITY[matchobj.group(0)]
        return "&%s;" % entity

    @classmethod
    def quoted_attribute_value(self, value):
        """Make a value into a quoted XML attribute, possibly escaping it.

         Most strings will be quoted using double quotes.

          Bob's Bar -> "Bob's Bar"

         If a string contains double quotes, it will be quoted using
         single quotes.

          Welcome to "my bar" -> 'Welcome to "my bar"'

         If a string contains both single and double quotes, the
         double quotes will be escaped, and the string will be quoted
         using double quotes.

          Welcome to "Bob's Bar" -> "Welcome to &quot;Bob's bar&quot;
        """
        quote_with = '"'
        if '"' in value:
            if "'" in value:
                # The string contains both single and double
                # quotes.  Turn the double quotes into
                # entities. We quote the double quotes rather than
                # the single quotes because the entity name is
                # "&quot;" whether this is HTML or XML.  If we
                # quoted the single quotes, we'd have to decide
                # between &apos; and &squot;.
                replace_with = "&quot;"
                value = value.replace('"', replace_with)
            else:
                # There are double quotes but no single quotes.
                # We can use single quotes to quote the attribute.
                quote_with = "'"
        return quote_with + value + quote_with

    @classmethod
    def substitute_xml(cls, value, make_quoted_attribute=False):
        """Substitute XML entities for special XML characters.

        :param value: A string to be substituted. The less-than sign
          will become &lt;, the greater-than sign will become &gt;,
          and any ampersands will become &amp;. If you want ampersands
          that appear to be part of an entity definition to be left
          alone, use substitute_xml_containing_entities() instead.

        :param make_quoted_attribute: If True, then the string will be
         quoted, as befits an attribute value.
        """
        # Escape angle brackets and ampersands.
        value = cls.AMPERSAND_OR_BRACKET.sub(
            cls._substitute_xml_entity, value)

        if make_quoted_attribute:
            value = cls.quoted_attribute_value(value)
        return value

    @classmethod
    def substitute_xml_containing_entities(
        cls, value, make_quoted_attribute=False):
        """Substitute XML entities for special XML characters.

        :param value: A string to be substituted. The less-than sign will
          become &lt;, the greater-than sign will become &gt;, and any
          ampersands that are not part of an entity defition will
          become &amp;.

        :param make_quoted_attribute: If True, then the string will be
         quoted, as befits an attribute value.
        """
        # Escape angle brackets, and ampersands that aren't part of
        # entities.
        value = cls.BARE_AMPERSAND_OR_BRACKET.sub(
            cls._substitute_xml_entity, value)

        if make_quoted_attribute:
            value = cls.quoted_attribute_value(value)
        return value

    @classmethod
    def substitute_html(cls, s):
        """Replace certain Unicode characters with named HTML entities.

        This differs from data.encode(encoding, 'xmlcharrefreplace')
        in that the goal is to make the result more readable (to those
        with ASCII displays) rather than to recover from
        errors. There's absolutely nothing wrong with a UTF-8 string
        containg a LATIN SMALL LETTER E WITH ACUTE, but replacing that
        character with "&eacute;" will make it more readable to some
        people.
        """
        return cls.CHARACTER_TO_HTML_ENTITY_RE.sub(
            cls._substitute_html_entity, s)


class EncodingDetector:
    """Suggests a number of possible encodings for a bytestring.

    Order of precedence:

    1. Encodings you specifically tell EncodingDetector to try first
    (the override_encodings argument to the constructor).

    2. An encoding declared within the bytestring itself, either in an
    XML declaration (if the bytestring is to be interpreted as an XML
    document), or in a <meta> tag (if the bytestring is to be
    interpreted as an HTML document.)

    3. An encoding detected through textual analysis by chardet,
    cchardet, or a similar external library.

    4. UTF-8.

    5. Windows-1252.
    """
    def __init__(self, markup, override_encodings=None, is_html=False,
                 exclude_encodings=None):
        self.override_encodings = override_encodings or []
        exclude_encodings = exclude_encodings or []
        self.exclude_encodings = set([x.lower() for x in exclude_encodings])
        self.chardet_encoding = None
        self.is_html = is_html
        self.declared_encoding = None

        # First order of business: strip a byte-order mark.
        self.markup, self.sniffed_encoding = self.strip_byte_order_mark(markup)

    def _usable(self, encoding, tried):
        if encoding is not None:
            encoding = encoding.lower()
            if encoding in self.exclude_encodings:
                return False
            if encoding not in tried:
                tried.add(encoding)
                return True
        return False

    @property
    def encodings(self):
        """Yield a number of encodings that might work for this markup."""
        tried = set()
        for e in self.override_encodings:
            if self._usable(e, tried):
                yield e

        # Did the document originally start with a byte-order mark
        # that indicated its encoding?
        if self._usable(self.sniffed_encoding, tried):
            yield self.sniffed_encoding

        # Look within the document for an XML or HTML encoding
        # declaration.
        if self.declared_encoding is None:
            self.declared_encoding = self.find_declared_encoding(
                self.markup, self.is_html)
        if self._usable(self.declared_encoding, tried):
            yield self.declared_encoding

        # Use third-party character set detection to guess at the
        # encoding.
        if self.chardet_encoding is None:
            self.chardet_encoding = chardet_dammit(self.markup)
        if self._usable(self.chardet_encoding, tried):
            yield self.chardet_encoding

        # As a last-ditch effort, try utf-8 and windows-1252.
        for e in ('utf-8', 'windows-1252'):
            if self._usable(e, tried):
                yield e

    @classmethod
    def strip_byte_order_mark(cls, data):
        """If a byte-order mark is present, strip it and return the encoding it implies."""
        encoding = None
        if isinstance(data, six.text_type):
            # Unicode data cannot have a byte-order mark.
            return data, encoding
        if (len(data) >= 4) and (data[:2] == b'\xfe\xff') \
               and (data[2:4] != '\x00\x00'):
            encoding = 'utf-16be'
            data = data[2:]
        elif (len(data) >= 4) and (data[:2] == b'\xff\xfe') \
                 and (data[2:4] != '\x00\x00'):
            encoding = 'utf-16le'
            data = data[2:]
        elif data[:3] == b'\xef\xbb\xbf':
            encoding = 'utf-8'
            data = data[3:]
        elif data[:4] == b'\x00\x00\xfe\xff':
            encoding = 'utf-32be'
            data = data[4:]
        elif data[:4] == b'\xff\xfe\x00\x00':
            encoding = 'utf-32le'
            data = data[4:]
        return data, encoding

    @classmethod
    def find_declared_encoding(cls, markup, is_html=False, search_entire_document=False):
        """Given a document, tries to find its declared encoding.

        An XML encoding is declared at the beginning of the document.

        An HTML encoding is declared in a <meta> tag, hopefully near the
        beginning of the document.
        """
        if search_entire_document:
            xml_endpos = html_endpos = len(markup)
        else:
            xml_endpos = 1024
            html_endpos = max(2048, int(len(markup) * 0.05))
            
        declared_encoding = None
        declared_encoding_match = xml_encoding_re.search(markup, endpos=xml_endpos)
        if not declared_encoding_match and is_html:
            declared_encoding_match = html_meta_re.search(markup, endpos=html_endpos)
        if declared_encoding_match is not None:
            declared_encoding = declared_encoding_match.groups()[0].decode(
                'ascii', 'replace')
        if declared_encoding:
            return declared_encoding.lower()
        return None

class UnicodeDammit:
    """A class for detecting the encoding of a *ML document and
    converting it to a Unicode string. If the source encoding is
    windows-1252, can replace MS smart quotes with their HTML or XML
    equivalents."""

    # This dictionary maps commonly seen values for "charset" in HTML
    # meta tags to the corresponding Python codec names. It only covers
    # values that aren't in Python's aliases and can't be determined
    # by the heuristics in find_codec.
    CHARSET_ALIASES = {"macintosh": "mac-roman",
                       "x-sjis": "shift-jis"}

    ENCODINGS_WITH_SMART_QUOTES = [
        "windows-1252",
        "iso-8859-1",
        "iso-8859-2",
        ]

    def __init__(self, markup, override_encodings=[],
                 smart_quotes_to=None, is_html=False, exclude_encodings=[]):
        self.smart_quotes_to = smart_quotes_to
        self.tried_encodings = []
        self.contains_replacement_characters = False
        self.is_html = is_html

        self.detector = EncodingDetector(
            markup, override_encodings, is_html, exclude_encodings)

        # Short-circuit if the data is in Unicode to begin with.
        if isinstance(markup, six.text_type) or markup == '':
            self.markup = markup
            self.unicode_markup = six.text_type(markup)
            self.original_encoding = None
            return

        # The encoding detector may have stripped a byte-order mark.
        # Use the stripped markup from this point on.
        self.markup = self.detector.markup

        u = None
        for encoding in self.detector.encodings:
            markup = self.detector.markup
            u = self._convert_from(encoding)
            if u is not None:
                break

        if not u:
            # None of the encodings worked. As an absolute last resort,
            # try them again with character replacement.

            for encoding in self.detector.encodings:
                if encoding != "ascii":
                    u = self._convert_from(encoding, "replace")
                if u is not None:
                    logging.warning(
                            "Some characters could not be decoded, and were "
                            "replaced with REPLACEMENT CHARACTER.")
                    self.contains_replacement_characters = True
                    break

        # If none of that worked, we could at this point force it to
        # ASCII, but that would destroy so much data that I think
        # giving up is better.
        self.unicode_markup = u
        if not u:
            self.original_encoding = None

    def _sub_ms_char(self, match):
        """Changes a MS smart quote character to an XML or HTML
        entity, or an ASCII character."""
        orig = match.group(1)
        if self.smart_quotes_to == 'ascii':
            sub = self.MS_CHARS_TO_ASCII.get(orig).encode()
        else:
            sub = self.MS_CHARS.get(orig)
            if type(sub) == tuple:
                if self.smart_quotes_to == 'xml':
                    sub = '&#x'.encode() + sub[1].encode() + ';'.encode()
                else:
                    sub = '&'.encode() + sub[0].encode() + ';'.encode()
            else:
                sub = sub.encode()
        return sub

    def _convert_from(self, proposed, errors="strict"):
        proposed = self.find_codec(proposed)
        if not proposed or (proposed, errors) in self.tried_encodings:
            return None
        self.tried_encodings.append((proposed, errors))
        markup = self.markup
        # Convert smart quotes to HTML if coming from an encoding
        # that might have them.
        if (self.smart_quotes_to is not None
            and proposed in self.ENCODINGS_WITH_SMART_QUOTES):
            smart_quotes_re = b"([\x80-\x9f])"
            smart_quotes_compiled = re.compile(smart_quotes_re)
            markup = smart_quotes_compiled.sub(self._sub_ms_char, markup)

        try:
            #print "Trying to convert document to %s (errors=%s)" % (
            #    proposed, errors)
            u = self._to_unicode(markup, proposed, errors)
            self.markup = u
            self.original_encoding = proposed
        except Exception as e:
            #print "That didn't work!"
            #print e
            return None
        #print "Correct encoding: %s" % proposed
        return self.markup

    def _to_unicode(self, data, encoding, errors="strict"):
        '''Given a string and its encoding, decodes the string into Unicode.
        %encoding is a string recognized by encodings.aliases'''
        return six.text_type(data, encoding, errors)

    @property
    def declared_html_encoding(self):
        if not self.is_html:
            return None
        return self.detector.declared_encoding

    def find_codec(self, charset):
        value = (self._codec(self.CHARSET_ALIASES.get(charset, charset))
               or (charset and self._codec(charset.replace("-", "")))
               or (charset and self._codec(charset.replace("-", "_")))
               or (charset and charset.lower())
               or charset
                )
        if value:
            return value.lower()
        return None

    def _codec(self, charset):
        if not charset:
            return charset
        codec = None
        try:
            codecs.lookup(charset)
            codec = charset
        except (LookupError, ValueError):
            pass
        return codec


    # A partial mapping of ISO-Latin-1 to HTML entities/XML numeric entities.
    MS_CHARS = {b'\x80': ('euro', '20AC'),
                b'\x81': ' ',
                b'\x82': ('sbquo', '201A'),
                b'\x83': ('fnof', '192'),
                b'\x84': ('bdquo', '201E'),
                b'\x85': ('hellip', '2026'),
                b'\x86': ('dagger', '2020'),
                b'\x87': ('Dagger', '2021'),
                b'\x88': ('circ', '2C6'),
                b'\x89': ('permil', '2030'),
                b'\x8A': ('Scaron', '160'),
                b'\x8B': ('lsaquo', '2039'),
                b'\x8C': ('OElig', '152'),
                b'\x8D': '?',
                b'\x8E': ('#x17D', '17D'),
                b'\x8F': '?',
                b'\x90': '?',
                b'\x91': ('lsquo', '2018'),
                b'\x92': ('rsquo', '2019'),
                b'\x93': ('ldquo', '201C'),
                b'\x94': ('rdquo', '201D'),
                b'\x95': ('bull', '2022'),
                b'\x96': ('ndash', '2013'),
                b'\x97': ('mdash', '2014'),
                b'\x98': ('tilde', '2DC'),
                b'\x99': ('trade', '2122'),
                b'\x9a': ('scaron', '161'),
                b'\x9b': ('rsaquo', '203A'),
                b'\x9c': ('oelig', '153'),
                b'\x9d': '?',
                b'\x9e': ('#x17E', '17E'),
                b'\x9f': ('Yuml', ''),}

    # A parochial partial mapping of ISO-Latin-1 to ASCII. Contains
    # horrors like stripping diacritical marks to turn  into a, but also
    # contains non-horrors like turning  into ".
    MS_CHARS_TO_ASCII = {
        b'\x80' : 'EUR',
        b'\x81' : ' ',
        b'\x82' : ',',
        b'\x83' : 'f',
        b'\x84' : ',,',
        b'\x85' : '...',
        b'\x86' : '+',
        b'\x87' : '++',
        b'\x88' : '^',
        b'\x89' : '%',
        b'\x8a' : 'S',
        b'\x8b' : '<',
        b'\x8c' : 'OE',
        b'\x8d' : '?',
        b'\x8e' : 'Z',
        b'\x8f' : '?',
        b'\x90' : '?',
        b'\x91' : "'",
        b'\x92' : "'",
        b'\x93' : '"',
        b'\x94' : '"',
        b'\x95' : '*',
        b'\x96' : '-',
        b'\x97' : '--',
        b'\x98' : '~',
        b'\x99' : '(TM)',
        b'\x9a' : 's',
        b'\x9b' : '>',
        b'\x9c' : 'oe',
        b'\x9d' : '?',
        b'\x9e' : 'z',
        b'\x9f' : 'Y',
        b'\xa0' : ' ',
        b'\xa1' : '!',
        b'\xa2' : 'c',
        b'\xa3' : 'GBP',
        b'\xa4' : '$', #This approximation is especially parochial--this is the
                       #generic currency symbol.
        b'\xa5' : 'YEN',
        b'\xa6' : '|',
        b'\xa7' : 'S',
        b'\xa8' : '..',
        b'\xa9' : '',
        b'\xaa' : '(th)',
        b'\xab' : '<<',
        b'\xac' : '!',
        b'\xad' : ' ',
        b'\xae' : '(R)',
        b'\xaf' : '-',
        b'\xb0' : 'o',
        b'\xb1' : '+-',
        b'\xb2' : '2',
        b'\xb3' : '3',
        b'\xb4' : ("'", 'acute'),
        b'\xb5' : 'u',
        b'\xb6' : 'P',
        b'\xb7' : '*',
        b'\xb8' : ',',
        b'\xb9' : '1',
        b'\xba' : '(th)',
        b'\xbb' : '>>',
        b'\xbc' : '1/4',
        b'\xbd' : '1/2',
        b'\xbe' : '3/4',
        b'\xbf' : '?',
        b'\xc0' : 'A',
        b'\xc1' : 'A',
        b'\xc2' : 'A',
        b'\xc3' : 'A',
        b'\xc4' : 'A',
        b'\xc5' : 'A',
        b'\xc6' : 'AE',
        b'\xc7' : 'C',
        b'\xc8' : 'E',
        b'\xc9' : 'E',
        b'\xca' : 'E',
        b'\xcb' : 'E',
        b'\xcc' : 'I',
        b'\xcd' : 'I',
        b'\xce' : 'I',
        b'\xcf' : 'I',
        b'\xd0' : 'D',
        b'\xd1' : 'N',
        b'\xd2' : 'O',
        b'\xd3' : 'O',
        b'\xd4' : 'O',
        b'\xd5' : 'O',
        b'\xd6' : 'O',
        b'\xd7' : '*',
        b'\xd8' : 'O',
        b'\xd9' : 'U',
        b'\xda' : 'U',
        b'\xdb' : 'U',
        b'\xdc' : 'U',
        b'\xdd' : 'Y',
        b'\xde' : 'b',
        b'\xdf' : 'B',
        b'\xe0' : 'a',
        b'\xe1' : 'a',
        b'\xe2' : 'a',
        b'\xe3' : 'a',
        b'\xe4' : 'a',
        b'\xe5' : 'a',
        b'\xe6' : 'ae',
        b'\xe7' : 'c',
        b'\xe8' : 'e',
        b'\xe9' : 'e',
        b'\xea' : 'e',
        b'\xeb' : 'e',
        b'\xec' : 'i',
        b'\xed' : 'i',
        b'\xee' : 'i',
        b'\xef' : 'i',
        b'\xf0' : 'o',
        b'\xf1' : 'n',
        b'\xf2' : 'o',
        b'\xf3' : 'o',
        b'\xf4' : 'o',
        b'\xf5' : 'o',
        b'\xf6' : 'o',
        b'\xf7' : '/',
        b'\xf8' : 'o',
        b'\xf9' : 'u',
        b'\xfa' : 'u',
        b'\xfb' : 'u',
        b'\xfc' : 'u',
        b'\xfd' : 'y',
        b'\xfe' : 'b',
        b'\xff' : 'y',
        }

    # A map used when removing rogue Windows-1252/ISO-8859-1
    # characters in otherwise UTF-8 documents.
    #
    # Note that \x81, \x8d, \x8f, \x90, and \x9d are undefined in
    # Windows-1252.
    WINDOWS_1252_TO_UTF8 = {
        0x80 : b'\xe2\x82\xac', # 
        0x82 : b'\xe2\x80\x9a', # 
        0x83 : b'\xc6\x92',     # 
        0x84 : b'\xe2\x80\x9e', # 
        0x85 : b'\xe2\x80\xa6', # 
        0x86 : b'\xe2\x80\xa0', # 
        0x87 : b'\xe2\x80\xa1', # 
        0x88 : b'\xcb\x86',     # 
        0x89 : b'\xe2\x80\xb0', # 
        0x8a : b'\xc5\xa0',     # 
        0x8b : b'\xe2\x80\xb9', # 
        0x8c : b'\xc5\x92',     # 
        0x8e : b'\xc5\xbd',     # 
        0x91 : b'\xe2\x80\x98', # 
        0x92 : b'\xe2\x80\x99', # 
        0x93 : b'\xe2\x80\x9c', # 
        0x94 : b'\xe2\x80\x9d', # 
        0x95 : b'\xe2\x80\xa2', # 
        0x96 : b'\xe2\x80\x93', # 
        0x97 : b'\xe2\x80\x94', # 
        0x98 : b'\xcb\x9c',     # 
        0x99 : b'\xe2\x84\xa2', # 
        0x9a : b'\xc5\xa1',     # 
        0x9b : b'\xe2\x80\xba', # 
        0x9c : b'\xc5\x93',     # 
        0x9e : b'\xc5\xbe',     # 
        0x9f : b'\xc5\xb8',     # 
        0xa0 : b'\xc2\xa0',     # 
        0xa1 : b'\xc2\xa1',     # 
        0xa2 : b'\xc2\xa2',     # 
        0xa3 : b'\xc2\xa3',     # 
        0xa4 : b'\xc2\xa4',     # 
        0xa5 : b'\xc2\xa5',     # 
        0xa6 : b'\xc2\xa6',     # 
        0xa7 : b'\xc2\xa7',     # 
        0xa8 : b'\xc2\xa8',     # 
        0xa9 : b'\xc2\xa9',     # 
        0xaa : b'\xc2\xaa',     # 
        0xab : b'\xc2\xab',     # 
        0xac : b'\xc2\xac',     # 
        0xad : b'\xc2\xad',     # 
        0xae : b'\xc2\xae',     # 
        0xaf : b'\xc2\xaf',     # 
        0xb0 : b'\xc2\xb0',     # 
        0xb1 : b'\xc2\xb1',     # 
        0xb2 : b'\xc2\xb2',     # 
        0xb3 : b'\xc2\xb3',     # 
        0xb4 : b'\xc2\xb4',     # 
        0xb5 : b'\xc2\xb5',     # 
        0xb6 : b'\xc2\xb6',     # 
        0xb7 : b'\xc2\xb7',     # 
        0xb8 : b'\xc2\xb8',     # 
        0xb9 : b'\xc2\xb9',     # 
        0xba : b'\xc2\xba',     # 
        0xbb : b'\xc2\xbb',     # 
        0xbc : b'\xc2\xbc',     # 
        0xbd : b'\xc2\xbd',     # 
        0xbe : b'\xc2\xbe',     # 
        0xbf : b'\xc2\xbf',     # 
        0xc0 : b'\xc3\x80',     # 
        0xc1 : b'\xc3\x81',     # 
        0xc2 : b'\xc3\x82',     # 
        0xc3 : b'\xc3\x83',     # 
        0xc4 : b'\xc3\x84',     # 
        0xc5 : b'\xc3\x85',     # 
        0xc6 : b'\xc3\x86',     # 
        0xc7 : b'\xc3\x87',     # 
        0xc8 : b'\xc3\x88',     # 
        0xc9 : b'\xc3\x89',     # 
        0xca : b'\xc3\x8a',     # 
        0xcb : b'\xc3\x8b',     # 
        0xcc : b'\xc3\x8c',     # 
        0xcd : b'\xc3\x8d',     # 
        0xce : b'\xc3\x8e',     # 
        0xcf : b'\xc3\x8f',     # 
        0xd0 : b'\xc3\x90',     # 
        0xd1 : b'\xc3\x91',     # 
        0xd2 : b'\xc3\x92',     # 
        0xd3 : b'\xc3\x93',     # 
        0xd4 : b'\xc3\x94',     # 
        0xd5 : b'\xc3\x95',     # 
        0xd6 : b'\xc3\x96',     # 
        0xd7 : b'\xc3\x97',     # 
        0xd8 : b'\xc3\x98',     # 
        0xd9 : b'\xc3\x99',     # 
        0xda : b'\xc3\x9a',     # 
        0xdb : b'\xc3\x9b',     # 
        0xdc : b'\xc3\x9c',     # 
        0xdd : b'\xc3\x9d',     # 
        0xde : b'\xc3\x9e',     # 
        0xdf : b'\xc3\x9f',     # 
        0xe0 : b'\xc3\xa0',     # 
        0xe1 : b'\xa1',     # 
        0xe2 : b'\xc3\xa2',     # 
        0xe3 : b'\xc3\xa3',     # 
        0xe4 : b'\xc3\xa4',     # 
        0xe5 : b'\xc3\xa5',     # 
        0xe6 : b'\xc3\xa6',     # 
        0xe7 : b'\xc3\xa7',     # 
        0xe8 : b'\xc3\xa8',     # 
        0xe9 : b'\xc3\xa9',     # 
        0xea : b'\xc3\xaa',     # 
        0xeb : b'\xc3\xab',     # 
        0xec : b'\xc3\xac',     # 
        0xed : b'\xc3\xad',     # 
        0xee : b'\xc3\xae',     # 
        0xef : b'\xc3\xaf',     # 
        0xf0 : b'\xc3\xb0',     # 
        0xf1 : b'\xc3\xb1',     # 
        0xf2 : b'\xc3\xb2',     # 
        0xf3 : b'\xc3\xb3',     # 
        0xf4 : b'\xc3\xb4',     # 
        0xf5 : b'\xc3\xb5',     # 
        0xf6 : b'\xc3\xb6',     # 
        0xf7 : b'\xc3\xb7',     # 
        0xf8 : b'\xc3\xb8',     # 
        0xf9 : b'\xc3\xb9',     # 
        0xfa : b'\xc3\xba',     # 
        0xfb : b'\xc3\xbb',     # 
        0xfc : b'\xc3\xbc',     # 
        0xfd : b'\xc3\xbd',     # 
        0xfe : b'\xc3\xbe',     # 
        }

    MULTIBYTE_MARKERS_AND_SIZES = [
        (0xc2, 0xdf, 2), # 2-byte characters start with a byte C2-DF
        (0xe0, 0xef, 3), # 3-byte characters start with E0-EF
        (0xf0, 0xf4, 4), # 4-byte characters start with F0-F4
        ]

    FIRST_MULTIBYTE_MARKER = MULTIBYTE_MARKERS_AND_SIZES[0][0]
    LAST_MULTIBYTE_MARKER = MULTIBYTE_MARKERS_AND_SIZES[-1][1]

    @classmethod
    def detwingle(cls, in_bytes, main_encoding="utf8",
                  embedded_encoding="windows-1252"):
        """Fix characters from one encoding embedded in some other encoding.

        Currently the only situation supported is Windows-1252 (or its
        subset ISO-8859-1), embedded in UTF-8.

        The input must be a bytestring. If you've already converted
        the document to Unicode, you're too late.

        The output is a bytestring in which `embedded_encoding`
        characters have been converted to their `main_encoding`
        equivalents.
        """
        if embedded_encoding.replace('_', '-').lower() not in (
            'windows-1252', 'windows_1252'):
            raise NotImplementedError(
                "Windows-1252 and ISO-8859-1 are the only currently supported "
                "embedded encodings.")

        if main_encoding.lower() not in ('utf8', 'utf-8'):
            raise NotImplementedError(
                "UTF-8 is the only currently supported main encoding.")

        byte_chunks = []

        chunk_start = 0
        pos = 0
        while pos < len(in_bytes):
            byte = in_bytes[pos]
            if not isinstance(byte, int):
                # Python 2.x
                byte = ord(byte)
            if (byte >= cls.FIRST_MULTIBYTE_MARKER
                and byte <= cls.LAST_MULTIBYTE_MARKER):
                # This is the start of a UTF-8 multibyte character. Skip
                # to the end.
                for start, end, size in cls.MULTIBYTE_MARKERS_AND_SIZES:
                    if byte >= start and byte <= end:
                        pos += size
                        break
            elif byte >= 0x80 and byte in cls.WINDOWS_1252_TO_UTF8:
                # We found a Windows-1252 character!
                # Save the string up to this point as a chunk.
                byte_chunks.append(in_bytes[chunk_start:pos])

                # Now translate the Windows-1252 character into UTF-8
                # and add it as another, one-byte chunk.
                byte_chunks.append(cls.WINDOWS_1252_TO_UTF8[byte])
                pos += 1
                chunk_start = pos
            else:
                # Go on to the next character.
                pos += 1
        if chunk_start == 0:
            # The string is unchanged.
            return in_bytes
        else:
            # Store the final chunk.
            byte_chunks.append(in_bytes[chunk_start:])
        return b''.join(byte_chunks)





############################################################
### File: diagnose.py
############################################################
"""Diagnostic functions, mainly for use when doing tech support."""

__license__ = "MIT"

import cProfile
from StringIO import StringIO
from HTMLParser import HTMLParser
import bs4
from bs4 import BeautifulSoup, __version__
from bs4.builder import builder_registry

import os
import pstats
import random
import tempfile
import time
import traceback
import sys
import cProfile

def diagnose(data):
    """Diagnostic suite for isolating common problems."""
    print("Diagnostic running on Beautiful Soup %s" % __version__)
    print("Python version %s" % sys.version)

    basic_parsers = ["html.parser", "html5lib", "lxml"]
    for name in basic_parsers:
        for builder in builder_registry.builders:
            if name in builder.features:
                break
        else:
            basic_parsers.remove(name)
            print(
                "I noticed that %s is not installed. Installing it may help." %
                name)

    if 'lxml' in basic_parsers:
        basic_parsers.append(["lxml", "xml"])
        try:
            from lxml import etree
            print("Found lxml version %s" % ".".join(map(str,etree.LXML_VERSION)))
        except ImportError, e:
            print(
                "lxml is not installed or couldn't be imported.")


    if 'html5lib' in basic_parsers:
        try:
            import html5lib
            print("Found html5lib version %s" % html5lib.__version__)
        except ImportError, e:
            print(
                "html5lib is not installed or couldn't be imported.")

    if hasattr(data, 'read'):
        data = data.read()
    elif os.path.exists(data):
        print('"%s" looks like a filename. Reading data from the file.' % data)
        data = open(data).read()
    elif data.startswith("http:") or data.startswith("https:"):
        print('"%s" looks like a URL. Beautiful Soup is not an HTTP client.' % data)
        print("You need to use some other library to get the document behind the URL, and feed that document to Beautiful Soup.")
        return
    print

    for parser in basic_parsers:
        print("Trying to parse your markup with %s" % parser)
        success = False
        try:
            soup = BeautifulSoup(data, parser)
            success = True
        except Exception, e:
            print("%s could not parse the markup." % parser)
            traceback.print_exc()
        if success:
            print("Here's what %s did with the markup:" % parser)
            print soup.prettify()

        print "-" * 80

def lxml_trace(data, html=True, **kwargs):
    """Print out the lxml events that occur during parsing.

    This lets you see how lxml parses a document when no Beautiful
    Soup code is running.
    """
    from lxml import etree
    for event, element in etree.iterparse(StringIO(data), html=html, **kwargs):
        print("%s, %4s, %s" % (event, element.tag, element.text))

class AnnouncingParser(HTMLParser):
    """Announces HTMLParser parse events, without doing anything else."""

    def _p(self, s):
        print(s)

    def handle_starttag(self, name, attrs):
        self._p("%s START" % name)

    def handle_endtag(self, name):
        self._p("%s END" % name)

    def handle_data(self, data):
        self._p("%s DATA" % data)

    def handle_charref(self, name):
        self._p("%s CHARREF" % name)

    def handle_entityref(self, name):
        self._p("%s ENTITYREF" % name)

    def handle_comment(self, data):
        self._p("%s COMMENT" % data)

    def handle_decl(self, data):
        self._p("%s DECL" % data)

    def unknown_decl(self, data):
        self._p("%s UNKNOWN-DECL" % data)

    def handle_pi(self, data):
        self._p("%s PI" % data)

def htmlparser_trace(data):
    """Print out the HTMLParser events that occur during parsing.

    This lets you see how HTMLParser parses a document when no
    Beautiful Soup code is running.
    """
    parser = AnnouncingParser()
    parser.feed(data)

_vowels = "aeiou"
_consonants = "bcdfghjklmnpqrstvwxyz"

def rword(length=5):
    "Generate a random word-like string."
    s = ''
    for i in range(length):
        if i % 2 == 0:
            t = _consonants
        else:
            t = _vowels
        s += random.choice(t)
    return s

def rsentence(length=4):
    "Generate a random sentence-like string."
    return " ".join(rword(random.randint(4,9)) for i in range(length))
        
def rdoc(num_elements=1000):
    """Randomly generate an invalid HTML document."""
    tag_names = ['p', 'div', 'span', 'i', 'b', 'script', 'table']
    elements = []
    for i in range(num_elements):
        choice = random.randint(0,3)
        if choice == 0:
            # New tag.
            tag_name = random.choice(tag_names)
            elements.append("<%s>" % tag_name)
        elif choice == 1:
            elements.append(rsentence(random.randint(1,4)))
        elif choice == 2:
            # Close a tag.
            tag_name = random.choice(tag_names)
            elements.append("</%s>" % tag_name)
    return "<html>" + "\n".join(elements) + "</html>"

def benchmark_parsers(num_elements=100000):
    """Very basic head-to-head performance benchmark."""
    print "Comparative parser benchmark on Beautiful Soup %s" % __version__
    data = rdoc(num_elements)
    print "Generated a large invalid HTML document (%d bytes)." % len(data)
    
    for parser in ["lxml", ["lxml", "html"], "html5lib", "html.parser"]:
        success = False
        try:
            a = time.time()
            soup = BeautifulSoup(data, parser)
            b = time.time()
            success = True
        except Exception, e:
            print "%s could not parse the markup." % parser
            traceback.print_exc()
        if success:
            print "BS4+%s parsed the markup in %.2fs." % (parser, b-a)

    from lxml import etree
    a = time.time()
    etree.HTML(data)
    b = time.time()
    print "Raw lxml parsed the markup in %.2fs." % (b-a)

    import html5lib
    parser = html5lib.HTMLParser()
    a = time.time()
    parser.parse(data)
    b = time.time()
    print "Raw html5lib parsed the markup in %.2fs." % (b-a)

def profile(num_elements=100000, parser="lxml"):

    filehandle = tempfile.NamedTemporaryFile()
    filename = filehandle.name

    data = rdoc(num_elements)
    vars = dict(bs4=bs4, data=data, parser=parser)
    cProfile.runctx('bs4.BeautifulSoup(data, parser)' , vars, vars, filename)

    stats = pstats.Stats(filename)
    # stats.strip_dirs()
    stats.sort_stats("cumulative")
    stats.print_stats('_html5lib|bs4', 50)

if __name__ == '__main__':
    diagnose(sys.stdin.read())




############################################################
### File: dnssec.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""Common DNSSEC-related functions and constants."""

from io import BytesIO
import struct
import time

import dns.exception
import dns.name
import dns.node
import dns.rdataset
import dns.rdata
import dns.rdatatype
import dns.rdataclass
from ._compat import string_types


class UnsupportedAlgorithm(dns.exception.DNSException):
    """The DNSSEC algorithm is not supported."""


class ValidationFailure(dns.exception.DNSException):
    """The DNSSEC signature is invalid."""


#: RSAMD5
RSAMD5 = 1
#: DH
DH = 2
#: DSA
DSA = 3
#: ECC
ECC = 4
#: RSASHA1
RSASHA1 = 5
#: DSANSEC3SHA1
DSANSEC3SHA1 = 6
#: RSASHA1NSEC3SHA1
RSASHA1NSEC3SHA1 = 7
#: RSASHA256
RSASHA256 = 8
#: RSASHA512
RSASHA512 = 10
#: ECDSAP256SHA256
ECDSAP256SHA256 = 13
#: ECDSAP384SHA384
ECDSAP384SHA384 = 14
#: INDIRECT
INDIRECT = 252
#: PRIVATEDNS
PRIVATEDNS = 253
#: PRIVATEOID
PRIVATEOID = 254

_algorithm_by_text = {
    'RSAMD5': RSAMD5,
    'DH': DH,
    'DSA': DSA,
    'ECC': ECC,
    'RSASHA1': RSASHA1,
    'DSANSEC3SHA1': DSANSEC3SHA1,
    'RSASHA1NSEC3SHA1': RSASHA1NSEC3SHA1,
    'RSASHA256': RSASHA256,
    'RSASHA512': RSASHA512,
    'INDIRECT': INDIRECT,
    'ECDSAP256SHA256': ECDSAP256SHA256,
    'ECDSAP384SHA384': ECDSAP384SHA384,
    'PRIVATEDNS': PRIVATEDNS,
    'PRIVATEOID': PRIVATEOID,
}

# We construct the inverse mapping programmatically to ensure that we
# cannot make any mistakes (e.g. omissions, cut-and-paste errors) that
# would cause the mapping not to be true inverse.

_algorithm_by_value = {y: x for x, y in _algorithm_by_text.items()}


def algorithm_from_text(text):
    """Convert text into a DNSSEC algorithm value.

    Returns an ``int``.
    """

    value = _algorithm_by_text.get(text.upper())
    if value is None:
        value = int(text)
    return value


def algorithm_to_text(value):
    """Convert a DNSSEC algorithm value to text

    Returns a ``str``.
    """

    text = _algorithm_by_value.get(value)
    if text is None:
        text = str(value)
    return text


def _to_rdata(record, origin):
    s = BytesIO()
    record.to_wire(s, origin=origin)
    return s.getvalue()


def key_id(key, origin=None):
    """Return the key id (a 16-bit number) for the specified key.

    Note the *origin* parameter of this function is historical and
    is not needed.

    Returns an ``int`` between 0 and 65535.
    """

    rdata = _to_rdata(key, origin)
    rdata = bytearray(rdata)
    if key.algorithm == RSAMD5:
        return (rdata[-3] << 8) + rdata[-2]
    else:
        total = 0
        for i in range(len(rdata) // 2):
            total += (rdata[2 * i] << 8) + \
                rdata[2 * i + 1]
        if len(rdata) % 2 != 0:
            total += rdata[len(rdata) - 1] << 8
        total += ((total >> 16) & 0xffff)
        return total & 0xffff


def make_ds(name, key, algorithm, origin=None):
    """Create a DS record for a DNSSEC key.

    *name* is the owner name of the DS record.

    *key* is a ``dns.rdtypes.ANY.DNSKEY``.

    *algorithm* is a string describing which hash algorithm to use.  The
    currently supported hashes are "SHA1" and "SHA256".  Case does not
    matter for these strings.

    *origin* is a ``dns.name.Name`` and will be used as the origin
    if *key* is a relative name.

    Returns a ``dns.rdtypes.ANY.DS``.
    """

    if algorithm.upper() == 'SHA1':
        dsalg = 1
        hash = SHA1.new()
    elif algorithm.upper() == 'SHA256':
        dsalg = 2
        hash = SHA256.new()
    else:
        raise UnsupportedAlgorithm('unsupported algorithm "%s"' % algorithm)

    if isinstance(name, string_types):
        name = dns.name.from_text(name, origin)
    hash.update(name.canonicalize().to_wire())
    hash.update(_to_rdata(key, origin))
    digest = hash.digest()

    dsrdata = struct.pack("!HBB", key_id(key), key.algorithm, dsalg) + digest
    return dns.rdata.from_wire(dns.rdataclass.IN, dns.rdatatype.DS, dsrdata, 0,
                               len(dsrdata))


def _find_candidate_keys(keys, rrsig):
    candidate_keys = []
    value = keys.get(rrsig.signer)
    if value is None:
        return None
    if isinstance(value, dns.node.Node):
        try:
            rdataset = value.find_rdataset(dns.rdataclass.IN,
                                           dns.rdatatype.DNSKEY)
        except KeyError:
            return None
    else:
        rdataset = value
    for rdata in rdataset:
        if rdata.algorithm == rrsig.algorithm and \
                key_id(rdata) == rrsig.key_tag:
            candidate_keys.append(rdata)
    return candidate_keys


def _is_rsa(algorithm):
    return algorithm in (RSAMD5, RSASHA1,
                         RSASHA1NSEC3SHA1, RSASHA256,
                         RSASHA512)


def _is_dsa(algorithm):
    return algorithm in (DSA, DSANSEC3SHA1)


def _is_ecdsa(algorithm):
    return _have_ecdsa and (algorithm in (ECDSAP256SHA256, ECDSAP384SHA384))


def _is_md5(algorithm):
    return algorithm == RSAMD5


def _is_sha1(algorithm):
    return algorithm in (DSA, RSASHA1,
                         DSANSEC3SHA1, RSASHA1NSEC3SHA1)


def _is_sha256(algorithm):
    return algorithm in (RSASHA256, ECDSAP256SHA256)


def _is_sha384(algorithm):
    return algorithm == ECDSAP384SHA384


def _is_sha512(algorithm):
    return algorithm == RSASHA512


def _make_hash(algorithm):
    if _is_md5(algorithm):
        return MD5.new()
    if _is_sha1(algorithm):
        return SHA1.new()
    if _is_sha256(algorithm):
        return SHA256.new()
    if _is_sha384(algorithm):
        return SHA384.new()
    if _is_sha512(algorithm):
        return SHA512.new()
    raise ValidationFailure('unknown hash for algorithm %u' % algorithm)


def _make_algorithm_id(algorithm):
    if _is_md5(algorithm):
        oid = [0x2a, 0x86, 0x48, 0x86, 0xf7, 0x0d, 0x02, 0x05]
    elif _is_sha1(algorithm):
        oid = [0x2b, 0x0e, 0x03, 0x02, 0x1a]
    elif _is_sha256(algorithm):
        oid = [0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x01]
    elif _is_sha512(algorithm):
        oid = [0x60, 0x86, 0x48, 0x01, 0x65, 0x03, 0x04, 0x02, 0x03]
    else:
        raise ValidationFailure('unknown algorithm %u' % algorithm)
    olen = len(oid)
    dlen = _make_hash(algorithm).digest_size
    idbytes = [0x30] + [8 + olen + dlen] + \
              [0x30, olen + 4] + [0x06, olen] + oid + \
              [0x05, 0x00] + [0x04, dlen]
    return struct.pack('!%dB' % len(idbytes), *idbytes)


def _validate_rrsig(rrset, rrsig, keys, origin=None, now=None):
    """Validate an RRset against a single signature rdata

    The owner name of *rrsig* is assumed to be the same as the owner name
    of *rrset*.

    *rrset* is the RRset to validate.  It can be a ``dns.rrset.RRset`` or
    a ``(dns.name.Name, dns.rdataset.Rdataset)`` tuple.

    *rrsig* is a ``dns.rdata.Rdata``, the signature to validate.

    *keys* is the key dictionary, used to find the DNSKEY associated with
    a given name.  The dictionary is keyed by a ``dns.name.Name``, and has
    ``dns.node.Node`` or ``dns.rdataset.Rdataset`` values.

    *origin* is a ``dns.name.Name``, the origin to use for relative names.

    *now* is an ``int``, the time to use when validating the signatures,
    in seconds since the UNIX epoch.  The default is the current time.
    """

    if isinstance(origin, string_types):
        origin = dns.name.from_text(origin, dns.name.root)

    candidate_keys = _find_candidate_keys(keys, rrsig)
    if candidate_keys is None:
        raise ValidationFailure('unknown key')

    for candidate_key in candidate_keys:
        # For convenience, allow the rrset to be specified as a (name,
        # rdataset) tuple as well as a proper rrset
        if isinstance(rrset, tuple):
            rrname = rrset[0]
            rdataset = rrset[1]
        else:
            rrname = rrset.name
            rdataset = rrset

        if now is None:
            now = time.time()
        if rrsig.expiration < now:
            raise ValidationFailure('expired')
        if rrsig.inception > now:
            raise ValidationFailure('not yet valid')

        hash = _make_hash(rrsig.algorithm)

        if _is_rsa(rrsig.algorithm):
            keyptr = candidate_key.key
            (bytes_,) = struct.unpack('!B', keyptr[0:1])
            keyptr = keyptr[1:]
            if bytes_ == 0:
                (bytes_,) = struct.unpack('!H', keyptr[0:2])
                keyptr = keyptr[2:]
            rsa_e = keyptr[0:bytes_]
            rsa_n = keyptr[bytes_:]
            try:
                pubkey = CryptoRSA.construct(
                    (number.bytes_to_long(rsa_n),
                     number.bytes_to_long(rsa_e)))
            except ValueError:
                raise ValidationFailure('invalid public key')
            sig = rrsig.signature
        elif _is_dsa(rrsig.algorithm):
            keyptr = candidate_key.key
            (t,) = struct.unpack('!B', keyptr[0:1])
            keyptr = keyptr[1:]
            octets = 64 + t * 8
            dsa_q = keyptr[0:20]
            keyptr = keyptr[20:]
            dsa_p = keyptr[0:octets]
            keyptr = keyptr[octets:]
            dsa_g = keyptr[0:octets]
            keyptr = keyptr[octets:]
            dsa_y = keyptr[0:octets]
            pubkey = CryptoDSA.construct(
                (number.bytes_to_long(dsa_y),
                 number.bytes_to_long(dsa_g),
                 number.bytes_to_long(dsa_p),
                 number.bytes_to_long(dsa_q)))
            sig = rrsig.signature[1:]
        elif _is_ecdsa(rrsig.algorithm):
            # use ecdsa for NIST-384p -- not currently supported by pycryptodome

            keyptr = candidate_key.key

            if rrsig.algorithm == ECDSAP256SHA256:
                curve = ecdsa.curves.NIST256p
                key_len = 32
            elif rrsig.algorithm == ECDSAP384SHA384:
                curve = ecdsa.curves.NIST384p
                key_len = 48

            x = number.bytes_to_long(keyptr[0:key_len])
            y = number.bytes_to_long(keyptr[key_len:key_len * 2])
            if not ecdsa.ecdsa.point_is_valid(curve.generator, x, y):
                raise ValidationFailure('invalid ECDSA key')
            point = ecdsa.ellipticcurve.Point(curve.curve, x, y, curve.order)
            verifying_key = ecdsa.keys.VerifyingKey.from_public_point(point,
                                                                      curve)
            pubkey = ECKeyWrapper(verifying_key, key_len)
            r = rrsig.signature[:key_len]
            s = rrsig.signature[key_len:]
            sig = ecdsa.ecdsa.Signature(number.bytes_to_long(r),
                                        number.bytes_to_long(s))

        else:
            raise ValidationFailure('unknown algorithm %u' % rrsig.algorithm)

        hash.update(_to_rdata(rrsig, origin)[:18])
        hash.update(rrsig.signer.to_digestable(origin))

        if rrsig.labels < len(rrname) - 1:
            suffix = rrname.split(rrsig.labels + 1)[1]
            rrname = dns.name.from_text('*', suffix)
        rrnamebuf = rrname.to_digestable(origin)
        rrfixed = struct.pack('!HHI', rdataset.rdtype, rdataset.rdclass,
                              rrsig.original_ttl)
        rrlist = sorted(rdataset)
        for rr in rrlist:
            hash.update(rrnamebuf)
            hash.update(rrfixed)
            rrdata = rr.to_digestable(origin)
            rrlen = struct.pack('!H', len(rrdata))
            hash.update(rrlen)
            hash.update(rrdata)

        try:
            if _is_rsa(rrsig.algorithm):
                verifier = pkcs1_15.new(pubkey)
                # will raise ValueError if verify fails:
                verifier.verify(hash, sig)
            elif _is_dsa(rrsig.algorithm):
                verifier = DSS.new(pubkey, 'fips-186-3')
                verifier.verify(hash, sig)
            elif _is_ecdsa(rrsig.algorithm):
                digest = hash.digest()
                if not pubkey.verify(digest, sig):
                    raise ValueError
            else:
                # Raise here for code clarity; this won't actually ever happen
                # since if the algorithm is really unknown we'd already have
                # raised an exception above
                raise ValidationFailure('unknown algorithm %u' % rrsig.algorithm)
            # If we got here, we successfully verified so we can return without error
            return
        except ValueError:
            # this happens on an individual validation failure
            continue
    # nothing verified -- raise failure:
    raise ValidationFailure('verify failure')


def _validate(rrset, rrsigset, keys, origin=None, now=None):
    """Validate an RRset.

    *rrset* is the RRset to validate.  It can be a ``dns.rrset.RRset`` or
    a ``(dns.name.Name, dns.rdataset.Rdataset)`` tuple.

    *rrsigset* is the signature RRset to be validated.  It can be a
    ``dns.rrset.RRset`` or a ``(dns.name.Name, dns.rdataset.Rdataset)`` tuple.

    *keys* is the key dictionary, used to find the DNSKEY associated with
    a given name.  The dictionary is keyed by a ``dns.name.Name``, and has
    ``dns.node.Node`` or ``dns.rdataset.Rdataset`` values.

    *origin* is a ``dns.name.Name``, the origin to use for relative names.

    *now* is an ``int``, the time to use when validating the signatures,
    in seconds since the UNIX epoch.  The default is the current time.
    """

    if isinstance(origin, string_types):
        origin = dns.name.from_text(origin, dns.name.root)

    if isinstance(rrset, tuple):
        rrname = rrset[0]
    else:
        rrname = rrset.name

    if isinstance(rrsigset, tuple):
        rrsigname = rrsigset[0]
        rrsigrdataset = rrsigset[1]
    else:
        rrsigname = rrsigset.name
        rrsigrdataset = rrsigset

    rrname = rrname.choose_relativity(origin)
    rrsigname = rrsigname.choose_relativity(origin)
    if rrname != rrsigname:
        raise ValidationFailure("owner names do not match")

    for rrsig in rrsigrdataset:
        try:
            _validate_rrsig(rrset, rrsig, keys, origin, now)
            return
        except ValidationFailure:
            pass
    raise ValidationFailure("no RRSIGs validated")


def _need_pycrypto(*args, **kwargs):
    raise NotImplementedError("DNSSEC validation requires pycryptodome/pycryptodomex")


try:
    try:
        # test we're using pycryptodome, not pycrypto (which misses SHA1 for example)
        from Crypto.Hash import MD5, SHA1, SHA256, SHA384, SHA512
        from Crypto.PublicKey import RSA as CryptoRSA, DSA as CryptoDSA
        from Crypto.Signature import pkcs1_15, DSS
        from Crypto.Util import number
    except ImportError:
        from Cryptodome.Hash import MD5, SHA1, SHA256, SHA384, SHA512
        from Cryptodome.PublicKey import RSA as CryptoRSA, DSA as CryptoDSA
        from Cryptodome.Signature import pkcs1_15, DSS
        from Cryptodome.Util import number
except ImportError:
    validate = _need_pycrypto
    validate_rrsig = _need_pycrypto
    _have_pycrypto = False
    _have_ecdsa = False
else:
    validate = _validate
    validate_rrsig = _validate_rrsig
    _have_pycrypto = True

    try:
        import ecdsa
        import ecdsa.ecdsa
        import ecdsa.ellipticcurve
        import ecdsa.keys
    except ImportError:
        _have_ecdsa = False
    else:
        _have_ecdsa = True

        class ECKeyWrapper(object):

            def __init__(self, key, key_len):
                self.key = key
                self.key_len = key_len

            def verify(self, digest, sig):
                diglong = number.bytes_to_long(digest)
                return self.key.pubkey.verifies(diglong, sig)




############################################################
### File: e164.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2006-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS E.164 helpers."""

import dns.exception
import dns.name
import dns.resolver
from ._compat import string_types, maybe_decode

#: The public E.164 domain.
public_enum_domain = dns.name.from_text('e164.arpa.')


def from_e164(text, origin=public_enum_domain):
    """Convert an E.164 number in textual form into a Name object whose
    value is the ENUM domain name for that number.

    Non-digits in the text are ignored, i.e. "16505551212",
    "+1.650.555.1212" and "1 (650) 555-1212" are all the same.

    *text*, a ``text``, is an E.164 number in textual form.

    *origin*, a ``dns.name.Name``, the domain in which the number
    should be constructed.  The default is ``e164.arpa.``.

    Returns a ``dns.name.Name``.
    """

    parts = [d for d in text if d.isdigit()]
    parts.reverse()
    return dns.name.from_text('.'.join(parts), origin=origin)


def to_e164(name, origin=public_enum_domain, want_plus_prefix=True):
    """Convert an ENUM domain name into an E.164 number.

    Note that dnspython does not have any information about preferred
    number formats within national numbering plans, so all numbers are
    emitted as a simple string of digits, prefixed by a '+' (unless
    *want_plus_prefix* is ``False``).

    *name* is a ``dns.name.Name``, the ENUM domain name.

    *origin* is a ``dns.name.Name``, a domain containing the ENUM
    domain name.  The name is relativized to this domain before being
    converted to text.  If ``None``, no relativization is done.

    *want_plus_prefix* is a ``bool``.  If True, add a '+' to the beginning of
    the returned number.

    Returns a ``text``.

    """
    if origin is not None:
        name = name.relativize(origin)
    dlabels = [d for d in name.labels if d.isdigit() and len(d) == 1]
    if len(dlabels) != len(name.labels):
        raise dns.exception.SyntaxError('non-digit labels in ENUM domain name')
    dlabels.reverse()
    text = b''.join(dlabels)
    if want_plus_prefix:
        text = b'+' + text
    return maybe_decode(text)


def query(number, domains, resolver=None):
    """Look for NAPTR RRs for the specified number in the specified domains.

    e.g. lookup('16505551212', ['e164.dnspython.org.', 'e164.arpa.'])

    *number*, a ``text`` is the number to look for.

    *domains* is an iterable containing ``dns.name.Name`` values.

    *resolver*, a ``dns.resolver.Resolver``, is the resolver to use.  If
    ``None``, the default resolver is used.
    """

    if resolver is None:
        resolver = dns.resolver.get_default_resolver()
    e_nx = dns.resolver.NXDOMAIN()
    for domain in domains:
        if isinstance(domain, string_types):
            domain = dns.name.from_text(domain)
        qname = dns.e164.from_e164(number, domain)
        try:
            return resolver.query(qname, 'NAPTR')
        except dns.resolver.NXDOMAIN as e:
            e_nx += e
    raise e_nx




############################################################
### File: easter.py
############################################################
# -*- coding: utf-8 -*-
"""
This module offers a generic easter computing method for any given year, using
Western, Orthodox or Julian algorithms.
"""

import datetime

__all__ = ["easter", "EASTER_JULIAN", "EASTER_ORTHODOX", "EASTER_WESTERN"]

EASTER_JULIAN = 1
EASTER_ORTHODOX = 2
EASTER_WESTERN = 3


def easter(year, method=EASTER_WESTERN):
    """
    This method was ported from the work done by GM Arts,
    on top of the algorithm by Claus Tondering, which was
    based in part on the algorithm of Ouding (1940), as
    quoted in "Explanatory Supplement to the Astronomical
    Almanac", P.  Kenneth Seidelmann, editor.

    This algorithm implements three different easter
    calculation methods:

    1 - Original calculation in Julian calendar, valid in
        dates after 326 AD
    2 - Original method, with date converted to Gregorian
        calendar, valid in years 1583 to 4099
    3 - Revised method, in Gregorian calendar, valid in
        years 1583 to 4099 as well

    These methods are represented by the constants:

    * ``EASTER_JULIAN   = 1``
    * ``EASTER_ORTHODOX = 2``
    * ``EASTER_WESTERN  = 3``

    The default method is method 3.

    More about the algorithm may be found at:

    `GM Arts: Easter Algorithms <http://www.gmarts.org/index.php?go=415>`_

    and

    `The Calendar FAQ: Easter <https://www.tondering.dk/claus/cal/easter.php>`_

    """

    if not (1 <= method <= 3):
        raise ValueError("invalid method")

    # g - Golden year - 1
    # c - Century
    # h - (23 - Epact) mod 30
    # i - Number of days from March 21 to Paschal Full Moon
    # j - Weekday for PFM (0=Sunday, etc)
    # p - Number of days from March 21 to Sunday on or before PFM
    #     (-6 to 28 methods 1 & 3, to 56 for method 2)
    # e - Extra days to add for method 2 (converting Julian
    #     date to Gregorian date)

    y = year
    g = y % 19
    e = 0
    if method < 3:
        # Old method
        i = (19*g + 15) % 30
        j = (y + y//4 + i) % 7
        if method == 2:
            # Extra dates to convert Julian to Gregorian date
            e = 10
            if y > 1600:
                e = e + y//100 - 16 - (y//100 - 16)//4
    else:
        # New method
        c = y//100
        h = (c - c//4 - (8*c + 13)//25 + 19*g + 15) % 30
        i = h - (h//28)*(1 - (h//28)*(29//(h + 1))*((21 - g)//11))
        j = (y + y//4 + i + 2 - c + c//4) % 7

    # p can be from -6 to 56 corresponding to dates 22 March to 23 May
    # (later dates apply to method 2, although 23 May never actually occurs)
    p = i - j + e
    d = 1 + (p + 27 + (p + 6)//40) % 31
    m = 3 + (p + 26)//30
    return datetime.date(int(y), int(m), int(d))




############################################################
### File: edns.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2009-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""EDNS Options"""

from __future__ import absolute_import

import math
import struct

import dns.inet

#: NSID
NSID = 3
#: DAU
DAU = 5
#: DHU
DHU = 6
#: N3U
N3U = 7
#: ECS (client-subnet)
ECS = 8
#: EXPIRE
EXPIRE = 9
#: COOKIE
COOKIE = 10
#: KEEPALIVE
KEEPALIVE = 11
#: PADDING
PADDING = 12
#: CHAIN
CHAIN = 13

class Option(object):

    """Base class for all EDNS option types."""

    def __init__(self, otype):
        """Initialize an option.

        *otype*, an ``int``, is the option type.
        """
        self.otype = otype

    def to_wire(self, file):
        """Convert an option to wire format.
        """
        raise NotImplementedError

    @classmethod
    def from_wire(cls, otype, wire, current, olen):
        """Build an EDNS option object from wire format.

        *otype*, an ``int``, is the option type.

        *wire*, a ``binary``, is the wire-format message.

        *current*, an ``int``, is the offset in *wire* of the beginning
        of the rdata.

        *olen*, an ``int``, is the length of the wire-format option data

        Returns a ``dns.edns.Option``.
        """

        raise NotImplementedError

    def _cmp(self, other):
        """Compare an EDNS option with another option of the same type.

        Returns < 0 if < *other*, 0 if == *other*, and > 0 if > *other*.
        """
        raise NotImplementedError

    def __eq__(self, other):
        if not isinstance(other, Option):
            return False
        if self.otype != other.otype:
            return False
        return self._cmp(other) == 0

    def __ne__(self, other):
        if not isinstance(other, Option):
            return False
        if self.otype != other.otype:
            return False
        return self._cmp(other) != 0

    def __lt__(self, other):
        if not isinstance(other, Option) or \
                self.otype != other.otype:
            return NotImplemented
        return self._cmp(other) < 0

    def __le__(self, other):
        if not isinstance(other, Option) or \
                self.otype != other.otype:
            return NotImplemented
        return self._cmp(other) <= 0

    def __ge__(self, other):
        if not isinstance(other, Option) or \
                self.otype != other.otype:
            return NotImplemented
        return self._cmp(other) >= 0

    def __gt__(self, other):
        if not isinstance(other, Option) or \
                self.otype != other.otype:
            return NotImplemented
        return self._cmp(other) > 0


class GenericOption(Option):

    """Generic Option Class

    This class is used for EDNS option types for which we have no better
    implementation.
    """

    def __init__(self, otype, data):
        super(GenericOption, self).__init__(otype)
        self.data = data

    def to_wire(self, file):
        file.write(self.data)

    def to_text(self):
        return "Generic %d" % self.otype

    @classmethod
    def from_wire(cls, otype, wire, current, olen):
        return cls(otype, wire[current: current + olen])

    def _cmp(self, other):
        if self.data == other.data:
            return 0
        if self.data > other.data:
            return 1
        return -1


class ECSOption(Option):
    """EDNS Client Subnet (ECS, RFC7871)"""

    def __init__(self, address, srclen=None, scopelen=0):
        """*address*, a ``text``, is the client address information.

        *srclen*, an ``int``, the source prefix length, which is the
        leftmost number of bits of the address to be used for the
        lookup.  The default is 24 for IPv4 and 56 for IPv6.

        *scopelen*, an ``int``, the scope prefix length.  This value
        must be 0 in queries, and should be set in responses.
        """

        super(ECSOption, self).__init__(ECS)
        af = dns.inet.af_for_address(address)

        if af == dns.inet.AF_INET6:
            self.family = 2
            if srclen is None:
                srclen = 56
        elif af == dns.inet.AF_INET:
            self.family = 1
            if srclen is None:
                srclen = 24
        else:
            raise ValueError('Bad ip family')

        self.address = address
        self.srclen = srclen
        self.scopelen = scopelen

        addrdata = dns.inet.inet_pton(af, address)
        nbytes = int(math.ceil(srclen/8.0))

        # Truncate to srclen and pad to the end of the last octet needed
        # See RFC section 6
        self.addrdata = addrdata[:nbytes]
        nbits = srclen % 8
        if nbits != 0:
            last = struct.pack('B', ord(self.addrdata[-1:]) & (0xff << nbits))
            self.addrdata = self.addrdata[:-1] + last

    def to_text(self):
        return "ECS {}/{} scope/{}".format(self.address, self.srclen,
                                           self.scopelen)

    def to_wire(self, file):
        file.write(struct.pack('!H', self.family))
        file.write(struct.pack('!BB', self.srclen, self.scopelen))
        file.write(self.addrdata)

    @classmethod
    def from_wire(cls, otype, wire, cur, olen):
        family, src, scope = struct.unpack('!HBB', wire[cur:cur+4])
        cur += 4

        addrlen = int(math.ceil(src/8.0))

        if family == 1:
            af = dns.inet.AF_INET
            pad = 4 - addrlen
        elif family == 2:
            af = dns.inet.AF_INET6
            pad = 16 - addrlen
        else:
            raise ValueError('unsupported family')

        addr = dns.inet.inet_ntop(af, wire[cur:cur+addrlen] + b'\x00' * pad)
        return cls(addr, src, scope)

    def _cmp(self, other):
        if self.addrdata == other.addrdata:
            return 0
        if self.addrdata > other.addrdata:
            return 1
        return -1

_type_to_class = {
        ECS: ECSOption
}

def get_option_class(otype):
    """Return the class for the specified option type.

    The GenericOption class is used if a more specific class is not
    known.
    """

    cls = _type_to_class.get(otype)
    if cls is None:
        cls = GenericOption
    return cls


def option_from_wire(otype, wire, current, olen):
    """Build an EDNS option object from wire format.

    *otype*, an ``int``, is the option type.

    *wire*, a ``binary``, is the wire-format message.

    *current*, an ``int``, is the offset in *wire* of the beginning
    of the rdata.

    *olen*, an ``int``, is the length of the wire-format option data

    Returns an instance of a subclass of ``dns.edns.Option``.
    """

    cls = get_option_class(otype)
    return cls.from_wire(otype, wire, current, olen)




############################################################
### File: element.py
############################################################
__license__ = "MIT"

from pdb import set_trace
import re
import sys
import six
import warnings
from bs4.dammit import EntitySubstitution

try:
    from collections.abc import Callable
except ImportError:
    from collections import Callable

DEFAULT_OUTPUT_ENCODING = "utf-8"
PY3K = (sys.version_info[0] > 2)

whitespace_re = re.compile(r"\s+")

def _alias(attr):
    """Alias one attribute name to another for backward compatibility"""
    @property
    def alias(self):
        return getattr(self, attr)

    @alias.setter
    def alias(self):
        return setattr(self, attr)
    return alias


class NamespacedAttribute(six.text_type):

    def __new__(cls, prefix, name, namespace=None):
        if name is None:
            obj = six.text_type.__new__(cls, prefix)
        elif prefix is None:
            # Not really namespaced.
            obj = six.text_type.__new__(cls, name)
        else:
            obj = six.text_type.__new__(cls, prefix + ":" + name)
        obj.prefix = prefix
        obj.name = name
        obj.namespace = namespace
        return obj

class AttributeValueWithCharsetSubstitution(six.text_type):
    """A stand-in object for a character encoding specified in HTML."""

class CharsetMetaAttributeValue(AttributeValueWithCharsetSubstitution):
    """A generic stand-in for the value of a meta tag's 'charset' attribute.

    When Beautiful Soup parses the markup '<meta charset="utf8">', the
    value of the 'charset' attribute will be one of these objects.
    """

    def __new__(cls, original_value):
        obj = six.text_type.__new__(cls, original_value)
        obj.original_value = original_value
        return obj

    def encode(self, encoding):
        return encoding


class ContentMetaAttributeValue(AttributeValueWithCharsetSubstitution):
    """A generic stand-in for the value of a meta tag's 'content' attribute.

    When Beautiful Soup parses the markup:
     <meta http-equiv="content-type" content="text/html; charset=utf8">

    The value of the 'content' attribute will be one of these objects.
    """

    CHARSET_RE = re.compile(r"((^|;)\s*charset=)([^;]*)", re.M)

    def __new__(cls, original_value):
        match = cls.CHARSET_RE.search(original_value)
        if match is None:
            # No substitution necessary.
            return six.text_type.__new__(six.text_type, original_value)

        obj = six.text_type.__new__(cls, original_value)
        obj.original_value = original_value
        return obj

    def encode(self, encoding):
        def rewrite(match):
            return match.group(1) + encoding
        return self.CHARSET_RE.sub(rewrite, self.original_value)

class HTMLAwareEntitySubstitution(EntitySubstitution):

    """Entity substitution rules that are aware of some HTML quirks.

    Specifically, the contents of <script> and <style> tags should not
    undergo entity substitution.

    Incoming NavigableString objects are checked to see if they're the
    direct children of a <script> or <style> tag.
    """

    cdata_containing_tags = set(["script", "style"])

    preformatted_tags = set(["pre"])

    @classmethod
    def _substitute_if_appropriate(cls, ns, f):
        if (isinstance(ns, NavigableString)
            and ns.parent is not None
            and ns.parent.name in cls.cdata_containing_tags):
            # Do nothing.
            return ns
        # Substitute.
        return f(ns)

    @classmethod
    def substitute_html(cls, ns):
        return cls._substitute_if_appropriate(
            ns, EntitySubstitution.substitute_html)

    @classmethod
    def substitute_xml(cls, ns):
        return cls._substitute_if_appropriate(
            ns, EntitySubstitution.substitute_xml)

class PageElement(object):
    """Contains the navigational information for some part of the page
    (either a tag or a piece of text)"""

    # There are five possible values for the "formatter" argument passed in
    # to methods like encode() and prettify():
    #
    # "html" - All Unicode characters with corresponding HTML entities
    #   are converted to those entities on output.
    # "minimal" - Bare ampersands and angle brackets are converted to
    #   XML entities: &amp; &lt; &gt;
    # None - The null formatter. Unicode characters are never
    #   converted to entities.  This is not recommended, but it's
    #   faster than "minimal".
    # A function - This function will be called on every string that
    #  needs to undergo entity substitution.
    #

    # In an HTML document, the default "html" and "minimal" functions
    # will leave the contents of <script> and <style> tags alone. For
    # an XML document, all tags will be given the same treatment.

    HTML_FORMATTERS = {
        "html" : HTMLAwareEntitySubstitution.substitute_html,
        "minimal" : HTMLAwareEntitySubstitution.substitute_xml,
        None : None
        }

    XML_FORMATTERS = {
        "html" : EntitySubstitution.substitute_html,
        "minimal" : EntitySubstitution.substitute_xml,
        None : None
        }

    def format_string(self, s, formatter='minimal'):
        """Format the given string using the given formatter."""
        if not callable(formatter):
            formatter = self._formatter_for_name(formatter)
        if formatter is None:
            output = s
        else:
            output = formatter(s)
        return output

    @property
    def _is_xml(self):
        """Is this element part of an XML tree or an HTML tree?

        This is used when mapping a formatter name ("minimal") to an
        appropriate function (one that performs entity-substitution on
        the contents of <script> and <style> tags, or not). It's
        inefficient, but it should be called very rarely.
        """
        if self.parent is None:
            # This is the top-level object. It should have .is_xml set
            # from tree creation. If not, take a guess--BS is usually
            # used on HTML markup.
            return getattr(self, 'is_xml', False)
        return self.parent._is_xml

    def _formatter_for_name(self, name):
        "Look up a formatter function based on its name and the tree."
        if self._is_xml:
            return self.XML_FORMATTERS.get(
                name, EntitySubstitution.substitute_xml)
        else:
            return self.HTML_FORMATTERS.get(
                name, HTMLAwareEntitySubstitution.substitute_xml)

    def setup(self, parent=None, previous_element=None, next_element=None,
              previous_sibling=None, next_sibling=None):
        """Sets up the initial relations between this element and
        other elements."""
        self.parent = parent

        self.previous_element = previous_element
        if previous_element is not None:
            self.previous_element.next_element = self

        self.next_element = next_element
        if self.next_element:
            self.next_element.previous_element = self

        self.next_sibling = next_sibling
        if self.next_sibling:
            self.next_sibling.previous_sibling = self

        if (not previous_sibling
            and self.parent is not None and self.parent.contents):
            previous_sibling = self.parent.contents[-1]

        self.previous_sibling = previous_sibling
        if previous_sibling:
            self.previous_sibling.next_sibling = self

    nextSibling = _alias("next_sibling")  # BS3
    previousSibling = _alias("previous_sibling")  # BS3

    def replace_with(self, replace_with):
        if not self.parent:
            raise ValueError(
                "Cannot replace one element with another when the"
                "element to be replaced is not part of a tree.")
        if replace_with is self:
            return
        if replace_with is self.parent:
            raise ValueError("Cannot replace a Tag with its parent.")
        old_parent = self.parent
        my_index = self.parent.index(self)
        self.extract()
        old_parent.insert(my_index, replace_with)
        return self
    replaceWith = replace_with  # BS3

    def unwrap(self):
        my_parent = self.parent
        if not self.parent:
            raise ValueError(
                "Cannot replace an element with its contents when that"
                "element is not part of a tree.")
        my_index = self.parent.index(self)
        self.extract()
        for child in reversed(self.contents[:]):
            my_parent.insert(my_index, child)
        return self
    replace_with_children = unwrap
    replaceWithChildren = unwrap  # BS3

    def wrap(self, wrap_inside):
        me = self.replace_with(wrap_inside)
        wrap_inside.append(me)
        return wrap_inside

    def extract(self):
        """Destructively rips this element out of the tree."""
        if self.parent is not None:
            del self.parent.contents[self.parent.index(self)]

        #Find the two elements that would be next to each other if
        #this element (and any children) hadn't been parsed. Connect
        #the two.
        last_child = self._last_descendant()
        next_element = last_child.next_element

        if (self.previous_element is not None and
            self.previous_element is not next_element):
            self.previous_element.next_element = next_element
        if next_element is not None and next_element is not self.previous_element:
            next_element.previous_element = self.previous_element
        self.previous_element = None
        last_child.next_element = None

        self.parent = None
        if (self.previous_sibling is not None
            and self.previous_sibling is not self.next_sibling):
            self.previous_sibling.next_sibling = self.next_sibling
        if (self.next_sibling is not None
            and self.next_sibling is not self.previous_sibling):
            self.next_sibling.previous_sibling = self.previous_sibling
        self.previous_sibling = self.next_sibling = None
        return self

    def _last_descendant(self, is_initialized=True, accept_self=True):
        "Finds the last element beneath this object to be parsed."
        if is_initialized and self.next_sibling:
            last_child = self.next_sibling.previous_element
        else:
            last_child = self
            while isinstance(last_child, Tag) and last_child.contents:
                last_child = last_child.contents[-1]
        if not accept_self and last_child is self:
            last_child = None
        return last_child
    # BS3: Not part of the API!
    _lastRecursiveChild = _last_descendant

    def insert(self, position, new_child):
        if new_child is None:
            raise ValueError("Cannot insert None into a tag.")
        if new_child is self:
            raise ValueError("Cannot insert a tag into itself.")
        if (isinstance(new_child, six.string_types)
            and not isinstance(new_child, NavigableString)):
            new_child = NavigableString(new_child)

        position = min(position, len(self.contents))
        if hasattr(new_child, 'parent') and new_child.parent is not None:
            # We're 'inserting' an element that's already one
            # of this object's children.
            if new_child.parent is self:
                current_index = self.index(new_child)
                if current_index < position:
                    # We're moving this element further down the list
                    # of this object's children. That means that when
                    # we extract this element, our target index will
                    # jump down one.
                    position -= 1
            new_child.extract()

        new_child.parent = self
        previous_child = None
        if position == 0:
            new_child.previous_sibling = None
            new_child.previous_element = self
        else:
            previous_child = self.contents[position - 1]
            new_child.previous_sibling = previous_child
            new_child.previous_sibling.next_sibling = new_child
            new_child.previous_element = previous_child._last_descendant(False)
        if new_child.previous_element is not None:
            new_child.previous_element.next_element = new_child

        new_childs_last_element = new_child._last_descendant(False)

        if position >= len(self.contents):
            new_child.next_sibling = None

            parent = self
            parents_next_sibling = None
            while parents_next_sibling is None and parent is not None:
                parents_next_sibling = parent.next_sibling
                parent = parent.parent
                if parents_next_sibling is not None:
                    # We found the element that comes next in the document.
                    break
            if parents_next_sibling is not None:
                new_childs_last_element.next_element = parents_next_sibling
            else:
                # The last element of this tag is the last element in
                # the document.
                new_childs_last_element.next_element = None
        else:
            next_child = self.contents[position]
            new_child.next_sibling = next_child
            if new_child.next_sibling is not None:
                new_child.next_sibling.previous_sibling = new_child
            new_childs_last_element.next_element = next_child

        if new_childs_last_element.next_element is not None:
            new_childs_last_element.next_element.previous_element = new_childs_last_element
        self.contents.insert(position, new_child)

    def append(self, tag):
        """Appends the given tag to the contents of this tag."""
        self.insert(len(self.contents), tag)

    def insert_before(self, predecessor):
        """Makes the given element the immediate predecessor of this one.

        The two elements will have the same parent, and the given element
        will be immediately before this one.
        """
        if self is predecessor:
            raise ValueError("Can't insert an element before itself.")
        parent = self.parent
        if parent is None:
            raise ValueError(
                "Element has no parent, so 'before' has no meaning.")
        # Extract first so that the index won't be screwed up if they
        # are siblings.
        if isinstance(predecessor, PageElement):
            predecessor.extract()
        index = parent.index(self)
        parent.insert(index, predecessor)

    def insert_after(self, successor):
        """Makes the given element the immediate successor of this one.

        The two elements will have the same parent, and the given element
        will be immediately after this one.
        """
        if self is successor:
            raise ValueError("Can't insert an element after itself.")
        parent = self.parent
        if parent is None:
            raise ValueError(
                "Element has no parent, so 'after' has no meaning.")
        # Extract first so that the index won't be screwed up if they
        # are siblings.
        if isinstance(successor, PageElement):
            successor.extract()
        index = parent.index(self)
        parent.insert(index+1, successor)

    def find_next(self, name=None, attrs={}, text=None, **kwargs):
        """Returns the first item that matches the given criteria and
        appears after this Tag in the document."""
        return self._find_one(self.find_all_next, name, attrs, text, **kwargs)
    findNext = find_next  # BS3

    def find_all_next(self, name=None, attrs={}, text=None, limit=None,
                    **kwargs):
        """Returns all items that match the given criteria and appear
        after this Tag in the document."""
        return self._find_all(name, attrs, text, limit, self.next_elements,
                             **kwargs)
    findAllNext = find_all_next  # BS3

    def find_next_sibling(self, name=None, attrs={}, text=None, **kwargs):
        """Returns the closest sibling to this Tag that matches the
        given criteria and appears after this Tag in the document."""
        return self._find_one(self.find_next_siblings, name, attrs, text,
                             **kwargs)
    findNextSibling = find_next_sibling  # BS3

    def find_next_siblings(self, name=None, attrs={}, text=None, limit=None,
                           **kwargs):
        """Returns the siblings of this Tag that match the given
        criteria and appear after this Tag in the document."""
        return self._find_all(name, attrs, text, limit,
                              self.next_siblings, **kwargs)
    findNextSiblings = find_next_siblings   # BS3
    fetchNextSiblings = find_next_siblings  # BS2

    def find_previous(self, name=None, attrs={}, text=None, **kwargs):
        """Returns the first item that matches the given criteria and
        appears before this Tag in the document."""
        return self._find_one(
            self.find_all_previous, name, attrs, text, **kwargs)
    findPrevious = find_previous  # BS3

    def find_all_previous(self, name=None, attrs={}, text=None, limit=None,
                        **kwargs):
        """Returns all items that match the given criteria and appear
        before this Tag in the document."""
        return self._find_all(name, attrs, text, limit, self.previous_elements,
                           **kwargs)
    findAllPrevious = find_all_previous  # BS3
    fetchPrevious = find_all_previous    # BS2

    def find_previous_sibling(self, name=None, attrs={}, text=None, **kwargs):
        """Returns the closest sibling to this Tag that matches the
        given criteria and appears before this Tag in the document."""
        return self._find_one(self.find_previous_siblings, name, attrs, text,
                             **kwargs)
    findPreviousSibling = find_previous_sibling  # BS3

    def find_previous_siblings(self, name=None, attrs={}, text=None,
                               limit=None, **kwargs):
        """Returns the siblings of this Tag that match the given
        criteria and appear before this Tag in the document."""
        return self._find_all(name, attrs, text, limit,
                              self.previous_siblings, **kwargs)
    findPreviousSiblings = find_previous_siblings   # BS3
    fetchPreviousSiblings = find_previous_siblings  # BS2

    def find_parent(self, name=None, attrs={}, **kwargs):
        """Returns the closest parent of this Tag that matches the given
        criteria."""
        # NOTE: We can't use _find_one because findParents takes a different
        # set of arguments.
        r = None
        l = self.find_parents(name, attrs, 1, **kwargs)
        if l:
            r = l[0]
        return r
    findParent = find_parent  # BS3

    def find_parents(self, name=None, attrs={}, limit=None, **kwargs):
        """Returns the parents of this Tag that match the given
        criteria."""

        return self._find_all(name, attrs, None, limit, self.parents,
                             **kwargs)
    findParents = find_parents   # BS3
    fetchParents = find_parents  # BS2

    @property
    def next(self):
        return self.next_element

    @property
    def previous(self):
        return self.previous_element

    #These methods do the real heavy lifting.

    def _find_one(self, method, name, attrs, text, **kwargs):
        r = None
        l = method(name, attrs, text, 1, **kwargs)
        if l:
            r = l[0]
        return r

    def _find_all(self, name, attrs, text, limit, generator, **kwargs):
        "Iterates over a generator looking for things that match."

        if text is None and 'string' in kwargs:
            text = kwargs['string']
            del kwargs['string']

        if isinstance(name, SoupStrainer):
            strainer = name
        else:
            strainer = SoupStrainer(name, attrs, text, **kwargs)

        if text is None and not limit and not attrs and not kwargs:
            if name is True or name is None:
                # Optimization to find all tags.
                result = (element for element in generator
                          if isinstance(element, Tag))
                return ResultSet(strainer, result)
            elif isinstance(name, six.string_types):
                # Optimization to find all tags with a given name.
                result = (element for element in generator
                          if isinstance(element, Tag)
                            and element.name == name)
                return ResultSet(strainer, result)
        results = ResultSet(strainer)
        while True:
            try:
                i = next(generator)
            except StopIteration:
                break
            if i:
                found = strainer.search(i)
                if found:
                    results.append(found)
                    if limit and len(results) >= limit:
                        break
        return results

    #These generators can be used to navigate starting from both
    #NavigableStrings and Tags.
    @property
    def next_elements(self):
        i = self.next_element
        while i is not None:
            yield i
            i = i.next_element

    @property
    def next_siblings(self):
        i = self.next_sibling
        while i is not None:
            yield i
            i = i.next_sibling

    @property
    def previous_elements(self):
        i = self.previous_element
        while i is not None:
            yield i
            i = i.previous_element

    @property
    def previous_siblings(self):
        i = self.previous_sibling
        while i is not None:
            yield i
            i = i.previous_sibling

    @property
    def parents(self):
        i = self.parent
        while i is not None:
            yield i
            i = i.parent

    # Methods for supporting CSS selectors.

    tag_name_re = re.compile('^[a-zA-Z0-9][-.a-zA-Z0-9:_]*$')

    # /^([a-zA-Z0-9][-.a-zA-Z0-9:_]*)\[(\w+)([=~\|\^\$\*]?)=?"?([^\]"]*)"?\]$/
    #   \---------------------------/  \---/\-------------/    \-------/
    #     |                              |         |               |
    #     |                              |         |           The value
    #     |                              |    ~,|,^,$,* or =
    #     |                           Attribute
    #    Tag
    attribselect_re = re.compile(
        r'^(?P<tag>[a-zA-Z0-9][-.a-zA-Z0-9:_]*)?\[(?P<attribute>[\w-]+)(?P<operator>[=~\|\^\$\*]?)' +
        r'=?"?(?P<value>[^\]"]*)"?\]$'
        )

    def _attr_value_as_string(self, value, default=None):
        """Force an attribute value into a string representation.

        A multi-valued attribute will be converted into a
        space-separated stirng.
        """
        value = self.get(value, default)
        if isinstance(value, list) or isinstance(value, tuple):
            value =" ".join(value)
        return value

    def _tag_name_matches_and(self, function, tag_name):
        if not tag_name:
            return function
        else:
            def _match(tag):
                return tag.name == tag_name and function(tag)
            return _match

    def _attribute_checker(self, operator, attribute, value=''):
        """Create a function that performs a CSS selector operation.

        Takes an operator, attribute and optional value. Returns a
        function that will return True for elements that match that
        combination.
        """
        if operator == '=':
            # string representation of `attribute` is equal to `value`
            return lambda el: el._attr_value_as_string(attribute) == value
        elif operator == '~':
            # space-separated list representation of `attribute`
            # contains `value`
            def _includes_value(element):
                attribute_value = element.get(attribute, [])
                if not isinstance(attribute_value, list):
                    attribute_value = attribute_value.split()
                return value in attribute_value
            return _includes_value
        elif operator == '^':
            # string representation of `attribute` starts with `value`
            return lambda el: el._attr_value_as_string(
                attribute, '').startswith(value)
        elif operator == '$':
            # string represenation of `attribute` ends with `value`
            return lambda el: el._attr_value_as_string(
                attribute, '').endswith(value)
        elif operator == '*':
            # string representation of `attribute` contains `value`
            return lambda el: value in el._attr_value_as_string(attribute, '')
        elif operator == '|':
            # string representation of `attribute` is either exactly
            # `value` or starts with `value` and then a dash.
            def _is_or_starts_with_dash(element):
                attribute_value = element._attr_value_as_string(attribute, '')
                return (attribute_value == value or attribute_value.startswith(
                        value + '-'))
            return _is_or_starts_with_dash
        else:
            return lambda el: el.has_attr(attribute)

    # Old non-property versions of the generators, for backwards
    # compatibility with BS3.
    def nextGenerator(self):
        return self.next_elements

    def nextSiblingGenerator(self):
        return self.next_siblings

    def previousGenerator(self):
        return self.previous_elements

    def previousSiblingGenerator(self):
        return self.previous_siblings

    def parentGenerator(self):
        return self.parents


class NavigableString(six.text_type, PageElement):

    PREFIX = ''
    SUFFIX = ''

    def __new__(cls, value):
        """Create a new NavigableString.

        When unpickling a NavigableString, this method is called with
        the string in DEFAULT_OUTPUT_ENCODING. That encoding needs to be
        passed in to the superclass's __new__ or the superclass won't know
        how to handle non-ASCII characters.
        """
        if isinstance(value, six.text_type):
            u = six.text_type.__new__(cls, value)
        else:
            u = six.text_type.__new__(cls, value, DEFAULT_OUTPUT_ENCODING)
        u.setup()
        return u

    def __copy__(self):
        """A copy of a NavigableString has the same contents and class
        as the original, but it is not connected to the parse tree.
        """
        return type(self)(self)

    def __getnewargs__(self):
        return (six.text_type(self),)

    def __getattr__(self, attr):
        """text.string gives you text. This is for backwards
        compatibility for Navigable*String, but for CData* it lets you
        get the string without the CData wrapper."""
        if attr == 'string':
            return self
        else:
            raise AttributeError(
                "'%s' object has no attribute '%s'" % (
                    self.__class__.__name__, attr))

    def output_ready(self, formatter="minimal"):
        output = self.format_string(self, formatter)
        return self.PREFIX + output + self.SUFFIX

    @property
    def name(self):
        return None

    @name.setter
    def name(self, name):
        raise AttributeError("A NavigableString cannot be given a name.")

class PreformattedString(NavigableString):
    """A NavigableString not subject to the normal formatting rules.

    The string will be passed into the formatter (to trigger side effects),
    but the return value will be ignored.
    """

    def output_ready(self, formatter="minimal"):
        """CData strings are passed into the formatter.
        But the return value is ignored."""
        self.format_string(self, formatter)
        return self.PREFIX + self + self.SUFFIX

class CData(PreformattedString):

    PREFIX = u'<![CDATA['
    SUFFIX = u']]>'

class ProcessingInstruction(PreformattedString):

    PREFIX = u'<?'
    SUFFIX = u'>'

class Comment(PreformattedString):

    PREFIX = u'<!--'
    SUFFIX = u'-->'


class Declaration(PreformattedString):
    PREFIX = u'<?'
    SUFFIX = u'?>'


class Doctype(PreformattedString):

    @classmethod
    def for_name_and_ids(cls, name, pub_id, system_id):
        value = name or ''
        if pub_id is not None:
            value += ' PUBLIC "%s"' % pub_id
            if system_id is not None:
                value += ' "%s"' % system_id
        elif system_id is not None:
            value += ' SYSTEM "%s"' % system_id

        return Doctype(value)

    PREFIX = u'<!DOCTYPE '
    SUFFIX = u'>\n'


class Tag(PageElement):

    """Represents a found HTML tag with its attributes and contents."""

    def __init__(self, parser=None, builder=None, name=None, namespace=None,
                 prefix=None, attrs=None, parent=None, previous=None):
        "Basic constructor."

        if parser is None:
            self.parser_class = None
        else:
            # We don't actually store the parser object: that lets extracted
            # chunks be garbage-collected.
            self.parser_class = parser.__class__
        if name is None:
            raise ValueError("No value provided for new tag's name.")
        self.name = name
        self.namespace = namespace
        self.prefix = prefix
        if attrs is None:
            attrs = {}
        elif attrs:
            if builder is not None and builder.cdata_list_attributes:
                attrs = builder._replace_cdata_list_attribute_values(
                    self.name, attrs)
            else:
                attrs = dict(attrs)
        else:
            attrs = dict(attrs)
        self.attrs = attrs
        self.contents = []
        self.setup(parent, previous)
        self.hidden = False

        # Set up any substitutions, such as the charset in a META tag.
        if builder is not None:
            builder.set_up_substitutions(self)
            self.can_be_empty_element = builder.can_be_empty_element(name)
        else:
            self.can_be_empty_element = False

    parserClass = _alias("parser_class")  # BS3

    def __copy__(self):
        """A copy of a Tag is a new Tag, unconnected to the parse tree.
        Its contents are a copy of the old Tag's contents.
        """
        clone = type(self)(None, self.builder, self.name, self.namespace,
                           self.nsprefix, self.attrs)
        for attr in ('can_be_empty_element', 'hidden'):
            setattr(clone, attr, getattr(self, attr))
        for child in self.contents:
            clone.append(child.__copy__())
        return clone

    @property
    def is_empty_element(self):
        """Is this tag an empty-element tag? (aka a self-closing tag)

        A tag that has contents is never an empty-element tag.

        A tag that has no contents may or may not be an empty-element
        tag. It depends on the builder used to create the tag. If the
        builder has a designated list of empty-element tags, then only
        a tag whose name shows up in that list is considered an
        empty-element tag.

        If the builder has no designated list of empty-element tags,
        then any tag with no contents is an empty-element tag.
        """
        return len(self.contents) == 0 and self.can_be_empty_element
    isSelfClosing = is_empty_element  # BS3

    @property
    def string(self):
        """Convenience property to get the single string within this tag.

        :Return: If this tag has a single string child, return value
         is that string. If this tag has no children, or more than one
         child, return value is None. If this tag has one child tag,
         return value is the 'string' attribute of the child tag,
         recursively.
        """
        if len(self.contents) != 1:
            return None
        child = self.contents[0]
        if isinstance(child, NavigableString):
            return child
        return child.string

    @string.setter
    def string(self, string):
        self.clear()
        self.append(string.__class__(string))

    def _all_strings(self, strip=False, types=(NavigableString, CData)):
        """Yield all strings of certain classes, possibly stripping them.

        By default, yields only NavigableString and CData objects. So
        no comments, processing instructions, etc.
        """
        for descendant in self.descendants:
            if (
                (types is None and not isinstance(descendant, NavigableString))
                or
                (types is not None and type(descendant) not in types)):
                continue
            if strip:
                descendant = descendant.strip()
                if len(descendant) == 0:
                    continue
            yield descendant

    strings = property(_all_strings)

    @property
    def stripped_strings(self):
        for string in self._all_strings(True):
            yield string

    def get_text(self, separator=u"", strip=False,
                 types=(NavigableString, CData)):
        """
        Get all child strings, concatenated using the given separator.
        """
        return separator.join([s for s in self._all_strings(
                    strip, types=types)])
    getText = get_text
    text = property(get_text)

    def decompose(self):
        """Recursively destroys the contents of this tree."""
        self.extract()
        i = self
        while i is not None:
            next = i.next_element
            i.__dict__.clear()
            i.contents = []
            i = next

    def clear(self, decompose=False):
        """
        Extract all children. If decompose is True, decompose instead.
        """
        if decompose:
            for element in self.contents[:]:
                if isinstance(element, Tag):
                    element.decompose()
                else:
                    element.extract()
        else:
            for element in self.contents[:]:
                element.extract()

    def index(self, element):
        """
        Find the index of a child by identity, not value. Avoids issues with
        tag.contents.index(element) getting the index of equal elements.
        """
        for i, child in enumerate(self.contents):
            if child is element:
                return i
        raise ValueError("Tag.index: element not in tag")

    def get(self, key, default=None):
        """Returns the value of the 'key' attribute for the tag, or
        the value given for 'default' if it doesn't have that
        attribute."""
        return self.attrs.get(key, default)

    def has_attr(self, key):
        return key in self.attrs

    def __hash__(self):
        return str(self).__hash__()

    def __getitem__(self, key):
        """tag[key] returns the value of the 'key' attribute for the tag,
        and throws an exception if it's not there."""
        return self.attrs[key]

    def __iter__(self):
        "Iterating over a tag iterates over its contents."
        return iter(self.contents)

    def __len__(self):
        "The length of a tag is the length of its list of contents."
        return len(self.contents)

    def __contains__(self, x):
        return x in self.contents

    def __nonzero__(self):
        "A tag is non-None even if it has no contents."
        return True

    def __bool__(self):
        "A tag is non-None even if it has no contents."
        return True

    def __setitem__(self, key, value):
        """Setting tag[key] sets the value of the 'key' attribute for the
        tag."""
        self.attrs[key] = value

    def __delitem__(self, key):
        "Deleting tag[key] deletes all 'key' attributes for the tag."
        self.attrs.pop(key, None)

    def __call__(self, *args, **kwargs):
        """Calling a tag like a function is the same as calling its
        find_all() method. Eg. tag('a') returns a list of all the A tags
        found within this tag."""
        return self.find_all(*args, **kwargs)

    def __getattr__(self, tag):
        #print "Getattr %s.%s" % (self.__class__, tag)
        if len(tag) > 3 and tag.endswith('Tag'):
            # BS3: soup.aTag -> "soup.find("a")
            tag_name = tag[:-3]
            warnings.warn(
                '.%sTag is deprecated, use .find("%s") instead.' % (
                    tag_name, tag_name))
            return self.find(tag_name)
        # We special case contents to avoid recursion.
        elif not tag.startswith("__") and not tag=="contents":
            return self.find(tag)
        raise AttributeError(
            "'%s' object has no attribute '%s'" % (self.__class__, tag))

    def __eq__(self, other):
        """Returns true iff this tag has the same name, the same attributes,
        and the same contents (recursively) as the given tag."""
        if self is other:
            return True
        if (not hasattr(other, 'name') or
            not hasattr(other, 'attrs') or
            not hasattr(other, 'contents') or
            self.name != other.name or
            self.attrs != other.attrs or
            len(self) != len(other)):
            return False
        for i, my_child in enumerate(self.contents):
            if my_child != other.contents[i]:
                return False
        return True

    def __ne__(self, other):
        """Returns true iff this tag is not identical to the other tag,
        as defined in __eq__."""
        return not self == other

    def __repr__(self, encoding="unicode-escape"):
        """Renders this tag as a string."""
        if PY3K:
            # "The return value must be a string object", i.e. Unicode
            return self.decode()
        else:
            # "The return value must be a string object", i.e. a bytestring.
            # By convention, the return value of __repr__ should also be
            # an ASCII string.
            return self.encode(encoding)

    def __unicode__(self):
        return self.decode()

    def __str__(self):
        if PY3K:
            return self.decode()
        else:
            return self.encode()

    if PY3K:
        __str__ = __repr__ = __unicode__

    def encode(self, encoding=DEFAULT_OUTPUT_ENCODING,
               indent_level=None, formatter="minimal",
               errors="xmlcharrefreplace"):
        # Turn the data structure into Unicode, then encode the
        # Unicode.
        u = self.decode(indent_level, encoding, formatter)
        return u.encode(encoding, errors)

    def _should_pretty_print(self, indent_level):
        """Should this tag be pretty-printed?"""
        return (
            indent_level is not None and
            (self.name not in HTMLAwareEntitySubstitution.preformatted_tags
             or self._is_xml))

    def decode(self, indent_level=None,
               eventual_encoding=DEFAULT_OUTPUT_ENCODING,
               formatter="minimal"):
        """Returns a Unicode representation of this tag and its contents.

        :param eventual_encoding: The tag is destined to be
           encoded into this encoding. This method is _not_
           responsible for performing that encoding. This information
           is passed in so that it can be substituted in if the
           document contains a <META> tag that mentions the document's
           encoding.
        """

        # First off, turn a string formatter into a function. This
        # will stop the lookup from happening over and over again.
        if not callable(formatter):
            formatter = self._formatter_for_name(formatter)

        attrs = []
        if self.attrs:
            for key, val in sorted(self.attrs.items()):
                if val is None:
                    decoded = key
                else:
                    if isinstance(val, list) or isinstance(val, tuple):
                        val = ' '.join(val)
                    elif not isinstance(val, six.string_types):
                        val = six.text_type(val)
                    elif (
                        isinstance(val, AttributeValueWithCharsetSubstitution)
                        and eventual_encoding is not None):
                        val = val.encode(eventual_encoding)

                    text = self.format_string(val, formatter)
                    decoded = (
                        six.text_type(key) + '='
                        + EntitySubstitution.quoted_attribute_value(text))
                attrs.append(decoded)
        close = ''
        closeTag = ''

        prefix = ''
        if self.prefix:
            prefix = self.prefix + ":"

        if self.is_empty_element:
            close = '/'
        else:
            closeTag = '</%s%s>' % (prefix, self.name)

        pretty_print = self._should_pretty_print(indent_level)
        space = ''
        indent_space = ''
        if indent_level is not None:
            indent_space = (' ' * (indent_level - 1))
        if pretty_print:
            space = indent_space
            indent_contents = indent_level + 1
        else:
            indent_contents = None
        contents = self.decode_contents(
            indent_contents, eventual_encoding, formatter)

        if self.hidden:
            # This is the 'document root' object.
            s = contents
        else:
            s = []
            attribute_string = ''
            if attrs:
                attribute_string = ' ' + ' '.join(attrs)
            if indent_level is not None:
                # Even if this particular tag is not pretty-printed,
                # we should indent up to the start of the tag.
                s.append(indent_space)
            s.append('<%s%s%s%s>' % (
                    prefix, self.name, attribute_string, close))
            if pretty_print:
                s.append("\n")
            s.append(contents)
            if pretty_print and contents and contents[-1] != "\n":
                s.append("\n")
            if pretty_print and closeTag:
                s.append(space)
            s.append(closeTag)
            if indent_level is not None and closeTag and self.next_sibling:
                # Even if this particular tag is not pretty-printed,
                # we're now done with the tag, and we should add a
                # newline if appropriate.
                s.append("\n")
            s = ''.join(s)
        return s

    def prettify(self, encoding=None, formatter="minimal"):
        if encoding is None:
            return self.decode(True, formatter=formatter)
        else:
            return self.encode(encoding, True, formatter=formatter)

    def decode_contents(self, indent_level=None,
                       eventual_encoding=DEFAULT_OUTPUT_ENCODING,
                       formatter="minimal"):
        """Renders the contents of this tag as a Unicode string.

        :param indent_level: Each line of the rendering will be
           indented this many spaces.

        :param eventual_encoding: The tag is destined to be
           encoded into this encoding. This method is _not_
           responsible for performing that encoding. This information
           is passed in so that it can be substituted in if the
           document contains a <META> tag that mentions the document's
           encoding.

        :param formatter: The output formatter responsible for converting
           entities to Unicode characters.
        """
        # First off, turn a string formatter into a function. This
        # will stop the lookup from happening over and over again.
        if not callable(formatter):
            formatter = self._formatter_for_name(formatter)

        pretty_print = (indent_level is not None)
        s = []
        for c in self:
            text = None
            if isinstance(c, NavigableString):
                text = c.output_ready(formatter)
            elif isinstance(c, Tag):
                s.append(c.decode(indent_level, eventual_encoding,
                                  formatter))
            if text and indent_level and not self.name == 'pre':
                text = text.strip()
            if text:
                if pretty_print and not self.name == 'pre':
                    s.append(" " * (indent_level - 1))
                s.append(text)
                if pretty_print and not self.name == 'pre':
                    s.append("\n")
        return ''.join(s)

    def encode_contents(
        self, indent_level=None, encoding=DEFAULT_OUTPUT_ENCODING,
        formatter="minimal"):
        """Renders the contents of this tag as a bytestring.

        :param indent_level: Each line of the rendering will be
           indented this many spaces.

        :param eventual_encoding: The bytestring will be in this encoding.

        :param formatter: The output formatter responsible for converting
           entities to Unicode characters.
        """

        contents = self.decode_contents(indent_level, encoding, formatter)
        return contents.encode(encoding)

    # Old method for BS3 compatibility
    def renderContents(self, encoding=DEFAULT_OUTPUT_ENCODING,
                       prettyPrint=False, indentLevel=0):
        if not prettyPrint:
            indentLevel = None
        return self.encode_contents(
            indent_level=indentLevel, encoding=encoding)

    #Soup methods

    def find(self, name=None, attrs={}, recursive=True, text=None,
             **kwargs):
        """Return only the first child of this Tag matching the given
        criteria."""
        r = None
        l = self.find_all(name, attrs, recursive, text, 1, **kwargs)
        if l:
            r = l[0]
        return r
    findChild = find

    def find_all(self, name=None, attrs={}, recursive=True, text=None,
                 limit=None, **kwargs):
        """Extracts a list of Tag objects that match the given
        criteria.  You can specify the name of the Tag and any
        attributes you want the Tag to have.

        The value of a key-value pair in the 'attrs' map can be a
        string, a list of strings, a regular expression object, or a
        callable that takes a string and returns whether or not the
        string matches for some custom definition of 'matches'. The
        same is true of the tag name."""

        generator = self.descendants
        if not recursive:
            generator = self.children
        return self._find_all(name, attrs, text, limit, generator, **kwargs)
    findAll = find_all       # BS3
    findChildren = find_all  # BS2

    #Generator methods
    @property
    def children(self):
        # return iter() to make the purpose of the method clear
        return iter(self.contents)  # XXX This seems to be untested.

    @property
    def descendants(self):
        if not len(self.contents):
            return
        stopNode = self._last_descendant().next_element
        current = self.contents[0]
        while current is not stopNode:
            yield current
            current = current.next_element

    # CSS selector code

    _selector_combinators = ['>', '+', '~']
    _select_debug = False
    def select_one(self, selector):
        """Perform a CSS selection operation on the current element."""
        value = self.select(selector, limit=1)
        if value:
            return value[0]
        return None

    def select(self, selector, _candidate_generator=None, limit=None):
        """Perform a CSS selection operation on the current element."""

        # Handle grouping selectors if ',' exists, ie: p,a
        if ',' in selector:
            context = []
            for partial_selector in selector.split(','):
                partial_selector = partial_selector.strip()
                if partial_selector == '':
                    raise ValueError('Invalid group selection syntax: %s' % selector)
                candidates = self.select(partial_selector, limit=limit)
                for candidate in candidates:
                    if candidate not in context:
                        context.append(candidate)

                if limit and len(context) >= limit:
                    break
            return context

        tokens = selector.split()
        current_context = [self]

        if tokens[-1] in self._selector_combinators:
            raise ValueError(
                'Final combinator "%s" is missing an argument.' % tokens[-1])

        if self._select_debug:
            print('Running CSS selector "%s"' % selector)

        for index, token in enumerate(tokens):
            new_context = []
            new_context_ids = set([])

            if tokens[index-1] in self._selector_combinators:
                # This token was consumed by the previous combinator. Skip it.
                if self._select_debug:
                    print('  Token was consumed by the previous combinator.')
                continue

            if self._select_debug:
                print(' Considering token "%s"' % token)
            recursive_candidate_generator = None
            tag_name = None

            # Each operation corresponds to a checker function, a rule
            # for determining whether a candidate matches the
            # selector. Candidates are generated by the active
            # iterator.
            checker = None

            m = self.attribselect_re.match(token)
            if m is not None:
                # Attribute selector
                tag_name, attribute, operator, value = m.groups()
                checker = self._attribute_checker(operator, attribute, value)

            elif '#' in token:
                # ID selector
                tag_name, tag_id = token.split('#', 1)
                def id_matches(tag):
                    return tag.get('id', None) == tag_id
                checker = id_matches

            elif '.' in token:
                # Class selector
                tag_name, klass = token.split('.', 1)
                classes = set(klass.split('.'))
                def classes_match(candidate):
                    return classes.issubset(candidate.get('class', []))
                checker = classes_match

            elif ':' in token:
                # Pseudo-class
                tag_name, pseudo = token.split(':', 1)
                if tag_name == '':
                    raise ValueError(
                        "A pseudo-class must be prefixed with a tag name.")
                pseudo_attributes = re.match(r'([a-zA-Z\d-]+)\(([a-zA-Z\d]+)\)', pseudo)
                found = []
                if pseudo_attributes is None:
                    pseudo_type = pseudo
                    pseudo_value = None
                else:
                    pseudo_type, pseudo_value = pseudo_attributes.groups()
                if pseudo_type == 'nth-of-type':
                    try:
                        pseudo_value = int(pseudo_value)
                    except:
                        raise NotImplementedError(
                            'Only numeric values are currently supported for the nth-of-type pseudo-class.')
                    if pseudo_value < 1:
                        raise ValueError(
                            'nth-of-type pseudo-class value must be at least 1.')
                    class Counter(object):
                        def __init__(self, destination):
                            self.count = 0
                            self.destination = destination

                        def nth_child_of_type(self, tag):
                            self.count += 1
                            if self.count == self.destination:
                                return True
                            if self.count > self.destination:
                                # Stop the generator that's sending us
                                # these things.
                                raise StopIteration()
                            return False
                    checker = Counter(pseudo_value).nth_child_of_type
                else:
                    raise NotImplementedError(
                        'Only the following pseudo-classes are implemented: nth-of-type.')

            elif token == '*':
                # Star selector -- matches everything
                pass
            elif token == '>':
                # Run the next token as a CSS selector against the
                # direct children of each tag in the current context.
                recursive_candidate_generator = lambda tag: tag.children
            elif token == '~':
                # Run the next token as a CSS selector against the
                # siblings of each tag in the current context.
                recursive_candidate_generator = lambda tag: tag.next_siblings
            elif token == '+':
                # For each tag in the current context, run the next
                # token as a CSS selector against the tag's next
                # sibling that's a tag.
                def next_tag_sibling(tag):
                    yield tag.find_next_sibling(True)
                recursive_candidate_generator = next_tag_sibling

            elif self.tag_name_re.match(token):
                # Just a tag name.
                tag_name = token
            else:
                raise ValueError(
                    'Unsupported or invalid CSS selector: "%s"' % token)
            if recursive_candidate_generator:
                # This happens when the selector looks like  "> foo".
                #
                # The generator calls select() recursively on every
                # member of the current context, passing in a different
                # candidate generator and a different selector.
                #
                # In the case of "> foo", the candidate generator is
                # one that yields a tag's direct children (">"), and
                # the selector is "foo".
                next_token = tokens[index+1]
                def recursive_select(tag):
                    if self._select_debug:
                        print('    Calling select("%s") recursively on %s %s' % (next_token, tag.name, tag.attrs))
                        print('-' * 40)
                    for i in tag.select(next_token, recursive_candidate_generator):
                        if self._select_debug:
                            print('(Recursive select picked up candidate %s %s)' % (i.name, i.attrs))
                        yield i
                    if self._select_debug:
                        print('-' * 40)
                _use_candidate_generator = recursive_select
            elif _candidate_generator is None:
                # By default, a tag's candidates are all of its
                # children. If tag_name is defined, only yield tags
                # with that name.
                if self._select_debug:
                    if tag_name:
                        check = "[any]"
                    else:
                        check = tag_name
                    print('   Default candidate generator, tag name="%s"' % check)
                if self._select_debug:
                    # This is redundant with later code, but it stops
                    # a bunch of bogus tags from cluttering up the
                    # debug log.
                    def default_candidate_generator(tag):
                        for child in tag.descendants:
                            if not isinstance(child, Tag):
                                continue
                            if tag_name and not child.name == tag_name:
                                continue
                            yield child
                    _use_candidate_generator = default_candidate_generator
                else:
                    _use_candidate_generator = lambda tag: tag.descendants
            else:
                _use_candidate_generator = _candidate_generator

            count = 0
            for tag in current_context:
                if self._select_debug:
                    print("    Running candidate generator on %s %s" % (
                        tag.name, repr(tag.attrs)))
                for candidate in _use_candidate_generator(tag):
                    if not isinstance(candidate, Tag):
                        continue
                    if tag_name and candidate.name != tag_name:
                        continue
                    if checker is not None:
                        try:
                            result = checker(candidate)
                        except StopIteration:
                            # The checker has decided we should no longer
                            # run the generator.
                            break
                    if checker is None or result:
                        if self._select_debug:
                            print("     SUCCESS %s %s" % (candidate.name, repr(candidate.attrs)))
                        if id(candidate) not in new_context_ids:
                            # If a tag matches a selector more than once,
                            # don't include it in the context more than once.
                            new_context.append(candidate)
                            new_context_ids.add(id(candidate))
                            if limit and len(new_context) >= limit:
                                break
                    elif self._select_debug:
                        print("     FAILURE %s %s" % (candidate.name, repr(candidate.attrs)))


            current_context = new_context

        if self._select_debug:
            print("Final verdict:")
            for i in current_context:
                print(" %s %s" % (i.name, i.attrs))
        return current_context

    # Old names for backwards compatibility
    def childGenerator(self):
        return self.children

    def recursiveChildGenerator(self):
        return self.descendants

    def has_key(self, key):
        """This was kind of misleading because has_key() (attributes)
        was different from __in__ (contents). has_key() is gone in
        Python 3, anyway."""
        warnings.warn('has_key is deprecated. Use has_attr("%s") instead.' % (
                key))
        return self.has_attr(key)

# Next, a couple classes to represent queries and their results.
class SoupStrainer(object):
    """Encapsulates a number of ways of matching a markup element (tag or
    text)."""

    def __init__(self, name=None, attrs={}, text=None, **kwargs):
        self.name = self._normalize_search_value(name)
        if not isinstance(attrs, dict):
            # Treat a non-dict value for attrs as a search for the 'class'
            # attribute.
            kwargs['class'] = attrs
            attrs = None

        if 'class_' in kwargs:
            # Treat class_="foo" as a search for the 'class'
            # attribute, overriding any non-dict value for attrs.
            kwargs['class'] = kwargs['class_']
            del kwargs['class_']

        if kwargs:
            if attrs:
                attrs = attrs.copy()
                attrs.update(kwargs)
            else:
                attrs = kwargs
        normalized_attrs = {}
        for key, value in list(attrs.items()):
            normalized_attrs[key] = self._normalize_search_value(value)

        self.attrs = normalized_attrs
        self.text = self._normalize_search_value(text)

    def _normalize_search_value(self, value):
        # Leave it alone if it's a Unicode string, a callable, a
        # regular expression, a boolean, or None.
        if (isinstance(value, six.text_type) or callable(value) or hasattr(value, 'match')
            or isinstance(value, bool) or value is None):
            return value

        # If it's a bytestring, convert it to Unicode, treating it as UTF-8.
        if isinstance(value, bytes):
            return value.decode("utf8")

        # If it's listlike, convert it into a list of strings.
        if hasattr(value, '__iter__'):
            new_value = []
            for v in value:
                if (hasattr(v, '__iter__') and not isinstance(v, bytes)
                    and not isinstance(v, six.text_type)):
                    # This is almost certainly the user's mistake. In the
                    # interests of avoiding infinite loops, we'll let
                    # it through as-is rather than doing a recursive call.
                    new_value.append(v)
                else:
                    new_value.append(self._normalize_search_value(v))
            return new_value

        # Otherwise, convert it into a Unicode string.
        # The unicode(str()) thing is so this will do the same thing on Python 2
        # and Python 3.
        return six.text_type(str(value))

    def __str__(self):
        if self.text:
            return self.text
        else:
            return "%s|%s" % (self.name, self.attrs)

    def search_tag(self, markup_name=None, markup_attrs={}):
        found = None
        markup = None
        if isinstance(markup_name, Tag):
            markup = markup_name
            markup_attrs = markup
        call_function_with_tag_data = (
            isinstance(self.name, Callable)
            and not isinstance(markup_name, Tag))

        if ((not self.name)
            or call_function_with_tag_data
            or (markup and self._matches(markup, self.name))
            or (not markup and self._matches(markup_name, self.name))):
            if call_function_with_tag_data:
                match = self.name(markup_name, markup_attrs)
            else:
                match = True
                markup_attr_map = None
                for attr, match_against in list(self.attrs.items()):
                    if not markup_attr_map:
                        if hasattr(markup_attrs, 'get'):
                            markup_attr_map = markup_attrs
                        else:
                            markup_attr_map = {}
                            for k, v in markup_attrs:
                                markup_attr_map[k] = v
                    attr_value = markup_attr_map.get(attr)
                    if not self._matches(attr_value, match_against):
                        match = False
                        break
            if match:
                if markup:
                    found = markup
                else:
                    found = markup_name
        if found and self.text and not self._matches(found.string, self.text):
            found = None
        return found
    searchTag = search_tag

    def search(self, markup):
        # print 'looking for %s in %s' % (self, markup)
        found = None
        # If given a list of items, scan it for a text element that
        # matches.
        if hasattr(markup, '__iter__') and not isinstance(markup, (Tag, six.string_types)):
            for element in markup:
                if isinstance(element, NavigableString) \
                       and self.search(element):
                    found = element
                    break
        # If it's a Tag, make sure its name or attributes match.
        # Don't bother with Tags if we're searching for text.
        elif isinstance(markup, Tag):
            if not self.text or self.name or self.attrs:
                found = self.search_tag(markup)
        # If it's text, make sure the text matches.
        elif isinstance(markup, NavigableString) or \
                 isinstance(markup, six.string_types):
            if not self.name and not self.attrs and self._matches(markup, self.text):
                found = markup
        else:
            raise Exception(
                "I don't know how to match against a %s" % markup.__class__)
        return found

    def _matches(self, markup, match_against):
        # print u"Matching %s against %s" % (markup, match_against)
        result = False
        if isinstance(markup, list) or isinstance(markup, tuple):
            # This should only happen when searching a multi-valued attribute
            # like 'class'.
            if (isinstance(match_against, six.text_type)
                and ' ' in match_against):
                # A bit of a special case. If they try to match "foo
                # bar" on a multivalue attribute's value, only accept
                # the literal value "foo bar"
                #
                # XXX This is going to be pretty slow because we keep
                # splitting match_against. But it shouldn't come up
                # too often.
                return (whitespace_re.split(match_against) == markup)
            else:
                for item in markup:
                    if self._matches(item, match_against):
                        return True
                return False

        if match_against is True:
            # True matches any non-None value.
            return markup is not None

        if isinstance(match_against, Callable):
            return match_against(markup)

        # Custom callables take the tag as an argument, but all
        # other ways of matching match the tag name as a string.
        if isinstance(markup, Tag):
            markup = markup.name

        # Ensure that `markup` is either a Unicode string, or None.
        markup = self._normalize_search_value(markup)

        if markup is None:
            # None matches None, False, an empty string, an empty list, and so on.
            return not match_against

        if isinstance(match_against, six.text_type):
            # Exact string match
            return markup == match_against

        if hasattr(match_against, 'match'):
            # Regexp match
            return match_against.search(markup)

        if hasattr(match_against, '__iter__'):
            # The markup must be an exact match against something
            # in the iterable.
            return markup in match_against


class ResultSet(list):
    """A ResultSet is just a list that keeps track of the SoupStrainer
    that created it."""
    def __init__(self, source, result=()):
        super(ResultSet, self).__init__(result)
        self.source = source




############################################################
### File: entropy.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2009-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

import os
import random
import time
from ._compat import long, binary_type
try:
    import threading as _threading
except ImportError:
    import dummy_threading as _threading


class EntropyPool(object):

    # This is an entropy pool for Python implementations that do not
    # have a working SystemRandom.  I'm not sure there are any, but
    # leaving this code doesn't hurt anything as the library code
    # is used if present.

    def __init__(self, seed=None):
        self.pool_index = 0
        self.digest = None
        self.next_byte = 0
        self.lock = _threading.Lock()
        try:
            import hashlib
            self.hash = hashlib.sha1()
            self.hash_len = 20
        except ImportError:
            try:
                import sha
                self.hash = sha.new()
                self.hash_len = 20
            except ImportError:
                import md5  # pylint: disable=import-error
                self.hash = md5.new()
                self.hash_len = 16
        self.pool = bytearray(b'\0' * self.hash_len)
        if seed is not None:
            self.stir(bytearray(seed))
            self.seeded = True
            self.seed_pid = os.getpid()
        else:
            self.seeded = False
            self.seed_pid = 0

    def stir(self, entropy, already_locked=False):
        if not already_locked:
            self.lock.acquire()
        try:
            for c in entropy:
                if self.pool_index == self.hash_len:
                    self.pool_index = 0
                b = c & 0xff
                self.pool[self.pool_index] ^= b
                self.pool_index += 1
        finally:
            if not already_locked:
                self.lock.release()

    def _maybe_seed(self):
        if not self.seeded or self.seed_pid != os.getpid():
            try:
                seed = os.urandom(16)
            except Exception:
                try:
                    r = open('/dev/urandom', 'rb', 0)
                    try:
                        seed = r.read(16)
                    finally:
                        r.close()
                except Exception:
                    seed = str(time.time())
            self.seeded = True
            self.seed_pid = os.getpid()
            self.digest = None
            seed = bytearray(seed)
            self.stir(seed, True)

    def random_8(self):
        self.lock.acquire()
        try:
            self._maybe_seed()
            if self.digest is None or self.next_byte == self.hash_len:
                self.hash.update(binary_type(self.pool))
                self.digest = bytearray(self.hash.digest())
                self.stir(self.digest, True)
                self.next_byte = 0
            value = self.digest[self.next_byte]
            self.next_byte += 1
        finally:
            self.lock.release()
        return value

    def random_16(self):
        return self.random_8() * 256 + self.random_8()

    def random_32(self):
        return self.random_16() * 65536 + self.random_16()

    def random_between(self, first, last):
        size = last - first + 1
        if size > long(4294967296):
            raise ValueError('too big')
        if size > 65536:
            rand = self.random_32
            max = long(4294967295)
        elif size > 256:
            rand = self.random_16
            max = 65535
        else:
            rand = self.random_8
            max = 255
        return first + size * rand() // (max + 1)

pool = EntropyPool()

try:
    system_random = random.SystemRandom()
except Exception:
    system_random = None

def random_16():
    if system_random is not None:
        return system_random.randrange(0, 65536)
    else:
        return pool.random_16()

def between(first, last):
    if system_random is not None:
        return system_random.randrange(first, last + 1)
    else:
        return pool.random_between(first, last)




############################################################
### File: enums.py
############################################################
"""
All of the Enums that are used throughout the chardet package.

:author: Dan Blanchard (dan.blanchard@gmail.com)
"""


class InputState(object):
    """
    This enum represents the different states a universal detector can be in.
    """
    PURE_ASCII = 0
    ESC_ASCII = 1
    HIGH_BYTE = 2


class LanguageFilter(object):
    """
    This enum represents the different language filters we can apply to a
    ``UniversalDetector``.
    """
    CHINESE_SIMPLIFIED = 0x01
    CHINESE_TRADITIONAL = 0x02
    JAPANESE = 0x04
    KOREAN = 0x08
    NON_CJK = 0x10
    ALL = 0x1F
    CHINESE = CHINESE_SIMPLIFIED | CHINESE_TRADITIONAL
    CJK = CHINESE | JAPANESE | KOREAN


class ProbingState(object):
    """
    This enum represents the different states a prober can be in.
    """
    DETECTING = 0
    FOUND_IT = 1
    NOT_ME = 2


class MachineState(object):
    """
    This enum represents the different states a state machine can be in.
    """
    START = 0
    ERROR = 1
    ITS_ME = 2


class SequenceLikelihood(object):
    """
    This enum represents the likelihood of a character following the previous one.
    """
    NEGATIVE = 0
    UNLIKELY = 1
    LIKELY = 2
    POSITIVE = 3

    @classmethod
    def get_num_categories(cls):
        """:returns: The number of likelihood categories in the enum."""
        return 4


class CharacterCategory(object):
    """
    This enum represents the different categories language models for
    ``SingleByteCharsetProber`` put characters into.

    Anything less than CONTROL is considered a letter.
    """
    UNDEFINED = 255
    LINE_BREAK = 254
    SYMBOL = 253
    DIGIT = 252
    CONTROL = 251




############################################################
### File: escprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetprober import CharSetProber
from .codingstatemachine import CodingStateMachine
from .enums import LanguageFilter, ProbingState, MachineState
from .escsm import (HZ_SM_MODEL, ISO2022CN_SM_MODEL, ISO2022JP_SM_MODEL,
                    ISO2022KR_SM_MODEL)


class EscCharSetProber(CharSetProber):
    """
    This CharSetProber uses a "code scheme" approach for detecting encodings,
    whereby easily recognizable escape or shift sequences are relied on to
    identify these encodings.
    """

    def __init__(self, lang_filter=None):
        super(EscCharSetProber, self).__init__(lang_filter=lang_filter)
        self.coding_sm = []
        if self.lang_filter & LanguageFilter.CHINESE_SIMPLIFIED:
            self.coding_sm.append(CodingStateMachine(HZ_SM_MODEL))
            self.coding_sm.append(CodingStateMachine(ISO2022CN_SM_MODEL))
        if self.lang_filter & LanguageFilter.JAPANESE:
            self.coding_sm.append(CodingStateMachine(ISO2022JP_SM_MODEL))
        if self.lang_filter & LanguageFilter.KOREAN:
            self.coding_sm.append(CodingStateMachine(ISO2022KR_SM_MODEL))
        self.active_sm_count = None
        self._detected_charset = None
        self._detected_language = None
        self._state = None
        self.reset()

    def reset(self):
        super(EscCharSetProber, self).reset()
        for coding_sm in self.coding_sm:
            if not coding_sm:
                continue
            coding_sm.active = True
            coding_sm.reset()
        self.active_sm_count = len(self.coding_sm)
        self._detected_charset = None
        self._detected_language = None

    @property
    def charset_name(self):
        return self._detected_charset

    @property
    def language(self):
        return self._detected_language

    def get_confidence(self):
        if self._detected_charset:
            return 0.99
        else:
            return 0.00

    def feed(self, byte_str):
        for c in byte_str:
            for coding_sm in self.coding_sm:
                if not coding_sm or not coding_sm.active:
                    continue
                coding_state = coding_sm.next_state(c)
                if coding_state == MachineState.ERROR:
                    coding_sm.active = False
                    self.active_sm_count -= 1
                    if self.active_sm_count <= 0:
                        self._state = ProbingState.NOT_ME
                        return self.state
                elif coding_state == MachineState.ITS_ME:
                    self._state = ProbingState.FOUND_IT
                    self._detected_charset = coding_sm.get_coding_state_machine()
                    self._detected_language = coding_sm.language
                    return self.state

        return self.state




############################################################
### File: escsm.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .enums import MachineState

HZ_CLS = (
1,0,0,0,0,0,0,0,  # 00 - 07
0,0,0,0,0,0,0,0,  # 08 - 0f
0,0,0,0,0,0,0,0,  # 10 - 17
0,0,0,1,0,0,0,0,  # 18 - 1f
0,0,0,0,0,0,0,0,  # 20 - 27
0,0,0,0,0,0,0,0,  # 28 - 2f
0,0,0,0,0,0,0,0,  # 30 - 37
0,0,0,0,0,0,0,0,  # 38 - 3f
0,0,0,0,0,0,0,0,  # 40 - 47
0,0,0,0,0,0,0,0,  # 48 - 4f
0,0,0,0,0,0,0,0,  # 50 - 57
0,0,0,0,0,0,0,0,  # 58 - 5f
0,0,0,0,0,0,0,0,  # 60 - 67
0,0,0,0,0,0,0,0,  # 68 - 6f
0,0,0,0,0,0,0,0,  # 70 - 77
0,0,0,4,0,5,2,0,  # 78 - 7f
1,1,1,1,1,1,1,1,  # 80 - 87
1,1,1,1,1,1,1,1,  # 88 - 8f
1,1,1,1,1,1,1,1,  # 90 - 97
1,1,1,1,1,1,1,1,  # 98 - 9f
1,1,1,1,1,1,1,1,  # a0 - a7
1,1,1,1,1,1,1,1,  # a8 - af
1,1,1,1,1,1,1,1,  # b0 - b7
1,1,1,1,1,1,1,1,  # b8 - bf
1,1,1,1,1,1,1,1,  # c0 - c7
1,1,1,1,1,1,1,1,  # c8 - cf
1,1,1,1,1,1,1,1,  # d0 - d7
1,1,1,1,1,1,1,1,  # d8 - df
1,1,1,1,1,1,1,1,  # e0 - e7
1,1,1,1,1,1,1,1,  # e8 - ef
1,1,1,1,1,1,1,1,  # f0 - f7
1,1,1,1,1,1,1,1,  # f8 - ff
)

HZ_ST = (
MachineState.START,MachineState.ERROR,     3,MachineState.START,MachineState.START,MachineState.START,MachineState.ERROR,MachineState.ERROR,# 00-07
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,# 08-0f
MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START,     4,MachineState.ERROR,# 10-17
     5,MachineState.ERROR,     6,MachineState.ERROR,     5,     5,     4,MachineState.ERROR,# 18-1f
     4,MachineState.ERROR,     4,     4,     4,MachineState.ERROR,     4,MachineState.ERROR,# 20-27
     4,MachineState.ITS_ME,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,# 28-2f
)

HZ_CHAR_LEN_TABLE = (0, 0, 0, 0, 0, 0)

HZ_SM_MODEL = {'class_table': HZ_CLS,
               'class_factor': 6,
               'state_table': HZ_ST,
               'char_len_table': HZ_CHAR_LEN_TABLE,
               'name': "HZ-GB-2312",
               'language': 'Chinese'}

ISO2022CN_CLS = (
2,0,0,0,0,0,0,0,  # 00 - 07
0,0,0,0,0,0,0,0,  # 08 - 0f
0,0,0,0,0,0,0,0,  # 10 - 17
0,0,0,1,0,0,0,0,  # 18 - 1f
0,0,0,0,0,0,0,0,  # 20 - 27
0,3,0,0,0,0,0,0,  # 28 - 2f
0,0,0,0,0,0,0,0,  # 30 - 37
0,0,0,0,0,0,0,0,  # 38 - 3f
0,0,0,4,0,0,0,0,  # 40 - 47
0,0,0,0,0,0,0,0,  # 48 - 4f
0,0,0,0,0,0,0,0,  # 50 - 57
0,0,0,0,0,0,0,0,  # 58 - 5f
0,0,0,0,0,0,0,0,  # 60 - 67
0,0,0,0,0,0,0,0,  # 68 - 6f
0,0,0,0,0,0,0,0,  # 70 - 77
0,0,0,0,0,0,0,0,  # 78 - 7f
2,2,2,2,2,2,2,2,  # 80 - 87
2,2,2,2,2,2,2,2,  # 88 - 8f
2,2,2,2,2,2,2,2,  # 90 - 97
2,2,2,2,2,2,2,2,  # 98 - 9f
2,2,2,2,2,2,2,2,  # a0 - a7
2,2,2,2,2,2,2,2,  # a8 - af
2,2,2,2,2,2,2,2,  # b0 - b7
2,2,2,2,2,2,2,2,  # b8 - bf
2,2,2,2,2,2,2,2,  # c0 - c7
2,2,2,2,2,2,2,2,  # c8 - cf
2,2,2,2,2,2,2,2,  # d0 - d7
2,2,2,2,2,2,2,2,  # d8 - df
2,2,2,2,2,2,2,2,  # e0 - e7
2,2,2,2,2,2,2,2,  # e8 - ef
2,2,2,2,2,2,2,2,  # f0 - f7
2,2,2,2,2,2,2,2,  # f8 - ff
)

ISO2022CN_ST = (
MachineState.START,     3,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,# 00-07
MachineState.START,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,# 08-0f
MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,# 10-17
MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     4,MachineState.ERROR,# 18-1f
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,# 20-27
     5,     6,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,# 28-2f
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,# 30-37
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ERROR,MachineState.START,# 38-3f
)

ISO2022CN_CHAR_LEN_TABLE = (0, 0, 0, 0, 0, 0, 0, 0, 0)

ISO2022CN_SM_MODEL = {'class_table': ISO2022CN_CLS,
                      'class_factor': 9,
                      'state_table': ISO2022CN_ST,
                      'char_len_table': ISO2022CN_CHAR_LEN_TABLE,
                      'name': "ISO-2022-CN",
                      'language': 'Chinese'}

ISO2022JP_CLS = (
2,0,0,0,0,0,0,0,  # 00 - 07
0,0,0,0,0,0,2,2,  # 08 - 0f
0,0,0,0,0,0,0,0,  # 10 - 17
0,0,0,1,0,0,0,0,  # 18 - 1f
0,0,0,0,7,0,0,0,  # 20 - 27
3,0,0,0,0,0,0,0,  # 28 - 2f
0,0,0,0,0,0,0,0,  # 30 - 37
0,0,0,0,0,0,0,0,  # 38 - 3f
6,0,4,0,8,0,0,0,  # 40 - 47
0,9,5,0,0,0,0,0,  # 48 - 4f
0,0,0,0,0,0,0,0,  # 50 - 57
0,0,0,0,0,0,0,0,  # 58 - 5f
0,0,0,0,0,0,0,0,  # 60 - 67
0,0,0,0,0,0,0,0,  # 68 - 6f
0,0,0,0,0,0,0,0,  # 70 - 77
0,0,0,0,0,0,0,0,  # 78 - 7f
2,2,2,2,2,2,2,2,  # 80 - 87
2,2,2,2,2,2,2,2,  # 88 - 8f
2,2,2,2,2,2,2,2,  # 90 - 97
2,2,2,2,2,2,2,2,  # 98 - 9f
2,2,2,2,2,2,2,2,  # a0 - a7
2,2,2,2,2,2,2,2,  # a8 - af
2,2,2,2,2,2,2,2,  # b0 - b7
2,2,2,2,2,2,2,2,  # b8 - bf
2,2,2,2,2,2,2,2,  # c0 - c7
2,2,2,2,2,2,2,2,  # c8 - cf
2,2,2,2,2,2,2,2,  # d0 - d7
2,2,2,2,2,2,2,2,  # d8 - df
2,2,2,2,2,2,2,2,  # e0 - e7
2,2,2,2,2,2,2,2,  # e8 - ef
2,2,2,2,2,2,2,2,  # f0 - f7
2,2,2,2,2,2,2,2,  # f8 - ff
)

ISO2022JP_ST = (
MachineState.START,     3,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,# 00-07
MachineState.START,MachineState.START,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,# 08-0f
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,# 10-17
MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ERROR,MachineState.ERROR,# 18-1f
MachineState.ERROR,     5,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     4,MachineState.ERROR,MachineState.ERROR,# 20-27
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     6,MachineState.ITS_ME,MachineState.ERROR,MachineState.ITS_ME,MachineState.ERROR,# 28-2f
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,# 30-37
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,# 38-3f
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ERROR,MachineState.START,MachineState.START,# 40-47
)

ISO2022JP_CHAR_LEN_TABLE = (0, 0, 0, 0, 0, 0, 0, 0, 0, 0)

ISO2022JP_SM_MODEL = {'class_table': ISO2022JP_CLS,
                      'class_factor': 10,
                      'state_table': ISO2022JP_ST,
                      'char_len_table': ISO2022JP_CHAR_LEN_TABLE,
                      'name': "ISO-2022-JP",
                      'language': 'Japanese'}

ISO2022KR_CLS = (
2,0,0,0,0,0,0,0,  # 00 - 07
0,0,0,0,0,0,0,0,  # 08 - 0f
0,0,0,0,0,0,0,0,  # 10 - 17
0,0,0,1,0,0,0,0,  # 18 - 1f
0,0,0,0,3,0,0,0,  # 20 - 27
0,4,0,0,0,0,0,0,  # 28 - 2f
0,0,0,0,0,0,0,0,  # 30 - 37
0,0,0,0,0,0,0,0,  # 38 - 3f
0,0,0,5,0,0,0,0,  # 40 - 47
0,0,0,0,0,0,0,0,  # 48 - 4f
0,0,0,0,0,0,0,0,  # 50 - 57
0,0,0,0,0,0,0,0,  # 58 - 5f
0,0,0,0,0,0,0,0,  # 60 - 67
0,0,0,0,0,0,0,0,  # 68 - 6f
0,0,0,0,0,0,0,0,  # 70 - 77
0,0,0,0,0,0,0,0,  # 78 - 7f
2,2,2,2,2,2,2,2,  # 80 - 87
2,2,2,2,2,2,2,2,  # 88 - 8f
2,2,2,2,2,2,2,2,  # 90 - 97
2,2,2,2,2,2,2,2,  # 98 - 9f
2,2,2,2,2,2,2,2,  # a0 - a7
2,2,2,2,2,2,2,2,  # a8 - af
2,2,2,2,2,2,2,2,  # b0 - b7
2,2,2,2,2,2,2,2,  # b8 - bf
2,2,2,2,2,2,2,2,  # c0 - c7
2,2,2,2,2,2,2,2,  # c8 - cf
2,2,2,2,2,2,2,2,  # d0 - d7
2,2,2,2,2,2,2,2,  # d8 - df
2,2,2,2,2,2,2,2,  # e0 - e7
2,2,2,2,2,2,2,2,  # e8 - ef
2,2,2,2,2,2,2,2,  # f0 - f7
2,2,2,2,2,2,2,2,  # f8 - ff
)

ISO2022KR_ST = (
MachineState.START,     3,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.ERROR,MachineState.ERROR,# 00-07
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,# 08-0f
MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     4,MachineState.ERROR,MachineState.ERROR,# 10-17
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     5,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,# 18-1f
MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.START,MachineState.START,MachineState.START,MachineState.START,# 20-27
)

ISO2022KR_CHAR_LEN_TABLE = (0, 0, 0, 0, 0, 0)

ISO2022KR_SM_MODEL = {'class_table': ISO2022KR_CLS,
                      'class_factor': 6,
                      'state_table': ISO2022KR_ST,
                      'char_len_table': ISO2022KR_CHAR_LEN_TABLE,
                      'name': "ISO-2022-KR",
                      'language': 'Korean'}






############################################################
### File: eucjpprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .enums import ProbingState, MachineState
from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import EUCJPDistributionAnalysis
from .jpcntx import EUCJPContextAnalysis
from .mbcssm import EUCJP_SM_MODEL


class EUCJPProber(MultiByteCharSetProber):
    def __init__(self):
        super(EUCJPProber, self).__init__()
        self.coding_sm = CodingStateMachine(EUCJP_SM_MODEL)
        self.distribution_analyzer = EUCJPDistributionAnalysis()
        self.context_analyzer = EUCJPContextAnalysis()
        self.reset()

    def reset(self):
        super(EUCJPProber, self).reset()
        self.context_analyzer.reset()

    @property
    def charset_name(self):
        return "EUC-JP"

    @property
    def language(self):
        return "Japanese"

    def feed(self, byte_str):
        for i in range(len(byte_str)):
            # PY3K: byte_str is a byte array, so byte_str[i] is an int, not a byte
            coding_state = self.coding_sm.next_state(byte_str[i])
            if coding_state == MachineState.ERROR:
                self.logger.debug('%s %s prober hit error at byte %s',
                                  self.charset_name, self.language, i)
                self._state = ProbingState.NOT_ME
                break
            elif coding_state == MachineState.ITS_ME:
                self._state = ProbingState.FOUND_IT
                break
            elif coding_state == MachineState.START:
                char_len = self.coding_sm.get_current_charlen()
                if i == 0:
                    self._last_char[1] = byte_str[0]
                    self.context_analyzer.feed(self._last_char, char_len)
                    self.distribution_analyzer.feed(self._last_char, char_len)
                else:
                    self.context_analyzer.feed(byte_str[i - 1:i + 1],
                                                char_len)
                    self.distribution_analyzer.feed(byte_str[i - 1:i + 1],
                                                     char_len)

        self._last_char[0] = byte_str[-1]

        if self.state == ProbingState.DETECTING:
            if (self.context_analyzer.got_enough_data() and
               (self.get_confidence() > self.SHORTCUT_THRESHOLD)):
                self._state = ProbingState.FOUND_IT

        return self.state

    def get_confidence(self):
        context_conf = self.context_analyzer.get_confidence()
        distrib_conf = self.distribution_analyzer.get_confidence()
        return max(context_conf, distrib_conf)




############################################################
### File: euckrfreq.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# Sampling from about 20M text materials include literature and computer technology

# 128  --> 0.79
# 256  --> 0.92
# 512  --> 0.986
# 1024 --> 0.99944
# 2048 --> 0.99999
#
# Idea Distribution Ratio = 0.98653 / (1-0.98653) = 73.24
# Random Distribution Ration = 512 / (2350-512) = 0.279.
#
# Typical Distribution Ratio

EUCKR_TYPICAL_DISTRIBUTION_RATIO = 6.0

EUCKR_TABLE_SIZE = 2352

# Char to FreqOrder table ,
EUCKR_CHAR_TO_FREQ_ORDER = (
  13, 130, 120,1396, 481,1719,1720, 328, 609, 212,1721, 707, 400, 299,1722,  87,
1397,1723, 104, 536,1117,1203,1724,1267, 685,1268, 508,1725,1726,1727,1728,1398,
1399,1729,1730,1731, 141, 621, 326,1057, 368,1732, 267, 488,  20,1733,1269,1734,
 945,1400,1735,  47, 904,1270,1736,1737, 773, 248,1738, 409, 313, 786, 429,1739,
 116, 987, 813,1401, 683,  75,1204, 145,1740,1741,1742,1743,  16, 847, 667, 622,
 708,1744,1745,1746, 966, 787, 304, 129,1747,  60, 820, 123, 676,1748,1749,1750,
1751, 617,1752, 626,1753,1754,1755,1756, 653,1757,1758,1759,1760,1761,1762, 856,
 344,1763,1764,1765,1766,  89, 401, 418, 806, 905, 848,1767,1768,1769, 946,1205,
 709,1770,1118,1771, 241,1772,1773,1774,1271,1775, 569,1776, 999,1777,1778,1779,
1780, 337, 751,1058,  28, 628, 254,1781, 177, 906, 270, 349, 891,1079,1782,  19,
1783, 379,1784, 315,1785, 629, 754,1402, 559,1786, 636, 203,1206,1787, 710, 567,
1788, 935, 814,1789,1790,1207, 766, 528,1791,1792,1208,1793,1794,1795,1796,1797,
1403,1798,1799, 533,1059,1404,1405,1156,1406, 936, 884,1080,1800, 351,1801,1802,
1803,1804,1805, 801,1806,1807,1808,1119,1809,1157, 714, 474,1407,1810, 298, 899,
 885,1811,1120, 802,1158,1812, 892,1813,1814,1408, 659,1815,1816,1121,1817,1818,
1819,1820,1821,1822, 319,1823, 594, 545,1824, 815, 937,1209,1825,1826, 573,1409,
1022,1827,1210,1828,1829,1830,1831,1832,1833, 556, 722, 807,1122,1060,1834, 697,
1835, 900, 557, 715,1836,1410, 540,1411, 752,1159, 294, 597,1211, 976, 803, 770,
1412,1837,1838,  39, 794,1413, 358,1839, 371, 925,1840, 453, 661, 788, 531, 723,
 544,1023,1081, 869,  91,1841, 392, 430, 790, 602,1414, 677,1082, 457,1415,1416,
1842,1843, 475, 327,1024,1417, 795, 121,1844, 733, 403,1418,1845,1846,1847, 300,
 119, 711,1212, 627,1848,1272, 207,1849,1850, 796,1213, 382,1851, 519,1852,1083,
 893,1853,1854,1855, 367, 809, 487, 671,1856, 663,1857,1858, 956, 471, 306, 857,
1859,1860,1160,1084,1861,1862,1863,1864,1865,1061,1866,1867,1868,1869,1870,1871,
 282,  96, 574,1872, 502,1085,1873,1214,1874, 907,1875,1876, 827, 977,1419,1420,
1421, 268,1877,1422,1878,1879,1880, 308,1881,   2, 537,1882,1883,1215,1884,1885,
 127, 791,1886,1273,1423,1887,  34, 336, 404, 643,1888, 571, 654, 894, 840,1889,
   0, 886,1274, 122, 575, 260, 908, 938,1890,1275, 410, 316,1891,1892, 100,1893,
1894,1123,  48,1161,1124,1025,1895, 633, 901,1276,1896,1897, 115, 816,1898, 317,
1899, 694,1900, 909, 734,1424, 572, 866,1425, 691,  85, 524,1010, 543, 394, 841,
1901,1902,1903,1026,1904,1905,1906,1907,1908,1909,  30, 451, 651, 988, 310,1910,
1911,1426, 810,1216,  93,1912,1913,1277,1217,1914, 858, 759,  45,  58, 181, 610,
 269,1915,1916, 131,1062, 551, 443,1000, 821,1427, 957, 895,1086,1917,1918, 375,
1919, 359,1920, 687,1921, 822,1922, 293,1923,1924,  40, 662, 118, 692,  29, 939,
 887, 640, 482, 174,1925,  69,1162, 728,1428, 910,1926,1278,1218,1279, 386, 870,
 217, 854,1163, 823,1927,1928,1929,1930, 834,1931,  78,1932, 859,1933,1063,1934,
1935,1936,1937, 438,1164, 208, 595,1938,1939,1940,1941,1219,1125,1942, 280, 888,
1429,1430,1220,1431,1943,1944,1945,1946,1947,1280, 150, 510,1432,1948,1949,1950,
1951,1952,1953,1954,1011,1087,1955,1433,1043,1956, 881,1957, 614, 958,1064,1065,
1221,1958, 638,1001, 860, 967, 896,1434, 989, 492, 553,1281,1165,1959,1282,1002,
1283,1222,1960,1961,1962,1963,  36, 383, 228, 753, 247, 454,1964, 876, 678,1965,
1966,1284, 126, 464, 490, 835, 136, 672, 529, 940,1088,1435, 473,1967,1968, 467,
  50, 390, 227, 587, 279, 378, 598, 792, 968, 240, 151, 160, 849, 882,1126,1285,
 639,1044, 133, 140, 288, 360, 811, 563,1027, 561, 142, 523,1969,1970,1971,   7,
 103, 296, 439, 407, 506, 634, 990,1972,1973,1974,1975, 645,1976,1977,1978,1979,
1980,1981, 236,1982,1436,1983,1984,1089, 192, 828, 618, 518,1166, 333,1127,1985,
 818,1223,1986,1987,1988,1989,1990,1991,1992,1993, 342,1128,1286, 746, 842,1994,
1995, 560, 223,1287,  98,   8, 189, 650, 978,1288,1996,1437,1997,  17, 345, 250,
 423, 277, 234, 512, 226,  97, 289,  42, 167,1998, 201,1999,2000, 843, 836, 824,
 532, 338, 783,1090, 182, 576, 436,1438,1439, 527, 500,2001, 947, 889,2002,2003,
2004,2005, 262, 600, 314, 447,2006, 547,2007, 693, 738,1129,2008,  71,1440, 745,
 619, 688,2009, 829,2010,2011, 147,2012,  33, 948,2013,2014,  74, 224,2015,  61,
 191, 918, 399, 637,2016,1028,1130, 257, 902,2017,2018,2019,2020,2021,2022,2023,
2024,2025,2026, 837,2027,2028,2029,2030, 179, 874, 591,  52, 724, 246,2031,2032,
2033,2034,1167, 969,2035,1289, 630, 605, 911,1091,1168,2036,2037,2038,1441, 912,
2039, 623,2040,2041, 253,1169,1290,2042,1442, 146, 620, 611, 577, 433,2043,1224,
 719,1170, 959, 440, 437, 534,  84, 388, 480,1131, 159, 220, 198, 679,2044,1012,
 819,1066,1443, 113,1225, 194, 318,1003,1029,2045,2046,2047,2048,1067,2049,2050,
2051,2052,2053,  59, 913, 112,2054, 632,2055, 455, 144, 739,1291,2056, 273, 681,
 499,2057, 448,2058,2059, 760,2060,2061, 970, 384, 169, 245,1132,2062,2063, 414,
1444,2064,2065,  41, 235,2066, 157, 252, 877, 568, 919, 789, 580,2067, 725,2068,
2069,1292,2070,2071,1445,2072,1446,2073,2074,  55, 588,  66,1447, 271,1092,2075,
1226,2076, 960,1013, 372,2077,2078,2079,2080,2081,1293,2082,2083,2084,2085, 850,
2086,2087,2088,2089,2090, 186,2091,1068, 180,2092,2093,2094, 109,1227, 522, 606,
2095, 867,1448,1093, 991,1171, 926, 353,1133,2096, 581,2097,2098,2099,1294,1449,
1450,2100, 596,1172,1014,1228,2101,1451,1295,1173,1229,2102,2103,1296,1134,1452,
 949,1135,2104,2105,1094,1453,1454,1455,2106,1095,2107,2108,2109,2110,2111,2112,
2113,2114,2115,2116,2117, 804,2118,2119,1230,1231, 805,1456, 405,1136,2120,2121,
2122,2123,2124, 720, 701,1297, 992,1457, 927,1004,2125,2126,2127,2128,2129,2130,
  22, 417,2131, 303,2132, 385,2133, 971, 520, 513,2134,1174,  73,1096, 231, 274,
 962,1458, 673,2135,1459,2136, 152,1137,2137,2138,2139,2140,1005,1138,1460,1139,
2141,2142,2143,2144,  11, 374, 844,2145, 154,1232,  46,1461,2146, 838, 830, 721,
1233, 106,2147,  90, 428, 462, 578, 566,1175, 352,2148,2149, 538,1234, 124,1298,
2150,1462, 761, 565,2151, 686,2152, 649,2153,  72, 173,2154, 460, 415,2155,1463,
2156,1235, 305,2157,2158,2159,2160,2161,2162, 579,2163,2164,2165,2166,2167, 747,
2168,2169,2170,2171,1464, 669,2172,2173,2174,2175,2176,1465,2177,  23, 530, 285,
2178, 335, 729,2179, 397,2180,2181,2182,1030,2183,2184, 698,2185,2186, 325,2187,
2188, 369,2189, 799,1097,1015, 348,2190,1069, 680,2191, 851,1466,2192,2193,  10,
2194, 613, 424,2195, 979, 108, 449, 589,  27, 172,  81,1031,  80, 774, 281, 350,
1032, 525, 301, 582,1176,2196, 674,1045,2197,2198,1467, 730, 762,2199,2200,2201,
2202,1468,2203, 993,2204,2205, 266,1070, 963,1140,2206,2207,2208, 664,1098, 972,
2209,2210,2211,1177,1469,1470, 871,2212,2213,2214,2215,2216,1471,2217,2218,2219,
2220,2221,2222,2223,2224,2225,2226,2227,1472,1236,2228,2229,2230,2231,2232,2233,
2234,2235,1299,2236,2237, 200,2238, 477, 373,2239,2240, 731, 825, 777,2241,2242,
2243, 521, 486, 548,2244,2245,2246,1473,1300,  53, 549, 137, 875,  76, 158,2247,
1301,1474, 469, 396,1016, 278, 712,2248, 321, 442, 503, 767, 744, 941,1237,1178,
1475,2249,  82, 178,1141,1179, 973,2250,1302,2251, 297,2252,2253, 570,2254,2255,
2256,  18, 450, 206,2257, 290, 292,1142,2258, 511, 162,  99, 346, 164, 735,2259,
1476,1477,   4, 554, 343, 798,1099,2260,1100,2261,  43, 171,1303, 139, 215,2262,
2263, 717, 775,2264,1033, 322, 216,2265, 831,2266, 149,2267,1304,2268,2269, 702,
1238, 135, 845, 347, 309,2270, 484,2271, 878, 655, 238,1006,1478,2272,  67,2273,
 295,2274,2275, 461,2276, 478, 942, 412,2277,1034,2278,2279,2280, 265,2281, 541,
2282,2283,2284,2285,2286,  70, 852,1071,2287,2288,2289,2290,  21,  56, 509, 117,
 432,2291,2292, 331, 980, 552,1101, 148, 284, 105, 393,1180,1239, 755,2293, 187,
2294,1046,1479,2295, 340,2296,  63,1047, 230,2297,2298,1305, 763,1306, 101, 800,
 808, 494,2299,2300,2301, 903,2302,  37,1072,  14,   5,2303,  79, 675,2304, 312,
2305,2306,2307,2308,2309,1480,   6,1307,2310,2311,2312,   1, 470,  35,  24, 229,
2313, 695, 210,  86, 778,  15, 784, 592, 779,  32,  77, 855, 964,2314, 259,2315,
 501, 380,2316,2317,  83, 981, 153, 689,1308,1481,1482,1483,2318,2319, 716,1484,
2320,2321,2322,2323,2324,2325,1485,2326,2327, 128,  57,  68, 261,1048, 211, 170,
1240,  31,2328,  51, 435, 742,2329,2330,2331, 635,2332, 264, 456,2333,2334,2335,
 425,2336,1486, 143, 507, 263, 943,2337, 363, 920,1487, 256,1488,1102, 243, 601,
1489,2338,2339,2340,2341,2342,2343,2344, 861,2345,2346,2347,2348,2349,2350, 395,
2351,1490,1491,  62, 535, 166, 225,2352,2353, 668, 419,1241, 138, 604, 928,2354,
1181,2355,1492,1493,2356,2357,2358,1143,2359, 696,2360, 387, 307,1309, 682, 476,
2361,2362, 332,  12, 222, 156,2363, 232,2364, 641, 276, 656, 517,1494,1495,1035,
 416, 736,1496,2365,1017, 586,2366,2367,2368,1497,2369, 242,2370,2371,2372,1498,
2373, 965, 713,2374,2375,2376,2377, 740, 982,1499, 944,1500,1007,2378,2379,1310,
1501,2380,2381,2382, 785, 329,2383,2384,1502,2385,2386,2387, 932,2388,1503,2389,
2390,2391,2392,1242,2393,2394,2395,2396,2397, 994, 950,2398,2399,2400,2401,1504,
1311,2402,2403,2404,2405,1049, 749,2406,2407, 853, 718,1144,1312,2408,1182,1505,
2409,2410, 255, 516, 479, 564, 550, 214,1506,1507,1313, 413, 239, 444, 339,1145,
1036,1508,1509,1314,1037,1510,1315,2411,1511,2412,2413,2414, 176, 703, 497, 624,
 593, 921, 302,2415, 341, 165,1103,1512,2416,1513,2417,2418,2419, 376,2420, 700,
2421,2422,2423, 258, 768,1316,2424,1183,2425, 995, 608,2426,2427,2428,2429, 221,
2430,2431,2432,2433,2434,2435,2436,2437, 195, 323, 726, 188, 897, 983,1317, 377,
 644,1050, 879,2438, 452,2439,2440,2441,2442,2443,2444, 914,2445,2446,2447,2448,
 915, 489,2449,1514,1184,2450,2451, 515,  64, 427, 495,2452, 583,2453, 483, 485,
1038, 562, 213,1515, 748, 666,2454,2455,2456,2457, 334,2458, 780, 996,1008, 705,
1243,2459,2460,2461,2462,2463, 114,2464, 493,1146, 366, 163,1516, 961,1104,2465,
 291,2466,1318,1105,2467,1517, 365,2468, 355, 951,1244,2469,1319,2470, 631,2471,
2472, 218,1320, 364, 320, 756,1518,1519,1321,1520,1322,2473,2474,2475,2476, 997,
2477,2478,2479,2480, 665,1185,2481, 916,1521,2482,2483,2484, 584, 684,2485,2486,
 797,2487,1051,1186,2488,2489,2490,1522,2491,2492, 370,2493,1039,1187,  65,2494,
 434, 205, 463,1188,2495, 125, 812, 391, 402, 826, 699, 286, 398, 155, 781, 771,
 585,2496, 590, 505,1073,2497, 599, 244, 219, 917,1018, 952, 646,1523,2498,1323,
2499,2500,  49, 984, 354, 741,2501, 625,2502,1324,2503,1019, 190, 357, 757, 491,
  95, 782, 868,2504,2505,2506,2507,2508,2509, 134,1524,1074, 422,1525, 898,2510,
 161,2511,2512,2513,2514, 769,2515,1526,2516,2517, 411,1325,2518, 472,1527,2519,
2520,2521,2522,2523,2524, 985,2525,2526,2527,2528,2529,2530, 764,2531,1245,2532,
2533,  25, 204, 311,2534, 496,2535,1052,2536,2537,2538,2539,2540,2541,2542, 199,
 704, 504, 468, 758, 657,1528, 196,  44, 839,1246, 272, 750,2543, 765, 862,2544,
2545,1326,2546, 132, 615, 933,2547, 732,2548,2549,2550,1189,1529,2551, 283,1247,
1053, 607, 929,2552,2553,2554, 930, 183, 872, 616,1040,1147,2555,1148,1020, 441,
 249,1075,2556,2557,2558, 466, 743,2559,2560,2561,  92, 514, 426, 420, 526,2562,
2563,2564,2565,2566,2567,2568, 185,2569,2570,2571,2572, 776,1530, 658,2573, 362,
2574, 361, 922,1076, 793,2575,2576,2577,2578,2579,2580,1531, 251,2581,2582,2583,
2584,1532,  54, 612, 237,1327,2585,2586, 275, 408, 647, 111,2587,1533,1106, 465,
   3, 458,   9,  38,2588, 107, 110, 890, 209,  26, 737, 498,2589,1534,2590, 431,
 202,  88,1535, 356, 287,1107, 660,1149,2591, 381,1536, 986,1150, 445,1248,1151,
 974,2592,2593, 846,2594, 446, 953, 184,1249,1250, 727,2595, 923, 193, 883,2596,
2597,2598, 102, 324, 539, 817,2599, 421,1041,2600, 832,2601,  94, 175, 197, 406,
2602, 459,2603,2604,2605,2606,2607, 330, 555,2608,2609,2610, 706,1108, 389,2611,
2612,2613,2614, 233,2615, 833, 558, 931, 954,1251,2616,2617,1537, 546,2618,2619,
1009,2620,2621,2622,1538, 690,1328,2623, 955,2624,1539,2625,2626, 772,2627,2628,
2629,2630,2631, 924, 648, 863, 603,2632,2633, 934,1540, 864, 865,2634, 642,1042,
 670,1190,2635,2636,2637,2638, 168,2639, 652, 873, 542,1054,1541,2640,2641,2642,  # 512, 256
)





############################################################
### File: euckrprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import EUCKRDistributionAnalysis
from .mbcssm import EUCKR_SM_MODEL


class EUCKRProber(MultiByteCharSetProber):
    def __init__(self):
        super(EUCKRProber, self).__init__()
        self.coding_sm = CodingStateMachine(EUCKR_SM_MODEL)
        self.distribution_analyzer = EUCKRDistributionAnalysis()
        self.reset()

    @property
    def charset_name(self):
        return "EUC-KR"

    @property
    def language(self):
        return "Korean"




############################################################
### File: euctwfreq.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# EUCTW frequency table
# Converted from big5 work
# by Taiwan's Mandarin Promotion Council
# <http:#www.edu.tw:81/mandr/>

# 128  --> 0.42261
# 256  --> 0.57851
# 512  --> 0.74851
# 1024 --> 0.89384
# 2048 --> 0.97583
#
# Idea Distribution Ratio = 0.74851/(1-0.74851) =2.98
# Random Distribution Ration = 512/(5401-512)=0.105
#
# Typical Distribution Ratio about 25% of Ideal one, still much higher than RDR

EUCTW_TYPICAL_DISTRIBUTION_RATIO = 0.75

# Char to FreqOrder table ,
EUCTW_TABLE_SIZE = 5376

EUCTW_CHAR_TO_FREQ_ORDER = (
   1,1800,1506, 255,1431, 198,   9,  82,   6,7310, 177, 202,3615,1256,2808, 110,  # 2742
3735,  33,3241, 261,  76,  44,2113,  16,2931,2184,1176, 659,3868,  26,3404,2643,  # 2758
1198,3869,3313,4060, 410,2211, 302, 590, 361,1963,   8, 204,  58,4296,7311,1931,  # 2774
  63,7312,7313, 317,1614,  75, 222, 159,4061,2412,1480,7314,3500,3068, 224,2809,  # 2790
3616,   3,  10,3870,1471,  29,2774,1135,2852,1939, 873, 130,3242,1123, 312,7315,  # 2806
4297,2051, 507, 252, 682,7316, 142,1914, 124, 206,2932,  34,3501,3173,  64, 604,  # 2822
7317,2494,1976,1977, 155,1990, 645, 641,1606,7318,3405, 337,  72, 406,7319,  80,  # 2838
 630, 238,3174,1509, 263, 939,1092,2644, 756,1440,1094,3406, 449,  69,2969, 591,  # 2854
 179,2095, 471, 115,2034,1843,  60,  50,2970, 134, 806,1868, 734,2035,3407, 180,  # 2870
 995,1607, 156, 537,2893, 688,7320, 319,1305, 779,2144, 514,2374, 298,4298, 359,  # 2886
2495,  90,2707,1338, 663,  11, 906,1099,2545,  20,2436, 182, 532,1716,7321, 732,  # 2902
1376,4062,1311,1420,3175,  25,2312,1056, 113, 399, 382,1949, 242,3408,2467, 529,  # 2918
3243, 475,1447,3617,7322, 117,  21, 656, 810,1297,2295,2329,3502,7323, 126,4063,  # 2934
 706, 456, 150, 613,4299,  71,1118,2036,4064, 145,3069,  85, 835, 486,2114,1246,  # 2950
1426, 428, 727,1285,1015, 800, 106, 623, 303,1281,7324,2127,2354, 347,3736, 221,  # 2966
3503,3110,7325,1955,1153,4065,  83, 296,1199,3070, 192, 624,  93,7326, 822,1897,  # 2982
2810,3111, 795,2064, 991,1554,1542,1592,  27,  43,2853, 859, 139,1456, 860,4300,  # 2998
 437, 712,3871, 164,2392,3112, 695, 211,3017,2096, 195,3872,1608,3504,3505,3618,  # 3014
3873, 234, 811,2971,2097,3874,2229,1441,3506,1615,2375, 668,2076,1638, 305, 228,  # 3030
1664,4301, 467, 415,7327, 262,2098,1593, 239, 108, 300, 200,1033, 512,1247,2077,  # 3046
7328,7329,2173,3176,3619,2673, 593, 845,1062,3244,  88,1723,2037,3875,1950, 212,  # 3062
 266, 152, 149, 468,1898,4066,4302,  77, 187,7330,3018,  37,   5,2972,7331,3876,  # 3078
7332,7333,  39,2517,4303,2894,3177,2078,  55, 148,  74,4304, 545, 483,1474,1029,  # 3094
1665, 217,1869,1531,3113,1104,2645,4067,  24, 172,3507, 900,3877,3508,3509,4305,  # 3110
  32,1408,2811,1312, 329, 487,2355,2247,2708, 784,2674,   4,3019,3314,1427,1788,  # 3126
 188, 109, 499,7334,3620,1717,1789, 888,1217,3020,4306,7335,3510,7336,3315,1520,  # 3142
3621,3878, 196,1034, 775,7337,7338, 929,1815, 249, 439,  38,7339,1063,7340, 794,  # 3158
3879,1435,2296,  46, 178,3245,2065,7341,2376,7342, 214,1709,4307, 804,  35, 707,  # 3174
 324,3622,1601,2546, 140, 459,4068,7343,7344,1365, 839, 272, 978,2257,2572,3409,  # 3190
2128,1363,3623,1423, 697, 100,3071,  48,  70,1231, 495,3114,2193,7345,1294,7346,  # 3206
2079, 462, 586,1042,3246, 853, 256, 988, 185,2377,3410,1698, 434,1084,7347,3411,  # 3222
 314,2615,2775,4308,2330,2331, 569,2280, 637,1816,2518, 757,1162,1878,1616,3412,  # 3238
 287,1577,2115, 768,4309,1671,2854,3511,2519,1321,3737, 909,2413,7348,4069, 933,  # 3254
3738,7349,2052,2356,1222,4310, 765,2414,1322, 786,4311,7350,1919,1462,1677,2895,  # 3270
1699,7351,4312,1424,2437,3115,3624,2590,3316,1774,1940,3413,3880,4070, 309,1369,  # 3286
1130,2812, 364,2230,1653,1299,3881,3512,3882,3883,2646, 525,1085,3021, 902,2000,  # 3302
1475, 964,4313, 421,1844,1415,1057,2281, 940,1364,3116, 376,4314,4315,1381,   7,  # 3318
2520, 983,2378, 336,1710,2675,1845, 321,3414, 559,1131,3022,2742,1808,1132,1313,  # 3334
 265,1481,1857,7352, 352,1203,2813,3247, 167,1089, 420,2814, 776, 792,1724,3513,  # 3350
4071,2438,3248,7353,4072,7354, 446, 229, 333,2743, 901,3739,1200,1557,4316,2647,  # 3366
1920, 395,2744,2676,3740,4073,1835, 125, 916,3178,2616,4317,7355,7356,3741,7357,  # 3382
7358,7359,4318,3117,3625,1133,2547,1757,3415,1510,2313,1409,3514,7360,2145, 438,  # 3398
2591,2896,2379,3317,1068, 958,3023, 461, 311,2855,2677,4074,1915,3179,4075,1978,  # 3414
 383, 750,2745,2617,4076, 274, 539, 385,1278,1442,7361,1154,1964, 384, 561, 210,  # 3430
  98,1295,2548,3515,7362,1711,2415,1482,3416,3884,2897,1257, 129,7363,3742, 642,  # 3446
 523,2776,2777,2648,7364, 141,2231,1333,  68, 176, 441, 876, 907,4077, 603,2592,  # 3462
 710, 171,3417, 404, 549,  18,3118,2393,1410,3626,1666,7365,3516,4319,2898,4320,  # 3478
7366,2973, 368,7367, 146, 366,  99, 871,3627,1543, 748, 807,1586,1185,  22,2258,  # 3494
 379,3743,3180,7368,3181, 505,1941,2618,1991,1382,2314,7369, 380,2357, 218, 702,  # 3510
1817,1248,3418,3024,3517,3318,3249,7370,2974,3628, 930,3250,3744,7371,  59,7372,  # 3526
 585, 601,4078, 497,3419,1112,1314,4321,1801,7373,1223,1472,2174,7374, 749,1836,  # 3542
 690,1899,3745,1772,3885,1476, 429,1043,1790,2232,2116, 917,4079, 447,1086,1629,  # 3558
7375, 556,7376,7377,2020,1654, 844,1090, 105, 550, 966,1758,2815,1008,1782, 686,  # 3574
1095,7378,2282, 793,1602,7379,3518,2593,4322,4080,2933,2297,4323,3746, 980,2496,  # 3590
 544, 353, 527,4324, 908,2678,2899,7380, 381,2619,1942,1348,7381,1341,1252, 560,  # 3606
3072,7382,3420,2856,7383,2053, 973, 886,2080, 143,4325,7384,7385, 157,3886, 496,  # 3622
4081,  57, 840, 540,2038,4326,4327,3421,2117,1445, 970,2259,1748,1965,2081,4082,  # 3638
3119,1234,1775,3251,2816,3629, 773,1206,2129,1066,2039,1326,3887,1738,1725,4083,  # 3654
 279,3120,  51,1544,2594, 423,1578,2130,2066, 173,4328,1879,7386,7387,1583, 264,  # 3670
 610,3630,4329,2439, 280, 154,7388,7389,7390,1739, 338,1282,3073, 693,2857,1411,  # 3686
1074,3747,2440,7391,4330,7392,7393,1240, 952,2394,7394,2900,1538,2679, 685,1483,  # 3702
4084,2468,1436, 953,4085,2054,4331, 671,2395,  79,4086,2441,3252, 608, 567,2680,  # 3718
3422,4087,4088,1691, 393,1261,1791,2396,7395,4332,7396,7397,7398,7399,1383,1672,  # 3734
3748,3182,1464, 522,1119, 661,1150, 216, 675,4333,3888,1432,3519, 609,4334,2681,  # 3750
2397,7400,7401,7402,4089,3025,   0,7403,2469, 315, 231,2442, 301,3319,4335,2380,  # 3766
7404, 233,4090,3631,1818,4336,4337,7405,  96,1776,1315,2082,7406, 257,7407,1809,  # 3782
3632,2709,1139,1819,4091,2021,1124,2163,2778,1777,2649,7408,3074, 363,1655,3183,  # 3798
7409,2975,7410,7411,7412,3889,1567,3890, 718, 103,3184, 849,1443, 341,3320,2934,  # 3814
1484,7413,1712, 127,  67, 339,4092,2398, 679,1412, 821,7414,7415, 834, 738, 351,  # 3830
2976,2146, 846, 235,1497,1880, 418,1992,3749,2710, 186,1100,2147,2746,3520,1545,  # 3846
1355,2935,2858,1377, 583,3891,4093,2573,2977,7416,1298,3633,1078,2549,3634,2358,  # 3862
  78,3750,3751, 267,1289,2099,2001,1594,4094, 348, 369,1274,2194,2175,1837,4338,  # 3878
1820,2817,3635,2747,2283,2002,4339,2936,2748, 144,3321, 882,4340,3892,2749,3423,  # 3894
4341,2901,7417,4095,1726, 320,7418,3893,3026, 788,2978,7419,2818,1773,1327,2859,  # 3910
3894,2819,7420,1306,4342,2003,1700,3752,3521,2359,2650, 787,2022, 506, 824,3636,  # 3926
 534, 323,4343,1044,3322,2023,1900, 946,3424,7421,1778,1500,1678,7422,1881,4344,  # 3942
 165, 243,4345,3637,2521, 123, 683,4096, 764,4346,  36,3895,1792, 589,2902, 816,  # 3958
 626,1667,3027,2233,1639,1555,1622,3753,3896,7423,3897,2860,1370,1228,1932, 891,  # 3974
2083,2903, 304,4097,7424, 292,2979,2711,3522, 691,2100,4098,1115,4347, 118, 662,  # 3990
7425, 611,1156, 854,2381,1316,2861,   2, 386, 515,2904,7426,7427,3253, 868,2234,  # 4006
1486, 855,2651, 785,2212,3028,7428,1040,3185,3523,7429,3121, 448,7430,1525,7431,  # 4022
2164,4348,7432,3754,7433,4099,2820,3524,3122, 503, 818,3898,3123,1568, 814, 676,  # 4038
1444, 306,1749,7434,3755,1416,1030, 197,1428, 805,2821,1501,4349,7435,7436,7437,  # 4054
1993,7438,4350,7439,7440,2195,  13,2779,3638,2980,3124,1229,1916,7441,3756,2131,  # 4070
7442,4100,4351,2399,3525,7443,2213,1511,1727,1120,7444,7445, 646,3757,2443, 307,  # 4086
7446,7447,1595,3186,7448,7449,7450,3639,1113,1356,3899,1465,2522,2523,7451, 519,  # 4102
7452, 128,2132,  92,2284,1979,7453,3900,1512, 342,3125,2196,7454,2780,2214,1980,  # 4118
3323,7455, 290,1656,1317, 789, 827,2360,7456,3758,4352, 562, 581,3901,7457, 401,  # 4134
4353,2248,  94,4354,1399,2781,7458,1463,2024,4355,3187,1943,7459, 828,1105,4101,  # 4150
1262,1394,7460,4102, 605,4356,7461,1783,2862,7462,2822, 819,2101, 578,2197,2937,  # 4166
7463,1502, 436,3254,4103,3255,2823,3902,2905,3425,3426,7464,2712,2315,7465,7466,  # 4182
2332,2067,  23,4357, 193, 826,3759,2102, 699,1630,4104,3075, 390,1793,1064,3526,  # 4198
7467,1579,3076,3077,1400,7468,4105,1838,1640,2863,7469,4358,4359, 137,4106, 598,  # 4214
3078,1966, 780, 104, 974,2938,7470, 278, 899, 253, 402, 572, 504, 493,1339,7471,  # 4230
3903,1275,4360,2574,2550,7472,3640,3029,3079,2249, 565,1334,2713, 863,  41,7473,  # 4246
7474,4361,7475,1657,2333,  19, 463,2750,4107, 606,7476,2981,3256,1087,2084,1323,  # 4262
2652,2982,7477,1631,1623,1750,4108,2682,7478,2864, 791,2714,2653,2334, 232,2416,  # 4278
7479,2983,1498,7480,2654,2620, 755,1366,3641,3257,3126,2025,1609, 119,1917,3427,  # 4294
 862,1026,4109,7481,3904,3760,4362,3905,4363,2260,1951,2470,7482,1125, 817,4110,  # 4310
4111,3906,1513,1766,2040,1487,4112,3030,3258,2824,3761,3127,7483,7484,1507,7485,  # 4326
2683, 733,  40,1632,1106,2865, 345,4113, 841,2524, 230,4364,2984,1846,3259,3428,  # 4342
7486,1263, 986,3429,7487, 735, 879, 254,1137, 857, 622,1300,1180,1388,1562,3907,  # 4358
3908,2939, 967,2751,2655,1349, 592,2133,1692,3324,2985,1994,4114,1679,3909,1901,  # 4374
2185,7488, 739,3642,2715,1296,1290,7489,4115,2198,2199,1921,1563,2595,2551,1870,  # 4390
2752,2986,7490, 435,7491, 343,1108, 596,  17,1751,4365,2235,3430,3643,7492,4366,  # 4406
 294,3527,2940,1693, 477, 979, 281,2041,3528, 643,2042,3644,2621,2782,2261,1031,  # 4422
2335,2134,2298,3529,4367, 367,1249,2552,7493,3530,7494,4368,1283,3325,2004, 240,  # 4438
1762,3326,4369,4370, 836,1069,3128, 474,7495,2148,2525, 268,3531,7496,3188,1521,  # 4454
1284,7497,1658,1546,4116,7498,3532,3533,7499,4117,3327,2684,1685,4118, 961,1673,  # 4470
2622, 190,2005,2200,3762,4371,4372,7500, 570,2497,3645,1490,7501,4373,2623,3260,  # 4486
1956,4374, 584,1514, 396,1045,1944,7502,4375,1967,2444,7503,7504,4376,3910, 619,  # 4502
7505,3129,3261, 215,2006,2783,2553,3189,4377,3190,4378, 763,4119,3763,4379,7506,  # 4518
7507,1957,1767,2941,3328,3646,1174, 452,1477,4380,3329,3130,7508,2825,1253,2382,  # 4534
2186,1091,2285,4120, 492,7509, 638,1169,1824,2135,1752,3911, 648, 926,1021,1324,  # 4550
4381, 520,4382, 997, 847,1007, 892,4383,3764,2262,1871,3647,7510,2400,1784,4384,  # 4566
1952,2942,3080,3191,1728,4121,2043,3648,4385,2007,1701,3131,1551,  30,2263,4122,  # 4582
7511,2026,4386,3534,7512, 501,7513,4123, 594,3431,2165,1821,3535,3432,3536,3192,  # 4598
 829,2826,4124,7514,1680,3132,1225,4125,7515,3262,4387,4126,3133,2336,7516,4388,  # 4614
4127,7517,3912,3913,7518,1847,2383,2596,3330,7519,4389, 374,3914, 652,4128,4129,  # 4630
 375,1140, 798,7520,7521,7522,2361,4390,2264, 546,1659, 138,3031,2445,4391,7523,  # 4646
2250, 612,1848, 910, 796,3765,1740,1371, 825,3766,3767,7524,2906,2554,7525, 692,  # 4662
 444,3032,2624, 801,4392,4130,7526,1491, 244,1053,3033,4131,4132, 340,7527,3915,  # 4678
1041,2987, 293,1168,  87,1357,7528,1539, 959,7529,2236, 721, 694,4133,3768, 219,  # 4694
1478, 644,1417,3331,2656,1413,1401,1335,1389,3916,7530,7531,2988,2362,3134,1825,  # 4710
 730,1515, 184,2827,  66,4393,7532,1660,2943, 246,3332, 378,1457, 226,3433, 975,  # 4726
3917,2944,1264,3537, 674, 696,7533, 163,7534,1141,2417,2166, 713,3538,3333,4394,  # 4742
3918,7535,7536,1186,  15,7537,1079,1070,7538,1522,3193,3539, 276,1050,2716, 758,  # 4758
1126, 653,2945,3263,7539,2337, 889,3540,3919,3081,2989, 903,1250,4395,3920,3434,  # 4774
3541,1342,1681,1718, 766,3264, 286,  89,2946,3649,7540,1713,7541,2597,3334,2990,  # 4790
7542,2947,2215,3194,2866,7543,4396,2498,2526, 181, 387,1075,3921, 731,2187,3335,  # 4806
7544,3265, 310, 313,3435,2299, 770,4134,  54,3034, 189,4397,3082,3769,3922,7545,  # 4822
1230,1617,1849, 355,3542,4135,4398,3336, 111,4136,3650,1350,3135,3436,3035,4137,  # 4838
2149,3266,3543,7546,2784,3923,3924,2991, 722,2008,7547,1071, 247,1207,2338,2471,  # 4854
1378,4399,2009, 864,1437,1214,4400, 373,3770,1142,2216, 667,4401, 442,2753,2555,  # 4870
3771,3925,1968,4138,3267,1839, 837, 170,1107, 934,1336,1882,7548,7549,2118,4139,  # 4886
2828, 743,1569,7550,4402,4140, 582,2384,1418,3437,7551,1802,7552, 357,1395,1729,  # 4902
3651,3268,2418,1564,2237,7553,3083,3772,1633,4403,1114,2085,4141,1532,7554, 482,  # 4918
2446,4404,7555,7556,1492, 833,1466,7557,2717,3544,1641,2829,7558,1526,1272,3652,  # 4934
4142,1686,1794, 416,2556,1902,1953,1803,7559,3773,2785,3774,1159,2316,7560,2867,  # 4950
4405,1610,1584,3036,2419,2754, 443,3269,1163,3136,7561,7562,3926,7563,4143,2499,  # 4966
3037,4406,3927,3137,2103,1647,3545,2010,1872,4144,7564,4145, 431,3438,7565, 250,  # 4982
  97,  81,4146,7566,1648,1850,1558, 160, 848,7567, 866, 740,1694,7568,2201,2830,  # 4998
3195,4147,4407,3653,1687, 950,2472, 426, 469,3196,3654,3655,3928,7569,7570,1188,  # 5014
 424,1995, 861,3546,4148,3775,2202,2685, 168,1235,3547,4149,7571,2086,1674,4408,  # 5030
3337,3270, 220,2557,1009,7572,3776, 670,2992, 332,1208, 717,7573,7574,3548,2447,  # 5046
3929,3338,7575, 513,7576,1209,2868,3339,3138,4409,1080,7577,7578,7579,7580,2527,  # 5062
3656,3549, 815,1587,3930,3931,7581,3550,3439,3777,1254,4410,1328,3038,1390,3932,  # 5078
1741,3933,3778,3934,7582, 236,3779,2448,3271,7583,7584,3657,3780,1273,3781,4411,  # 5094
7585, 308,7586,4412, 245,4413,1851,2473,1307,2575, 430, 715,2136,2449,7587, 270,  # 5110
 199,2869,3935,7588,3551,2718,1753, 761,1754, 725,1661,1840,4414,3440,3658,7589,  # 5126
7590, 587,  14,3272, 227,2598, 326, 480,2265, 943,2755,3552, 291, 650,1883,7591,  # 5142
1702,1226, 102,1547,  62,3441, 904,4415,3442,1164,4150,7592,7593,1224,1548,2756,  # 5158
 391, 498,1493,7594,1386,1419,7595,2055,1177,4416, 813, 880,1081,2363, 566,1145,  # 5174
4417,2286,1001,1035,2558,2599,2238, 394,1286,7596,7597,2068,7598,  86,1494,1730,  # 5190
3936, 491,1588, 745, 897,2948, 843,3340,3937,2757,2870,3273,1768, 998,2217,2069,  # 5206
 397,1826,1195,1969,3659,2993,3341, 284,7599,3782,2500,2137,2119,1903,7600,3938,  # 5222
2150,3939,4151,1036,3443,1904, 114,2559,4152, 209,1527,7601,7602,2949,2831,2625,  # 5238
2385,2719,3139, 812,2560,7603,3274,7604,1559, 737,1884,3660,1210, 885,  28,2686,  # 5254
3553,3783,7605,4153,1004,1779,4418,7606, 346,1981,2218,2687,4419,3784,1742, 797,  # 5270
1642,3940,1933,1072,1384,2151, 896,3941,3275,3661,3197,2871,3554,7607,2561,1958,  # 5286
4420,2450,1785,7608,7609,7610,3942,4154,1005,1308,3662,4155,2720,4421,4422,1528,  # 5302
2600, 161,1178,4156,1982, 987,4423,1101,4157, 631,3943,1157,3198,2420,1343,1241,  # 5318
1016,2239,2562, 372, 877,2339,2501,1160, 555,1934, 911,3944,7611, 466,1170, 169,  # 5334
1051,2907,2688,3663,2474,2994,1182,2011,2563,1251,2626,7612, 992,2340,3444,1540,  # 5350
2721,1201,2070,2401,1996,2475,7613,4424, 528,1922,2188,1503,1873,1570,2364,3342,  # 5366
3276,7614, 557,1073,7615,1827,3445,2087,2266,3140,3039,3084, 767,3085,2786,4425,  # 5382
1006,4158,4426,2341,1267,2176,3664,3199, 778,3945,3200,2722,1597,2657,7616,4427,  # 5398
7617,3446,7618,7619,7620,3277,2689,1433,3278, 131,  95,1504,3946, 723,4159,3141,  # 5414
1841,3555,2758,2189,3947,2027,2104,3665,7621,2995,3948,1218,7622,3343,3201,3949,  # 5430
4160,2576, 248,1634,3785, 912,7623,2832,3666,3040,3786, 654,  53,7624,2996,7625,  # 5446
1688,4428, 777,3447,1032,3950,1425,7626, 191, 820,2120,2833, 971,4429, 931,3202,  # 5462
 135, 664, 783,3787,1997, 772,2908,1935,3951,3788,4430,2909,3203, 282,2723, 640,  # 5478
1372,3448,1127, 922, 325,3344,7627,7628, 711,2044,7629,7630,3952,2219,2787,1936,  # 5494
3953,3345,2220,2251,3789,2300,7631,4431,3790,1258,3279,3954,3204,2138,2950,3955,  # 5510
3956,7632,2221, 258,3205,4432, 101,1227,7633,3280,1755,7634,1391,3281,7635,2910,  # 5526
2056, 893,7636,7637,7638,1402,4161,2342,7639,7640,3206,3556,7641,7642, 878,1325,  # 5542
1780,2788,4433, 259,1385,2577, 744,1183,2267,4434,7643,3957,2502,7644, 684,1024,  # 5558
4162,7645, 472,3557,3449,1165,3282,3958,3959, 322,2152, 881, 455,1695,1152,1340,  # 5574
 660, 554,2153,4435,1058,4436,4163, 830,1065,3346,3960,4437,1923,7646,1703,1918,  # 5590
7647, 932,2268, 122,7648,4438, 947, 677,7649,3791,2627, 297,1905,1924,2269,4439,  # 5606
2317,3283,7650,7651,4164,7652,4165,  84,4166, 112, 989,7653, 547,1059,3961, 701,  # 5622
3558,1019,7654,4167,7655,3450, 942, 639, 457,2301,2451, 993,2951, 407, 851, 494,  # 5638
4440,3347, 927,7656,1237,7657,2421,3348, 573,4168, 680, 921,2911,1279,1874, 285,  # 5654
 790,1448,1983, 719,2167,7658,7659,4441,3962,3963,1649,7660,1541, 563,7661,1077,  # 5670
7662,3349,3041,3451, 511,2997,3964,3965,3667,3966,1268,2564,3350,3207,4442,4443,  # 5686
7663, 535,1048,1276,1189,2912,2028,3142,1438,1373,2834,2952,1134,2012,7664,4169,  # 5702
1238,2578,3086,1259,7665, 700,7666,2953,3143,3668,4170,7667,4171,1146,1875,1906,  # 5718
4444,2601,3967, 781,2422, 132,1589, 203, 147, 273,2789,2402, 898,1786,2154,3968,  # 5734
3969,7668,3792,2790,7669,7670,4445,4446,7671,3208,7672,1635,3793, 965,7673,1804,  # 5750
2690,1516,3559,1121,1082,1329,3284,3970,1449,3794,  65,1128,2835,2913,2759,1590,  # 5766
3795,7674,7675,  12,2658,  45, 976,2579,3144,4447, 517,2528,1013,1037,3209,7676,  # 5782
3796,2836,7677,3797,7678,3452,7679,2602, 614,1998,2318,3798,3087,2724,2628,7680,  # 5798
2580,4172, 599,1269,7681,1810,3669,7682,2691,3088, 759,1060, 489,1805,3351,3285,  # 5814
1358,7683,7684,2386,1387,1215,2629,2252, 490,7685,7686,4173,1759,2387,2343,7687,  # 5830
4448,3799,1907,3971,2630,1806,3210,4449,3453,3286,2760,2344, 874,7688,7689,3454,  # 5846
3670,1858,  91,2914,3671,3042,3800,4450,7690,3145,3972,2659,7691,3455,1202,1403,  # 5862
3801,2954,2529,1517,2503,4451,3456,2504,7692,4452,7693,2692,1885,1495,1731,3973,  # 5878
2365,4453,7694,2029,7695,7696,3974,2693,1216, 237,2581,4174,2319,3975,3802,4454,  # 5894
4455,2694,3560,3457, 445,4456,7697,7698,7699,7700,2761,  61,3976,3672,1822,3977,  # 5910
7701, 687,2045, 935, 925, 405,2660, 703,1096,1859,2725,4457,3978,1876,1367,2695,  # 5926
3352, 918,2105,1781,2476, 334,3287,1611,1093,4458, 564,3146,3458,3673,3353, 945,  # 5942
2631,2057,4459,7702,1925, 872,4175,7703,3459,2696,3089, 349,4176,3674,3979,4460,  # 5958
3803,4177,3675,2155,3980,4461,4462,4178,4463,2403,2046, 782,3981, 400, 251,4179,  # 5974
1624,7704,7705, 277,3676, 299,1265, 476,1191,3804,2121,4180,4181,1109, 205,7706,  # 5990
2582,1000,2156,3561,1860,7707,7708,7709,4464,7710,4465,2565, 107,2477,2157,3982,  # 6006
3460,3147,7711,1533, 541,1301, 158, 753,4182,2872,3562,7712,1696, 370,1088,4183,  # 6022
4466,3563, 579, 327, 440, 162,2240, 269,1937,1374,3461, 968,3043,  56,1396,3090,  # 6038
2106,3288,3354,7713,1926,2158,4467,2998,7714,3564,7715,7716,3677,4468,2478,7717,  # 6054
2791,7718,1650,4469,7719,2603,7720,7721,3983,2661,3355,1149,3356,3984,3805,3985,  # 6070
7722,1076,  49,7723, 951,3211,3289,3290, 450,2837, 920,7724,1811,2792,2366,4184,  # 6086
1908,1138,2367,3806,3462,7725,3212,4470,1909,1147,1518,2423,4471,3807,7726,4472,  # 6102
2388,2604, 260,1795,3213,7727,7728,3808,3291, 708,7729,3565,1704,7730,3566,1351,  # 6118
1618,3357,2999,1886, 944,4185,3358,4186,3044,3359,4187,7731,3678, 422, 413,1714,  # 6134
3292, 500,2058,2345,4188,2479,7732,1344,1910, 954,7733,1668,7734,7735,3986,2404,  # 6150
4189,3567,3809,4190,7736,2302,1318,2505,3091, 133,3092,2873,4473, 629,  31,2838,  # 6166
2697,3810,4474, 850, 949,4475,3987,2955,1732,2088,4191,1496,1852,7737,3988, 620,  # 6182
3214, 981,1242,3679,3360,1619,3680,1643,3293,2139,2452,1970,1719,3463,2168,7738,  # 6198
3215,7739,7740,3361,1828,7741,1277,4476,1565,2047,7742,1636,3568,3093,7743, 869,  # 6214
2839, 655,3811,3812,3094,3989,3000,3813,1310,3569,4477,7744,7745,7746,1733, 558,  # 6230
4478,3681, 335,1549,3045,1756,4192,3682,1945,3464,1829,1291,1192, 470,2726,2107,  # 6246
2793, 913,1054,3990,7747,1027,7748,3046,3991,4479, 982,2662,3362,3148,3465,3216,  # 6262
3217,1946,2794,7749, 571,4480,7750,1830,7751,3570,2583,1523,2424,7752,2089, 984,  # 6278
4481,3683,1959,7753,3684, 852, 923,2795,3466,3685, 969,1519, 999,2048,2320,1705,  # 6294
7754,3095, 615,1662, 151, 597,3992,2405,2321,1049, 275,4482,3686,4193, 568,3687,  # 6310
3571,2480,4194,3688,7755,2425,2270, 409,3218,7756,1566,2874,3467,1002, 769,2840,  # 6326
 194,2090,3149,3689,2222,3294,4195, 628,1505,7757,7758,1763,2177,3001,3993, 521,  # 6342
1161,2584,1787,2203,2406,4483,3994,1625,4196,4197, 412,  42,3096, 464,7759,2632,  # 6358
4484,3363,1760,1571,2875,3468,2530,1219,2204,3814,2633,2140,2368,4485,4486,3295,  # 6374
1651,3364,3572,7760,7761,3573,2481,3469,7762,3690,7763,7764,2271,2091, 460,7765,  # 6390
4487,7766,3002, 962, 588,3574, 289,3219,2634,1116,  52,7767,3047,1796,7768,7769,  # 6406
7770,1467,7771,1598,1143,3691,4198,1984,1734,1067,4488,1280,3365, 465,4489,1572,  # 6422
 510,7772,1927,2241,1812,1644,3575,7773,4490,3692,7774,7775,2663,1573,1534,7776,  # 6438
7777,4199, 536,1807,1761,3470,3815,3150,2635,7778,7779,7780,4491,3471,2915,1911,  # 6454
2796,7781,3296,1122, 377,3220,7782, 360,7783,7784,4200,1529, 551,7785,2059,3693,  # 6470
1769,2426,7786,2916,4201,3297,3097,2322,2108,2030,4492,1404, 136,1468,1479, 672,  # 6486
1171,3221,2303, 271,3151,7787,2762,7788,2049, 678,2727, 865,1947,4493,7789,2013,  # 6502
3995,2956,7790,2728,2223,1397,3048,3694,4494,4495,1735,2917,3366,3576,7791,3816,  # 6518
 509,2841,2453,2876,3817,7792,7793,3152,3153,4496,4202,2531,4497,2304,1166,1010,  # 6534
 552, 681,1887,7794,7795,2957,2958,3996,1287,1596,1861,3154, 358, 453, 736, 175,  # 6550
 478,1117, 905,1167,1097,7796,1853,1530,7797,1706,7798,2178,3472,2287,3695,3473,  # 6566
3577,4203,2092,4204,7799,3367,1193,2482,4205,1458,2190,2205,1862,1888,1421,3298,  # 6582
2918,3049,2179,3474, 595,2122,7800,3997,7801,7802,4206,1707,2636, 223,3696,1359,  # 6598
 751,3098, 183,3475,7803,2797,3003, 419,2369, 633, 704,3818,2389, 241,7804,7805,  # 6614
7806, 838,3004,3697,2272,2763,2454,3819,1938,2050,3998,1309,3099,2242,1181,7807,  # 6630
1136,2206,3820,2370,1446,4207,2305,4498,7808,7809,4208,1055,2605, 484,3698,7810,  # 6646
3999, 625,4209,2273,3368,1499,4210,4000,7811,4001,4211,3222,2274,2275,3476,7812,  # 6662
7813,2764, 808,2606,3699,3369,4002,4212,3100,2532, 526,3370,3821,4213, 955,7814,  # 6678
1620,4214,2637,2427,7815,1429,3700,1669,1831, 994, 928,7816,3578,1260,7817,7818,  # 6694
7819,1948,2288, 741,2919,1626,4215,2729,2455, 867,1184, 362,3371,1392,7820,7821,  # 6710
4003,4216,1770,1736,3223,2920,4499,4500,1928,2698,1459,1158,7822,3050,3372,2877,  # 6726
1292,1929,2506,2842,3701,1985,1187,2071,2014,2607,4217,7823,2566,2507,2169,3702,  # 6742
2483,3299,7824,3703,4501,7825,7826, 666,1003,3005,1022,3579,4218,7827,4502,1813,  # 6758
2253, 574,3822,1603, 295,1535, 705,3823,4219, 283, 858, 417,7828,7829,3224,4503,  # 6774
4504,3051,1220,1889,1046,2276,2456,4004,1393,1599, 689,2567, 388,4220,7830,2484,  # 6790
 802,7831,2798,3824,2060,1405,2254,7832,4505,3825,2109,1052,1345,3225,1585,7833,  # 6806
 809,7834,7835,7836, 575,2730,3477, 956,1552,1469,1144,2323,7837,2324,1560,2457,  # 6822
3580,3226,4005, 616,2207,3155,2180,2289,7838,1832,7839,3478,4506,7840,1319,3704,  # 6838
3705,1211,3581,1023,3227,1293,2799,7841,7842,7843,3826, 607,2306,3827, 762,2878,  # 6854
1439,4221,1360,7844,1485,3052,7845,4507,1038,4222,1450,2061,2638,4223,1379,4508,  # 6870
2585,7846,7847,4224,1352,1414,2325,2921,1172,7848,7849,3828,3829,7850,1797,1451,  # 6886
7851,7852,7853,7854,2922,4006,4007,2485,2346, 411,4008,4009,3582,3300,3101,4509,  # 6902
1561,2664,1452,4010,1375,7855,7856,  47,2959, 316,7857,1406,1591,2923,3156,7858,  # 6918
1025,2141,3102,3157, 354,2731, 884,2224,4225,2407, 508,3706, 726,3583, 996,2428,  # 6934
3584, 729,7859, 392,2191,1453,4011,4510,3707,7860,7861,2458,3585,2608,1675,2800,  # 6950
 919,2347,2960,2348,1270,4511,4012,  73,7862,7863, 647,7864,3228,2843,2255,1550,  # 6966
1346,3006,7865,1332, 883,3479,7866,7867,7868,7869,3301,2765,7870,1212, 831,1347,  # 6982
4226,4512,2326,3830,1863,3053, 720,3831,4513,4514,3832,7871,4227,7872,7873,4515,  # 6998
7874,7875,1798,4516,3708,2609,4517,3586,1645,2371,7876,7877,2924, 669,2208,2665,  # 7014
2429,7878,2879,7879,7880,1028,3229,7881,4228,2408,7882,2256,1353,7883,7884,4518,  # 7030
3158, 518,7885,4013,7886,4229,1960,7887,2142,4230,7888,7889,3007,2349,2350,3833,  # 7046
 516,1833,1454,4014,2699,4231,4519,2225,2610,1971,1129,3587,7890,2766,7891,2961,  # 7062
1422, 577,1470,3008,1524,3373,7892,7893, 432,4232,3054,3480,7894,2586,1455,2508,  # 7078
2226,1972,1175,7895,1020,2732,4015,3481,4520,7896,2733,7897,1743,1361,3055,3482,  # 7094
2639,4016,4233,4521,2290, 895, 924,4234,2170, 331,2243,3056, 166,1627,3057,1098,  # 7110
7898,1232,2880,2227,3374,4522, 657, 403,1196,2372, 542,3709,3375,1600,4235,3483,  # 7126
7899,4523,2767,3230, 576, 530,1362,7900,4524,2533,2666,3710,4017,7901, 842,3834,  # 7142
7902,2801,2031,1014,4018, 213,2700,3376, 665, 621,4236,7903,3711,2925,2430,7904,  # 7158
2431,3302,3588,3377,7905,4237,2534,4238,4525,3589,1682,4239,3484,1380,7906, 724,  # 7174
2277, 600,1670,7907,1337,1233,4526,3103,2244,7908,1621,4527,7909, 651,4240,7910,  # 7190
1612,4241,2611,7911,2844,7912,2734,2307,3058,7913, 716,2459,3059, 174,1255,2701,  # 7206
4019,3590, 548,1320,1398, 728,4020,1574,7914,1890,1197,3060,4021,7915,3061,3062,  # 7222
3712,3591,3713, 747,7916, 635,4242,4528,7917,7918,7919,4243,7920,7921,4529,7922,  # 7238
3378,4530,2432, 451,7923,3714,2535,2072,4244,2735,4245,4022,7924,1764,4531,7925,  # 7254
4246, 350,7926,2278,2390,2486,7927,4247,4023,2245,1434,4024, 488,4532, 458,4248,  # 7270
4025,3715, 771,1330,2391,3835,2568,3159,2159,2409,1553,2667,3160,4249,7928,2487,  # 7286
2881,2612,1720,2702,4250,3379,4533,7929,2536,4251,7930,3231,4252,2768,7931,2015,  # 7302
2736,7932,1155,1017,3716,3836,7933,3303,2308, 201,1864,4253,1430,7934,4026,7935,  # 7318
7936,7937,7938,7939,4254,1604,7940, 414,1865, 371,2587,4534,4535,3485,2016,3104,  # 7334
4536,1708, 960,4255, 887, 389,2171,1536,1663,1721,7941,2228,4027,2351,2926,1580,  # 7350
7942,7943,7944,1744,7945,2537,4537,4538,7946,4539,7947,2073,7948,7949,3592,3380,  # 7366
2882,4256,7950,4257,2640,3381,2802, 673,2703,2460, 709,3486,4028,3593,4258,7951,  # 7382
1148, 502, 634,7952,7953,1204,4540,3594,1575,4541,2613,3717,7954,3718,3105, 948,  # 7398
3232, 121,1745,3837,1110,7955,4259,3063,2509,3009,4029,3719,1151,1771,3838,1488,  # 7414
4030,1986,7956,2433,3487,7957,7958,2093,7959,4260,3839,1213,1407,2803, 531,2737,  # 7430
2538,3233,1011,1537,7960,2769,4261,3106,1061,7961,3720,3721,1866,2883,7962,2017,  # 7446
 120,4262,4263,2062,3595,3234,2309,3840,2668,3382,1954,4542,7963,7964,3488,1047,  # 7462
2704,1266,7965,1368,4543,2845, 649,3383,3841,2539,2738,1102,2846,2669,7966,7967,  # 7478
1999,7968,1111,3596,2962,7969,2488,3842,3597,2804,1854,3384,3722,7970,7971,3385,  # 7494
2410,2884,3304,3235,3598,7972,2569,7973,3599,2805,4031,1460, 856,7974,3600,7975,  # 7510
2885,2963,7976,2886,3843,7977,4264, 632,2510, 875,3844,1697,3845,2291,7978,7979,  # 7526
4544,3010,1239, 580,4545,4265,7980, 914, 936,2074,1190,4032,1039,2123,7981,7982,  # 7542
7983,3386,1473,7984,1354,4266,3846,7985,2172,3064,4033, 915,3305,4267,4268,3306,  # 7558
1605,1834,7986,2739, 398,3601,4269,3847,4034, 328,1912,2847,4035,3848,1331,4270,  # 7574
3011, 937,4271,7987,3602,4036,4037,3387,2160,4546,3388, 524, 742, 538,3065,1012,  # 7590
7988,7989,3849,2461,7990, 658,1103, 225,3850,7991,7992,4547,7993,4548,7994,3236,  # 7606
1243,7995,4038, 963,2246,4549,7996,2705,3603,3161,7997,7998,2588,2327,7999,4550,  # 7622
8000,8001,8002,3489,3307, 957,3389,2540,2032,1930,2927,2462, 870,2018,3604,1746,  # 7638
2770,2771,2434,2463,8003,3851,8004,3723,3107,3724,3490,3390,3725,8005,1179,3066,  # 7654
8006,3162,2373,4272,3726,2541,3163,3108,2740,4039,8007,3391,1556,2542,2292, 977,  # 7670
2887,2033,4040,1205,3392,8008,1765,3393,3164,2124,1271,1689, 714,4551,3491,8009,  # 7686
2328,3852, 533,4273,3605,2181, 617,8010,2464,3308,3492,2310,8011,8012,3165,8013,  # 7702
8014,3853,1987, 618, 427,2641,3493,3394,8015,8016,1244,1690,8017,2806,4274,4552,  # 7718
8018,3494,8019,8020,2279,1576, 473,3606,4275,3395, 972,8021,3607,8022,3067,8023,  # 7734
8024,4553,4554,8025,3727,4041,4042,8026, 153,4555, 356,8027,1891,2888,4276,2143,  # 7750
 408, 803,2352,8028,3854,8029,4277,1646,2570,2511,4556,4557,3855,8030,3856,4278,  # 7766
8031,2411,3396, 752,8032,8033,1961,2964,8034, 746,3012,2465,8035,4279,3728, 698,  # 7782
4558,1892,4280,3608,2543,4559,3609,3857,8036,3166,3397,8037,1823,1302,4043,2706,  # 7798
3858,1973,4281,8038,4282,3167, 823,1303,1288,1236,2848,3495,4044,3398, 774,3859,  # 7814
8039,1581,4560,1304,2849,3860,4561,8040,2435,2161,1083,3237,4283,4045,4284, 344,  # 7830
1173, 288,2311, 454,1683,8041,8042,1461,4562,4046,2589,8043,8044,4563, 985, 894,  # 7846
8045,3399,3168,8046,1913,2928,3729,1988,8047,2110,1974,8048,4047,8049,2571,1194,  # 7862
 425,8050,4564,3169,1245,3730,4285,8051,8052,2850,8053, 636,4565,1855,3861, 760,  # 7878
1799,8054,4286,2209,1508,4566,4048,1893,1684,2293,8055,8056,8057,4287,4288,2210,  # 7894
 479,8058,8059, 832,8060,4049,2489,8061,2965,2490,3731, 990,3109, 627,1814,2642,  # 7910
4289,1582,4290,2125,2111,3496,4567,8062, 799,4291,3170,8063,4568,2112,1737,3013,  # 7926
1018, 543, 754,4292,3309,1676,4569,4570,4050,8064,1489,8065,3497,8066,2614,2889,  # 7942
4051,8067,8068,2966,8069,8070,8071,8072,3171,4571,4572,2182,1722,8073,3238,3239,  # 7958
1842,3610,1715, 481, 365,1975,1856,8074,8075,1962,2491,4573,8076,2126,3611,3240,  # 7974
 433,1894,2063,2075,8077, 602,2741,8078,8079,8080,8081,8082,3014,1628,3400,8083,  # 7990
3172,4574,4052,2890,4575,2512,8084,2544,2772,8085,8086,8087,3310,4576,2891,8088,  # 8006
4577,8089,2851,4578,4579,1221,2967,4053,2513,8090,8091,8092,1867,1989,8093,8094,  # 8022
8095,1895,8096,8097,4580,1896,4054, 318,8098,2094,4055,4293,8099,8100, 485,8101,  # 8038
 938,3862, 553,2670, 116,8102,3863,3612,8103,3498,2671,2773,3401,3311,2807,8104,  # 8054
3613,2929,4056,1747,2930,2968,8105,8106, 207,8107,8108,2672,4581,2514,8109,3015,  # 8070
 890,3614,3864,8110,1877,3732,3402,8111,2183,2353,3403,1652,8112,8113,8114, 941,  # 8086
2294, 208,3499,4057,2019, 330,4294,3865,2892,2492,3733,4295,8115,8116,8117,8118,  # 8102
)





############################################################
### File: euctwprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import EUCTWDistributionAnalysis
from .mbcssm import EUCTW_SM_MODEL

class EUCTWProber(MultiByteCharSetProber):
    def __init__(self):
        super(EUCTWProber, self).__init__()
        self.coding_sm = CodingStateMachine(EUCTW_SM_MODEL)
        self.distribution_analyzer = EUCTWDistributionAnalysis()
        self.reset()

    @property
    def charset_name(self):
        return "EUC-TW"

    @property
    def language(self):
        return "Taiwan"




############################################################
### File: evaljs.py
############################################################
# coding=utf-8
from .translators import translate_js, DEFAULT_HEADER
from .es6 import js6_to_js5
import sys
import time
import json
import six
import os
import hashlib
import codecs

__all__ = [
    'EvalJs', 'translate_js', 'import_js', 'eval_js', 'translate_file',
    'eval_js6', 'translate_js6', 'run_file', 'disable_pyimport',
    'get_file_contents', 'write_file_contents'
]
DEBUG = False


def disable_pyimport():
    import pyjsparser.parser
    pyjsparser.parser.ENABLE_PYIMPORT = False


def path_as_local(path):
    if os.path.isabs(path):
        return path
    # relative to cwd
    return os.path.join(os.getcwd(), path)


def import_js(path, lib_name, globals):
    """Imports from javascript source file.
      globals is your globals()"""
    with codecs.open(path_as_local(path), "r", "utf-8") as f:
        js = f.read()
    e = EvalJs()
    e.execute(js)
    var = e.context['var']
    globals[lib_name] = var.to_python()


def get_file_contents(path_or_file):
    if hasattr(path_or_file, 'read'):
        js = path_or_file.read()
    else:
        with codecs.open(path_as_local(path_or_file), "r", "utf-8") as f:
            js = f.read()
    return js


def write_file_contents(path_or_file, contents):
    if hasattr(path_or_file, 'write'):
        path_or_file.write(contents)
    else:
        with codecs.open(path_as_local(path_or_file), "w", "utf-8") as f:
            f.write(contents)


def translate_file(input_path, output_path):
    '''
    Translates input JS file to python and saves the it to the output path.
    It appends some convenience code at the end so that it is easy to import JS objects.

    For example we have a file 'example.js' with:   var a = function(x) {return x}
    translate_file('example.js', 'example.py')

    Now example.py can be easily importend and used:
    >>> from example import example
    >>> example.a(30)
    30
    '''
    js = get_file_contents(input_path)

    py_code = translate_js(js)
    lib_name = os.path.basename(output_path).split('.')[0]
    head = '__all__ = [%s]\n\n# Don\'t look below, you will not understand this Python code :) I don\'t.\n\n' % repr(
        lib_name)
    tail = '\n\n# Add lib to the module scope\n%s = var.to_python()' % lib_name
    out = head + py_code + tail
    write_file_contents(output_path, out)


def run_file(path_or_file, context=None):
    ''' Context must be EvalJS object. Runs given path as a JS program. Returns (eval_value, context).
    '''
    if context is None:
        context = EvalJs()
    if not isinstance(context, EvalJs):
        raise TypeError('context must be the instance of EvalJs')
    eval_value = context.eval(get_file_contents(path_or_file))
    return eval_value, context


def eval_js(js):
    """Just like javascript eval. Translates javascript to python,
       executes and returns python object.
       js is javascript source code

       EXAMPLE:
        >>> import js2py
        >>> add = js2py.eval_js('function add(a, b) {return a + b}')
        >>> add(1, 2) + 3
        6
        >>> add('1', 2, 3)
        u'12'
        >>> add.constructor
        function Function() { [python code] }

       NOTE: For Js Number, String, Boolean and other base types returns appropriate python BUILTIN type.
       For Js functions and objects, returns Python wrapper - basically behaves like normal python object.
       If you really want to convert object to python dict you can use to_dict method.
       """
    e = EvalJs()
    return e.eval(js)


def eval_js6(js):
    """Just like eval_js but with experimental support for js6 via babel."""
    return eval_js(js6_to_js5(js))


def translate_js6(js):
    """Just like translate_js but with experimental support for js6 via babel."""
    return translate_js(js6_to_js5(js))


class EvalJs(object):
    """This class supports continuous execution of javascript under same context.

        >>> ctx = EvalJs()
        >>> ctx.execute('var a = 10;function f(x) {return x*x};')
        >>> ctx.f(9)
        81
        >>> ctx.a
        10

        context is a python dict or object that contains python variables that should be available to JavaScript
        For example:
        >>> ctx = EvalJs({'a': 30})
        >>> ctx.execute('var x = a')
        >>> ctx.x
        30

        You can enable JS require function via enable_require. With this feature enabled you can use js modules
        from npm, for example:
        >>> ctx = EvalJs(enable_require=True)
        >>> ctx.execute("var esprima = require('esprima');")
        >>> ctx.execute("esprima.parse('var a = 1')")

       You can run interactive javascript console with console method!"""

    def __init__(self, context={}, enable_require=False):
        self.__dict__['_context'] = {}
        exec (DEFAULT_HEADER, self._context)
        self.__dict__['_var'] = self._context['var'].to_python()

        if enable_require:
            def _js_require_impl(npm_module_name):
                from .node_import import require
                from .base import to_python
                return require(to_python(npm_module_name), context=self._context)
            setattr(self._var, 'require', _js_require_impl)

        if not isinstance(context, dict):
            try:
                context = context.__dict__
            except:
                raise TypeError(
                    'context has to be either a dict or have __dict__ attr')
        for k, v in six.iteritems(context):
            setattr(self._var, k, v)

    def execute(self, js=None, use_compilation_plan=False):
        """executes javascript js in current context

        During initial execute() the converted js is cached for re-use. That means next time you
        run the same javascript snippet you save many instructions needed to parse and convert the
        js code to python code.

        This cache causes minor overhead (a cache dicts is updated) but the Js=>Py conversion process
        is typically expensive compared to actually running the generated python code.

        Note that the cache is just a dict, it has no expiration or cleanup so when running this
        in automated situations with vast amounts of snippets it might increase memory usage.
        """
        try:
            cache = self.__dict__['cache']
        except KeyError:
            cache = self.__dict__['cache'] = {}
        hashkey = hashlib.md5(js.encode('utf-8')).digest()
        try:
            compiled = cache[hashkey]
        except KeyError:
            code = translate_js(
                js, '', use_compilation_plan=use_compilation_plan)
            compiled = cache[hashkey] = compile(code, '<EvalJS snippet>',
                                                'exec')
        exec (compiled, self._context)

    def eval(self, expression, use_compilation_plan=False):
        """evaluates expression in current context and returns its value"""
        code = 'PyJsEvalResult = eval(%s)' % json.dumps(expression)
        self.execute(code, use_compilation_plan=use_compilation_plan)
        return self['PyJsEvalResult']

    def execute_debug(self, js):
        """executes javascript js in current context
        as opposed to the (faster) self.execute method, you can use your regular debugger
        to set breakpoints and inspect the generated python code
        """
        code = translate_js(js, '')
        # make sure you have a temp folder:
        filename = 'temp' + os.sep + '_' + hashlib.md5(
            code.encode("utf-8")).hexdigest() + '.py'
        try:
            with open(filename, mode='w') as f:
                f.write(code)
            with open(filename, "r") as f:
                pyCode = compile(f.read(), filename, 'exec')
                exec(pyCode, self._context)
                
        except Exception as err:
            raise err
        finally:
            os.remove(filename)
            try:
                os.remove(filename + 'c')
            except:
                pass

    def eval_debug(self, expression):
        """evaluates expression in current context and returns its value
        as opposed to the (faster) self.execute method, you can use your regular debugger
        to set breakpoints and inspect the generated python code
        """
        code = 'PyJsEvalResult = eval(%s)' % json.dumps(expression)
        self.execute_debug(code)
        return self['PyJsEvalResult']

    @property
    def context(self):
        return self._context
    
    def __getattr__(self, var):
        return getattr(self._var, var)

    def __getitem__(self, var):
        return getattr(self._var, var)

    def __setattr__(self, var, val):
        return setattr(self._var, var, val)

    def __setitem__(self, var, val):
        return setattr(self._var, var, val)

    def console(self):
        """starts to interact (starts interactive console) Something like code.InteractiveConsole"""
        while True:
            if six.PY2:
                code = raw_input('>>> ')
            else:
                code = input('>>>')
            try:
                print(self.eval(code))
            except KeyboardInterrupt:
                break
            except Exception as e:
                import traceback
                if DEBUG:
                    sys.stderr.write(traceback.format_exc())
                else:
                    sys.stderr.write('EXCEPTION: ' + str(e) + '\n')
                time.sleep(0.01)




############################################################
### File: exception.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""Common DNS Exceptions.

Dnspython modules may also define their own exceptions, which will
always be subclasses of ``DNSException``.
"""

class DNSException(Exception):
    """Abstract base class shared by all dnspython exceptions.

    It supports two basic modes of operation:

    a) Old/compatible mode is used if ``__init__`` was called with
    empty *kwargs*.  In compatible mode all *args* are passed
    to the standard Python Exception class as before and all *args* are
    printed by the standard ``__str__`` implementation.  Class variable
    ``msg`` (or doc string if ``msg`` is ``None``) is returned from ``str()``
    if *args* is empty.

    b) New/parametrized mode is used if ``__init__`` was called with
    non-empty *kwargs*.
    In the new mode *args* must be empty and all kwargs must match
    those set in class variable ``supp_kwargs``. All kwargs are stored inside
    ``self.kwargs`` and used in a new ``__str__`` implementation to construct
    a formatted message based on the ``fmt`` class variable, a ``string``.

    In the simplest case it is enough to override the ``supp_kwargs``
    and ``fmt`` class variables to get nice parametrized messages.
    """

    msg = None  # non-parametrized message
    supp_kwargs = set()  # accepted parameters for _fmt_kwargs (sanity check)
    fmt = None  # message parametrized with results from _fmt_kwargs

    def __init__(self, *args, **kwargs):
        self._check_params(*args, **kwargs)
        if kwargs:
            self.kwargs = self._check_kwargs(**kwargs)
            self.msg = str(self)
        else:
            self.kwargs = dict()  # defined but empty for old mode exceptions
        if self.msg is None:
            # doc string is better implicit message than empty string
            self.msg = self.__doc__
        if args:
            super(DNSException, self).__init__(*args)
        else:
            super(DNSException, self).__init__(self.msg)

    def _check_params(self, *args, **kwargs):
        """Old exceptions supported only args and not kwargs.

        For sanity we do not allow to mix old and new behavior."""
        if args or kwargs:
            assert bool(args) != bool(kwargs), \
                'keyword arguments are mutually exclusive with positional args'

    def _check_kwargs(self, **kwargs):
        if kwargs:
            assert set(kwargs.keys()) == self.supp_kwargs, \
                'following set of keyword args is required: %s' % (
                    self.supp_kwargs)
        return kwargs

    def _fmt_kwargs(self, **kwargs):
        """Format kwargs before printing them.

        Resulting dictionary has to have keys necessary for str.format call
        on fmt class variable.
        """
        fmtargs = {}
        for kw, data in kwargs.items():
            if isinstance(data, (list, set)):
                # convert list of <someobj> to list of str(<someobj>)
                fmtargs[kw] = list(map(str, data))
                if len(fmtargs[kw]) == 1:
                    # remove list brackets [] from single-item lists
                    fmtargs[kw] = fmtargs[kw].pop()
            else:
                fmtargs[kw] = data
        return fmtargs

    def __str__(self):
        if self.kwargs and self.fmt:
            # provide custom message constructed from keyword arguments
            fmtargs = self._fmt_kwargs(**self.kwargs)
            return self.fmt.format(**fmtargs)
        else:
            # print *args directly in the same way as old DNSException
            return super(DNSException, self).__str__()


class FormError(DNSException):
    """DNS message is malformed."""


class SyntaxError(DNSException):
    """Text input is malformed."""


class UnexpectedEnd(SyntaxError):
    """Text input ended unexpectedly."""


class TooBig(DNSException):
    """The DNS message is too big."""


class Timeout(DNSException):
    """The DNS operation timed out."""
    supp_kwargs = {'timeout'}
    fmt = "The DNS operation timed out after {timeout} seconds"




############################################################
### File: exceptions.py
############################################################
from __future__ import absolute_import

from .packages.six.moves.http_client import IncompleteRead as httplib_IncompleteRead

# Base Exceptions


class HTTPError(Exception):
    """Base exception used by this module."""

    pass


class HTTPWarning(Warning):
    """Base warning used by this module."""

    pass


class PoolError(HTTPError):
    """Base exception for errors caused within a pool."""

    def __init__(self, pool, message):
        self.pool = pool
        HTTPError.__init__(self, "%s: %s" % (pool, message))

    def __reduce__(self):
        # For pickling purposes.
        return self.__class__, (None, None)


class RequestError(PoolError):
    """Base exception for PoolErrors that have associated URLs."""

    def __init__(self, pool, url, message):
        self.url = url
        PoolError.__init__(self, pool, message)

    def __reduce__(self):
        # For pickling purposes.
        return self.__class__, (None, self.url, None)


class SSLError(HTTPError):
    """Raised when SSL certificate fails in an HTTPS connection."""

    pass


class ProxyError(HTTPError):
    """Raised when the connection to a proxy fails."""

    def __init__(self, message, error, *args):
        super(ProxyError, self).__init__(message, error, *args)
        self.original_error = error


class DecodeError(HTTPError):
    """Raised when automatic decoding based on Content-Type fails."""

    pass


class ProtocolError(HTTPError):
    """Raised when something unexpected happens mid-request/response."""

    pass


#: Renamed to ProtocolError but aliased for backwards compatibility.
ConnectionError = ProtocolError


# Leaf Exceptions


class MaxRetryError(RequestError):
    """Raised when the maximum number of retries is exceeded.

    :param pool: The connection pool
    :type pool: :class:`~urllib3.connectionpool.HTTPConnectionPool`
    :param string url: The requested Url
    :param exceptions.Exception reason: The underlying error

    """

    def __init__(self, pool, url, reason=None):
        self.reason = reason

        message = "Max retries exceeded with url: %s (Caused by %r)" % (url, reason)

        RequestError.__init__(self, pool, url, message)


class HostChangedError(RequestError):
    """Raised when an existing pool gets a request for a foreign host."""

    def __init__(self, pool, url, retries=3):
        message = "Tried to open a foreign host with url: %s" % url
        RequestError.__init__(self, pool, url, message)
        self.retries = retries


class TimeoutStateError(HTTPError):
    """Raised when passing an invalid state to a timeout"""

    pass


class TimeoutError(HTTPError):
    """Raised when a socket timeout error occurs.

    Catching this error will catch both :exc:`ReadTimeoutErrors
    <ReadTimeoutError>` and :exc:`ConnectTimeoutErrors <ConnectTimeoutError>`.
    """

    pass


class ReadTimeoutError(TimeoutError, RequestError):
    """Raised when a socket timeout occurs while receiving data from a server"""

    pass


# This timeout error does not have a URL attached and needs to inherit from the
# base HTTPError
class ConnectTimeoutError(TimeoutError):
    """Raised when a socket timeout occurs while connecting to a server"""

    pass


class NewConnectionError(ConnectTimeoutError, PoolError):
    """Raised when we fail to establish a new connection. Usually ECONNREFUSED."""

    pass


class EmptyPoolError(PoolError):
    """Raised when a pool runs out of connections and no more are allowed."""

    pass


class ClosedPoolError(PoolError):
    """Raised when a request enters a pool after the pool has been closed."""

    pass


class LocationValueError(ValueError, HTTPError):
    """Raised when there is something wrong with a given URL input."""

    pass


class LocationParseError(LocationValueError):
    """Raised when get_host or similar fails to parse the URL input."""

    def __init__(self, location):
        message = "Failed to parse: %s" % location
        HTTPError.__init__(self, message)

        self.location = location


class URLSchemeUnknown(LocationValueError):
    """Raised when a URL input has an unsupported scheme."""

    def __init__(self, scheme):
        message = "Not supported URL scheme %s" % scheme
        super(URLSchemeUnknown, self).__init__(message)

        self.scheme = scheme


class ResponseError(HTTPError):
    """Used as a container for an error reason supplied in a MaxRetryError."""

    GENERIC_ERROR = "too many error responses"
    SPECIFIC_ERROR = "too many {status_code} error responses"


class SecurityWarning(HTTPWarning):
    """Warned when performing security reducing actions"""

    pass


class SubjectAltNameWarning(SecurityWarning):
    """Warned when connecting to a host with a certificate missing a SAN."""

    pass


class InsecureRequestWarning(SecurityWarning):
    """Warned when making an unverified HTTPS request."""

    pass


class SystemTimeWarning(SecurityWarning):
    """Warned when system time is suspected to be wrong"""

    pass


class InsecurePlatformWarning(SecurityWarning):
    """Warned when certain TLS/SSL configuration is not available on a platform."""

    pass


class SNIMissingWarning(HTTPWarning):
    """Warned when making a HTTPS request without SNI available."""

    pass


class DependencyWarning(HTTPWarning):
    """
    Warned when an attempt is made to import a module with missing optional
    dependencies.
    """

    pass


class ResponseNotChunked(ProtocolError, ValueError):
    """Response needs to be chunked in order to read it as chunks."""

    pass


class BodyNotHttplibCompatible(HTTPError):
    """
    Body should be :class:`http.client.HTTPResponse` like
    (have an fp attribute which returns raw chunks) for read_chunked().
    """

    pass


class IncompleteRead(HTTPError, httplib_IncompleteRead):
    """
    Response length doesn't match expected Content-Length

    Subclass of :class:`http.client.IncompleteRead` to allow int value
    for ``partial`` to avoid creating large objects on streamed reads.
    """

    def __init__(self, partial, expected):
        super(IncompleteRead, self).__init__(partial, expected)

    def __repr__(self):
        return "IncompleteRead(%i bytes read, %i more expected)" % (
            self.partial,
            self.expected,
        )


class InvalidChunkLength(HTTPError, httplib_IncompleteRead):
    """Invalid chunk length in a chunked response."""

    def __init__(self, response, length):
        super(InvalidChunkLength, self).__init__(
            response.tell(), response.length_remaining
        )
        self.response = response
        self.length = length

    def __repr__(self):
        return "InvalidChunkLength(got length %r, %i bytes read)" % (
            self.length,
            self.partial,
        )


class InvalidHeader(HTTPError):
    """The header provided was somehow invalid."""

    pass


class ProxySchemeUnknown(AssertionError, URLSchemeUnknown):
    """ProxyManager does not support the supplied scheme"""

    # TODO(t-8ch): Stop inheriting from AssertionError in v2.0.

    def __init__(self, scheme):
        # 'localhost' is here because our URL parser parses
        # localhost:8080 -> scheme=localhost, remove if we fix this.
        if scheme == "localhost":
            scheme = None
        if scheme is None:
            message = "Proxy URL had no scheme, should start with http:// or https://"
        else:
            message = (
                "Proxy URL had unsupported scheme %s, should use http:// or https://"
                % scheme
            )
        super(ProxySchemeUnknown, self).__init__(message)


class ProxySchemeUnsupported(ValueError):
    """Fetching HTTPS resources through HTTPS proxies is unsupported"""

    pass


class HeaderParsingError(HTTPError):
    """Raised by assert_header_parsing, but we convert it to a log.warning statement."""

    def __init__(self, defects, unparsed_data):
        message = "%s, unparsed data: %r" % (defects or "Unknown", unparsed_data)
        super(HeaderParsingError, self).__init__(message)


class UnrewindableBodyError(HTTPError):
    """urllib3 encountered an error when trying to rewind a body"""

    pass




############################################################
### File: factory.py
############################################################
# -*- coding: utf-8 -*-
"""
Implements the :class:`ArrowFactory <arrow.factory.ArrowFactory>` class,
providing factory methods for common :class:`Arrow <arrow.arrow.Arrow>`
construction scenarios.

"""

from __future__ import absolute_import

import calendar
from datetime import date, datetime
from datetime import tzinfo as dt_tzinfo
from time import struct_time

from dateutil import tz as dateutil_tz

from arrow import parser
from arrow.arrow import Arrow
from arrow.util import is_timestamp, iso_to_gregorian, isstr


class ArrowFactory(object):
    """ A factory for generating :class:`Arrow <arrow.arrow.Arrow>` objects.

    :param type: (optional) the :class:`Arrow <arrow.arrow.Arrow>`-based class to construct from.
        Defaults to :class:`Arrow <arrow.arrow.Arrow>`.

    """

    def __init__(self, type=Arrow):
        self.type = type

    def get(self, *args, **kwargs):
        """ Returns an :class:`Arrow <arrow.arrow.Arrow>` object based on flexible inputs.

        :param locale: (optional) a ``str`` specifying a locale for the parser. Defaults to
            'en_us'.
        :param tzinfo: (optional) a :ref:`timezone expression <tz-expr>` or tzinfo object.
            Replaces the timezone unless using an input form that is explicitly UTC or specifies
            the timezone in a positional argument. Defaults to UTC.

        Usage::

            >>> import arrow

        **No inputs** to get current UTC time::

            >>> arrow.get()
            <Arrow [2013-05-08T05:51:43.316458+00:00]>

        **None** to also get current UTC time::

            >>> arrow.get(None)
            <Arrow [2013-05-08T05:51:49.016458+00:00]>

        **One** :class:`Arrow <arrow.arrow.Arrow>` object, to get a copy.

            >>> arw = arrow.utcnow()
            >>> arrow.get(arw)
            <Arrow [2013-10-23T15:21:54.354846+00:00]>

        **One** ``float`` or ``int``, convertible to a floating-point timestamp, to get
        that timestamp in UTC::

            >>> arrow.get(1367992474.293378)
            <Arrow [2013-05-08T05:54:34.293378+00:00]>

            >>> arrow.get(1367992474)
            <Arrow [2013-05-08T05:54:34+00:00]>

        **One** ISO 8601-formatted ``str``, to parse it::

            >>> arrow.get('2013-09-29T01:26:43.830580')
            <Arrow [2013-09-29T01:26:43.830580+00:00]>

        **One** ISO 8601-formatted ``str``, in basic format, to parse it::

            >>> arrow.get('20160413T133656.456289')
            <Arrow [2016-04-13T13:36:56.456289+00:00]>

        **One** ``tzinfo``, to get the current time **converted** to that timezone::

            >>> arrow.get(tz.tzlocal())
            <Arrow [2013-05-07T22:57:28.484717-07:00]>

        **One** naive ``datetime``, to get that datetime in UTC::

            >>> arrow.get(datetime(2013, 5, 5))
            <Arrow [2013-05-05T00:00:00+00:00]>

        **One** aware ``datetime``, to get that datetime::

            >>> arrow.get(datetime(2013, 5, 5, tzinfo=tz.tzlocal()))
            <Arrow [2013-05-05T00:00:00-07:00]>

        **One** naive ``date``, to get that date in UTC::

            >>> arrow.get(date(2013, 5, 5))
            <Arrow [2013-05-05T00:00:00+00:00]>

        **One** time.struct time::

            >>> arrow.get(gmtime(0))
            <Arrow [1970-01-01T00:00:00+00:00]>

        **One** iso calendar ``tuple``, to get that week date in UTC::

            >>> arrow.get((2013, 18, 7))
            <Arrow [2013-05-05T00:00:00+00:00]>

        **Two** arguments, a naive or aware ``datetime``, and a replacement
        :ref:`timezone expression <tz-expr>`::

            >>> arrow.get(datetime(2013, 5, 5), 'US/Pacific')
            <Arrow [2013-05-05T00:00:00-07:00]>

        **Two** arguments, a naive ``date``, and a replacement
        :ref:`timezone expression <tz-expr>`::

            >>> arrow.get(date(2013, 5, 5), 'US/Pacific')
            <Arrow [2013-05-05T00:00:00-07:00]>

        **Two** arguments, both ``str``, to parse the first according to the format of the second::

            >>> arrow.get('2013-05-05 12:30:45 America/Chicago', 'YYYY-MM-DD HH:mm:ss ZZZ')
            <Arrow [2013-05-05T12:30:45-05:00]>

        **Two** arguments, first a ``str`` to parse and second a ``list`` of formats to try::

            >>> arrow.get('2013-05-05 12:30:45', ['MM/DD/YYYY', 'YYYY-MM-DD HH:mm:ss'])
            <Arrow [2013-05-05T12:30:45+00:00]>

        **Three or more** arguments, as for the constructor of a ``datetime``::

            >>> arrow.get(2013, 5, 5, 12, 30, 45)
            <Arrow [2013-05-05T12:30:45+00:00]>

        """

        arg_count = len(args)
        locale = kwargs.pop("locale", "en_us")
        tz = kwargs.get("tzinfo", None)

        # if kwargs given, send to constructor unless only tzinfo provided
        if len(kwargs) > 1:
            arg_count = 3

        # tzinfo kwarg is not provided
        if len(kwargs) == 1 and tz is None:
            arg_count = 3

        # () -> now, @ utc.
        if arg_count == 0:
            if isstr(tz):
                tz = parser.TzinfoParser.parse(tz)
                return self.type.now(tz)

            if isinstance(tz, dt_tzinfo):
                return self.type.now(tz)

            return self.type.utcnow()

        if arg_count == 1:
            arg = args[0]

            # (None) -> now, @ utc.
            if arg is None:
                return self.type.utcnow()

            # try (int, float) -> from timestamp with tz
            elif not isstr(arg) and is_timestamp(arg):
                if tz is None:
                    # set to UTC by default
                    tz = dateutil_tz.tzutc()
                return self.type.fromtimestamp(arg, tzinfo=tz)

            # (Arrow) -> from the object's datetime.
            elif isinstance(arg, Arrow):
                return self.type.fromdatetime(arg.datetime)

            # (datetime) -> from datetime.
            elif isinstance(arg, datetime):
                return self.type.fromdatetime(arg)

            # (date) -> from date.
            elif isinstance(arg, date):
                return self.type.fromdate(arg)

            # (tzinfo) -> now, @ tzinfo.
            elif isinstance(arg, dt_tzinfo):
                return self.type.now(arg)

            # (str) -> parse.
            elif isstr(arg):
                dt = parser.DateTimeParser(locale).parse_iso(arg)
                return self.type.fromdatetime(dt, tz)

            # (struct_time) -> from struct_time
            elif isinstance(arg, struct_time):
                return self.type.utcfromtimestamp(calendar.timegm(arg))

            # (iso calendar) -> convert then from date
            elif isinstance(arg, tuple) and len(arg) == 3:
                dt = iso_to_gregorian(*arg)
                return self.type.fromdate(dt)

            else:
                raise TypeError(
                    "Can't parse single argument of type '{}'".format(type(arg))
                )

        elif arg_count == 2:

            arg_1, arg_2 = args[0], args[1]

            if isinstance(arg_1, datetime):

                # (datetime, tzinfo/str) -> fromdatetime replace tzinfo.
                if isinstance(arg_2, dt_tzinfo) or isstr(arg_2):
                    return self.type.fromdatetime(arg_1, arg_2)
                else:
                    raise TypeError(
                        "Can't parse two arguments of types 'datetime', '{}'".format(
                            type(arg_2)
                        )
                    )

            elif isinstance(arg_1, date):

                # (date, tzinfo/str) -> fromdate replace tzinfo.
                if isinstance(arg_2, dt_tzinfo) or isstr(arg_2):
                    return self.type.fromdate(arg_1, tzinfo=arg_2)
                else:
                    raise TypeError(
                        "Can't parse two arguments of types 'date', '{}'".format(
                            type(arg_2)
                        )
                    )

            # (str, format) -> parse.
            elif isstr(arg_1) and (isstr(arg_2) or isinstance(arg_2, list)):
                dt = parser.DateTimeParser(locale).parse(args[0], args[1])
                return self.type.fromdatetime(dt, tzinfo=tz)

            else:
                raise TypeError(
                    "Can't parse two arguments of types '{}' and '{}'".format(
                        type(arg_1), type(arg_2)
                    )
                )

        # 3+ args -> datetime-like via constructor.
        else:
            return self.type(*args, **kwargs)

    def utcnow(self):
        """Returns an :class:`Arrow <arrow.arrow.Arrow>` object, representing "now" in UTC time.

        Usage::

            >>> import arrow
            >>> arrow.utcnow()
            <Arrow [2013-05-08T05:19:07.018993+00:00]>
        """

        return self.type.utcnow()

    def now(self, tz=None):
        """Returns an :class:`Arrow <arrow.arrow.Arrow>` object, representing "now" in the given
        timezone.

        :param tz: (optional) A :ref:`timezone expression <tz-expr>`.  Defaults to local time.

        Usage::

            >>> import arrow
            >>> arrow.now()
            <Arrow [2013-05-07T22:19:11.363410-07:00]>

            >>> arrow.now('US/Pacific')
            <Arrow [2013-05-07T22:19:15.251821-07:00]>

            >>> arrow.now('+02:00')
            <Arrow [2013-05-08T07:19:25.618646+02:00]>

            >>> arrow.now('local')
            <Arrow [2013-05-07T22:19:39.130059-07:00]>
        """

        if tz is None:
            tz = dateutil_tz.tzlocal()
        elif not isinstance(tz, dt_tzinfo):
            tz = parser.TzinfoParser.parse(tz)

        return self.type.now(tz)




############################################################
### File: fields.py
############################################################
from __future__ import absolute_import

import email.utils
import mimetypes
import re

from .packages import six


def guess_content_type(filename, default="application/octet-stream"):
    """
    Guess the "Content-Type" of a file.

    :param filename:
        The filename to guess the "Content-Type" of using :mod:`mimetypes`.
    :param default:
        If no "Content-Type" can be guessed, default to `default`.
    """
    if filename:
        return mimetypes.guess_type(filename)[0] or default
    return default


def format_header_param_rfc2231(name, value):
    """
    Helper function to format and quote a single header parameter using the
    strategy defined in RFC 2231.

    Particularly useful for header parameters which might contain
    non-ASCII values, like file names. This follows
    `RFC 2388 Section 4.4 <https://tools.ietf.org/html/rfc2388#section-4.4>`_.

    :param name:
        The name of the parameter, a string expected to be ASCII only.
    :param value:
        The value of the parameter, provided as ``bytes`` or `str``.
    :ret:
        An RFC-2231-formatted unicode string.
    """
    if isinstance(value, six.binary_type):
        value = value.decode("utf-8")

    if not any(ch in value for ch in '"\\\r\n'):
        result = u'%s="%s"' % (name, value)
        try:
            result.encode("ascii")
        except (UnicodeEncodeError, UnicodeDecodeError):
            pass
        else:
            return result

    if six.PY2:  # Python 2:
        value = value.encode("utf-8")

    # encode_rfc2231 accepts an encoded string and returns an ascii-encoded
    # string in Python 2 but accepts and returns unicode strings in Python 3
    value = email.utils.encode_rfc2231(value, "utf-8")
    value = "%s*=%s" % (name, value)

    if six.PY2:  # Python 2:
        value = value.decode("utf-8")

    return value


_HTML5_REPLACEMENTS = {
    u"\u0022": u"%22",
    # Replace "\" with "\\".
    u"\u005C": u"\u005C\u005C",
}

# All control characters from 0x00 to 0x1F *except* 0x1B.
_HTML5_REPLACEMENTS.update(
    {
        six.unichr(cc): u"%{:02X}".format(cc)
        for cc in range(0x00, 0x1F + 1)
        if cc not in (0x1B,)
    }
)


def _replace_multiple(value, needles_and_replacements):
    def replacer(match):
        return needles_and_replacements[match.group(0)]

    pattern = re.compile(
        r"|".join([re.escape(needle) for needle in needles_and_replacements.keys()])
    )

    result = pattern.sub(replacer, value)

    return result


def format_header_param_html5(name, value):
    """
    Helper function to format and quote a single header parameter using the
    HTML5 strategy.

    Particularly useful for header parameters which might contain
    non-ASCII values, like file names. This follows the `HTML5 Working Draft
    Section 4.10.22.7`_ and matches the behavior of curl and modern browsers.

    .. _HTML5 Working Draft Section 4.10.22.7:
        https://w3c.github.io/html/sec-forms.html#multipart-form-data

    :param name:
        The name of the parameter, a string expected to be ASCII only.
    :param value:
        The value of the parameter, provided as ``bytes`` or `str``.
    :ret:
        A unicode string, stripped of troublesome characters.
    """
    if isinstance(value, six.binary_type):
        value = value.decode("utf-8")

    value = _replace_multiple(value, _HTML5_REPLACEMENTS)

    return u'%s="%s"' % (name, value)


# For backwards-compatibility.
format_header_param = format_header_param_html5


class RequestField(object):
    """
    A data container for request body parameters.

    :param name:
        The name of this request field. Must be unicode.
    :param data:
        The data/value body.
    :param filename:
        An optional filename of the request field. Must be unicode.
    :param headers:
        An optional dict-like object of headers to initially use for the field.
    :param header_formatter:
        An optional callable that is used to encode and format the headers. By
        default, this is :func:`format_header_param_html5`.
    """

    def __init__(
        self,
        name,
        data,
        filename=None,
        headers=None,
        header_formatter=format_header_param_html5,
    ):
        self._name = name
        self._filename = filename
        self.data = data
        self.headers = {}
        if headers:
            self.headers = dict(headers)
        self.header_formatter = header_formatter

    @classmethod
    def from_tuples(cls, fieldname, value, header_formatter=format_header_param_html5):
        """
        A :class:`~urllib3.fields.RequestField` factory from old-style tuple parameters.

        Supports constructing :class:`~urllib3.fields.RequestField` from
        parameter of key/value strings AND key/filetuple. A filetuple is a
        (filename, data, MIME type) tuple where the MIME type is optional.
        For example::

            'foo': 'bar',
            'fakefile': ('foofile.txt', 'contents of foofile'),
            'realfile': ('barfile.txt', open('realfile').read()),
            'typedfile': ('bazfile.bin', open('bazfile').read(), 'image/jpeg'),
            'nonamefile': 'contents of nonamefile field',

        Field names and filenames must be unicode.
        """
        if isinstance(value, tuple):
            if len(value) == 3:
                filename, data, content_type = value
            else:
                filename, data = value
                content_type = guess_content_type(filename)
        else:
            filename = None
            content_type = None
            data = value

        request_param = cls(
            fieldname, data, filename=filename, header_formatter=header_formatter
        )
        request_param.make_multipart(content_type=content_type)

        return request_param

    def _render_part(self, name, value):
        """
        Overridable helper function to format a single header parameter. By
        default, this calls ``self.header_formatter``.

        :param name:
            The name of the parameter, a string expected to be ASCII only.
        :param value:
            The value of the parameter, provided as a unicode string.
        """

        return self.header_formatter(name, value)

    def _render_parts(self, header_parts):
        """
        Helper function to format and quote a single header.

        Useful for single headers that are composed of multiple items. E.g.,
        'Content-Disposition' fields.

        :param header_parts:
            A sequence of (k, v) tuples or a :class:`dict` of (k, v) to format
            as `k1="v1"; k2="v2"; ...`.
        """
        parts = []
        iterable = header_parts
        if isinstance(header_parts, dict):
            iterable = header_parts.items()

        for name, value in iterable:
            if value is not None:
                parts.append(self._render_part(name, value))

        return u"; ".join(parts)

    def render_headers(self):
        """
        Renders the headers for this request field.
        """
        lines = []

        sort_keys = ["Content-Disposition", "Content-Type", "Content-Location"]
        for sort_key in sort_keys:
            if self.headers.get(sort_key, False):
                lines.append(u"%s: %s" % (sort_key, self.headers[sort_key]))

        for header_name, header_value in self.headers.items():
            if header_name not in sort_keys:
                if header_value:
                    lines.append(u"%s: %s" % (header_name, header_value))

        lines.append(u"\r\n")
        return u"\r\n".join(lines)

    def make_multipart(
        self, content_disposition=None, content_type=None, content_location=None
    ):
        """
        Makes this request field into a multipart request field.

        This method overrides "Content-Disposition", "Content-Type" and
        "Content-Location" headers to the request parameter.

        :param content_type:
            The 'Content-Type' of the request body.
        :param content_location:
            The 'Content-Location' of the request body.

        """
        self.headers["Content-Disposition"] = content_disposition or u"form-data"
        self.headers["Content-Disposition"] += u"; ".join(
            [
                u"",
                self._render_parts(
                    ((u"name", self._name), (u"filename", self._filename))
                ),
            ]
        )
        self.headers["Content-Type"] = content_type
        self.headers["Content-Location"] = content_location




############################################################
### File: filepost.py
############################################################
from __future__ import absolute_import

import binascii
import codecs
import os
from io import BytesIO

from .fields import RequestField
from .packages import six
from .packages.six import b

writer = codecs.lookup("utf-8")[3]


def choose_boundary():
    """
    Our embarrassingly-simple replacement for mimetools.choose_boundary.
    """
    boundary = binascii.hexlify(os.urandom(16))
    if not six.PY2:
        boundary = boundary.decode("ascii")
    return boundary


def iter_field_objects(fields):
    """
    Iterate over fields.

    Supports list of (k, v) tuples and dicts, and lists of
    :class:`~urllib3.fields.RequestField`.

    """
    if isinstance(fields, dict):
        i = six.iteritems(fields)
    else:
        i = iter(fields)

    for field in i:
        if isinstance(field, RequestField):
            yield field
        else:
            yield RequestField.from_tuples(*field)


def iter_fields(fields):
    """
    .. deprecated:: 1.6

    Iterate over fields.

    The addition of :class:`~urllib3.fields.RequestField` makes this function
    obsolete. Instead, use :func:`iter_field_objects`, which returns
    :class:`~urllib3.fields.RequestField` objects.

    Supports list of (k, v) tuples and dicts.
    """
    if isinstance(fields, dict):
        return ((k, v) for k, v in six.iteritems(fields))

    return ((k, v) for k, v in fields)


def encode_multipart_formdata(fields, boundary=None):
    """
    Encode a dictionary of ``fields`` using the multipart/form-data MIME format.

    :param fields:
        Dictionary of fields or list of (key, :class:`~urllib3.fields.RequestField`).

    :param boundary:
        If not specified, then a random boundary will be generated using
        :func:`urllib3.filepost.choose_boundary`.
    """
    body = BytesIO()
    if boundary is None:
        boundary = choose_boundary()

    for field in iter_field_objects(fields):
        body.write(b("--%s\r\n" % (boundary)))

        writer(body).write(field.render_headers())
        data = field.data

        if isinstance(data, int):
            data = str(data)  # Backwards compatibility

        if isinstance(data, six.text_type):
            writer(body).write(data)
        else:
            body.write(data)

        body.write(b"\r\n")

    body.write(b("--%s--\r\n" % (boundary)))

    content_type = str("multipart/form-data; boundary=%s" % boundary)

    return body.getvalue(), content_type




############################################################
### File: flags.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Message Flags."""

# Standard DNS flags

#: Query Response
QR = 0x8000
#: Authoritative Answer
AA = 0x0400
#: Truncated Response
TC = 0x0200
#: Recursion Desired
RD = 0x0100
#: Recursion Available
RA = 0x0080
#: Authentic Data
AD = 0x0020
#: Checking Disabled
CD = 0x0010

# EDNS flags

#: DNSSEC answer OK
DO = 0x8000

_by_text = {
    'QR': QR,
    'AA': AA,
    'TC': TC,
    'RD': RD,
    'RA': RA,
    'AD': AD,
    'CD': CD
}

_edns_by_text = {
    'DO': DO
}


# We construct the inverse mappings programmatically to ensure that we
# cannot make any mistakes (e.g. omissions, cut-and-paste errors) that
# would cause the mappings not to be true inverses.

_by_value = {y: x for x, y in _by_text.items()}

_edns_by_value = {y: x for x, y in _edns_by_text.items()}


def _order_flags(table):
    order = list(table.items())
    order.sort()
    order.reverse()
    return order

_flags_order = _order_flags(_by_value)

_edns_flags_order = _order_flags(_edns_by_value)


def _from_text(text, table):
    flags = 0
    tokens = text.split()
    for t in tokens:
        flags = flags | table[t.upper()]
    return flags


def _to_text(flags, table, order):
    text_flags = []
    for k, v in order:
        if flags & k != 0:
            text_flags.append(v)
    return ' '.join(text_flags)


def from_text(text):
    """Convert a space-separated list of flag text values into a flags
    value.

    Returns an ``int``
    """

    return _from_text(text, _by_text)


def to_text(flags):
    """Convert a flags value into a space-separated list of flag text
    values.

    Returns a ``text``.
    """

    return _to_text(flags, _by_value, _flags_order)


def edns_from_text(text):
    """Convert a space-separated list of EDNS flag text values into a EDNS
    flags value.

    Returns an ``int``
    """

    return _from_text(text, _edns_by_text)


def edns_to_text(flags):
    """Convert an EDNS flags value into a space-separated list of EDNS flag
    text values.

    Returns a ``text``.
    """

    return _to_text(flags, _edns_by_value, _edns_flags_order)




############################################################
### File: formatter.py
############################################################
# -*- coding: utf-8 -*-
from __future__ import absolute_import, division

import calendar
import re

from dateutil import tz as dateutil_tz

from arrow import locales, util

FORMAT_ATOM = "YYYY-MM-DD HH:mm:ssZZ"
FORMAT_COOKIE = "dddd, DD-MMM-YYYY HH:mm:ss ZZZ"
FORMAT_RFC822 = "ddd, DD MMM YY HH:mm:ss Z"
FORMAT_RFC850 = "dddd, DD-MMM-YY HH:mm:ss ZZZ"
FORMAT_RFC1036 = "ddd, DD MMM YY HH:mm:ss Z"
FORMAT_RFC1123 = "ddd, DD MMM YYYY HH:mm:ss Z"
FORMAT_RFC2822 = "ddd, DD MMM YYYY HH:mm:ss Z"
FORMAT_RFC3339 = "YYYY-MM-DD HH:mm:ssZZ"
FORMAT_RSS = "ddd, DD MMM YYYY HH:mm:ss Z"
FORMAT_W3C = "YYYY-MM-DD HH:mm:ssZZ"


class DateTimeFormatter(object):

    # This pattern matches characters enclosed in square brackets are matched as
    # an atomic group. For more info on atomic groups and how to they are
    # emulated in Python's re library, see https://stackoverflow.com/a/13577411/2701578

    _FORMAT_RE = re.compile(
        r"(\[(?:(?=(?P<literal>[^]]))(?P=literal))*\]|YYY?Y?|MM?M?M?|Do|DD?D?D?|d?dd?d?|HH?|hh?|mm?|ss?|SS?S?S?S?S?|ZZ?Z?|a|A|X|x|W)"
    )

    def __init__(self, locale="en_us"):

        self.locale = locales.get_locale(locale)

    def format(cls, dt, fmt):

        return cls._FORMAT_RE.sub(lambda m: cls._format_token(dt, m.group(0)), fmt)

    def _format_token(self, dt, token):

        if token and token.startswith("[") and token.endswith("]"):
            return token[1:-1]

        if token == "YYYY":
            return self.locale.year_full(dt.year)
        if token == "YY":
            return self.locale.year_abbreviation(dt.year)

        if token == "MMMM":
            return self.locale.month_name(dt.month)
        if token == "MMM":
            return self.locale.month_abbreviation(dt.month)
        if token == "MM":
            return "{:02d}".format(dt.month)
        if token == "M":
            return str(dt.month)

        if token == "DDDD":
            return "{:03d}".format(dt.timetuple().tm_yday)
        if token == "DDD":
            return str(dt.timetuple().tm_yday)
        if token == "DD":
            return "{:02d}".format(dt.day)
        if token == "D":
            return str(dt.day)

        if token == "Do":
            return self.locale.ordinal_number(dt.day)

        if token == "dddd":
            return self.locale.day_name(dt.isoweekday())
        if token == "ddd":
            return self.locale.day_abbreviation(dt.isoweekday())
        if token == "d":
            return str(dt.isoweekday())

        if token == "HH":
            return "{:02d}".format(dt.hour)
        if token == "H":
            return str(dt.hour)
        if token == "hh":
            return "{:02d}".format(dt.hour if 0 < dt.hour < 13 else abs(dt.hour - 12))
        if token == "h":
            return str(dt.hour if 0 < dt.hour < 13 else abs(dt.hour - 12))

        if token == "mm":
            return "{:02d}".format(dt.minute)
        if token == "m":
            return str(dt.minute)

        if token == "ss":
            return "{:02d}".format(dt.second)
        if token == "s":
            return str(dt.second)

        if token == "SSSSSS":
            return str("{:06d}".format(int(dt.microsecond)))
        if token == "SSSSS":
            return str("{:05d}".format(int(dt.microsecond / 10)))
        if token == "SSSS":
            return str("{:04d}".format(int(dt.microsecond / 100)))
        if token == "SSS":
            return str("{:03d}".format(int(dt.microsecond / 1000)))
        if token == "SS":
            return str("{:02d}".format(int(dt.microsecond / 10000)))
        if token == "S":
            return str(int(dt.microsecond / 100000))

        if token == "X":
            # TODO: replace with a call to dt.timestamp() when we drop Python 2.7
            return str(calendar.timegm(dt.utctimetuple()))

        if token == "x":
            # TODO: replace with a call to dt.timestamp() when we drop Python 2.7
            ts = calendar.timegm(dt.utctimetuple()) + (dt.microsecond / 1000000)
            return str(int(ts * 1000000))

        if token == "ZZZ":
            return dt.tzname()

        if token in ["ZZ", "Z"]:
            separator = ":" if token == "ZZ" else ""
            tz = dateutil_tz.tzutc() if dt.tzinfo is None else dt.tzinfo
            total_minutes = int(util.total_seconds(tz.utcoffset(dt)) / 60)

            sign = "+" if total_minutes >= 0 else "-"
            total_minutes = abs(total_minutes)
            hour, minute = divmod(total_minutes, 60)

            return "{}{:02d}{}{:02d}".format(sign, hour, separator, minute)

        if token in ("a", "A"):
            return self.locale.meridian(dt.hour, token)

        if token == "W":
            year, week, day = dt.isocalendar()
            return "{}-W{:02d}-{}".format(year, week, day)




############################################################
### File: functools_lru_cache.py
############################################################
from __future__ import absolute_import

import functools
from collections import namedtuple
from threading import RLock

_CacheInfo = namedtuple("CacheInfo", ["hits", "misses", "maxsize", "currsize"])


@functools.wraps(functools.update_wrapper)
def update_wrapper(wrapper,
                   wrapped,
                   assigned = functools.WRAPPER_ASSIGNMENTS,
                   updated = functools.WRAPPER_UPDATES):
    """
    Patch two bugs in functools.update_wrapper.
    """
    # workaround for http://bugs.python.org/issue3445
    assigned = tuple(attr for attr in assigned if hasattr(wrapped, attr))
    wrapper = functools.update_wrapper(wrapper, wrapped, assigned, updated)
    # workaround for https://bugs.python.org/issue17482
    wrapper.__wrapped__ = wrapped
    return wrapper


class _HashedSeq(list):
    __slots__ = 'hashvalue'

    def __init__(self, tup, hash=hash):
        self[:] = tup
        self.hashvalue = hash(tup)

    def __hash__(self):
        return self.hashvalue


def _make_key(args, kwds, typed,
              kwd_mark=(object(),),
              fasttypes=set([int, str, frozenset, type(None)]),
              sorted=sorted, tuple=tuple, type=type, len=len):
    'Make a cache key from optionally typed positional and keyword arguments'
    key = args
    if kwds:
        sorted_items = sorted(kwds.items())
        key += kwd_mark
        for item in sorted_items:
            key += item
    if typed:
        key += tuple(type(v) for v in args)
        if kwds:
            key += tuple(type(v) for k, v in sorted_items)
    elif len(key) == 1 and type(key[0]) in fasttypes:
        return key[0]
    return _HashedSeq(key)


def lru_cache(maxsize=100, typed=False):
    """Least-recently-used cache decorator.

    If *maxsize* is set to None, the LRU features are disabled and the cache
    can grow without bound.

    If *typed* is True, arguments of different types will be cached separately.
    For example, f(3.0) and f(3) will be treated as distinct calls with
    distinct results.

    Arguments to the cached function must be hashable.

    View the cache statistics named tuple (hits, misses, maxsize, currsize) with
    f.cache_info().  Clear the cache and statistics with f.cache_clear().
    Access the underlying function with f.__wrapped__.

    See:  http://en.wikipedia.org/wiki/Cache_algorithms#Least_Recently_Used

    """

    # Users should only access the lru_cache through its public API:
    #       cache_info, cache_clear, and f.__wrapped__
    # The internals of the lru_cache are encapsulated for thread safety and
    # to allow the implementation to change (including a possible C version).

    def decorating_function(user_function):

        cache = dict()
        stats = [0, 0]                  # make statistics updateable non-locally
        HITS, MISSES = 0, 1             # names for the stats fields
        make_key = _make_key
        cache_get = cache.get           # bound method to lookup key or return None
        _len = len                      # localize the global len() function
        lock = RLock()                  # because linkedlist updates aren't threadsafe
        root = []                       # root of the circular doubly linked list
        root[:] = [root, root, None, None]      # initialize by pointing to self
        nonlocal_root = [root]                  # make updateable non-locally
        PREV, NEXT, KEY, RESULT = 0, 1, 2, 3    # names for the link fields

        if maxsize == 0:

            def wrapper(*args, **kwds):
                # no caching, just do a statistics update after a successful call
                result = user_function(*args, **kwds)
                stats[MISSES] += 1
                return result

        elif maxsize is None:

            def wrapper(*args, **kwds):
                # simple caching without ordering or size limit
                key = make_key(args, kwds, typed)
                result = cache_get(key, root)   # root used here as a unique not-found sentinel
                if result is not root:
                    stats[HITS] += 1
                    return result
                result = user_function(*args, **kwds)
                cache[key] = result
                stats[MISSES] += 1
                return result

        else:

            def wrapper(*args, **kwds):
                # size limited caching that tracks accesses by recency
                key = make_key(args, kwds, typed) if kwds or typed else args
                with lock:
                    link = cache_get(key)
                    if link is not None:
                        # record recent use of the key by moving it to the front of the list
                        root, = nonlocal_root
                        link_prev, link_next, key, result = link
                        link_prev[NEXT] = link_next
                        link_next[PREV] = link_prev
                        last = root[PREV]
                        last[NEXT] = root[PREV] = link
                        link[PREV] = last
                        link[NEXT] = root
                        stats[HITS] += 1
                        return result
                result = user_function(*args, **kwds)
                with lock:
                    root, = nonlocal_root
                    if key in cache:
                        # getting here means that this same key was added to the
                        # cache while the lock was released.  since the link
                        # update is already done, we need only return the
                        # computed result and update the count of misses.
                        pass
                    elif _len(cache) >= maxsize:
                        # use the old root to store the new key and result
                        oldroot = root
                        oldroot[KEY] = key
                        oldroot[RESULT] = result
                        # empty the oldest link and make it the new root
                        root = nonlocal_root[0] = oldroot[NEXT]
                        oldkey = root[KEY]
                        root[KEY] = root[RESULT] = None
                        # now update the cache dictionary for the new links
                        del cache[oldkey]
                        cache[key] = oldroot
                    else:
                        # put result in a new link at the front of the list
                        last = root[PREV]
                        link = [last, root, key, result]
                        last[NEXT] = root[PREV] = cache[key] = link
                    stats[MISSES] += 1
                return result

        def cache_info():
            """Report cache statistics"""
            with lock:
                return _CacheInfo(stats[HITS], stats[MISSES], maxsize, len(cache))

        def cache_clear():
            """Clear the cache and cache statistics"""
            with lock:
                cache.clear()
                root = nonlocal_root[0]
                root[:] = [root, root, None, None]
                stats[:] = [0, 0]

        wrapper.__wrapped__ = user_function
        wrapper.cache_info = cache_info
        wrapper.cache_clear = cache_clear
        return update_wrapper(wrapper, user_function)

    return decorating_function




############################################################
### File: gb2312freq.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# GB2312 most frequently used character table
#
# Char to FreqOrder table , from hz6763

# 512  --> 0.79  -- 0.79
# 1024 --> 0.92  -- 0.13
# 2048 --> 0.98  -- 0.06
# 6768 --> 1.00  -- 0.02
#
# Ideal Distribution Ratio = 0.79135/(1-0.79135) = 3.79
# Random Distribution Ration = 512 / (3755 - 512) = 0.157
#
# Typical Distribution Ratio about 25% of Ideal one, still much higher that RDR

GB2312_TYPICAL_DISTRIBUTION_RATIO = 0.9

GB2312_TABLE_SIZE = 3760

GB2312_CHAR_TO_FREQ_ORDER = (
1671, 749,1443,2364,3924,3807,2330,3921,1704,3463,2691,1511,1515, 572,3191,2205,
2361, 224,2558, 479,1711, 963,3162, 440,4060,1905,2966,2947,3580,2647,3961,3842,
2204, 869,4207, 970,2678,5626,2944,2956,1479,4048, 514,3595, 588,1346,2820,3409,
 249,4088,1746,1873,2047,1774, 581,1813, 358,1174,3590,1014,1561,4844,2245, 670,
1636,3112, 889,1286, 953, 556,2327,3060,1290,3141, 613, 185,3477,1367, 850,3820,
1715,2428,2642,2303,2732,3041,2562,2648,3566,3946,1349, 388,3098,2091,1360,3585,
 152,1687,1539, 738,1559,  59,1232,2925,2267,1388,1249,1741,1679,2960, 151,1566,
1125,1352,4271, 924,4296, 385,3166,4459, 310,1245,2850,  70,3285,2729,3534,3575,
2398,3298,3466,1960,2265, 217,3647, 864,1909,2084,4401,2773,1010,3269,5152, 853,
3051,3121,1244,4251,1895, 364,1499,1540,2313,1180,3655,2268, 562, 715,2417,3061,
 544, 336,3768,2380,1752,4075, 950, 280,2425,4382, 183,2759,3272, 333,4297,2155,
1688,2356,1444,1039,4540, 736,1177,3349,2443,2368,2144,2225, 565, 196,1482,3406,
 927,1335,4147, 692, 878,1311,1653,3911,3622,1378,4200,1840,2969,3149,2126,1816,
2534,1546,2393,2760, 737,2494,  13, 447, 245,2747,  38,2765,2129,2589,1079, 606,
 360, 471,3755,2890, 404, 848, 699,1785,1236, 370,2221,1023,3746,2074,2026,2023,
2388,1581,2119, 812,1141,3091,2536,1519, 804,2053, 406,1596,1090, 784, 548,4414,
1806,2264,2936,1100, 343,4114,5096, 622,3358, 743,3668,1510,1626,5020,3567,2513,
3195,4115,5627,2489,2991,  24,2065,2697,1087,2719,  48,1634, 315,  68, 985,2052,
 198,2239,1347,1107,1439, 597,2366,2172, 871,3307, 919,2487,2790,1867, 236,2570,
1413,3794, 906,3365,3381,1701,1982,1818,1524,2924,1205, 616,2586,2072,2004, 575,
 253,3099,  32,1365,1182, 197,1714,2454,1201, 554,3388,3224,2748, 756,2587, 250,
2567,1507,1517,3529,1922,2761,2337,3416,1961,1677,2452,2238,3153, 615, 911,1506,
1474,2495,1265,1906,2749,3756,3280,2161, 898,2714,1759,3450,2243,2444, 563,  26,
3286,2266,3769,3344,2707,3677, 611,1402, 531,1028,2871,4548,1375, 261,2948, 835,
1190,4134, 353, 840,2684,1900,3082,1435,2109,1207,1674, 329,1872,2781,4055,2686,
2104, 608,3318,2423,2957,2768,1108,3739,3512,3271,3985,2203,1771,3520,1418,2054,
1681,1153, 225,1627,2929, 162,2050,2511,3687,1954, 124,1859,2431,1684,3032,2894,
 585,4805,3969,2869,2704,2088,2032,2095,3656,2635,4362,2209, 256, 518,2042,2105,
3777,3657, 643,2298,1148,1779, 190, 989,3544, 414,  11,2135,2063,2979,1471, 403,
3678, 126, 770,1563, 671,2499,3216,2877, 600,1179, 307,2805,4937,1268,1297,2694,
 252,4032,1448,1494,1331,1394, 127,2256, 222,1647,1035,1481,3056,1915,1048, 873,
3651, 210,  33,1608,2516, 200,1520, 415, 102,   0,3389,1287, 817,  91,3299,2940,
 836,1814, 549,2197,1396,1669,2987,3582,2297,2848,4528,1070, 687,  20,1819, 121,
1552,1364,1461,1968,2617,3540,2824,2083, 177, 948,4938,2291, 110,4549,2066, 648,
3359,1755,2110,2114,4642,4845,1693,3937,3308,1257,1869,2123, 208,1804,3159,2992,
2531,2549,3361,2418,1350,2347,2800,2568,1291,2036,2680,  72, 842,1990, 212,1233,
1154,1586,  75,2027,3410,4900,1823,1337,2710,2676, 728,2810,1522,3026,4995, 157,
 755,1050,4022, 710, 785,1936,2194,2085,1406,2777,2400, 150,1250,4049,1206, 807,
1910, 534, 529,3309,1721,1660, 274,  39,2827, 661,2670,1578, 925,3248,3815,1094,
4278,4901,4252,  41,1150,3747,2572,2227,4501,3658,4902,3813,3357,3617,2884,2258,
 887, 538,4187,3199,1294,2439,3042,2329,2343,2497,1255, 107, 543,1527, 521,3478,
3568, 194,5062,  15, 961,3870,1241,1192,2664,  66,5215,3260,2111,1295,1127,2152,
3805,4135, 901,1164,1976, 398,1278, 530,1460, 748, 904,1054,1966,1426,  53,2909,
 509, 523,2279,1534, 536,1019, 239,1685, 460,2353, 673,1065,2401,3600,4298,2272,
1272,2363, 284,1753,3679,4064,1695,  81, 815,2677,2757,2731,1386, 859, 500,4221,
2190,2566, 757,1006,2519,2068,1166,1455, 337,2654,3203,1863,1682,1914,3025,1252,
1409,1366, 847, 714,2834,2038,3209, 964,2970,1901, 885,2553,1078,1756,3049, 301,
1572,3326, 688,2130,1996,2429,1805,1648,2930,3421,2750,3652,3088, 262,1158,1254,
 389,1641,1812, 526,1719, 923,2073,1073,1902, 468, 489,4625,1140, 857,2375,3070,
3319,2863, 380, 116,1328,2693,1161,2244, 273,1212,1884,2769,3011,1775,1142, 461,
3066,1200,2147,2212, 790, 702,2695,4222,1601,1058, 434,2338,5153,3640,  67,2360,
4099,2502, 618,3472,1329, 416,1132, 830,2782,1807,2653,3211,3510,1662, 192,2124,
 296,3979,1739,1611,3684,  23, 118, 324, 446,1239,1225, 293,2520,3814,3795,2535,
3116,  17,1074, 467,2692,2201, 387,2922,  45,1326,3055,1645,3659,2817, 958, 243,
1903,2320,1339,2825,1784,3289, 356, 576, 865,2315,2381,3377,3916,1088,3122,1713,
1655, 935, 628,4689,1034,1327, 441, 800, 720, 894,1979,2183,1528,5289,2702,1071,
4046,3572,2399,1571,3281,  79, 761,1103, 327, 134, 758,1899,1371,1615, 879, 442,
 215,2605,2579, 173,2048,2485,1057,2975,3317,1097,2253,3801,4263,1403,1650,2946,
 814,4968,3487,1548,2644,1567,1285,   2, 295,2636,  97, 946,3576, 832, 141,4257,
3273, 760,3821,3521,3156,2607, 949,1024,1733,1516,1803,1920,2125,2283,2665,3180,
1501,2064,3560,2171,1592, 803,3518,1416, 732,3897,4258,1363,1362,2458, 119,1427,
 602,1525,2608,1605,1639,3175, 694,3064,  10, 465,  76,2000,4846,4208, 444,3781,
1619,3353,2206,1273,3796, 740,2483, 320,1723,2377,3660,2619,1359,1137,1762,1724,
2345,2842,1850,1862, 912, 821,1866, 612,2625,1735,2573,3369,1093, 844,  89, 937,
 930,1424,3564,2413,2972,1004,3046,3019,2011, 711,3171,1452,4178, 428, 801,1943,
 432, 445,2811, 206,4136,1472, 730, 349,  73, 397,2802,2547, 998,1637,1167, 789,
 396,3217, 154,1218, 716,1120,1780,2819,4826,1931,3334,3762,2139,1215,2627, 552,
3664,3628,3232,1405,2383,3111,1356,2652,3577,3320,3101,1703, 640,1045,1370,1246,
4996, 371,1575,2436,1621,2210, 984,4033,1734,2638,  16,4529, 663,2755,3255,1451,
3917,2257,1253,1955,2234,1263,2951, 214,1229, 617, 485, 359,1831,1969, 473,2310,
 750,2058, 165,  80,2864,2419, 361,4344,2416,2479,1134, 796,3726,1266,2943, 860,
2715, 938, 390,2734,1313,1384, 248, 202, 877,1064,2854, 522,3907, 279,1602, 297,
2357, 395,3740, 137,2075, 944,4089,2584,1267,3802,  62,1533,2285, 178, 176, 780,
2440, 201,3707, 590, 478,1560,4354,2117,1075,  30,  74,4643,4004,1635,1441,2745,
 776,2596, 238,1077,1692,1912,2844, 605, 499,1742,3947, 241,3053, 980,1749, 936,
2640,4511,2582, 515,1543,2162,5322,2892,2993, 890,2148,1924, 665,1827,3581,1032,
 968,3163, 339,1044,1896, 270, 583,1791,1720,4367,1194,3488,3669,  43,2523,1657,
 163,2167, 290,1209,1622,3378, 550, 634,2508,2510, 695,2634,2384,2512,1476,1414,
 220,1469,2341,2138,2852,3183,2900,4939,2865,3502,1211,3680, 854,3227,1299,2976,
3172, 186,2998,1459, 443,1067,3251,1495, 321,1932,3054, 909, 753,1410,1828, 436,
2441,1119,1587,3164,2186,1258, 227, 231,1425,1890,3200,3942, 247, 959, 725,5254,
2741, 577,2158,2079, 929, 120, 174, 838,2813, 591,1115, 417,2024,  40,3240,1536,
1037, 291,4151,2354, 632,1298,2406,2500,3535,1825,1846,3451, 205,1171, 345,4238,
  18,1163, 811, 685,2208,1217, 425,1312,1508,1175,4308,2552,1033, 587,1381,3059,
2984,3482, 340,1316,4023,3972, 792,3176, 519, 777,4690, 918, 933,4130,2981,3741,
  90,3360,2911,2200,5184,4550, 609,3079,2030, 272,3379,2736, 363,3881,1130,1447,
 286, 779, 357,1169,3350,3137,1630,1220,2687,2391, 747,1277,3688,2618,2682,2601,
1156,3196,5290,4034,3102,1689,3596,3128, 874, 219,2783, 798, 508,1843,2461, 269,
1658,1776,1392,1913,2983,3287,2866,2159,2372, 829,4076,  46,4253,2873,1889,1894,
 915,1834,1631,2181,2318, 298, 664,2818,3555,2735, 954,3228,3117, 527,3511,2173,
 681,2712,3033,2247,2346,3467,1652, 155,2164,3382, 113,1994, 450, 899, 494, 994,
1237,2958,1875,2336,1926,3727, 545,1577,1550, 633,3473, 204,1305,3072,2410,1956,
2471, 707,2134, 841,2195,2196,2663,3843,1026,4940, 990,3252,4997, 368,1092, 437,
3212,3258,1933,1829, 675,2977,2893, 412, 943,3723,4644,3294,3283,2230,2373,5154,
2389,2241,2661,2323,1404,2524, 593, 787, 677,3008,1275,2059, 438,2709,2609,2240,
2269,2246,1446,  36,1568,1373,3892,1574,2301,1456,3962, 693,2276,5216,2035,1143,
2720,1919,1797,1811,2763,4137,2597,1830,1699,1488,1198,2090, 424,1694, 312,3634,
3390,4179,3335,2252,1214, 561,1059,3243,2295,2561, 975,5155,2321,2751,3772, 472,
1537,3282,3398,1047,2077,2348,2878,1323,3340,3076, 690,2906,  51, 369, 170,3541,
1060,2187,2688,3670,2541,1083,1683, 928,3918, 459, 109,4427, 599,3744,4286, 143,
2101,2730,2490,  82,1588,3036,2121, 281,1860, 477,4035,1238,2812,3020,2716,3312,
1530,2188,2055,1317, 843, 636,1808,1173,3495, 649, 181,1002, 147,3641,1159,2414,
3750,2289,2795, 813,3123,2610,1136,4368,   5,3391,4541,2174, 420, 429,1728, 754,
1228,2115,2219, 347,2223,2733, 735,1518,3003,2355,3134,1764,3948,3329,1888,2424,
1001,1234,1972,3321,3363,1672,1021,1450,1584, 226, 765, 655,2526,3404,3244,2302,
3665, 731, 594,2184, 319,1576, 621, 658,2656,4299,2099,3864,1279,2071,2598,2739,
 795,3086,3699,3908,1707,2352,2402,1382,3136,2475,1465,4847,3496,3865,1085,3004,
2591,1084, 213,2287,1963,3565,2250, 822, 793,4574,3187,1772,1789,3050, 595,1484,
1959,2770,1080,2650, 456, 422,2996, 940,3322,4328,4345,3092,2742, 965,2784, 739,
4124, 952,1358,2498,2949,2565, 332,2698,2378, 660,2260,2473,4194,3856,2919, 535,
1260,2651,1208,1428,1300,1949,1303,2942, 433,2455,2450,1251,1946, 614,1269, 641,
1306,1810,2737,3078,2912, 564,2365,1419,1415,1497,4460,2367,2185,1379,3005,1307,
3218,2175,1897,3063, 682,1157,4040,4005,1712,1160,1941,1399, 394, 402,2952,1573,
1151,2986,2404, 862, 299,2033,1489,3006, 346, 171,2886,3401,1726,2932, 168,2533,
  47,2507,1030,3735,1145,3370,1395,1318,1579,3609,4560,2857,4116,1457,2529,1965,
 504,1036,2690,2988,2405, 745,5871, 849,2397,2056,3081, 863,2359,3857,2096,  99,
1397,1769,2300,4428,1643,3455,1978,1757,3718,1440,  35,4879,3742,1296,4228,2280,
 160,5063,1599,2013, 166, 520,3479,1646,3345,3012, 490,1937,1545,1264,2182,2505,
1096,1188,1369,1436,2421,1667,2792,2460,1270,2122, 727,3167,2143, 806,1706,1012,
1800,3037, 960,2218,1882, 805, 139,2456,1139,1521, 851,1052,3093,3089, 342,2039,
 744,5097,1468,1502,1585,2087, 223, 939, 326,2140,2577, 892,2481,1623,4077, 982,
3708, 135,2131,  87,2503,3114,2326,1106, 876,1616, 547,2997,2831,2093,3441,4530,
4314,   9,3256,4229,4148, 659,1462,1986,1710,2046,2913,2231,4090,4880,5255,3392,
3274,1368,3689,4645,1477, 705,3384,3635,1068,1529,2941,1458,3782,1509, 100,1656,
2548, 718,2339, 408,1590,2780,3548,1838,4117,3719,1345,3530, 717,3442,2778,3220,
2898,1892,4590,3614,3371,2043,1998,1224,3483, 891, 635, 584,2559,3355, 733,1766,
1729,1172,3789,1891,2307, 781,2982,2271,1957,1580,5773,2633,2005,4195,3097,1535,
3213,1189,1934,5693,3262, 586,3118,1324,1598, 517,1564,2217,1868,1893,4445,3728,
2703,3139,1526,1787,1992,3882,2875,1549,1199,1056,2224,1904,2711,5098,4287, 338,
1993,3129,3489,2689,1809,2815,1997, 957,1855,3898,2550,3275,3057,1105,1319, 627,
1505,1911,1883,3526, 698,3629,3456,1833,1431, 746,  77,1261,2017,2296,1977,1885,
 125,1334,1600, 525,1798,1109,2222,1470,1945, 559,2236,1186,3443,2476,1929,1411,
2411,3135,1777,3372,2621,1841,1613,3229, 668,1430,1839,2643,2916, 195,1989,2671,
2358,1387, 629,3205,2293,5256,4439, 123,1310, 888,1879,4300,3021,3605,1003,1162,
3192,2910,2010, 140,2395,2859,  55,1082,2012,2901, 662, 419,2081,1438, 680,2774,
4654,3912,1620,1731,1625,5035,4065,2328, 512,1344, 802,5443,2163,2311,2537, 524,
3399,  98,1155,2103,1918,2606,3925,2816,1393,2465,1504,3773,2177,3963,1478,4346,
 180,1113,4655,3461,2028,1698, 833,2696,1235,1322,1594,4408,3623,3013,3225,2040,
3022, 541,2881, 607,3632,2029,1665,1219, 639,1385,1686,1099,2803,3231,1938,3188,
2858, 427, 676,2772,1168,2025, 454,3253,2486,3556, 230,1950, 580, 791,1991,1280,
1086,1974,2034, 630, 257,3338,2788,4903,1017,  86,4790, 966,2789,1995,1696,1131,
 259,3095,4188,1308, 179,1463,5257, 289,4107,1248,  42,3413,1725,2288, 896,1947,
 774,4474,4254, 604,3430,4264, 392,2514,2588, 452, 237,1408,3018, 988,4531,1970,
3034,3310, 540,2370,1562,1288,2990, 502,4765,1147,   4,1853,2708, 207, 294,2814,
4078,2902,2509, 684,  34,3105,3532,2551, 644, 709,2801,2344, 573,1727,3573,3557,
2021,1081,3100,4315,2100,3681, 199,2263,1837,2385, 146,3484,1195,2776,3949, 997,
1939,3973,1008,1091,1202,1962,1847,1149,4209,5444,1076, 493, 117,5400,2521, 972,
1490,2934,1796,4542,2374,1512,2933,2657, 413,2888,1135,2762,2314,2156,1355,2369,
 766,2007,2527,2170,3124,2491,2593,2632,4757,2437, 234,3125,3591,1898,1750,1376,
1942,3468,3138, 570,2127,2145,3276,4131, 962, 132,1445,4196,  19, 941,3624,3480,
3366,1973,1374,4461,3431,2629, 283,2415,2275, 808,2887,3620,2112,2563,1353,3610,
 955,1089,3103,1053,  96,  88,4097, 823,3808,1583, 399, 292,4091,3313, 421,1128,
 642,4006, 903,2539,1877,2082, 596,  29,4066,1790, 722,2157, 130, 995,1569, 769,
1485, 464, 513,2213, 288,1923,1101,2453,4316, 133, 486,2445,  50, 625, 487,2207,
  57, 423, 481,2962, 159,3729,1558, 491, 303, 482, 501, 240,2837, 112,3648,2392,
1783, 362,   8,3433,3422, 610,2793,3277,1390,1284,1654,  21,3823, 734, 367, 623,
 193, 287, 374,1009,1483, 816, 476, 313,2255,2340,1262,2150,2899,1146,2581, 782,
2116,1659,2018,1880, 255,3586,3314,1110,2867,2137,2564, 986,2767,5185,2006, 650,
 158, 926, 762, 881,3157,2717,2362,3587, 306,3690,3245,1542,3077,2427,1691,2478,
2118,2985,3490,2438, 539,2305, 983, 129,1754, 355,4201,2386, 827,2923, 104,1773,
2838,2771, 411,2905,3919, 376, 767, 122,1114, 828,2422,1817,3506, 266,3460,1007,
1609,4998, 945,2612,4429,2274, 726,1247,1964,2914,2199,2070,4002,4108, 657,3323,
1422, 579, 455,2764,4737,1222,2895,1670, 824,1223,1487,2525, 558, 861,3080, 598,
2659,2515,1967, 752,2583,2376,2214,4180, 977, 704,2464,4999,2622,4109,1210,2961,
 819,1541, 142,2284,  44, 418, 457,1126,3730,4347,4626,1644,1876,3671,1864, 302,
1063,5694, 624, 723,1984,3745,1314,1676,2488,1610,1449,3558,3569,2166,2098, 409,
1011,2325,3704,2306, 818,1732,1383,1824,1844,3757, 999,2705,3497,1216,1423,2683,
2426,2954,2501,2726,2229,1475,2554,5064,1971,1794,1666,2014,1343, 783, 724, 191,
2434,1354,2220,5065,1763,2752,2472,4152, 131, 175,2885,3434,  92,1466,4920,2616,
3871,3872,3866, 128,1551,1632, 669,1854,3682,4691,4125,1230, 188,2973,3290,1302,
1213, 560,3266, 917, 763,3909,3249,1760, 868,1958, 764,1782,2097, 145,2277,3774,
4462,  64,1491,3062, 971,2132,3606,2442, 221,1226,1617, 218, 323,1185,3207,3147,
 571, 619,1473,1005,1744,2281, 449,1887,2396,3685, 275, 375,3816,1743,3844,3731,
 845,1983,2350,4210,1377, 773, 967,3499,3052,3743,2725,4007,1697,1022,3943,1464,
3264,2855,2722,1952,1029,2839,2467,  84,4383,2215, 820,1391,2015,2448,3672, 377,
1948,2168, 797,2545,3536,2578,2645,  94,2874,1678, 405,1259,3071, 771, 546,1315,
 470,1243,3083, 895,2468, 981, 969,2037, 846,4181, 653,1276,2928,  14,2594, 557,
3007,2474, 156, 902,1338,1740,2574, 537,2518, 973,2282,2216,2433,1928, 138,2903,
1293,2631,1612, 646,3457, 839,2935, 111, 496,2191,2847, 589,3186, 149,3994,2060,
4031,2641,4067,3145,1870,  37,3597,2136,1025,2051,3009,3383,3549,1121,1016,3261,
1301, 251,2446,2599,2153, 872,3246, 637, 334,3705, 831, 884, 921,3065,3140,4092,
2198,1944, 246,2964, 108,2045,1152,1921,2308,1031, 203,3173,4170,1907,3890, 810,
1401,2003,1690, 506, 647,1242,2828,1761,1649,3208,2249,1589,3709,2931,5156,1708,
 498, 666,2613, 834,3817,1231, 184,2851,1124, 883,3197,2261,3710,1765,1553,2658,
1178,2639,2351,  93,1193, 942,2538,2141,4402, 235,1821, 870,1591,2192,1709,1871,
3341,1618,4126,2595,2334, 603, 651,  69, 701, 268,2662,3411,2555,1380,1606, 503,
 448, 254,2371,2646, 574,1187,2309,1770, 322,2235,1292,1801, 305, 566,1133, 229,
2067,2057, 706, 167, 483,2002,2672,3295,1820,3561,3067, 316, 378,2746,3452,1112,
 136,1981, 507,1651,2917,1117, 285,4591, 182,2580,3522,1304, 335,3303,1835,2504,
1795,1792,2248, 674,1018,2106,2449,1857,2292,2845, 976,3047,1781,2600,2727,1389,
1281,  52,3152, 153, 265,3950, 672,3485,3951,4463, 430,1183, 365, 278,2169,  27,
1407,1336,2304, 209,1340,1730,2202,1852,2403,2883, 979,1737,1062, 631,2829,2542,
3876,2592, 825,2086,2226,3048,3625, 352,1417,3724, 542, 991, 431,1351,3938,1861,
2294, 826,1361,2927,3142,3503,1738, 463,2462,2723, 582,1916,1595,2808, 400,3845,
3891,2868,3621,2254,  58,2492,1123, 910,2160,2614,1372,1603,1196,1072,3385,1700,
3267,1980, 696, 480,2430, 920, 799,1570,2920,1951,2041,4047,2540,1321,4223,2469,
3562,2228,1271,2602, 401,2833,3351,2575,5157, 907,2312,1256, 410, 263,3507,1582,
 996, 678,1849,2316,1480, 908,3545,2237, 703,2322, 667,1826,2849,1531,2604,2999,
2407,3146,2151,2630,1786,3711, 469,3542, 497,3899,2409, 858, 837,4446,3393,1274,
 786, 620,1845,2001,3311, 484, 308,3367,1204,1815,3691,2332,1532,2557,1842,2020,
2724,1927,2333,4440, 567,  22,1673,2728,4475,1987,1858,1144,1597, 101,1832,3601,
  12, 974,3783,4391, 951,1412,   1,3720, 453,4608,4041, 528,1041,1027,3230,2628,
1129, 875,1051,3291,1203,2262,1069,2860,2799,2149,2615,3278, 144,1758,3040,  31,
 475,1680, 366,2685,3184, 311,1642,4008,2466,5036,1593,1493,2809, 216,1420,1668,
 233, 304,2128,3284, 232,1429,1768,1040,2008,3407,2740,2967,2543, 242,2133, 778,
1565,2022,2620, 505,2189,2756,1098,2273, 372,1614, 708, 553,2846,2094,2278, 169,
3626,2835,4161, 228,2674,3165, 809,1454,1309, 466,1705,1095, 900,3423, 880,2667,
3751,5258,2317,3109,2571,4317,2766,1503,1342, 866,4447,1118,  63,2076, 314,1881,
1348,1061, 172, 978,3515,1747, 532, 511,3970,   6, 601, 905,2699,3300,1751, 276,
1467,3725,2668,  65,4239,2544,2779,2556,1604, 578,2451,1802, 992,2331,2624,1320,
3446, 713,1513,1013, 103,2786,2447,1661, 886,1702, 916, 654,3574,2031,1556, 751,
2178,2821,2179,1498,1538,2176, 271, 914,2251,2080,1325, 638,1953,2937,3877,2432,
2754,  95,3265,1716, 260,1227,4083, 775, 106,1357,3254, 426,1607, 555,2480, 772,
1985, 244,2546, 474, 495,1046,2611,1851,2061,  71,2089,1675,2590, 742,3758,2843,
3222,1433, 267,2180,2576,2826,2233,2092,3913,2435, 956,1745,3075, 856,2113,1116,
 451,   3,1988,2896,1398, 993,2463,1878,2049,1341,2718,2721,2870,2108, 712,2904,
4363,2753,2324, 277,2872,2349,2649, 384, 987, 435, 691,3000, 922, 164,3939, 652,
1500,1184,4153,2482,3373,2165,4848,2335,3775,3508,3154,2806,2830,1554,2102,1664,
2530,1434,2408, 893,1547,2623,3447,2832,2242,2532,3169,2856,3223,2078,  49,3770,
3469, 462, 318, 656,2259,3250,3069, 679,1629,2758, 344,1138,1104,3120,1836,1283,
3115,2154,1437,4448, 934, 759,1999, 794,2862,1038, 533,2560,1722,2342, 855,2626,
1197,1663,4476,3127,  85,4240,2528,  25,1111,1181,3673, 407,3470,4561,2679,2713,
 768,1925,2841,3986,1544,1165, 932, 373,1240,2146,1930,2673, 721,4766, 354,4333,
 391,2963, 187,  61,3364,1442,1102, 330,1940,1767, 341,3809,4118, 393,2496,2062,
2211, 105, 331, 300, 439, 913,1332, 626, 379,3304,1557, 328, 689,3952, 309,1555,
 931, 317,2517,3027, 325, 569, 686,2107,3084,  60,1042,1333,2794, 264,3177,4014,
1628, 258,3712,   7,4464,1176,1043,1778, 683, 114,1975,  78,1492, 383,1886, 510,
 386, 645,5291,2891,2069,3305,4138,3867,2939,2603,2493,1935,1066,1848,3588,1015,
1282,1289,4609, 697,1453,3044,2666,3611,1856,2412,  54, 719,1330, 568,3778,2459,
1748, 788, 492, 551,1191,1000, 488,3394,3763, 282,1799, 348,2016,1523,3155,2390,
1049, 382,2019,1788,1170, 729,2968,3523, 897,3926,2785,2938,3292, 350,2319,3238,
1718,1717,2655,3453,3143,4465, 161,2889,2980,2009,1421,  56,1908,1640,2387,2232,
1917,1874,2477,4921, 148,  83,3438, 592,4245,2882,1822,1055, 741, 115,1496,1624,
 381,1638,4592,1020, 516,3214, 458, 947,4575,1432, 211,1514,2926,1865,2142, 189,
 852,1221,1400,1486, 882,2299,4036, 351,  28,1122, 700,6479,6480,6481,6482,6483,  #last 512
)





############################################################
### File: gb2312prober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import GB2312DistributionAnalysis
from .mbcssm import GB2312_SM_MODEL

class GB2312Prober(MultiByteCharSetProber):
    def __init__(self):
        super(GB2312Prober, self).__init__()
        self.coding_sm = CodingStateMachine(GB2312_SM_MODEL)
        self.distribution_analyzer = GB2312DistributionAnalysis()
        self.reset()

    @property
    def charset_name(self):
        return "GB2312"

    @property
    def language(self):
        return "Chinese"




############################################################
### File: geometry.py
############################################################
"""
This module implements the classes used to represent positioning information.

CONVENTIONS:
* None of the methods should modify the state of the objects on which they're
  called. If the values of an object need to be recalculated, the method
  responsible for the recalculation should return a new object with the
  necessary modifications.
"""
import six

from .exceptions import RelativizationError

class Enum(object):
    """Generic class that's not easily instantiable, serving as a base for
    the enumeration classes
    """
    def __new__(cls, *args, **kwargs):
        raise Exception(u"Don't instantiate. Use like an enum")

    __init__ = __new__

class UnitEnum(Enum):
    """Enumeration-like object, specifying the units of measure for length

    Usage:
        unit = UnitEnum.PIXEL
        unit = UnitEnum.EM
        if unit == UnitEnum.CELL :
            ...
    """
    PIXEL = 'px'
    EM = 'em'
    PERCENT = '%'
    CELL = 'c'
    PT = 'pt'

class VerticalAlignmentEnum(Enum):
    """Enumeration object, specifying the allowed vertical alignment options

    Usage:
        alignment = VerticalAlignmentEnum.TOP
        if alignment == VerticalAlignmentEnum.BOTTOM:
            ...
    """
    TOP = 'top'
    CENTER = 'center'
    BOTTOM = 'bottom'


class HorizontalAlignmentEnum(Enum):
    """Enumeration object specifying the horizontal alignment preferences
    """
    LEFT = 'left'
    CENTER = 'center'
    RIGHT = 'right'
    START = 'start'
    END = 'end'


class Alignment(object):
    def __init__(self, horizontal, vertical):
        """
        :type horizontal: HorizontalAlignmentEnum
        :param horizontal: HorizontalAlignmentEnum member
        :type vertical: VerticalAlignmentEnum
        :param vertical: VerticalAlignmentEnum member
        """
        self.horizontal = horizontal
        self.vertical = vertical

    def __hash__(self):
        return hash(
            hash(self.horizontal) * 83 +
            hash(self.vertical) * 89 +
            97
        )

    def __eq__(self, other):
        return (
            other and
            type(self) == type(other) and
            self.horizontal == other.horizontal and
            self.vertical == other.vertical
        )

    def __repr__(self):
        return "<Alignment ({horizontal} {vertical})>".format(
            horizontal=self.horizontal, vertical=self.vertical
        )

    def serialized(self):
        """Returns a tuple of the useful information regarding this object
        """
        return self.horizontal, self.vertical

    @classmethod
    def from_horizontal_and_vertical_align(cls, text_align=None,
                                           display_align=None):
        horizontal_obj = None
        vertical_obj = None

        if text_align == 'left':
            horizontal_obj = HorizontalAlignmentEnum.LEFT
        if text_align == 'start':
            horizontal_obj = HorizontalAlignmentEnum.START
        if text_align == 'center':
            horizontal_obj = HorizontalAlignmentEnum.CENTER
        if text_align == 'right':
            horizontal_obj = HorizontalAlignmentEnum.RIGHT
        if text_align == 'end':
            horizontal_obj = HorizontalAlignmentEnum.END

        if display_align == 'before':
            vertical_obj = VerticalAlignmentEnum.TOP
        if display_align == 'center':
            vertical_obj = VerticalAlignmentEnum.CENTER
        if display_align == 'after':
            vertical_obj = VerticalAlignmentEnum.BOTTOM

        if not any([horizontal_obj, vertical_obj]):
            return None
        return cls(horizontal_obj, vertical_obj)


class TwoDimensionalObject(object):
    """Adds a couple useful methods to its subclasses, nothing fancy.
    """
    @classmethod
    # TODO - highly cachable. Should use WeakValueDictionary here to return
    # flyweights, not new objects.
    def from_xml_attribute(cls, attribute):
        """Instantiate the class from a value of the type "4px" or "5%"
        or any number concatenated with a measuring unit (member of UnitEnum)

        :type attribute: unicode
        """
        horizontal, vertical = six.text_type(attribute).split(' ')
        horizontal = Size.from_string(horizontal)
        vertical = Size.from_string(vertical)

        return cls(horizontal, vertical)


class Stretch(TwoDimensionalObject):
    """Used for specifying the extent of a rectangle (how much it stretches),
    or the padding in a rectangle (how much space should be left empty until
    text can be displayed)
    """
    def __init__(self, horizontal, vertical):
        """Use the .from_xxx methods. They know what's best for you.

        :type horizontal: Size
        :type vertical: Size
        """
        for parameter in [horizontal, vertical]:
            if not isinstance(parameter, Size):
                raise ValueError("Stretch must be initialized with two valid "
                                 "Size objects.")
        self.horizontal = horizontal
        self.vertical = vertical

    def is_measured_in(self, measure_unit):
        """Whether the stretch is only measured in the provided units

        :param measure_unit: a UnitEnum member
        :return: True/False
        """
        return (
            self.horizontal.unit == measure_unit and
            self.vertical.unit == measure_unit
        )

    def __repr__(self):
        return '<Stretch ({horizontal}, {vertical})>'.format(
            horizontal=self.horizontal, vertical=self.vertical
        )

    def serialized(self):
        """Returns a tuple of the useful attributes of this object"""
        return (
            None if not self.horizontal else self.horizontal.serialized(),
            None if not self.vertical else self.vertical.serialized()
        )

    def __eq__(self, other):
        return (
            other and
            type(self) == type(other) and
            self.horizontal == other.horizontal and
            self.vertical == other.vertical
        )

    def __hash__(self):
        return hash(
            hash(self.horizontal) * 59 +
            hash(self.vertical) * 61 +
            67
        )

    def __bool__(self):
        return True if self.horizontal or self.vertical else False

    def to_xml_attribute(self, **kwargs):
        """Returns a unicode representation of this object as an xml attribute
        """
        return '{horizontal} {vertical}'.format(
            horizontal=self.horizontal.to_xml_attribute(),
            vertical=self.vertical.to_xml_attribute()
        )

    def is_relative(self):
        """
        Returns True if all dimensions are expressed as percentages,
        False otherwise.
        """
        is_relative = True
        if self.horizontal:
            is_relative &= self.horizontal.is_relative()
        if self.vertical:
            is_relative &= self.vertical.is_relative()
        return is_relative

    def as_percentage_of(self, video_width, video_height):
        """
        Converts absolute units (e.g. px, pt etc) to percentage
        """
        return Stretch(
            self.horizontal.as_percentage_of(video_width=video_width),
            self.vertical.as_percentage_of(video_height=video_height)
        )


class Region(object):
    """Represents the spatial coordinates of a rectangle

    Don't instantiate by hand. use Region.from_points or Region.from_extent
    """
    @classmethod
    def from_points(cls, p1, p2):
        """Create a rectangle, knowing 2 points on the plane.
        We assume that p1 is in the upper left (closer to the origin)

        :param p1: Point instance
        :param p2: Point instance
        :return: a Point instance
        """
        inst = cls()
        inst._p1 = p1
        inst._p2 = p2
        return inst

    @classmethod
    def from_extent(cls, extent, origin):
        """Create a rectangle, knowing its upper left origin, and
        spatial extension

        :type extent: Stretch
        :type origin: Point
        :return: a Point instance
        """
        inst = cls()
        inst._extent = extent
        inst._origin = origin
        return inst

    @property
    def extent(self):
        """How wide this rectangle stretches (horizontally and vertically)
        """
        if hasattr(self, '_extent'):
            return self._extent
        else:
            return self._p1 - self._p2

    @property
    def origin(self):
        """Out of its 4 points, returns the one closest to the origin
        """
        if hasattr(self, '_origin'):
            return self._origin
        else:
            return Point.align_from_origin(self._p1, self._p2)[0]

    upper_left_point = origin

    @property
    def lower_right_point(self):
        """The point furthest from the origin from the rectangle's 4 points
        """
        if hasattr(self, '_p2'):
            return Point.align_from_origin(self._p1, self._p2)[1]
        else:
            return self.origin.add_extent(self.extent)

    def __eq__(self, other):
        return (
            other and
            type(self) == type(other) and
            self.extent == other.extent and
            self.origin == other.origin
        )

    def __hash__(self):
        return hash(
            hash(self.origin) * 71 +
            hash(self.extent) * 73 +
            79
        )


class Point(TwoDimensionalObject):
    """Represent a point in 2d space.
    """
    def __init__(self, x, y):
        """
        :type x: Size
        :type y: Size
        """
        for parameter in [x, y]:
            if not isinstance(parameter, Size):
                raise ValueError("Point must be initialized with two valid "
                                 "Size objects.")
        self.x = x
        self.y = y

    def __sub__(self, other):
        """Returns an Stretch object, if the other point's units are compatible
        """
        return Stretch(abs(self.x - other.x), abs(self.y - other.y))

    def add_stretch(self, stretch):
        """Returns another Point instance, whose coordinates are the sum of the
         current Point's, and the Stretch instance's.
        """
        return Point(self.x + stretch.horizontal, self.y + stretch.vertical)

    def is_relative(self):
        """
        Returns True if all dimensions are expressed as percentages,
        False otherwise.
        """
        is_relative = True
        if self.x:
            is_relative &= self.x.is_relative()
        if self.y:
            is_relative &= self.y.is_relative()
        return is_relative

    def as_percentage_of(self, video_width, video_height):
        """
        Converts absolute units (e.g. px, pt etc) to percentage
        """
        return Point(
            self.x.as_percentage_of(video_width=video_width),
            self.y.as_percentage_of(video_height=video_height)
        )

    @classmethod
    def align_from_origin(cls, p1, p2):
        """Returns a tuple of 2 points. The first is closest to the origin
        on both axes than the second.

        If the 2 points fulfill this condition, returns them (ordered), if not,
        creates 2 new points.
        """
        if p1.x <= p2.x and p1.y <= p2.y:
            return p1
        if p1.x >= p2.x and p1.y >= p2.y:
            return p2
        else:
            return (Point(min(p1.x, p2.x), min(p1.y, p2.y)),
                    Point(max(p1.x, p2.x), max(p1.y, p2.y)))

    def __repr__(self):
        return '<Point ({x}, {y})>'.format(
            x=self.x, y=self.y
        )

    def serialized(self):
        """Returns the "useful" values of this object.
        """
        return (
            None if not self.x else self.x.serialized(),
            None if not self.y else self.y.serialized()
        )

    def __eq__(self, other):
        return (
            other and
            type(self) == type(other) and
            self.x == other.x and
            self.y == other.y
        )

    def __hash__(self):
        return hash(
            hash(self.x) * 51 +
            hash(self.y) * 53 +
            57
        )

    def __bool__(self):
        return True if self.x or self.y else False

    def to_xml_attribute(self, **kwargs):
        """Returns a unicode representation of this object as an xml attribute
        """
        return '{x} {y}'.format(
            x=self.x.to_xml_attribute(), y=self.y.to_xml_attribute())


@six.python_2_unicode_compatible
class Size(object):
    """Ties together a number with a unit, to represent a size.

    Use as value objects! (don't change after creation)
    """
    def __init__(self, value, unit):
        """
        :param value: A number (float or int will do)
        :param unit: A UnitEnum member
        """
        if value is None:
            raise ValueError("Size must be initialized with a value.")

        self.value = float(value)
        self.unit = unit

    def __sub__(self, other):
        if self.unit == other.unit:
            return Size(self.value - other.value, self.unit)
        else:
            raise ValueError("The sizes should have the same measure units.")

    def __abs__(self):
        return Size(abs(self.value), self.unit)

    def __cmp__(self, other):
        if self.unit == other.unit:
            # python3 does not have cmp
            return (self.value > other.value) - (self.value < other.value)
        else:
            raise ValueError("The sizes should have the same measure units.")

    def __lt__(self, other):
        return self.value < other.value


    def __add__(self, other):
        if self.unit == other.unit:
            return Size(self.value + other.value, self.unit)
        else:
            raise ValueError("The sizes should have the same measure units.")

    def is_relative(self):
        """
        Returns True if value is expressed as percentage, False otherwise.
        """
        return self.unit == UnitEnum.PERCENT

    def as_percentage_of(self, video_width=None, video_height=None):
        """
        :param video_width: An integer representing a width in pixels
        :param video_height: An integer representing a height in pixels
        """
        value = self.value
        unit = self.unit

        if unit == UnitEnum.PERCENT:
            return self  # Nothing to do here

        # The input must be valid so that any conversion can be done
        if not (video_width or video_height):
            raise RelativizationError(
                "Either video width or height must be given as a reference")
        elif video_width and video_height:
            raise RelativizationError(
                "Only video width or height can be given as reference")

        if unit == UnitEnum.EM:
            # TODO: Implement proper conversion of em in function of font-size
            # The em unit is relative to the font-size, to which we currently
            # have no access. As a workaround, we presume the font-size is 16px,
            # which is a common default value but not guaranteed.
            value *= 16
            unit = UnitEnum.PIXEL

        if unit == UnitEnum.PT:
            # XXX: we will convert first to "px" and from "px" this will be
            # converted to percent. we don't take into consideration the
            # font-size
            value = value / 72.0 * 96.0
            unit = UnitEnum.PIXEL

        if unit == UnitEnum.PIXEL:
            value = value * 100.0 / (video_width or video_height)
            unit = UnitEnum.PERCENT

        if unit == UnitEnum.CELL:
            # TODO: Implement proper cell resolution
            # (w3.org/TR/ttaf1-dfxp/#parameter-attribute-cellResolution)
            # For now we will use the default values (32 columns and 15 rows)
            cell_reference = 32 if video_width else 15
            value = value * 100.0 / cell_reference
            unit = UnitEnum.PERCENT

        return Size(value, unit)

    @classmethod
    # TODO - this also looks highly cachable. Should use a WeakValueDict here
    # to return flyweights
    def from_string(cls, string):
        """Given a string of the form "46px" or "5%" etc., returns the proper
        size object

        :param string: a number concatenated to any of the UnitEnum members.
        :type string: unicode
        :rtype: Size
        """

        units = [UnitEnum.CELL, UnitEnum.PERCENT, UnitEnum.PIXEL,
                 UnitEnum.EM, UnitEnum.PT]

        raw_number = string
        for unit in units:
            if raw_number.endswith(unit):
                raw_number = raw_number.rstrip(unit)
                break
        else:
            unit = None

        if unit is not None:
            value = None
            try:
                value = float(raw_number)
                value = int(raw_number)
            except ValueError:
                pass

            if value is None:
                raise ValueError(
                    """Couldn't recognize the value "{value}" as a number"""
                    .format(value=raw_number)
                )
            instance = cls(value, unit)
            return instance
        else:
            raise ValueError(
                "The specified value is not valid because its unit "
                "is not recognized: {value}. "
                "The only supported units are: {supported}"
                .format(value=raw_number, supported=', '.join(UnitEnum._member_map_))
            )

    def __repr__(self):
        return '<Size ({value} {unit})>'.format(
            value=self.value, unit=self.unit
        )

    def __str__(self):
        value = round(self.value, 2)
        if value.is_integer():
            s = "{}".format(int(value))
        else:
            s = "{:.2f}".format(value).rstrip('0').rstrip('.')
        return "{}{}".format(s, self.unit)

    def to_xml_attribute(self, **kwargs):
        """Returns a unicode representation of this object, as an xml attribute
        """
        return six.text_type(self)

    def serialized(self):
        """Returns the "useful" values of this object"""
        return self.value, self.unit

    def __eq__(self, other):
        return (
            other and
            type(self) == type(other) and
            self.value == other.value and
            self.unit == other.unit
        )

    def __hash__(self):
        return hash(
            hash(self.value) * 41 +
            hash(self.unit) * 43 +
            47
        )

    def __bool__(self):
        return self.value is not None


class Padding(object):
    """Represents padding information. Consists of 4 Size objects, representing
    padding from (in this order): before (up), after (down), start (left) and
    end (right).

    A valid Padding object must always have all paddings set and different from
    None. If this is not true Writers may fail for they rely on this assumption.
    """
    def __init__(self, before=None, after=None, start=None, end=None):
        """
        :type before: Size
        :type after: Size
        :type start: Size
        :type end: Size
        """
        self.before = before  # top
        self.after = after  # bottom
        self.start = start  # left
        self.end = end  # right

        for attr in ['before', 'after', 'start', 'end']:
            # Ensure that a Padding object always explicitly defines all
            # four possible paddings
            if not isinstance(getattr(self, attr), Size):
                # Sets default padding (0%)
                setattr(self, attr, Size(0, UnitEnum.PERCENT))

    @classmethod
    def from_xml_attribute(cls, attribute):
        """As per the docs, the style attribute can contain 1,2,3 or 4 values.

        If 1 value: apply to all edges
        If 2: first applies to before and after, second to start and end
        If 3: first applies to before, second to start and end, third to after
        If 4: before, end, after, start;

        http://www.w3.org/TR/ttaf1-dfxp/#style-attribute-padding

        :param attribute: a string like object, representing a dfxp attr. value
        :return: a Padding object
        """
        values_list = six.text_type(attribute).split(' ')
        sizes = []

        for value in values_list:
            sizes.append(Size.from_string(value))

        if len(sizes) == 1:
            return cls(sizes[0], sizes[0], sizes[0], sizes[0])
        elif len(sizes) == 2:
            return cls(sizes[0], sizes[0], sizes[1], sizes[1])
        elif len(sizes) == 3:
            return cls(sizes[0], sizes[2], sizes[1], sizes[1])
        elif len(sizes) == 4:
            return cls(sizes[0], sizes[2], sizes[3], sizes[1])
        else:
            raise ValueError('The provided value "{value}" could not be '
                             "parsed into the a padding. Check out "
                             "http://www.w3.org/TR/ttaf1-dfxp/"
                             "#style-attribute-padding for the definition "
                             "and examples".format(value=attribute))

    def __repr__(self):
        return (
            "<Padding (before: {before}, after: {after}, start: {start}, "
            "end: {end})>".format(
                before=self.before, after=self.after, start=self.start,
                end=self.end
            )
        )

    def serialized(self):
        """Returns a tuple containing the useful values of this object
        """
        return (
            None if not self.before else self.before.serialized(),
            None if not self.after else self.after.serialized(),
            None if not self.start else self.start.serialized(),
            None if not self.end else self.end.serialized()
        )

    def __eq__(self, other):
        return (
            other and
            type(self) == type(other) and
            self.before == other.before and
            self.after == other.after and
            self.start == other.start and
            self.end == other.end
        )

    def __hash__(self):
        return hash(
            hash(self.before) * 19 +
            hash(self.after) * 23 +
            hash(self.start) * 29 +
            hash(self.end) * 31 +
            37
        )

    def to_xml_attribute(
            self, attribute_order=('before', 'end', 'after', 'start'),
            **kwargs):
        """Returns a unicode representation of this object as an xml attribute

        TODO - should extend the attribute_order tuple to contain 4 tuples,
        so we can reduce the output length to 3, 2 or 1 element.

        :type attribute_order: tuple
        :param attribute_order: the order that the attributes should be
            serialized
        """
        try:
            string_list = []
            for attrib in attribute_order:
                if hasattr(self, attrib):
                    string_list.append(
                        getattr(self, attrib).to_xml_attribute())
        except AttributeError:
            # A Padding object with attributes set to None is considered
            # invalid. All four possible paddings must be set. If one of them
            # is not, this error is raised.
            raise ValueError("The attribute order specified is invalid.")

        return ' '.join(string_list)

    def as_percentage_of(self, video_width, video_height):
        return Padding(
            self.before.as_percentage_of(video_height=video_height),
            self.after.as_percentage_of(video_height=video_height),
            self.start.as_percentage_of(video_width=video_width),
            self.end.as_percentage_of(video_width=video_width)
        )

    def is_relative(self):
        is_relative = True
        if self.before:
            is_relative &= self.before.is_relative()
        if self.after:
            is_relative &= self.after.is_relative()
        if self.start:
            is_relative &= self.start.is_relative()
        if self.end:
            is_relative &= self.end.is_relative()
        return is_relative


class Layout(object):
    """Should encapsulate all the information needed to determine (as correctly
    as possible) the layout (positioning) of elements on the screen.

     Inheritance of this property, from the CaptionSet to its children is
     specific for each caption type.
    """
    def __init__(self, origin=None, extent=None, padding=None, alignment=None,
                 webvtt_positioning=None, inherit_from=None):
        """
        :type origin: Point
        :param origin: The point on the screen which is the top left vertex
            of a rectangular region where the captions should be placed

        :type extent: Stretch
        :param extent: The width and height of the rectangle where the caption
            should be placed on the screen.

        :type padding: Padding
        :param padding: The padding of the text inside the region described
            by the origin and the extent

        :type alignment: Alignment

        :type webvtt_positioning: unicode
        :param webvtt_positioning: A string with the raw WebVTT cue settings.
            This is used so that WebVTT positioning isn't lost on conversion
            from WebVTT to WebVTT. It is needed only because pycaption
            currently doesn't support reading positioning from WebVTT.

        :type inherit_from: Layout
        :param inherit_from: A Layout with the positioning parameters to be
            used if not specified by the positioning arguments,
        """

        self.origin = origin
        self.extent = extent
        self.padding = padding
        self.alignment = alignment
        self.webvtt_positioning = webvtt_positioning

        if inherit_from:
            for attr_name in ['origin', 'extent', 'padding', 'alignment']:
                attr = getattr(self, attr_name)
                if not attr:
                    setattr(self, attr_name, getattr(inherit_from, attr_name))

    def __bool__(self):
        return any([
            self.origin, self.extent, self.padding, self.alignment,
            self.webvtt_positioning
        ])

    def __repr__(self):
        return (
            "<Layout (origin: {origin}, extent: {extent}, "
            "padding: {padding}, alignment: {alignment})>".format(
                origin=self.origin, extent=self.extent, padding=self.padding,
                alignment=self.alignment
            )
        )

    def serialized(self):
        """Returns nested tuple containing the "useful" values of this object
        """
        return (
            None if not self.origin else self.origin.serialized(),
            None if not self.extent else self.extent.serialized(),
            None if not self.padding else self.padding.serialized(),
            None if not self.alignment else self.alignment.serialized()
        )

    def __eq__(self, other):
        return (
            type(self) == type(other) and
            self.origin == other.origin and
            self.extent == other.extent and
            self.padding == other.padding and
            self.alignment == other.alignment
        )

    def __ne__(self, other):
        return not self == other

    def __hash__(self):
        return hash(
            hash(self.origin) * 7
            + hash(self.extent) * 11
            + hash(self.padding) * 13
            + hash(self.alignment) * 5
            + 17
        )

    def is_relative(self):
        """
        Returns True if all positioning values are expressed as percentages,
        False otherwise.
        """
        is_relative = True
        if self.origin:
            is_relative &= self.origin.is_relative()
        if self.extent:
            is_relative &= self.extent.is_relative()
        if self.padding:
            is_relative &= self.padding.is_relative()
        return is_relative

    def as_percentage_of(self, video_width, video_height):
        params = {'alignment': self.alignment}
        # We don't need to preserve webvtt_positioning on Layout
        # transformations because, if it is set, the WebVTT writer
        # returns as soon as it's found and the transformations are
        # never triggered.
        for attr_name in ['origin', 'extent', 'padding']:
            attr = getattr(self, attr_name)
            if attr:
                params[attr_name] = attr.as_percentage_of(video_width,
                                                          video_height)
        return Layout(**params)

    def fit_to_screen(self):
        """
        If extent is not set or if origin + extent > 100%, (re)calculate it
        based on origin. It is a pycaption fix for caption files that are
        technically valid but contain inconsistent settings that may cause
        long captions to be cut out of the screen.

        ATTENTION: This must be called on relativized objects (such as the one
        returned by as_percentage_of). All units are presumed to be percentages.
        """

        if self.origin:
            # Calculated values to be used if replacement is needed
            diff_horizontal = Size(100 - self.origin.x.value, UnitEnum.PERCENT)
            diff_vertical = Size(100 - self.origin.y.value, UnitEnum.PERCENT)
            if not self.extent:
                # Extent is not set, use the calculated values
                new_extent = Stretch(diff_horizontal, diff_vertical)
            else:
                # Extent is set but may have inconsistent values,
                # e.g. origin="35% 25%" extent="80% 80%", which would cause
                # captions to end horizontally at 115% and vertically at 105%,
                # which would result in them being cut out of the screen.
                # In this case, the horizontal and vertical values are
                # corrected so that origin + extent = 100%.
                bottom_right = self.origin.add_stretch(self.extent)

                found_absolute_unit = False
                if bottom_right.x.unit != UnitEnum.PERCENT:
                    found_absolute_unit = True
                elif bottom_right.x.unit != UnitEnum.PERCENT:
                    found_absolute_unit = True

                if found_absolute_unit:
                    raise ValueError("Units must be relativized before extent "
                                     "can be calculated based on origin.")

                new_horizontal = self.extent.horizontal
                new_vertical = self.extent.vertical
                # If extent is set but it's inconsistent, replace with
                # calculated values
                if bottom_right.x.value > 100:
                    new_horizontal = diff_horizontal
                if bottom_right.y.value > 100:
                    new_vertical = diff_vertical

                new_extent = Stretch(new_horizontal, new_vertical)

            return Layout(
                origin=self.origin,
                extent=new_extent,
                padding=self.padding,
                alignment=self.alignment
                # We don't need to preserve webvtt_positioning on Layout
                # transformations because, if it is set, the WebVTT writer
                # returns as soon as it's found and the transformations are
                # never triggered.
            )

        return self




############################################################
### File: grange.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2012-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS GENERATE range conversion."""

import dns

def from_text(text):
    """Convert the text form of a range in a ``$GENERATE`` statement to an
    integer.

    *text*, a ``str``, the textual range in ``$GENERATE`` form.

    Returns a tuple of three ``int`` values ``(start, stop, step)``.
    """

    # TODO, figure out the bounds on start, stop and step.
    step = 1
    cur = ''
    state = 0
    # state   0 1 2 3 4
    #         x - y / z

    if text and text[0] == '-':
        raise dns.exception.SyntaxError("Start cannot be a negative number")

    for c in text:
        if c == '-' and state == 0:
            start = int(cur)
            cur = ''
            state = 2
        elif c == '/':
            stop = int(cur)
            cur = ''
            state = 4
        elif c.isdigit():
            cur += c
        else:
            raise dns.exception.SyntaxError("Could not parse %s" % (c))

    if state in (1, 3):
        raise dns.exception.SyntaxError()

    if state == 2:
        stop = int(cur)

    if state == 4:
        step = int(cur)

    assert step >= 1
    assert start >= 0
    assert start <= stop
    # TODO, can start == stop?

    return (start, stop, step)




############################################################
### File: gtoken.py
############################################################
# -*- coding: utf-8 -*-
import ast
import math
import re
import time

from six import PY3
from googletrans.utils import rshift


class TokenAcquirer(object):
    """Google Translate API token generator

    translate.google.com uses a token to authorize the requests. If you are
    not Google, you do have this token and will have to pay for use.
    This class is the result of reverse engineering on the obfuscated and
    minified code used by Google to generate such token.

    The token is based on a seed which is updated once per hour and on the
    text that will be translated.
    Both are combined - by some strange math - in order to generate a final
    token (e.g. 744915.856682) which is used by the API to validate the
    request.

    This operation will cause an additional request to get an initial
    token from translate.google.com.

    Example usage:
        >>> from googletrans.gtoken import TokenAcquirer
        >>> acquirer = TokenAcquirer()
        >>> text = 'test'
        >>> tk = acquirer.do(text)
        >>> tk
        950629.577246
    """

    RE_TKK = re.compile(r'tkk:\'(.+?)\'', re.DOTALL)
    RE_RAWTKK = re.compile(r'tkk:\'(.+?)\'', re.DOTALL)

    def __init__(self, client, tkk='0', host='translate.google.com'):
        self.client = client
        self.tkk = tkk
        self.host = host if 'http' in host else 'https://' + host

    def _update(self):
        """update tkk
        """
        # we don't need to update the base TKK value when it is still valid
        now = math.floor(int(time.time() * 1000) / 3600000.0)
        if self.tkk and int(self.tkk.split('.')[0]) == now:
            return

        r = self.client.get(self.host)

        raw_tkk = self.RE_TKK.search(r.text)
        if raw_tkk:
            self.tkk = raw_tkk.group(1)
            return

        try:
            # this will be the same as python code after stripping out a reserved word 'var'
            code = unicode(self.RE_TKK.search(r.text).group(1)).replace('var ', '')
            # unescape special ascii characters such like a \x3d(=)
            if PY3:  # pragma: no cover
                code = code.encode().decode('unicode-escape')
            else:  # pragma: no cover
                code = code.decode('string_escape')
        except AttributeError:
            raise Exception('Could not find TKK token for this request.\nSee https://github.com/ssut/py-googletrans/issues/234 for more details.')
        except:
            raise

        if code:
            tree = ast.parse(code)
            visit_return = False
            operator = '+'
            n, keys = 0, dict(a=0, b=0)
            for node in ast.walk(tree):
                if isinstance(node, ast.Assign):
                    name = node.targets[0].id
                    if name in keys:
                        if isinstance(node.value, ast.Num):
                            keys[name] = node.value.n
                        # the value can sometimes be negative
                        elif isinstance(node.value, ast.UnaryOp) and \
                                isinstance(node.value.op, ast.USub):  # pragma: nocover
                            keys[name] = -node.value.operand.n
                elif isinstance(node, ast.Return):
                    # parameters should be set after this point
                    visit_return = True
                elif visit_return and isinstance(node, ast.Num):
                    n = node.n
                elif visit_return and n > 0:
                    # the default operator is '+' but implement some more for
                    # all possible scenarios
                    if isinstance(node, ast.Add):  # pragma: nocover
                        pass
                    elif isinstance(node, ast.Sub):  # pragma: nocover
                        operator = '-'
                    elif isinstance(node, ast.Mult):  # pragma: nocover
                        operator = '*'
                    elif isinstance(node, ast.Pow):  # pragma: nocover
                        operator = '**'
                    elif isinstance(node, ast.BitXor):  # pragma: nocover
                        operator = '^'
            # a safety way to avoid Exceptions
            clause = compile('{1}{0}{2}'.format(
                operator, keys['a'], keys['b']), '', 'eval')
            value = eval(clause, dict(__builtin__={}))
            result = '{}.{}'.format(n, value)

            self.tkk = result

    def _lazy(self, value):
        """like lazy evaluation, this method returns a lambda function that
        returns value given.
        We won't be needing this because this seems to have been built for
        code obfuscation.

        the original code of this method is as follows:

           ... code-block: javascript

               var ek = function(a) {
                return function() {
                    return a;
                };
               }
        """
        return lambda: value

    def _xr(self, a, b):
        size_b = len(b)
        c = 0
        while c < size_b - 2:
            d = b[c + 2]
            d = ord(d[0]) - 87 if 'a' <= d else int(d)
            d = rshift(a, d) if '+' == b[c + 1] else a << d
            a = a + d & 4294967295 if '+' == b[c] else a ^ d

            c += 3
        return a

    def acquire(self, text):
        a = []
        # Convert text to ints
        for i in text:
            val = ord(i)
            if val < 0x10000:
                a += [val]
            else:
                # Python doesn't natively use Unicode surrogates, so account for those
                a += [
                    math.floor((val - 0x10000) / 0x400 + 0xD800),
                    math.floor((val - 0x10000) % 0x400 + 0xDC00)
                ]

        b = self.tkk if self.tkk != '0' else ''
        d = b.split('.')
        b = int(d[0]) if len(d) > 1 else 0

        # assume e means char code array
        e = []
        g = 0
        size = len(a)
        while g < size:
            l = a[g]
            # just append if l is less than 128(ascii: DEL)
            if l < 128:
                e.append(l)
            # append calculated value if l is less than 2048
            else:
                if l < 2048:
                    e.append(l >> 6 | 192)
                else:
                    # append calculated value if l matches special condition
                    if (l & 64512) == 55296 and g + 1 < size and \
                            a[g + 1] & 64512 == 56320:
                        g += 1
                        l = 65536 + ((l & 1023) << 10) + (a[g] & 1023)  # This bracket is important
                        e.append(l >> 18 | 240)
                        e.append(l >> 12 & 63 | 128)
                    else:
                        e.append(l >> 12 | 224)
                    e.append(l >> 6 & 63 | 128)
                e.append(l & 63 | 128)
            g += 1
        a = b
        for i, value in enumerate(e):
            a += value
            a = self._xr(a, '+-a^+6')
        a = self._xr(a, '+-3^+b+-f')
        a ^= int(d[1]) if len(d) > 1 else 0
        if a < 0:  # pragma: nocover
            a = (a & 2147483647) + 2147483648
        a %= 1000000  # int(1E6)

        return '{}.{}'.format(a, a ^ b)

    def do(self, text):
        self._update()
        tk = self.acquire(text)
        return tk




############################################################
### File: hash.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2011 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""Hashing backwards compatibility wrapper"""

import hashlib
import warnings

warnings.warn(
    "dns.hash module will be removed in future versions. Please use hashlib instead.",
    DeprecationWarning)

hashes = {}
hashes['MD5'] = hashlib.md5
hashes['SHA1'] = hashlib.sha1
hashes['SHA224'] = hashlib.sha224
hashes['SHA256'] = hashlib.sha256
hashes['SHA384'] = hashlib.sha384
hashes['SHA512'] = hashlib.sha512


def get(algorithm):
    return hashes[algorithm.upper()]




############################################################
### File: hebrewprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
#          Shy Shalom
# Portions created by the Initial Developer are Copyright (C) 2005
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetprober import CharSetProber
from .enums import ProbingState

# This prober doesn't actually recognize a language or a charset.
# It is a helper prober for the use of the Hebrew model probers

### General ideas of the Hebrew charset recognition ###
#
# Four main charsets exist in Hebrew:
# "ISO-8859-8" - Visual Hebrew
# "windows-1255" - Logical Hebrew
# "ISO-8859-8-I" - Logical Hebrew
# "x-mac-hebrew" - ?? Logical Hebrew ??
#
# Both "ISO" charsets use a completely identical set of code points, whereas
# "windows-1255" and "x-mac-hebrew" are two different proper supersets of
# these code points. windows-1255 defines additional characters in the range
# 0x80-0x9F as some misc punctuation marks as well as some Hebrew-specific
# diacritics and additional 'Yiddish' ligature letters in the range 0xc0-0xd6.
# x-mac-hebrew defines similar additional code points but with a different
# mapping.
#
# As far as an average Hebrew text with no diacritics is concerned, all four
# charsets are identical with respect to code points. Meaning that for the
# main Hebrew alphabet, all four map the same values to all 27 Hebrew letters
# (including final letters).
#
# The dominant difference between these charsets is their directionality.
# "Visual" directionality means that the text is ordered as if the renderer is
# not aware of a BIDI rendering algorithm. The renderer sees the text and
# draws it from left to right. The text itself when ordered naturally is read
# backwards. A buffer of Visual Hebrew generally looks like so:
# "[last word of first line spelled backwards] [whole line ordered backwards
# and spelled backwards] [first word of first line spelled backwards]
# [end of line] [last word of second line] ... etc' "
# adding punctuation marks, numbers and English text to visual text is
# naturally also "visual" and from left to right.
#
# "Logical" directionality means the text is ordered "naturally" according to
# the order it is read. It is the responsibility of the renderer to display
# the text from right to left. A BIDI algorithm is used to place general
# punctuation marks, numbers and English text in the text.
#
# Texts in x-mac-hebrew are almost impossible to find on the Internet. From
# what little evidence I could find, it seems that its general directionality
# is Logical.
#
# To sum up all of the above, the Hebrew probing mechanism knows about two
# charsets:
# Visual Hebrew - "ISO-8859-8" - backwards text - Words and sentences are
#    backwards while line order is natural. For charset recognition purposes
#    the line order is unimportant (In fact, for this implementation, even
#    word order is unimportant).
# Logical Hebrew - "windows-1255" - normal, naturally ordered text.
#
# "ISO-8859-8-I" is a subset of windows-1255 and doesn't need to be
#    specifically identified.
# "x-mac-hebrew" is also identified as windows-1255. A text in x-mac-hebrew
#    that contain special punctuation marks or diacritics is displayed with
#    some unconverted characters showing as question marks. This problem might
#    be corrected using another model prober for x-mac-hebrew. Due to the fact
#    that x-mac-hebrew texts are so rare, writing another model prober isn't
#    worth the effort and performance hit.
#
#### The Prober ####
#
# The prober is divided between two SBCharSetProbers and a HebrewProber,
# all of which are managed, created, fed data, inquired and deleted by the
# SBCSGroupProber. The two SBCharSetProbers identify that the text is in
# fact some kind of Hebrew, Logical or Visual. The final decision about which
# one is it is made by the HebrewProber by combining final-letter scores
# with the scores of the two SBCharSetProbers to produce a final answer.
#
# The SBCSGroupProber is responsible for stripping the original text of HTML
# tags, English characters, numbers, low-ASCII punctuation characters, spaces
# and new lines. It reduces any sequence of such characters to a single space.
# The buffer fed to each prober in the SBCS group prober is pure text in
# high-ASCII.
# The two SBCharSetProbers (model probers) share the same language model:
# Win1255Model.
# The first SBCharSetProber uses the model normally as any other
# SBCharSetProber does, to recognize windows-1255, upon which this model was
# built. The second SBCharSetProber is told to make the pair-of-letter
# lookup in the language model backwards. This in practice exactly simulates
# a visual Hebrew model using the windows-1255 logical Hebrew model.
#
# The HebrewProber is not using any language model. All it does is look for
# final-letter evidence suggesting the text is either logical Hebrew or visual
# Hebrew. Disjointed from the model probers, the results of the HebrewProber
# alone are meaningless. HebrewProber always returns 0.00 as confidence
# since it never identifies a charset by itself. Instead, the pointer to the
# HebrewProber is passed to the model probers as a helper "Name Prober".
# When the Group prober receives a positive identification from any prober,
# it asks for the name of the charset identified. If the prober queried is a
# Hebrew model prober, the model prober forwards the call to the
# HebrewProber to make the final decision. In the HebrewProber, the
# decision is made according to the final-letters scores maintained and Both
# model probers scores. The answer is returned in the form of the name of the
# charset identified, either "windows-1255" or "ISO-8859-8".

class HebrewProber(CharSetProber):
    # windows-1255 / ISO-8859-8 code points of interest
    FINAL_KAF = 0xea
    NORMAL_KAF = 0xeb
    FINAL_MEM = 0xed
    NORMAL_MEM = 0xee
    FINAL_NUN = 0xef
    NORMAL_NUN = 0xf0
    FINAL_PE = 0xf3
    NORMAL_PE = 0xf4
    FINAL_TSADI = 0xf5
    NORMAL_TSADI = 0xf6

    # Minimum Visual vs Logical final letter score difference.
    # If the difference is below this, don't rely solely on the final letter score
    # distance.
    MIN_FINAL_CHAR_DISTANCE = 5

    # Minimum Visual vs Logical model score difference.
    # If the difference is below this, don't rely at all on the model score
    # distance.
    MIN_MODEL_DISTANCE = 0.01

    VISUAL_HEBREW_NAME = "ISO-8859-8"
    LOGICAL_HEBREW_NAME = "windows-1255"

    def __init__(self):
        super(HebrewProber, self).__init__()
        self._final_char_logical_score = None
        self._final_char_visual_score = None
        self._prev = None
        self._before_prev = None
        self._logical_prober = None
        self._visual_prober = None
        self.reset()

    def reset(self):
        self._final_char_logical_score = 0
        self._final_char_visual_score = 0
        # The two last characters seen in the previous buffer,
        # mPrev and mBeforePrev are initialized to space in order to simulate
        # a word delimiter at the beginning of the data
        self._prev = ' '
        self._before_prev = ' '
        # These probers are owned by the group prober.

    def set_model_probers(self, logicalProber, visualProber):
        self._logical_prober = logicalProber
        self._visual_prober = visualProber

    def is_final(self, c):
        return c in [self.FINAL_KAF, self.FINAL_MEM, self.FINAL_NUN,
                     self.FINAL_PE, self.FINAL_TSADI]

    def is_non_final(self, c):
        # The normal Tsadi is not a good Non-Final letter due to words like
        # 'lechotet' (to chat) containing an apostrophe after the tsadi. This
        # apostrophe is converted to a space in FilterWithoutEnglishLetters
        # causing the Non-Final tsadi to appear at an end of a word even
        # though this is not the case in the original text.
        # The letters Pe and Kaf rarely display a related behavior of not being
        # a good Non-Final letter. Words like 'Pop', 'Winamp' and 'Mubarak'
        # for example legally end with a Non-Final Pe or Kaf. However, the
        # benefit of these letters as Non-Final letters outweighs the damage
        # since these words are quite rare.
        return c in [self.NORMAL_KAF, self.NORMAL_MEM,
                     self.NORMAL_NUN, self.NORMAL_PE]

    def feed(self, byte_str):
        # Final letter analysis for logical-visual decision.
        # Look for evidence that the received buffer is either logical Hebrew
        # or visual Hebrew.
        # The following cases are checked:
        # 1) A word longer than 1 letter, ending with a final letter. This is
        #    an indication that the text is laid out "naturally" since the
        #    final letter really appears at the end. +1 for logical score.
        # 2) A word longer than 1 letter, ending with a Non-Final letter. In
        #    normal Hebrew, words ending with Kaf, Mem, Nun, Pe or Tsadi,
        #    should not end with the Non-Final form of that letter. Exceptions
        #    to this rule are mentioned above in isNonFinal(). This is an
        #    indication that the text is laid out backwards. +1 for visual
        #    score
        # 3) A word longer than 1 letter, starting with a final letter. Final
        #    letters should not appear at the beginning of a word. This is an
        #    indication that the text is laid out backwards. +1 for visual
        #    score.
        #
        # The visual score and logical score are accumulated throughout the
        # text and are finally checked against each other in GetCharSetName().
        # No checking for final letters in the middle of words is done since
        # that case is not an indication for either Logical or Visual text.
        #
        # We automatically filter out all 7-bit characters (replace them with
        # spaces) so the word boundary detection works properly. [MAP]

        if self.state == ProbingState.NOT_ME:
            # Both model probers say it's not them. No reason to continue.
            return ProbingState.NOT_ME

        byte_str = self.filter_high_byte_only(byte_str)

        for cur in byte_str:
            if cur == ' ':
                # We stand on a space - a word just ended
                if self._before_prev != ' ':
                    # next-to-last char was not a space so self._prev is not a
                    # 1 letter word
                    if self.is_final(self._prev):
                        # case (1) [-2:not space][-1:final letter][cur:space]
                        self._final_char_logical_score += 1
                    elif self.is_non_final(self._prev):
                        # case (2) [-2:not space][-1:Non-Final letter][
                        #  cur:space]
                        self._final_char_visual_score += 1
            else:
                # Not standing on a space
                if ((self._before_prev == ' ') and
                        (self.is_final(self._prev)) and (cur != ' ')):
                    # case (3) [-2:space][-1:final letter][cur:not space]
                    self._final_char_visual_score += 1
            self._before_prev = self._prev
            self._prev = cur

        # Forever detecting, till the end or until both model probers return
        # ProbingState.NOT_ME (handled above)
        return ProbingState.DETECTING

    @property
    def charset_name(self):
        # Make the decision: is it Logical or Visual?
        # If the final letter score distance is dominant enough, rely on it.
        finalsub = self._final_char_logical_score - self._final_char_visual_score
        if finalsub >= self.MIN_FINAL_CHAR_DISTANCE:
            return self.LOGICAL_HEBREW_NAME
        if finalsub <= -self.MIN_FINAL_CHAR_DISTANCE:
            return self.VISUAL_HEBREW_NAME

        # It's not dominant enough, try to rely on the model scores instead.
        modelsub = (self._logical_prober.get_confidence()
                    - self._visual_prober.get_confidence())
        if modelsub > self.MIN_MODEL_DISTANCE:
            return self.LOGICAL_HEBREW_NAME
        if modelsub < -self.MIN_MODEL_DISTANCE:
            return self.VISUAL_HEBREW_NAME

        # Still no good, back to final letter distance, maybe it'll save the
        # day.
        if finalsub < 0.0:
            return self.VISUAL_HEBREW_NAME

        # (finalsub > 0 - Logical) or (don't know what to do) default to
        # Logical.
        return self.LOGICAL_HEBREW_NAME

    @property
    def language(self):
        return 'Hebrew'

    @property
    def state(self):
        # Remain active as long as any of the model probers are active.
        if (self._logical_prober.state == ProbingState.NOT_ME) and \
           (self._visual_prober.state == ProbingState.NOT_ME):
            return ProbingState.NOT_ME
        return ProbingState.DETECTING




############################################################
### File: help.py
############################################################
"""Module containing bug report helper(s)."""
from __future__ import print_function

import json
import platform
import sys
import ssl

import idna
import urllib3

from . import __version__ as requests_version

try:
    import charset_normalizer
except ImportError:
    charset_normalizer = None

try:
    import chardet
except ImportError:
    chardet = None

try:
    from urllib3.contrib import pyopenssl
except ImportError:
    pyopenssl = None
    OpenSSL = None
    cryptography = None
else:
    import OpenSSL
    import cryptography


def _implementation():
    """Return a dict with the Python implementation and version.

    Provide both the name and the version of the Python implementation
    currently running. For example, on CPython 2.7.5 it will return
    {'name': 'CPython', 'version': '2.7.5'}.

    This function works best on CPython and PyPy: in particular, it probably
    doesn't work for Jython or IronPython. Future investigation should be done
    to work out the correct shape of the code for those platforms.
    """
    implementation = platform.python_implementation()

    if implementation == 'CPython':
        implementation_version = platform.python_version()
    elif implementation == 'PyPy':
        implementation_version = '%s.%s.%s' % (sys.pypy_version_info.major,
                                               sys.pypy_version_info.minor,
                                               sys.pypy_version_info.micro)
        if sys.pypy_version_info.releaselevel != 'final':
            implementation_version = ''.join([
                implementation_version, sys.pypy_version_info.releaselevel
            ])
    elif implementation == 'Jython':
        implementation_version = platform.python_version()  # Complete Guess
    elif implementation == 'IronPython':
        implementation_version = platform.python_version()  # Complete Guess
    else:
        implementation_version = 'Unknown'

    return {'name': implementation, 'version': implementation_version}


def info():
    """Generate information for a bug report."""
    try:
        platform_info = {
            'system': platform.system(),
            'release': platform.release(),
        }
    except IOError:
        platform_info = {
            'system': 'Unknown',
            'release': 'Unknown',
        }

    implementation_info = _implementation()
    urllib3_info = {'version': urllib3.__version__}
    charset_normalizer_info = {'version': None}
    chardet_info = {'version': None}
    if charset_normalizer:
        charset_normalizer_info = {'version': charset_normalizer.__version__}
    if chardet:
        chardet_info = {'version': chardet.__version__}

    pyopenssl_info = {
        'version': None,
        'openssl_version': '',
    }
    if OpenSSL:
        pyopenssl_info = {
            'version': OpenSSL.__version__,
            'openssl_version': '%x' % OpenSSL.SSL.OPENSSL_VERSION_NUMBER,
        }
    cryptography_info = {
        'version': getattr(cryptography, '__version__', ''),
    }
    idna_info = {
        'version': getattr(idna, '__version__', ''),
    }

    system_ssl = ssl.OPENSSL_VERSION_NUMBER
    system_ssl_info = {
        'version': '%x' % system_ssl if system_ssl is not None else ''
    }

    return {
        'platform': platform_info,
        'implementation': implementation_info,
        'system_ssl': system_ssl_info,
        'using_pyopenssl': pyopenssl is not None,
        'using_charset_normalizer': chardet is None,
        'pyOpenSSL': pyopenssl_info,
        'urllib3': urllib3_info,
        'chardet': chardet_info,
        'charset_normalizer': charset_normalizer_info,
        'cryptography': cryptography_info,
        'idna': idna_info,
        'requests': {
            'version': requests_version,
        },
    }


def main():
    """Pretty-print the bug information as JSON."""
    print(json.dumps(info(), sort_keys=True, indent=2))


if __name__ == '__main__':
    main()




############################################################
### File: hooks.py
############################################################
# -*- coding: utf-8 -*-

"""
requests.hooks
~~~~~~~~~~~~~~

This module provides the capabilities for the Requests hooks system.

Available hooks:

``response``:
    The response generated from a Request.
"""
HOOKS = ['response']


def default_hooks():
    return {event: [] for event in HOOKS}

# TODO: response is the only one


def dispatch_hook(key, hooks, hook_data, **kwargs):
    """Dispatches a hook dictionary on a given piece of data."""
    hooks = hooks or {}
    hooks = hooks.get(key)
    if hooks:
        if hasattr(hooks, '__call__'):
            hooks = [hooks]
        for hook in hooks:
            _hook_data = hook(hook_data, **kwargs)
            if _hook_data is not None:
                hook_data = _hook_data
    return hook_data




############################################################
### File: idnadata.py
############################################################
# This file is automatically generated by tools/idna-data

__version__ = "13.0.0"
scripts = {
    'Greek': (
        0x37000000374,
        0x37500000378,
        0x37a0000037e,
        0x37f00000380,
        0x38400000385,
        0x38600000387,
        0x3880000038b,
        0x38c0000038d,
        0x38e000003a2,
        0x3a3000003e2,
        0x3f000000400,
        0x1d2600001d2b,
        0x1d5d00001d62,
        0x1d6600001d6b,
        0x1dbf00001dc0,
        0x1f0000001f16,
        0x1f1800001f1e,
        0x1f2000001f46,
        0x1f4800001f4e,
        0x1f5000001f58,
        0x1f5900001f5a,
        0x1f5b00001f5c,
        0x1f5d00001f5e,
        0x1f5f00001f7e,
        0x1f8000001fb5,
        0x1fb600001fc5,
        0x1fc600001fd4,
        0x1fd600001fdc,
        0x1fdd00001ff0,
        0x1ff200001ff5,
        0x1ff600001fff,
        0x212600002127,
        0xab650000ab66,
        0x101400001018f,
        0x101a0000101a1,
        0x1d2000001d246,
    ),
    'Han': (
        0x2e8000002e9a,
        0x2e9b00002ef4,
        0x2f0000002fd6,
        0x300500003006,
        0x300700003008,
        0x30210000302a,
        0x30380000303c,
        0x340000004dc0,
        0x4e0000009ffd,
        0xf9000000fa6e,
        0xfa700000fada,
        0x16ff000016ff2,
        0x200000002a6de,
        0x2a7000002b735,
        0x2b7400002b81e,
        0x2b8200002cea2,
        0x2ceb00002ebe1,
        0x2f8000002fa1e,
        0x300000003134b,
    ),
    'Hebrew': (
        0x591000005c8,
        0x5d0000005eb,
        0x5ef000005f5,
        0xfb1d0000fb37,
        0xfb380000fb3d,
        0xfb3e0000fb3f,
        0xfb400000fb42,
        0xfb430000fb45,
        0xfb460000fb50,
    ),
    'Hiragana': (
        0x304100003097,
        0x309d000030a0,
        0x1b0010001b11f,
        0x1b1500001b153,
        0x1f2000001f201,
    ),
    'Katakana': (
        0x30a1000030fb,
        0x30fd00003100,
        0x31f000003200,
        0x32d0000032ff,
        0x330000003358,
        0xff660000ff70,
        0xff710000ff9e,
        0x1b0000001b001,
        0x1b1640001b168,
    ),
}
joining_types = {
    0x600: 85,
    0x601: 85,
    0x602: 85,
    0x603: 85,
    0x604: 85,
    0x605: 85,
    0x608: 85,
    0x60b: 85,
    0x620: 68,
    0x621: 85,
    0x622: 82,
    0x623: 82,
    0x624: 82,
    0x625: 82,
    0x626: 68,
    0x627: 82,
    0x628: 68,
    0x629: 82,
    0x62a: 68,
    0x62b: 68,
    0x62c: 68,
    0x62d: 68,
    0x62e: 68,
    0x62f: 82,
    0x630: 82,
    0x631: 82,
    0x632: 82,
    0x633: 68,
    0x634: 68,
    0x635: 68,
    0x636: 68,
    0x637: 68,
    0x638: 68,
    0x639: 68,
    0x63a: 68,
    0x63b: 68,
    0x63c: 68,
    0x63d: 68,
    0x63e: 68,
    0x63f: 68,
    0x640: 67,
    0x641: 68,
    0x642: 68,
    0x643: 68,
    0x644: 68,
    0x645: 68,
    0x646: 68,
    0x647: 68,
    0x648: 82,
    0x649: 68,
    0x64a: 68,
    0x66e: 68,
    0x66f: 68,
    0x671: 82,
    0x672: 82,
    0x673: 82,
    0x674: 85,
    0x675: 82,
    0x676: 82,
    0x677: 82,
    0x678: 68,
    0x679: 68,
    0x67a: 68,
    0x67b: 68,
    0x67c: 68,
    0x67d: 68,
    0x67e: 68,
    0x67f: 68,
    0x680: 68,
    0x681: 68,
    0x682: 68,
    0x683: 68,
    0x684: 68,
    0x685: 68,
    0x686: 68,
    0x687: 68,
    0x688: 82,
    0x689: 82,
    0x68a: 82,
    0x68b: 82,
    0x68c: 82,
    0x68d: 82,
    0x68e: 82,
    0x68f: 82,
    0x690: 82,
    0x691: 82,
    0x692: 82,
    0x693: 82,
    0x694: 82,
    0x695: 82,
    0x696: 82,
    0x697: 82,
    0x698: 82,
    0x699: 82,
    0x69a: 68,
    0x69b: 68,
    0x69c: 68,
    0x69d: 68,
    0x69e: 68,
    0x69f: 68,
    0x6a0: 68,
    0x6a1: 68,
    0x6a2: 68,
    0x6a3: 68,
    0x6a4: 68,
    0x6a5: 68,
    0x6a6: 68,
    0x6a7: 68,
    0x6a8: 68,
    0x6a9: 68,
    0x6aa: 68,
    0x6ab: 68,
    0x6ac: 68,
    0x6ad: 68,
    0x6ae: 68,
    0x6af: 68,
    0x6b0: 68,
    0x6b1: 68,
    0x6b2: 68,
    0x6b3: 68,
    0x6b4: 68,
    0x6b5: 68,
    0x6b6: 68,
    0x6b7: 68,
    0x6b8: 68,
    0x6b9: 68,
    0x6ba: 68,
    0x6bb: 68,
    0x6bc: 68,
    0x6bd: 68,
    0x6be: 68,
    0x6bf: 68,
    0x6c0: 82,
    0x6c1: 68,
    0x6c2: 68,
    0x6c3: 82,
    0x6c4: 82,
    0x6c5: 82,
    0x6c6: 82,
    0x6c7: 82,
    0x6c8: 82,
    0x6c9: 82,
    0x6ca: 82,
    0x6cb: 82,
    0x6cc: 68,
    0x6cd: 82,
    0x6ce: 68,
    0x6cf: 82,
    0x6d0: 68,
    0x6d1: 68,
    0x6d2: 82,
    0x6d3: 82,
    0x6d5: 82,
    0x6dd: 85,
    0x6ee: 82,
    0x6ef: 82,
    0x6fa: 68,
    0x6fb: 68,
    0x6fc: 68,
    0x6ff: 68,
    0x70f: 84,
    0x710: 82,
    0x712: 68,
    0x713: 68,
    0x714: 68,
    0x715: 82,
    0x716: 82,
    0x717: 82,
    0x718: 82,
    0x719: 82,
    0x71a: 68,
    0x71b: 68,
    0x71c: 68,
    0x71d: 68,
    0x71e: 82,
    0x71f: 68,
    0x720: 68,
    0x721: 68,
    0x722: 68,
    0x723: 68,
    0x724: 68,
    0x725: 68,
    0x726: 68,
    0x727: 68,
    0x728: 82,
    0x729: 68,
    0x72a: 82,
    0x72b: 68,
    0x72c: 82,
    0x72d: 68,
    0x72e: 68,
    0x72f: 82,
    0x74d: 82,
    0x74e: 68,
    0x74f: 68,
    0x750: 68,
    0x751: 68,
    0x752: 68,
    0x753: 68,
    0x754: 68,
    0x755: 68,
    0x756: 68,
    0x757: 68,
    0x758: 68,
    0x759: 82,
    0x75a: 82,
    0x75b: 82,
    0x75c: 68,
    0x75d: 68,
    0x75e: 68,
    0x75f: 68,
    0x760: 68,
    0x761: 68,
    0x762: 68,
    0x763: 68,
    0x764: 68,
    0x765: 68,
    0x766: 68,
    0x767: 68,
    0x768: 68,
    0x769: 68,
    0x76a: 68,
    0x76b: 82,
    0x76c: 82,
    0x76d: 68,
    0x76e: 68,
    0x76f: 68,
    0x770: 68,
    0x771: 82,
    0x772: 68,
    0x773: 82,
    0x774: 82,
    0x775: 68,
    0x776: 68,
    0x777: 68,
    0x778: 82,
    0x779: 82,
    0x77a: 68,
    0x77b: 68,
    0x77c: 68,
    0x77d: 68,
    0x77e: 68,
    0x77f: 68,
    0x7ca: 68,
    0x7cb: 68,
    0x7cc: 68,
    0x7cd: 68,
    0x7ce: 68,
    0x7cf: 68,
    0x7d0: 68,
    0x7d1: 68,
    0x7d2: 68,
    0x7d3: 68,
    0x7d4: 68,
    0x7d5: 68,
    0x7d6: 68,
    0x7d7: 68,
    0x7d8: 68,
    0x7d9: 68,
    0x7da: 68,
    0x7db: 68,
    0x7dc: 68,
    0x7dd: 68,
    0x7de: 68,
    0x7df: 68,
    0x7e0: 68,
    0x7e1: 68,
    0x7e2: 68,
    0x7e3: 68,
    0x7e4: 68,
    0x7e5: 68,
    0x7e6: 68,
    0x7e7: 68,
    0x7e8: 68,
    0x7e9: 68,
    0x7ea: 68,
    0x7fa: 67,
    0x840: 82,
    0x841: 68,
    0x842: 68,
    0x843: 68,
    0x844: 68,
    0x845: 68,
    0x846: 82,
    0x847: 82,
    0x848: 68,
    0x849: 82,
    0x84a: 68,
    0x84b: 68,
    0x84c: 68,
    0x84d: 68,
    0x84e: 68,
    0x84f: 68,
    0x850: 68,
    0x851: 68,
    0x852: 68,
    0x853: 68,
    0x854: 82,
    0x855: 68,
    0x856: 82,
    0x857: 82,
    0x858: 82,
    0x860: 68,
    0x861: 85,
    0x862: 68,
    0x863: 68,
    0x864: 68,
    0x865: 68,
    0x866: 85,
    0x867: 82,
    0x868: 68,
    0x869: 82,
    0x86a: 82,
    0x8a0: 68,
    0x8a1: 68,
    0x8a2: 68,
    0x8a3: 68,
    0x8a4: 68,
    0x8a5: 68,
    0x8a6: 68,
    0x8a7: 68,
    0x8a8: 68,
    0x8a9: 68,
    0x8aa: 82,
    0x8ab: 82,
    0x8ac: 82,
    0x8ad: 85,
    0x8ae: 82,
    0x8af: 68,
    0x8b0: 68,
    0x8b1: 82,
    0x8b2: 82,
    0x8b3: 68,
    0x8b4: 68,
    0x8b6: 68,
    0x8b7: 68,
    0x8b8: 68,
    0x8b9: 82,
    0x8ba: 68,
    0x8bb: 68,
    0x8bc: 68,
    0x8bd: 68,
    0x8be: 68,
    0x8bf: 68,
    0x8c0: 68,
    0x8c1: 68,
    0x8c2: 68,
    0x8c3: 68,
    0x8c4: 68,
    0x8c5: 68,
    0x8c6: 68,
    0x8c7: 68,
    0x8e2: 85,
    0x1806: 85,
    0x1807: 68,
    0x180a: 67,
    0x180e: 85,
    0x1820: 68,
    0x1821: 68,
    0x1822: 68,
    0x1823: 68,
    0x1824: 68,
    0x1825: 68,
    0x1826: 68,
    0x1827: 68,
    0x1828: 68,
    0x1829: 68,
    0x182a: 68,
    0x182b: 68,
    0x182c: 68,
    0x182d: 68,
    0x182e: 68,
    0x182f: 68,
    0x1830: 68,
    0x1831: 68,
    0x1832: 68,
    0x1833: 68,
    0x1834: 68,
    0x1835: 68,
    0x1836: 68,
    0x1837: 68,
    0x1838: 68,
    0x1839: 68,
    0x183a: 68,
    0x183b: 68,
    0x183c: 68,
    0x183d: 68,
    0x183e: 68,
    0x183f: 68,
    0x1840: 68,
    0x1841: 68,
    0x1842: 68,
    0x1843: 68,
    0x1844: 68,
    0x1845: 68,
    0x1846: 68,
    0x1847: 68,
    0x1848: 68,
    0x1849: 68,
    0x184a: 68,
    0x184b: 68,
    0x184c: 68,
    0x184d: 68,
    0x184e: 68,
    0x184f: 68,
    0x1850: 68,
    0x1851: 68,
    0x1852: 68,
    0x1853: 68,
    0x1854: 68,
    0x1855: 68,
    0x1856: 68,
    0x1857: 68,
    0x1858: 68,
    0x1859: 68,
    0x185a: 68,
    0x185b: 68,
    0x185c: 68,
    0x185d: 68,
    0x185e: 68,
    0x185f: 68,
    0x1860: 68,
    0x1861: 68,
    0x1862: 68,
    0x1863: 68,
    0x1864: 68,
    0x1865: 68,
    0x1866: 68,
    0x1867: 68,
    0x1868: 68,
    0x1869: 68,
    0x186a: 68,
    0x186b: 68,
    0x186c: 68,
    0x186d: 68,
    0x186e: 68,
    0x186f: 68,
    0x1870: 68,
    0x1871: 68,
    0x1872: 68,
    0x1873: 68,
    0x1874: 68,
    0x1875: 68,
    0x1876: 68,
    0x1877: 68,
    0x1878: 68,
    0x1880: 85,
    0x1881: 85,
    0x1882: 85,
    0x1883: 85,
    0x1884: 85,
    0x1885: 84,
    0x1886: 84,
    0x1887: 68,
    0x1888: 68,
    0x1889: 68,
    0x188a: 68,
    0x188b: 68,
    0x188c: 68,
    0x188d: 68,
    0x188e: 68,
    0x188f: 68,
    0x1890: 68,
    0x1891: 68,
    0x1892: 68,
    0x1893: 68,
    0x1894: 68,
    0x1895: 68,
    0x1896: 68,
    0x1897: 68,
    0x1898: 68,
    0x1899: 68,
    0x189a: 68,
    0x189b: 68,
    0x189c: 68,
    0x189d: 68,
    0x189e: 68,
    0x189f: 68,
    0x18a0: 68,
    0x18a1: 68,
    0x18a2: 68,
    0x18a3: 68,
    0x18a4: 68,
    0x18a5: 68,
    0x18a6: 68,
    0x18a7: 68,
    0x18a8: 68,
    0x18aa: 68,
    0x200c: 85,
    0x200d: 67,
    0x202f: 85,
    0x2066: 85,
    0x2067: 85,
    0x2068: 85,
    0x2069: 85,
    0xa840: 68,
    0xa841: 68,
    0xa842: 68,
    0xa843: 68,
    0xa844: 68,
    0xa845: 68,
    0xa846: 68,
    0xa847: 68,
    0xa848: 68,
    0xa849: 68,
    0xa84a: 68,
    0xa84b: 68,
    0xa84c: 68,
    0xa84d: 68,
    0xa84e: 68,
    0xa84f: 68,
    0xa850: 68,
    0xa851: 68,
    0xa852: 68,
    0xa853: 68,
    0xa854: 68,
    0xa855: 68,
    0xa856: 68,
    0xa857: 68,
    0xa858: 68,
    0xa859: 68,
    0xa85a: 68,
    0xa85b: 68,
    0xa85c: 68,
    0xa85d: 68,
    0xa85e: 68,
    0xa85f: 68,
    0xa860: 68,
    0xa861: 68,
    0xa862: 68,
    0xa863: 68,
    0xa864: 68,
    0xa865: 68,
    0xa866: 68,
    0xa867: 68,
    0xa868: 68,
    0xa869: 68,
    0xa86a: 68,
    0xa86b: 68,
    0xa86c: 68,
    0xa86d: 68,
    0xa86e: 68,
    0xa86f: 68,
    0xa870: 68,
    0xa871: 68,
    0xa872: 76,
    0xa873: 85,
    0x10ac0: 68,
    0x10ac1: 68,
    0x10ac2: 68,
    0x10ac3: 68,
    0x10ac4: 68,
    0x10ac5: 82,
    0x10ac6: 85,
    0x10ac7: 82,
    0x10ac8: 85,
    0x10ac9: 82,
    0x10aca: 82,
    0x10acb: 85,
    0x10acc: 85,
    0x10acd: 76,
    0x10ace: 82,
    0x10acf: 82,
    0x10ad0: 82,
    0x10ad1: 82,
    0x10ad2: 82,
    0x10ad3: 68,
    0x10ad4: 68,
    0x10ad5: 68,
    0x10ad6: 68,
    0x10ad7: 76,
    0x10ad8: 68,
    0x10ad9: 68,
    0x10ada: 68,
    0x10adb: 68,
    0x10adc: 68,
    0x10add: 82,
    0x10ade: 68,
    0x10adf: 68,
    0x10ae0: 68,
    0x10ae1: 82,
    0x10ae2: 85,
    0x10ae3: 85,
    0x10ae4: 82,
    0x10aeb: 68,
    0x10aec: 68,
    0x10aed: 68,
    0x10aee: 68,
    0x10aef: 82,
    0x10b80: 68,
    0x10b81: 82,
    0x10b82: 68,
    0x10b83: 82,
    0x10b84: 82,
    0x10b85: 82,
    0x10b86: 68,
    0x10b87: 68,
    0x10b88: 68,
    0x10b89: 82,
    0x10b8a: 68,
    0x10b8b: 68,
    0x10b8c: 82,
    0x10b8d: 68,
    0x10b8e: 82,
    0x10b8f: 82,
    0x10b90: 68,
    0x10b91: 82,
    0x10ba9: 82,
    0x10baa: 82,
    0x10bab: 82,
    0x10bac: 82,
    0x10bad: 68,
    0x10bae: 68,
    0x10baf: 85,
    0x10d00: 76,
    0x10d01: 68,
    0x10d02: 68,
    0x10d03: 68,
    0x10d04: 68,
    0x10d05: 68,
    0x10d06: 68,
    0x10d07: 68,
    0x10d08: 68,
    0x10d09: 68,
    0x10d0a: 68,
    0x10d0b: 68,
    0x10d0c: 68,
    0x10d0d: 68,
    0x10d0e: 68,
    0x10d0f: 68,
    0x10d10: 68,
    0x10d11: 68,
    0x10d12: 68,
    0x10d13: 68,
    0x10d14: 68,
    0x10d15: 68,
    0x10d16: 68,
    0x10d17: 68,
    0x10d18: 68,
    0x10d19: 68,
    0x10d1a: 68,
    0x10d1b: 68,
    0x10d1c: 68,
    0x10d1d: 68,
    0x10d1e: 68,
    0x10d1f: 68,
    0x10d20: 68,
    0x10d21: 68,
    0x10d22: 82,
    0x10d23: 68,
    0x10f30: 68,
    0x10f31: 68,
    0x10f32: 68,
    0x10f33: 82,
    0x10f34: 68,
    0x10f35: 68,
    0x10f36: 68,
    0x10f37: 68,
    0x10f38: 68,
    0x10f39: 68,
    0x10f3a: 68,
    0x10f3b: 68,
    0x10f3c: 68,
    0x10f3d: 68,
    0x10f3e: 68,
    0x10f3f: 68,
    0x10f40: 68,
    0x10f41: 68,
    0x10f42: 68,
    0x10f43: 68,
    0x10f44: 68,
    0x10f45: 85,
    0x10f51: 68,
    0x10f52: 68,
    0x10f53: 68,
    0x10f54: 82,
    0x10fb0: 68,
    0x10fb1: 85,
    0x10fb2: 68,
    0x10fb3: 68,
    0x10fb4: 82,
    0x10fb5: 82,
    0x10fb6: 82,
    0x10fb7: 85,
    0x10fb8: 68,
    0x10fb9: 82,
    0x10fba: 82,
    0x10fbb: 68,
    0x10fbc: 68,
    0x10fbd: 82,
    0x10fbe: 68,
    0x10fbf: 68,
    0x10fc0: 85,
    0x10fc1: 68,
    0x10fc2: 82,
    0x10fc3: 82,
    0x10fc4: 68,
    0x10fc5: 85,
    0x10fc6: 85,
    0x10fc7: 85,
    0x10fc8: 85,
    0x10fc9: 82,
    0x10fca: 68,
    0x10fcb: 76,
    0x110bd: 85,
    0x110cd: 85,
    0x1e900: 68,
    0x1e901: 68,
    0x1e902: 68,
    0x1e903: 68,
    0x1e904: 68,
    0x1e905: 68,
    0x1e906: 68,
    0x1e907: 68,
    0x1e908: 68,
    0x1e909: 68,
    0x1e90a: 68,
    0x1e90b: 68,
    0x1e90c: 68,
    0x1e90d: 68,
    0x1e90e: 68,
    0x1e90f: 68,
    0x1e910: 68,
    0x1e911: 68,
    0x1e912: 68,
    0x1e913: 68,
    0x1e914: 68,
    0x1e915: 68,
    0x1e916: 68,
    0x1e917: 68,
    0x1e918: 68,
    0x1e919: 68,
    0x1e91a: 68,
    0x1e91b: 68,
    0x1e91c: 68,
    0x1e91d: 68,
    0x1e91e: 68,
    0x1e91f: 68,
    0x1e920: 68,
    0x1e921: 68,
    0x1e922: 68,
    0x1e923: 68,
    0x1e924: 68,
    0x1e925: 68,
    0x1e926: 68,
    0x1e927: 68,
    0x1e928: 68,
    0x1e929: 68,
    0x1e92a: 68,
    0x1e92b: 68,
    0x1e92c: 68,
    0x1e92d: 68,
    0x1e92e: 68,
    0x1e92f: 68,
    0x1e930: 68,
    0x1e931: 68,
    0x1e932: 68,
    0x1e933: 68,
    0x1e934: 68,
    0x1e935: 68,
    0x1e936: 68,
    0x1e937: 68,
    0x1e938: 68,
    0x1e939: 68,
    0x1e93a: 68,
    0x1e93b: 68,
    0x1e93c: 68,
    0x1e93d: 68,
    0x1e93e: 68,
    0x1e93f: 68,
    0x1e940: 68,
    0x1e941: 68,
    0x1e942: 68,
    0x1e943: 68,
    0x1e94b: 84,
}
codepoint_classes = {
    'PVALID': (
        0x2d0000002e,
        0x300000003a,
        0x610000007b,
        0xdf000000f7,
        0xf800000100,
        0x10100000102,
        0x10300000104,
        0x10500000106,
        0x10700000108,
        0x1090000010a,
        0x10b0000010c,
        0x10d0000010e,
        0x10f00000110,
        0x11100000112,
        0x11300000114,
        0x11500000116,
        0x11700000118,
        0x1190000011a,
        0x11b0000011c,
        0x11d0000011e,
        0x11f00000120,
        0x12100000122,
        0x12300000124,
        0x12500000126,
        0x12700000128,
        0x1290000012a,
        0x12b0000012c,
        0x12d0000012e,
        0x12f00000130,
        0x13100000132,
        0x13500000136,
        0x13700000139,
        0x13a0000013b,
        0x13c0000013d,
        0x13e0000013f,
        0x14200000143,
        0x14400000145,
        0x14600000147,
        0x14800000149,
        0x14b0000014c,
        0x14d0000014e,
        0x14f00000150,
        0x15100000152,
        0x15300000154,
        0x15500000156,
        0x15700000158,
        0x1590000015a,
        0x15b0000015c,
        0x15d0000015e,
        0x15f00000160,
        0x16100000162,
        0x16300000164,
        0x16500000166,
        0x16700000168,
        0x1690000016a,
        0x16b0000016c,
        0x16d0000016e,
        0x16f00000170,
        0x17100000172,
        0x17300000174,
        0x17500000176,
        0x17700000178,
        0x17a0000017b,
        0x17c0000017d,
        0x17e0000017f,
        0x18000000181,
        0x18300000184,
        0x18500000186,
        0x18800000189,
        0x18c0000018e,
        0x19200000193,
        0x19500000196,
        0x1990000019c,
        0x19e0000019f,
        0x1a1000001a2,
        0x1a3000001a4,
        0x1a5000001a6,
        0x1a8000001a9,
        0x1aa000001ac,
        0x1ad000001ae,
        0x1b0000001b1,
        0x1b4000001b5,
        0x1b6000001b7,
        0x1b9000001bc,
        0x1bd000001c4,
        0x1ce000001cf,
        0x1d0000001d1,
        0x1d2000001d3,
        0x1d4000001d5,
        0x1d6000001d7,
        0x1d8000001d9,
        0x1da000001db,
        0x1dc000001de,
        0x1df000001e0,
        0x1e1000001e2,
        0x1e3000001e4,
        0x1e5000001e6,
        0x1e7000001e8,
        0x1e9000001ea,
        0x1eb000001ec,
        0x1ed000001ee,
        0x1ef000001f1,
        0x1f5000001f6,
        0x1f9000001fa,
        0x1fb000001fc,
        0x1fd000001fe,
        0x1ff00000200,
        0x20100000202,
        0x20300000204,
        0x20500000206,
        0x20700000208,
        0x2090000020a,
        0x20b0000020c,
        0x20d0000020e,
        0x20f00000210,
        0x21100000212,
        0x21300000214,
        0x21500000216,
        0x21700000218,
        0x2190000021a,
        0x21b0000021c,
        0x21d0000021e,
        0x21f00000220,
        0x22100000222,
        0x22300000224,
        0x22500000226,
        0x22700000228,
        0x2290000022a,
        0x22b0000022c,
        0x22d0000022e,
        0x22f00000230,
        0x23100000232,
        0x2330000023a,
        0x23c0000023d,
        0x23f00000241,
        0x24200000243,
        0x24700000248,
        0x2490000024a,
        0x24b0000024c,
        0x24d0000024e,
        0x24f000002b0,
        0x2b9000002c2,
        0x2c6000002d2,
        0x2ec000002ed,
        0x2ee000002ef,
        0x30000000340,
        0x34200000343,
        0x3460000034f,
        0x35000000370,
        0x37100000372,
        0x37300000374,
        0x37700000378,
        0x37b0000037e,
        0x39000000391,
        0x3ac000003cf,
        0x3d7000003d8,
        0x3d9000003da,
        0x3db000003dc,
        0x3dd000003de,
        0x3df000003e0,
        0x3e1000003e2,
        0x3e3000003e4,
        0x3e5000003e6,
        0x3e7000003e8,
        0x3e9000003ea,
        0x3eb000003ec,
        0x3ed000003ee,
        0x3ef000003f0,
        0x3f3000003f4,
        0x3f8000003f9,
        0x3fb000003fd,
        0x43000000460,
        0x46100000462,
        0x46300000464,
        0x46500000466,
        0x46700000468,
        0x4690000046a,
        0x46b0000046c,
        0x46d0000046e,
        0x46f00000470,
        0x47100000472,
        0x47300000474,
        0x47500000476,
        0x47700000478,
        0x4790000047a,
        0x47b0000047c,
        0x47d0000047e,
        0x47f00000480,
        0x48100000482,
        0x48300000488,
        0x48b0000048c,
        0x48d0000048e,
        0x48f00000490,
        0x49100000492,
        0x49300000494,
        0x49500000496,
        0x49700000498,
        0x4990000049a,
        0x49b0000049c,
        0x49d0000049e,
        0x49f000004a0,
        0x4a1000004a2,
        0x4a3000004a4,
        0x4a5000004a6,
        0x4a7000004a8,
        0x4a9000004aa,
        0x4ab000004ac,
        0x4ad000004ae,
        0x4af000004b0,
        0x4b1000004b2,
        0x4b3000004b4,
        0x4b5000004b6,
        0x4b7000004b8,
        0x4b9000004ba,
        0x4bb000004bc,
        0x4bd000004be,
        0x4bf000004c0,
        0x4c2000004c3,
        0x4c4000004c5,
        0x4c6000004c7,
        0x4c8000004c9,
        0x4ca000004cb,
        0x4cc000004cd,
        0x4ce000004d0,
        0x4d1000004d2,
        0x4d3000004d4,
        0x4d5000004d6,
        0x4d7000004d8,
        0x4d9000004da,
        0x4db000004dc,
        0x4dd000004de,
        0x4df000004e0,
        0x4e1000004e2,
        0x4e3000004e4,
        0x4e5000004e6,
        0x4e7000004e8,
        0x4e9000004ea,
        0x4eb000004ec,
        0x4ed000004ee,
        0x4ef000004f0,
        0x4f1000004f2,
        0x4f3000004f4,
        0x4f5000004f6,
        0x4f7000004f8,
        0x4f9000004fa,
        0x4fb000004fc,
        0x4fd000004fe,
        0x4ff00000500,
        0x50100000502,
        0x50300000504,
        0x50500000506,
        0x50700000508,
        0x5090000050a,
        0x50b0000050c,
        0x50d0000050e,
        0x50f00000510,
        0x51100000512,
        0x51300000514,
        0x51500000516,
        0x51700000518,
        0x5190000051a,
        0x51b0000051c,
        0x51d0000051e,
        0x51f00000520,
        0x52100000522,
        0x52300000524,
        0x52500000526,
        0x52700000528,
        0x5290000052a,
        0x52b0000052c,
        0x52d0000052e,
        0x52f00000530,
        0x5590000055a,
        0x56000000587,
        0x58800000589,
        0x591000005be,
        0x5bf000005c0,
        0x5c1000005c3,
        0x5c4000005c6,
        0x5c7000005c8,
        0x5d0000005eb,
        0x5ef000005f3,
        0x6100000061b,
        0x62000000640,
        0x64100000660,
        0x66e00000675,
        0x679000006d4,
        0x6d5000006dd,
        0x6df000006e9,
        0x6ea000006f0,
        0x6fa00000700,
        0x7100000074b,
        0x74d000007b2,
        0x7c0000007f6,
        0x7fd000007fe,
        0x8000000082e,
        0x8400000085c,
        0x8600000086b,
        0x8a0000008b5,
        0x8b6000008c8,
        0x8d3000008e2,
        0x8e300000958,
        0x96000000964,
        0x96600000970,
        0x97100000984,
        0x9850000098d,
        0x98f00000991,
        0x993000009a9,
        0x9aa000009b1,
        0x9b2000009b3,
        0x9b6000009ba,
        0x9bc000009c5,
        0x9c7000009c9,
        0x9cb000009cf,
        0x9d7000009d8,
        0x9e0000009e4,
        0x9e6000009f2,
        0x9fc000009fd,
        0x9fe000009ff,
        0xa0100000a04,
        0xa0500000a0b,
        0xa0f00000a11,
        0xa1300000a29,
        0xa2a00000a31,
        0xa3200000a33,
        0xa3500000a36,
        0xa3800000a3a,
        0xa3c00000a3d,
        0xa3e00000a43,
        0xa4700000a49,
        0xa4b00000a4e,
        0xa5100000a52,
        0xa5c00000a5d,
        0xa6600000a76,
        0xa8100000a84,
        0xa8500000a8e,
        0xa8f00000a92,
        0xa9300000aa9,
        0xaaa00000ab1,
        0xab200000ab4,
        0xab500000aba,
        0xabc00000ac6,
        0xac700000aca,
        0xacb00000ace,
        0xad000000ad1,
        0xae000000ae4,
        0xae600000af0,
        0xaf900000b00,
        0xb0100000b04,
        0xb0500000b0d,
        0xb0f00000b11,
        0xb1300000b29,
        0xb2a00000b31,
        0xb3200000b34,
        0xb3500000b3a,
        0xb3c00000b45,
        0xb4700000b49,
        0xb4b00000b4e,
        0xb5500000b58,
        0xb5f00000b64,
        0xb6600000b70,
        0xb7100000b72,
        0xb8200000b84,
        0xb8500000b8b,
        0xb8e00000b91,
        0xb9200000b96,
        0xb9900000b9b,
        0xb9c00000b9d,
        0xb9e00000ba0,
        0xba300000ba5,
        0xba800000bab,
        0xbae00000bba,
        0xbbe00000bc3,
        0xbc600000bc9,
        0xbca00000bce,
        0xbd000000bd1,
        0xbd700000bd8,
        0xbe600000bf0,
        0xc0000000c0d,
        0xc0e00000c11,
        0xc1200000c29,
        0xc2a00000c3a,
        0xc3d00000c45,
        0xc4600000c49,
        0xc4a00000c4e,
        0xc5500000c57,
        0xc5800000c5b,
        0xc6000000c64,
        0xc6600000c70,
        0xc8000000c84,
        0xc8500000c8d,
        0xc8e00000c91,
        0xc9200000ca9,
        0xcaa00000cb4,
        0xcb500000cba,
        0xcbc00000cc5,
        0xcc600000cc9,
        0xcca00000cce,
        0xcd500000cd7,
        0xcde00000cdf,
        0xce000000ce4,
        0xce600000cf0,
        0xcf100000cf3,
        0xd0000000d0d,
        0xd0e00000d11,
        0xd1200000d45,
        0xd4600000d49,
        0xd4a00000d4f,
        0xd5400000d58,
        0xd5f00000d64,
        0xd6600000d70,
        0xd7a00000d80,
        0xd8100000d84,
        0xd8500000d97,
        0xd9a00000db2,
        0xdb300000dbc,
        0xdbd00000dbe,
        0xdc000000dc7,
        0xdca00000dcb,
        0xdcf00000dd5,
        0xdd600000dd7,
        0xdd800000de0,
        0xde600000df0,
        0xdf200000df4,
        0xe0100000e33,
        0xe3400000e3b,
        0xe4000000e4f,
        0xe5000000e5a,
        0xe8100000e83,
        0xe8400000e85,
        0xe8600000e8b,
        0xe8c00000ea4,
        0xea500000ea6,
        0xea700000eb3,
        0xeb400000ebe,
        0xec000000ec5,
        0xec600000ec7,
        0xec800000ece,
        0xed000000eda,
        0xede00000ee0,
        0xf0000000f01,
        0xf0b00000f0c,
        0xf1800000f1a,
        0xf2000000f2a,
        0xf3500000f36,
        0xf3700000f38,
        0xf3900000f3a,
        0xf3e00000f43,
        0xf4400000f48,
        0xf4900000f4d,
        0xf4e00000f52,
        0xf5300000f57,
        0xf5800000f5c,
        0xf5d00000f69,
        0xf6a00000f6d,
        0xf7100000f73,
        0xf7400000f75,
        0xf7a00000f81,
        0xf8200000f85,
        0xf8600000f93,
        0xf9400000f98,
        0xf9900000f9d,
        0xf9e00000fa2,
        0xfa300000fa7,
        0xfa800000fac,
        0xfad00000fb9,
        0xfba00000fbd,
        0xfc600000fc7,
        0x10000000104a,
        0x10500000109e,
        0x10d0000010fb,
        0x10fd00001100,
        0x120000001249,
        0x124a0000124e,
        0x125000001257,
        0x125800001259,
        0x125a0000125e,
        0x126000001289,
        0x128a0000128e,
        0x1290000012b1,
        0x12b2000012b6,
        0x12b8000012bf,
        0x12c0000012c1,
        0x12c2000012c6,
        0x12c8000012d7,
        0x12d800001311,
        0x131200001316,
        0x13180000135b,
        0x135d00001360,
        0x138000001390,
        0x13a0000013f6,
        0x14010000166d,
        0x166f00001680,
        0x16810000169b,
        0x16a0000016eb,
        0x16f1000016f9,
        0x17000000170d,
        0x170e00001715,
        0x172000001735,
        0x174000001754,
        0x17600000176d,
        0x176e00001771,
        0x177200001774,
        0x1780000017b4,
        0x17b6000017d4,
        0x17d7000017d8,
        0x17dc000017de,
        0x17e0000017ea,
        0x18100000181a,
        0x182000001879,
        0x1880000018ab,
        0x18b0000018f6,
        0x19000000191f,
        0x19200000192c,
        0x19300000193c,
        0x19460000196e,
        0x197000001975,
        0x1980000019ac,
        0x19b0000019ca,
        0x19d0000019da,
        0x1a0000001a1c,
        0x1a2000001a5f,
        0x1a6000001a7d,
        0x1a7f00001a8a,
        0x1a9000001a9a,
        0x1aa700001aa8,
        0x1ab000001abe,
        0x1abf00001ac1,
        0x1b0000001b4c,
        0x1b5000001b5a,
        0x1b6b00001b74,
        0x1b8000001bf4,
        0x1c0000001c38,
        0x1c4000001c4a,
        0x1c4d00001c7e,
        0x1cd000001cd3,
        0x1cd400001cfb,
        0x1d0000001d2c,
        0x1d2f00001d30,
        0x1d3b00001d3c,
        0x1d4e00001d4f,
        0x1d6b00001d78,
        0x1d7900001d9b,
        0x1dc000001dfa,
        0x1dfb00001e00,
        0x1e0100001e02,
        0x1e0300001e04,
        0x1e0500001e06,
        0x1e0700001e08,
        0x1e0900001e0a,
        0x1e0b00001e0c,
        0x1e0d00001e0e,
        0x1e0f00001e10,
        0x1e1100001e12,
        0x1e1300001e14,
        0x1e1500001e16,
        0x1e1700001e18,
        0x1e1900001e1a,
        0x1e1b00001e1c,
        0x1e1d00001e1e,
        0x1e1f00001e20,
        0x1e2100001e22,
        0x1e2300001e24,
        0x1e2500001e26,
        0x1e2700001e28,
        0x1e2900001e2a,
        0x1e2b00001e2c,
        0x1e2d00001e2e,
        0x1e2f00001e30,
        0x1e3100001e32,
        0x1e3300001e34,
        0x1e3500001e36,
        0x1e3700001e38,
        0x1e3900001e3a,
        0x1e3b00001e3c,
        0x1e3d00001e3e,
        0x1e3f00001e40,
        0x1e4100001e42,
        0x1e4300001e44,
        0x1e4500001e46,
        0x1e4700001e48,
        0x1e4900001e4a,
        0x1e4b00001e4c,
        0x1e4d00001e4e,
        0x1e4f00001e50,
        0x1e5100001e52,
        0x1e5300001e54,
        0x1e5500001e56,
        0x1e5700001e58,
        0x1e5900001e5a,
        0x1e5b00001e5c,
        0x1e5d00001e5e,
        0x1e5f00001e60,
        0x1e6100001e62,
        0x1e6300001e64,
        0x1e6500001e66,
        0x1e6700001e68,
        0x1e6900001e6a,
        0x1e6b00001e6c,
        0x1e6d00001e6e,
        0x1e6f00001e70,
        0x1e7100001e72,
        0x1e7300001e74,
        0x1e7500001e76,
        0x1e7700001e78,
        0x1e7900001e7a,
        0x1e7b00001e7c,
        0x1e7d00001e7e,
        0x1e7f00001e80,
        0x1e8100001e82,
        0x1e8300001e84,
        0x1e8500001e86,
        0x1e8700001e88,
        0x1e8900001e8a,
        0x1e8b00001e8c,
        0x1e8d00001e8e,
        0x1e8f00001e90,
        0x1e9100001e92,
        0x1e9300001e94,
        0x1e9500001e9a,
        0x1e9c00001e9e,
        0x1e9f00001ea0,
        0x1ea100001ea2,
        0x1ea300001ea4,
        0x1ea500001ea6,
        0x1ea700001ea8,
        0x1ea900001eaa,
        0x1eab00001eac,
        0x1ead00001eae,
        0x1eaf00001eb0,
        0x1eb100001eb2,
        0x1eb300001eb4,
        0x1eb500001eb6,
        0x1eb700001eb8,
        0x1eb900001eba,
        0x1ebb00001ebc,
        0x1ebd00001ebe,
        0x1ebf00001ec0,
        0x1ec100001ec2,
        0x1ec300001ec4,
        0x1ec500001ec6,
        0x1ec700001ec8,
        0x1ec900001eca,
        0x1ecb00001ecc,
        0x1ecd00001ece,
        0x1ecf00001ed0,
        0x1ed100001ed2,
        0x1ed300001ed4,
        0x1ed500001ed6,
        0x1ed700001ed8,
        0x1ed900001eda,
        0x1edb00001edc,
        0x1edd00001ede,
        0x1edf00001ee0,
        0x1ee100001ee2,
        0x1ee300001ee4,
        0x1ee500001ee6,
        0x1ee700001ee8,
        0x1ee900001eea,
        0x1eeb00001eec,
        0x1eed00001eee,
        0x1eef00001ef0,
        0x1ef100001ef2,
        0x1ef300001ef4,
        0x1ef500001ef6,
        0x1ef700001ef8,
        0x1ef900001efa,
        0x1efb00001efc,
        0x1efd00001efe,
        0x1eff00001f08,
        0x1f1000001f16,
        0x1f2000001f28,
        0x1f3000001f38,
        0x1f4000001f46,
        0x1f5000001f58,
        0x1f6000001f68,
        0x1f7000001f71,
        0x1f7200001f73,
        0x1f7400001f75,
        0x1f7600001f77,
        0x1f7800001f79,
        0x1f7a00001f7b,
        0x1f7c00001f7d,
        0x1fb000001fb2,
        0x1fb600001fb7,
        0x1fc600001fc7,
        0x1fd000001fd3,
        0x1fd600001fd8,
        0x1fe000001fe3,
        0x1fe400001fe8,
        0x1ff600001ff7,
        0x214e0000214f,
        0x218400002185,
        0x2c3000002c5f,
        0x2c6100002c62,
        0x2c6500002c67,
        0x2c6800002c69,
        0x2c6a00002c6b,
        0x2c6c00002c6d,
        0x2c7100002c72,
        0x2c7300002c75,
        0x2c7600002c7c,
        0x2c8100002c82,
        0x2c8300002c84,
        0x2c8500002c86,
        0x2c8700002c88,
        0x2c8900002c8a,
        0x2c8b00002c8c,
        0x2c8d00002c8e,
        0x2c8f00002c90,
        0x2c9100002c92,
        0x2c9300002c94,
        0x2c9500002c96,
        0x2c9700002c98,
        0x2c9900002c9a,
        0x2c9b00002c9c,
        0x2c9d00002c9e,
        0x2c9f00002ca0,
        0x2ca100002ca2,
        0x2ca300002ca4,
        0x2ca500002ca6,
        0x2ca700002ca8,
        0x2ca900002caa,
        0x2cab00002cac,
        0x2cad00002cae,
        0x2caf00002cb0,
        0x2cb100002cb2,
        0x2cb300002cb4,
        0x2cb500002cb6,
        0x2cb700002cb8,
        0x2cb900002cba,
        0x2cbb00002cbc,
        0x2cbd00002cbe,
        0x2cbf00002cc0,
        0x2cc100002cc2,
        0x2cc300002cc4,
        0x2cc500002cc6,
        0x2cc700002cc8,
        0x2cc900002cca,
        0x2ccb00002ccc,
        0x2ccd00002cce,
        0x2ccf00002cd0,
        0x2cd100002cd2,
        0x2cd300002cd4,
        0x2cd500002cd6,
        0x2cd700002cd8,
        0x2cd900002cda,
        0x2cdb00002cdc,
        0x2cdd00002cde,
        0x2cdf00002ce0,
        0x2ce100002ce2,
        0x2ce300002ce5,
        0x2cec00002ced,
        0x2cee00002cf2,
        0x2cf300002cf4,
        0x2d0000002d26,
        0x2d2700002d28,
        0x2d2d00002d2e,
        0x2d3000002d68,
        0x2d7f00002d97,
        0x2da000002da7,
        0x2da800002daf,
        0x2db000002db7,
        0x2db800002dbf,
        0x2dc000002dc7,
        0x2dc800002dcf,
        0x2dd000002dd7,
        0x2dd800002ddf,
        0x2de000002e00,
        0x2e2f00002e30,
        0x300500003008,
        0x302a0000302e,
        0x303c0000303d,
        0x304100003097,
        0x30990000309b,
        0x309d0000309f,
        0x30a1000030fb,
        0x30fc000030ff,
        0x310500003130,
        0x31a0000031c0,
        0x31f000003200,
        0x340000004dc0,
        0x4e0000009ffd,
        0xa0000000a48d,
        0xa4d00000a4fe,
        0xa5000000a60d,
        0xa6100000a62c,
        0xa6410000a642,
        0xa6430000a644,
        0xa6450000a646,
        0xa6470000a648,
        0xa6490000a64a,
        0xa64b0000a64c,
        0xa64d0000a64e,
        0xa64f0000a650,
        0xa6510000a652,
        0xa6530000a654,
        0xa6550000a656,
        0xa6570000a658,
        0xa6590000a65a,
        0xa65b0000a65c,
        0xa65d0000a65e,
        0xa65f0000a660,
        0xa6610000a662,
        0xa6630000a664,
        0xa6650000a666,
        0xa6670000a668,
        0xa6690000a66a,
        0xa66b0000a66c,
        0xa66d0000a670,
        0xa6740000a67e,
        0xa67f0000a680,
        0xa6810000a682,
        0xa6830000a684,
        0xa6850000a686,
        0xa6870000a688,
        0xa6890000a68a,
        0xa68b0000a68c,
        0xa68d0000a68e,
        0xa68f0000a690,
        0xa6910000a692,
        0xa6930000a694,
        0xa6950000a696,
        0xa6970000a698,
        0xa6990000a69a,
        0xa69b0000a69c,
        0xa69e0000a6e6,
        0xa6f00000a6f2,
        0xa7170000a720,
        0xa7230000a724,
        0xa7250000a726,
        0xa7270000a728,
        0xa7290000a72a,
        0xa72b0000a72c,
        0xa72d0000a72e,
        0xa72f0000a732,
        0xa7330000a734,
        0xa7350000a736,
        0xa7370000a738,
        0xa7390000a73a,
        0xa73b0000a73c,
        0xa73d0000a73e,
        0xa73f0000a740,
        0xa7410000a742,
        0xa7430000a744,
        0xa7450000a746,
        0xa7470000a748,
        0xa7490000a74a,
        0xa74b0000a74c,
        0xa74d0000a74e,
        0xa74f0000a750,
        0xa7510000a752,
        0xa7530000a754,
        0xa7550000a756,
        0xa7570000a758,
        0xa7590000a75a,
        0xa75b0000a75c,
        0xa75d0000a75e,
        0xa75f0000a760,
        0xa7610000a762,
        0xa7630000a764,
        0xa7650000a766,
        0xa7670000a768,
        0xa7690000a76a,
        0xa76b0000a76c,
        0xa76d0000a76e,
        0xa76f0000a770,
        0xa7710000a779,
        0xa77a0000a77b,
        0xa77c0000a77d,
        0xa77f0000a780,
        0xa7810000a782,
        0xa7830000a784,
        0xa7850000a786,
        0xa7870000a789,
        0xa78c0000a78d,
        0xa78e0000a790,
        0xa7910000a792,
        0xa7930000a796,
        0xa7970000a798,
        0xa7990000a79a,
        0xa79b0000a79c,
        0xa79d0000a79e,
        0xa79f0000a7a0,
        0xa7a10000a7a2,
        0xa7a30000a7a4,
        0xa7a50000a7a6,
        0xa7a70000a7a8,
        0xa7a90000a7aa,
        0xa7af0000a7b0,
        0xa7b50000a7b6,
        0xa7b70000a7b8,
        0xa7b90000a7ba,
        0xa7bb0000a7bc,
        0xa7bd0000a7be,
        0xa7bf0000a7c0,
        0xa7c30000a7c4,
        0xa7c80000a7c9,
        0xa7ca0000a7cb,
        0xa7f60000a7f8,
        0xa7fa0000a828,
        0xa82c0000a82d,
        0xa8400000a874,
        0xa8800000a8c6,
        0xa8d00000a8da,
        0xa8e00000a8f8,
        0xa8fb0000a8fc,
        0xa8fd0000a92e,
        0xa9300000a954,
        0xa9800000a9c1,
        0xa9cf0000a9da,
        0xa9e00000a9ff,
        0xaa000000aa37,
        0xaa400000aa4e,
        0xaa500000aa5a,
        0xaa600000aa77,
        0xaa7a0000aac3,
        0xaadb0000aade,
        0xaae00000aaf0,
        0xaaf20000aaf7,
        0xab010000ab07,
        0xab090000ab0f,
        0xab110000ab17,
        0xab200000ab27,
        0xab280000ab2f,
        0xab300000ab5b,
        0xab600000ab6a,
        0xabc00000abeb,
        0xabec0000abee,
        0xabf00000abfa,
        0xac000000d7a4,
        0xfa0e0000fa10,
        0xfa110000fa12,
        0xfa130000fa15,
        0xfa1f0000fa20,
        0xfa210000fa22,
        0xfa230000fa25,
        0xfa270000fa2a,
        0xfb1e0000fb1f,
        0xfe200000fe30,
        0xfe730000fe74,
        0x100000001000c,
        0x1000d00010027,
        0x100280001003b,
        0x1003c0001003e,
        0x1003f0001004e,
        0x100500001005e,
        0x10080000100fb,
        0x101fd000101fe,
        0x102800001029d,
        0x102a0000102d1,
        0x102e0000102e1,
        0x1030000010320,
        0x1032d00010341,
        0x103420001034a,
        0x103500001037b,
        0x103800001039e,
        0x103a0000103c4,
        0x103c8000103d0,
        0x104280001049e,
        0x104a0000104aa,
        0x104d8000104fc,
        0x1050000010528,
        0x1053000010564,
        0x1060000010737,
        0x1074000010756,
        0x1076000010768,
        0x1080000010806,
        0x1080800010809,
        0x1080a00010836,
        0x1083700010839,
        0x1083c0001083d,
        0x1083f00010856,
        0x1086000010877,
        0x108800001089f,
        0x108e0000108f3,
        0x108f4000108f6,
        0x1090000010916,
        0x109200001093a,
        0x10980000109b8,
        0x109be000109c0,
        0x10a0000010a04,
        0x10a0500010a07,
        0x10a0c00010a14,
        0x10a1500010a18,
        0x10a1900010a36,
        0x10a3800010a3b,
        0x10a3f00010a40,
        0x10a6000010a7d,
        0x10a8000010a9d,
        0x10ac000010ac8,
        0x10ac900010ae7,
        0x10b0000010b36,
        0x10b4000010b56,
        0x10b6000010b73,
        0x10b8000010b92,
        0x10c0000010c49,
        0x10cc000010cf3,
        0x10d0000010d28,
        0x10d3000010d3a,
        0x10e8000010eaa,
        0x10eab00010ead,
        0x10eb000010eb2,
        0x10f0000010f1d,
        0x10f2700010f28,
        0x10f3000010f51,
        0x10fb000010fc5,
        0x10fe000010ff7,
        0x1100000011047,
        0x1106600011070,
        0x1107f000110bb,
        0x110d0000110e9,
        0x110f0000110fa,
        0x1110000011135,
        0x1113600011140,
        0x1114400011148,
        0x1115000011174,
        0x1117600011177,
        0x11180000111c5,
        0x111c9000111cd,
        0x111ce000111db,
        0x111dc000111dd,
        0x1120000011212,
        0x1121300011238,
        0x1123e0001123f,
        0x1128000011287,
        0x1128800011289,
        0x1128a0001128e,
        0x1128f0001129e,
        0x1129f000112a9,
        0x112b0000112eb,
        0x112f0000112fa,
        0x1130000011304,
        0x113050001130d,
        0x1130f00011311,
        0x1131300011329,
        0x1132a00011331,
        0x1133200011334,
        0x113350001133a,
        0x1133b00011345,
        0x1134700011349,
        0x1134b0001134e,
        0x1135000011351,
        0x1135700011358,
        0x1135d00011364,
        0x113660001136d,
        0x1137000011375,
        0x114000001144b,
        0x114500001145a,
        0x1145e00011462,
        0x11480000114c6,
        0x114c7000114c8,
        0x114d0000114da,
        0x11580000115b6,
        0x115b8000115c1,
        0x115d8000115de,
        0x1160000011641,
        0x1164400011645,
        0x116500001165a,
        0x11680000116b9,
        0x116c0000116ca,
        0x117000001171b,
        0x1171d0001172c,
        0x117300001173a,
        0x118000001183b,
        0x118c0000118ea,
        0x118ff00011907,
        0x119090001190a,
        0x1190c00011914,
        0x1191500011917,
        0x1191800011936,
        0x1193700011939,
        0x1193b00011944,
        0x119500001195a,
        0x119a0000119a8,
        0x119aa000119d8,
        0x119da000119e2,
        0x119e3000119e5,
        0x11a0000011a3f,
        0x11a4700011a48,
        0x11a5000011a9a,
        0x11a9d00011a9e,
        0x11ac000011af9,
        0x11c0000011c09,
        0x11c0a00011c37,
        0x11c3800011c41,
        0x11c5000011c5a,
        0x11c7200011c90,
        0x11c9200011ca8,
        0x11ca900011cb7,
        0x11d0000011d07,
        0x11d0800011d0a,
        0x11d0b00011d37,
        0x11d3a00011d3b,
        0x11d3c00011d3e,
        0x11d3f00011d48,
        0x11d5000011d5a,
        0x11d6000011d66,
        0x11d6700011d69,
        0x11d6a00011d8f,
        0x11d9000011d92,
        0x11d9300011d99,
        0x11da000011daa,
        0x11ee000011ef7,
        0x11fb000011fb1,
        0x120000001239a,
        0x1248000012544,
        0x130000001342f,
        0x1440000014647,
        0x1680000016a39,
        0x16a4000016a5f,
        0x16a6000016a6a,
        0x16ad000016aee,
        0x16af000016af5,
        0x16b0000016b37,
        0x16b4000016b44,
        0x16b5000016b5a,
        0x16b6300016b78,
        0x16b7d00016b90,
        0x16e6000016e80,
        0x16f0000016f4b,
        0x16f4f00016f88,
        0x16f8f00016fa0,
        0x16fe000016fe2,
        0x16fe300016fe5,
        0x16ff000016ff2,
        0x17000000187f8,
        0x1880000018cd6,
        0x18d0000018d09,
        0x1b0000001b11f,
        0x1b1500001b153,
        0x1b1640001b168,
        0x1b1700001b2fc,
        0x1bc000001bc6b,
        0x1bc700001bc7d,
        0x1bc800001bc89,
        0x1bc900001bc9a,
        0x1bc9d0001bc9f,
        0x1da000001da37,
        0x1da3b0001da6d,
        0x1da750001da76,
        0x1da840001da85,
        0x1da9b0001daa0,
        0x1daa10001dab0,
        0x1e0000001e007,
        0x1e0080001e019,
        0x1e01b0001e022,
        0x1e0230001e025,
        0x1e0260001e02b,
        0x1e1000001e12d,
        0x1e1300001e13e,
        0x1e1400001e14a,
        0x1e14e0001e14f,
        0x1e2c00001e2fa,
        0x1e8000001e8c5,
        0x1e8d00001e8d7,
        0x1e9220001e94c,
        0x1e9500001e95a,
        0x1fbf00001fbfa,
        0x200000002a6de,
        0x2a7000002b735,
        0x2b7400002b81e,
        0x2b8200002cea2,
        0x2ceb00002ebe1,
        0x300000003134b,
    ),
    'CONTEXTJ': (
        0x200c0000200e,
    ),
    'CONTEXTO': (
        0xb7000000b8,
        0x37500000376,
        0x5f3000005f5,
        0x6600000066a,
        0x6f0000006fa,
        0x30fb000030fc,
    ),
}




############################################################
### File: inet.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""Generic Internet address helper functions."""

import socket

import dns.ipv4
import dns.ipv6

from ._compat import maybe_ord

# We assume that AF_INET is always defined.

AF_INET = socket.AF_INET

# AF_INET6 might not be defined in the socket module, but we need it.
# We'll try to use the socket module's value, and if it doesn't work,
# we'll use our own value.

try:
    AF_INET6 = socket.AF_INET6
except AttributeError:
    AF_INET6 = 9999


def inet_pton(family, text):
    """Convert the textual form of a network address into its binary form.

    *family* is an ``int``, the address family.

    *text* is a ``text``, the textual address.

    Raises ``NotImplementedError`` if the address family specified is not
    implemented.

    Returns a ``binary``.
    """

    if family == AF_INET:
        return dns.ipv4.inet_aton(text)
    elif family == AF_INET6:
        return dns.ipv6.inet_aton(text)
    else:
        raise NotImplementedError


def inet_ntop(family, address):
    """Convert the binary form of a network address into its textual form.

    *family* is an ``int``, the address family.

    *address* is a ``binary``, the network address in binary form.

    Raises ``NotImplementedError`` if the address family specified is not
    implemented.

    Returns a ``text``.
    """

    if family == AF_INET:
        return dns.ipv4.inet_ntoa(address)
    elif family == AF_INET6:
        return dns.ipv6.inet_ntoa(address)
    else:
        raise NotImplementedError


def af_for_address(text):
    """Determine the address family of a textual-form network address.

    *text*, a ``text``, the textual address.

    Raises ``ValueError`` if the address family cannot be determined
    from the input.

    Returns an ``int``.
    """

    try:
        dns.ipv4.inet_aton(text)
        return AF_INET
    except Exception:
        try:
            dns.ipv6.inet_aton(text)
            return AF_INET6
        except:
            raise ValueError


def is_multicast(text):
    """Is the textual-form network address a multicast address?

    *text*, a ``text``, the textual address.

    Raises ``ValueError`` if the address family cannot be determined
    from the input.

    Returns a ``bool``.
    """

    try:
        first = maybe_ord(dns.ipv4.inet_aton(text)[0])
        return first >= 224 and first <= 239
    except Exception:
        try:
            first = maybe_ord(dns.ipv6.inet_aton(text)[0])
            return first == 255
        except Exception:
            raise ValueError




############################################################
### File: intranges.py
############################################################
"""
Given a list of integers, made up of (hopefully) a small number of long runs
of consecutive integers, compute a representation of the form
((start1, end1), (start2, end2) ...). Then answer the question "was x present
in the original list?" in time O(log(# runs)).
"""

import bisect

def intranges_from_list(list_):
    """Represent a list of integers as a sequence of ranges:
    ((start_0, end_0), (start_1, end_1), ...), such that the original
    integers are exactly those x such that start_i <= x < end_i for some i.

    Ranges are encoded as single integers (start << 32 | end), not as tuples.
    """

    sorted_list = sorted(list_)
    ranges = []
    last_write = -1
    for i in range(len(sorted_list)):
        if i+1 < len(sorted_list):
            if sorted_list[i] == sorted_list[i+1]-1:
                continue
        current_range = sorted_list[last_write+1:i+1]
        ranges.append(_encode_range(current_range[0], current_range[-1] + 1))
        last_write = i

    return tuple(ranges)

def _encode_range(start, end):
    return (start << 32) | end

def _decode_range(r):
    return (r >> 32), (r & ((1 << 32) - 1))


def intranges_contain(int_, ranges):
    """Determine if `int_` falls into one of the ranges in `ranges`."""
    tuple_ = _encode_range(int_, 0)
    pos = bisect.bisect_left(ranges, tuple_)
    # we could be immediately ahead of a tuple (start, end)
    # with start < int_ <= end
    if pos > 0:
        left, right = _decode_range(ranges[pos-1])
        if left <= int_ < right:
            return True
    # or we could be immediately behind a tuple (int_, end)
    if pos < len(ranges):
        left, _ = _decode_range(ranges[pos])
        if left == int_:
            return True
    return False




############################################################
### File: ipv4.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""IPv4 helper functions."""

import struct

import dns.exception
from ._compat import binary_type

def inet_ntoa(address):
    """Convert an IPv4 address in binary form to text form.

    *address*, a ``binary``, the IPv4 address in binary form.

    Returns a ``text``.
    """

    if len(address) != 4:
        raise dns.exception.SyntaxError
    if not isinstance(address, bytearray):
        address = bytearray(address)
    return ('%u.%u.%u.%u' % (address[0], address[1],
                             address[2], address[3]))

def inet_aton(text):
    """Convert an IPv4 address in text form to binary form.

    *text*, a ``text``, the IPv4 address in textual form.

    Returns a ``binary``.
    """

    if not isinstance(text, binary_type):
        text = text.encode()
    parts = text.split(b'.')
    if len(parts) != 4:
        raise dns.exception.SyntaxError
    for part in parts:
        if not part.isdigit():
            raise dns.exception.SyntaxError
        if len(part) > 1 and part[0] == '0':
            # No leading zeros
            raise dns.exception.SyntaxError
    try:
        bytes = [int(part) for part in parts]
        return struct.pack('BBBB', *bytes)
    except:
        raise dns.exception.SyntaxError




############################################################
### File: ipv6.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""IPv6 helper functions."""

import re
import binascii

import dns.exception
import dns.ipv4
from ._compat import xrange, binary_type, maybe_decode

_leading_zero = re.compile(r'0+([0-9a-f]+)')

def inet_ntoa(address):
    """Convert an IPv6 address in binary form to text form.

    *address*, a ``binary``, the IPv6 address in binary form.

    Raises ``ValueError`` if the address isn't 16 bytes long.
    Returns a ``text``.
    """

    if len(address) != 16:
        raise ValueError("IPv6 addresses are 16 bytes long")
    hex = binascii.hexlify(address)
    chunks = []
    i = 0
    l = len(hex)
    while i < l:
        chunk = maybe_decode(hex[i : i + 4])
        # strip leading zeros.  we do this with an re instead of
        # with lstrip() because lstrip() didn't support chars until
        # python 2.2.2
        m = _leading_zero.match(chunk)
        if not m is None:
            chunk = m.group(1)
        chunks.append(chunk)
        i += 4
    #
    # Compress the longest subsequence of 0-value chunks to ::
    #
    best_start = 0
    best_len = 0
    start = -1
    last_was_zero = False
    for i in xrange(8):
        if chunks[i] != '0':
            if last_was_zero:
                end = i
                current_len = end - start
                if current_len > best_len:
                    best_start = start
                    best_len = current_len
                last_was_zero = False
        elif not last_was_zero:
            start = i
            last_was_zero = True
    if last_was_zero:
        end = 8
        current_len = end - start
        if current_len > best_len:
            best_start = start
            best_len = current_len
    if best_len > 1:
        if best_start == 0 and \
           (best_len == 6 or
            best_len == 5 and chunks[5] == 'ffff'):
            # We have an embedded IPv4 address
            if best_len == 6:
                prefix = '::'
            else:
                prefix = '::ffff:'
            hex = prefix + dns.ipv4.inet_ntoa(address[12:])
        else:
            hex = ':'.join(chunks[:best_start]) + '::' + \
                  ':'.join(chunks[best_start + best_len:])
    else:
        hex = ':'.join(chunks)
    return hex

_v4_ending = re.compile(br'(.*):(\d+\.\d+\.\d+\.\d+)$')
_colon_colon_start = re.compile(br'::.*')
_colon_colon_end = re.compile(br'.*::$')

def inet_aton(text):
    """Convert an IPv6 address in text form to binary form.

    *text*, a ``text``, the IPv6 address in textual form.

    Returns a ``binary``.
    """

    #
    # Our aim here is not something fast; we just want something that works.
    #
    if not isinstance(text, binary_type):
        text = text.encode()

    if text == b'::':
        text = b'0::'
    #
    # Get rid of the icky dot-quad syntax if we have it.
    #
    m = _v4_ending.match(text)
    if not m is None:
        b = bytearray(dns.ipv4.inet_aton(m.group(2)))
        text = (u"{}:{:02x}{:02x}:{:02x}{:02x}".format(m.group(1).decode(),
                                                       b[0], b[1], b[2],
                                                       b[3])).encode()
    #
    # Try to turn '::<whatever>' into ':<whatever>'; if no match try to
    # turn '<whatever>::' into '<whatever>:'
    #
    m = _colon_colon_start.match(text)
    if not m is None:
        text = text[1:]
    else:
        m = _colon_colon_end.match(text)
        if not m is None:
            text = text[:-1]
    #
    # Now canonicalize into 8 chunks of 4 hex digits each
    #
    chunks = text.split(b':')
    l = len(chunks)
    if l > 8:
        raise dns.exception.SyntaxError
    seen_empty = False
    canonical = []
    for c in chunks:
        if c == b'':
            if seen_empty:
                raise dns.exception.SyntaxError
            seen_empty = True
            for i in xrange(0, 8 - l + 1):
                canonical.append(b'0000')
        else:
            lc = len(c)
            if lc > 4:
                raise dns.exception.SyntaxError
            if lc != 4:
                c = (b'0' * (4 - lc)) + c
            canonical.append(c)
    if l < 8 and not seen_empty:
        raise dns.exception.SyntaxError
    text = b''.join(canonical)

    #
    # Finally we can go to binary.
    #
    try:
        return binascii.unhexlify(text)
    except (binascii.Error, TypeError):
        raise dns.exception.SyntaxError

_mapped_prefix = b'\x00' * 10 + b'\xff\xff'

def is_mapped(address):
    """Is the specified address a mapped IPv4 address?

    *address*, a ``binary`` is an IPv6 address in binary form.

    Returns a ``bool``.
    """

    return address.startswith(_mapped_prefix)




############################################################
### File: jisfreq.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

# Sampling from about 20M text materials include literature and computer technology
#
# Japanese frequency table, applied to both S-JIS and EUC-JP
# They are sorted in order.

# 128  --> 0.77094
# 256  --> 0.85710
# 512  --> 0.92635
# 1024 --> 0.97130
# 2048 --> 0.99431
#
# Ideal Distribution Ratio = 0.92635 / (1-0.92635) = 12.58
# Random Distribution Ration = 512 / (2965+62+83+86-512) = 0.191
#
# Typical Distribution Ratio, 25% of IDR

JIS_TYPICAL_DISTRIBUTION_RATIO = 3.0

# Char to FreqOrder table ,
JIS_TABLE_SIZE = 4368

JIS_CHAR_TO_FREQ_ORDER = (
  40,   1,   6, 182, 152, 180, 295,2127, 285, 381,3295,4304,3068,4606,3165,3510, #   16
3511,1822,2785,4607,1193,2226,5070,4608, 171,2996,1247,  18, 179,5071, 856,1661, #   32
1262,5072, 619, 127,3431,3512,3230,1899,1700, 232, 228,1294,1298, 284, 283,2041, #   48
2042,1061,1062,  48,  49,  44,  45, 433, 434,1040,1041, 996, 787,2997,1255,4305, #   64
2108,4609,1684,1648,5073,5074,5075,5076,5077,5078,3687,5079,4610,5080,3927,3928, #   80
5081,3296,3432, 290,2285,1471,2187,5082,2580,2825,1303,2140,1739,1445,2691,3375, #   96
1691,3297,4306,4307,4611, 452,3376,1182,2713,3688,3069,4308,5083,5084,5085,5086, #  112
5087,5088,5089,5090,5091,5092,5093,5094,5095,5096,5097,5098,5099,5100,5101,5102, #  128
5103,5104,5105,5106,5107,5108,5109,5110,5111,5112,4097,5113,5114,5115,5116,5117, #  144
5118,5119,5120,5121,5122,5123,5124,5125,5126,5127,5128,5129,5130,5131,5132,5133, #  160
5134,5135,5136,5137,5138,5139,5140,5141,5142,5143,5144,5145,5146,5147,5148,5149, #  176
5150,5151,5152,4612,5153,5154,5155,5156,5157,5158,5159,5160,5161,5162,5163,5164, #  192
5165,5166,5167,5168,5169,5170,5171,5172,5173,5174,5175,1472, 598, 618, 820,1205, #  208
1309,1412,1858,1307,1692,5176,5177,5178,5179,5180,5181,5182,1142,1452,1234,1172, #  224
1875,2043,2149,1793,1382,2973, 925,2404,1067,1241, 960,1377,2935,1491, 919,1217, #  240
1865,2030,1406,1499,2749,4098,5183,5184,5185,5186,5187,5188,2561,4099,3117,1804, #  256
2049,3689,4309,3513,1663,5189,3166,3118,3298,1587,1561,3433,5190,3119,1625,2998, #  272
3299,4613,1766,3690,2786,4614,5191,5192,5193,5194,2161,  26,3377,   2,3929,  20, #  288
3691,  47,4100,  50,  17,  16,  35, 268,  27, 243,  42, 155,  24, 154,  29, 184, #  304
   4,  91,  14,  92,  53, 396,  33, 289,   9,  37,  64, 620,  21,  39, 321,   5, #  320
  12,  11,  52,  13,   3, 208, 138,   0,   7,  60, 526, 141, 151,1069, 181, 275, #  336
1591,  83, 132,1475, 126, 331, 829,  15,  69, 160,  59,  22, 157,  55,1079, 312, #  352
 109,  38,  23,  25,  10,  19,  79,5195,  61, 382,1124,   8,  30,5196,5197,5198, #  368
5199,5200,5201,5202,5203,5204,5205,5206,  89,  62,  74,  34,2416, 112, 139, 196, #  384
 271, 149,  84, 607, 131, 765,  46,  88, 153, 683,  76, 874, 101, 258,  57,  80, #  400
  32, 364, 121,1508, 169,1547,  68, 235, 145,2999,  41, 360,3027,  70,  63,  31, #  416
  43, 259, 262,1383,  99, 533, 194,  66,  93, 846, 217, 192,  56, 106,  58, 565, #  432
 280, 272, 311, 256, 146,  82, 308,  71, 100, 128, 214, 655, 110, 261, 104,1140, #  448
  54,  51,  36,  87,  67,3070, 185,2618,2936,2020,  28,1066,2390,2059,5207,5208, #  464
5209,5210,5211,5212,5213,5214,5215,5216,4615,5217,5218,5219,5220,5221,5222,5223, #  480
5224,5225,5226,5227,5228,5229,5230,5231,5232,5233,5234,5235,5236,3514,5237,5238, #  496
5239,5240,5241,5242,5243,5244,2297,2031,4616,4310,3692,5245,3071,5246,3598,5247, #  512
4617,3231,3515,5248,4101,4311,4618,3808,4312,4102,5249,4103,4104,3599,5250,5251, #  528
5252,5253,5254,5255,5256,5257,5258,5259,5260,5261,5262,5263,5264,5265,5266,5267, #  544
5268,5269,5270,5271,5272,5273,5274,5275,5276,5277,5278,5279,5280,5281,5282,5283, #  560
5284,5285,5286,5287,5288,5289,5290,5291,5292,5293,5294,5295,5296,5297,5298,5299, #  576
5300,5301,5302,5303,5304,5305,5306,5307,5308,5309,5310,5311,5312,5313,5314,5315, #  592
5316,5317,5318,5319,5320,5321,5322,5323,5324,5325,5326,5327,5328,5329,5330,5331, #  608
5332,5333,5334,5335,5336,5337,5338,5339,5340,5341,5342,5343,5344,5345,5346,5347, #  624
5348,5349,5350,5351,5352,5353,5354,5355,5356,5357,5358,5359,5360,5361,5362,5363, #  640
5364,5365,5366,5367,5368,5369,5370,5371,5372,5373,5374,5375,5376,5377,5378,5379, #  656
5380,5381, 363, 642,2787,2878,2788,2789,2316,3232,2317,3434,2011, 165,1942,3930, #  672
3931,3932,3933,5382,4619,5383,4620,5384,5385,5386,5387,5388,5389,5390,5391,5392, #  688
5393,5394,5395,5396,5397,5398,5399,5400,5401,5402,5403,5404,5405,5406,5407,5408, #  704
5409,5410,5411,5412,5413,5414,5415,5416,5417,5418,5419,5420,5421,5422,5423,5424, #  720
5425,5426,5427,5428,5429,5430,5431,5432,5433,5434,5435,5436,5437,5438,5439,5440, #  736
5441,5442,5443,5444,5445,5446,5447,5448,5449,5450,5451,5452,5453,5454,5455,5456, #  752
5457,5458,5459,5460,5461,5462,5463,5464,5465,5466,5467,5468,5469,5470,5471,5472, #  768
5473,5474,5475,5476,5477,5478,5479,5480,5481,5482,5483,5484,5485,5486,5487,5488, #  784
5489,5490,5491,5492,5493,5494,5495,5496,5497,5498,5499,5500,5501,5502,5503,5504, #  800
5505,5506,5507,5508,5509,5510,5511,5512,5513,5514,5515,5516,5517,5518,5519,5520, #  816
5521,5522,5523,5524,5525,5526,5527,5528,5529,5530,5531,5532,5533,5534,5535,5536, #  832
5537,5538,5539,5540,5541,5542,5543,5544,5545,5546,5547,5548,5549,5550,5551,5552, #  848
5553,5554,5555,5556,5557,5558,5559,5560,5561,5562,5563,5564,5565,5566,5567,5568, #  864
5569,5570,5571,5572,5573,5574,5575,5576,5577,5578,5579,5580,5581,5582,5583,5584, #  880
5585,5586,5587,5588,5589,5590,5591,5592,5593,5594,5595,5596,5597,5598,5599,5600, #  896
5601,5602,5603,5604,5605,5606,5607,5608,5609,5610,5611,5612,5613,5614,5615,5616, #  912
5617,5618,5619,5620,5621,5622,5623,5624,5625,5626,5627,5628,5629,5630,5631,5632, #  928
5633,5634,5635,5636,5637,5638,5639,5640,5641,5642,5643,5644,5645,5646,5647,5648, #  944
5649,5650,5651,5652,5653,5654,5655,5656,5657,5658,5659,5660,5661,5662,5663,5664, #  960
5665,5666,5667,5668,5669,5670,5671,5672,5673,5674,5675,5676,5677,5678,5679,5680, #  976
5681,5682,5683,5684,5685,5686,5687,5688,5689,5690,5691,5692,5693,5694,5695,5696, #  992
5697,5698,5699,5700,5701,5702,5703,5704,5705,5706,5707,5708,5709,5710,5711,5712, # 1008
5713,5714,5715,5716,5717,5718,5719,5720,5721,5722,5723,5724,5725,5726,5727,5728, # 1024
5729,5730,5731,5732,5733,5734,5735,5736,5737,5738,5739,5740,5741,5742,5743,5744, # 1040
5745,5746,5747,5748,5749,5750,5751,5752,5753,5754,5755,5756,5757,5758,5759,5760, # 1056
5761,5762,5763,5764,5765,5766,5767,5768,5769,5770,5771,5772,5773,5774,5775,5776, # 1072
5777,5778,5779,5780,5781,5782,5783,5784,5785,5786,5787,5788,5789,5790,5791,5792, # 1088
5793,5794,5795,5796,5797,5798,5799,5800,5801,5802,5803,5804,5805,5806,5807,5808, # 1104
5809,5810,5811,5812,5813,5814,5815,5816,5817,5818,5819,5820,5821,5822,5823,5824, # 1120
5825,5826,5827,5828,5829,5830,5831,5832,5833,5834,5835,5836,5837,5838,5839,5840, # 1136
5841,5842,5843,5844,5845,5846,5847,5848,5849,5850,5851,5852,5853,5854,5855,5856, # 1152
5857,5858,5859,5860,5861,5862,5863,5864,5865,5866,5867,5868,5869,5870,5871,5872, # 1168
5873,5874,5875,5876,5877,5878,5879,5880,5881,5882,5883,5884,5885,5886,5887,5888, # 1184
5889,5890,5891,5892,5893,5894,5895,5896,5897,5898,5899,5900,5901,5902,5903,5904, # 1200
5905,5906,5907,5908,5909,5910,5911,5912,5913,5914,5915,5916,5917,5918,5919,5920, # 1216
5921,5922,5923,5924,5925,5926,5927,5928,5929,5930,5931,5932,5933,5934,5935,5936, # 1232
5937,5938,5939,5940,5941,5942,5943,5944,5945,5946,5947,5948,5949,5950,5951,5952, # 1248
5953,5954,5955,5956,5957,5958,5959,5960,5961,5962,5963,5964,5965,5966,5967,5968, # 1264
5969,5970,5971,5972,5973,5974,5975,5976,5977,5978,5979,5980,5981,5982,5983,5984, # 1280
5985,5986,5987,5988,5989,5990,5991,5992,5993,5994,5995,5996,5997,5998,5999,6000, # 1296
6001,6002,6003,6004,6005,6006,6007,6008,6009,6010,6011,6012,6013,6014,6015,6016, # 1312
6017,6018,6019,6020,6021,6022,6023,6024,6025,6026,6027,6028,6029,6030,6031,6032, # 1328
6033,6034,6035,6036,6037,6038,6039,6040,6041,6042,6043,6044,6045,6046,6047,6048, # 1344
6049,6050,6051,6052,6053,6054,6055,6056,6057,6058,6059,6060,6061,6062,6063,6064, # 1360
6065,6066,6067,6068,6069,6070,6071,6072,6073,6074,6075,6076,6077,6078,6079,6080, # 1376
6081,6082,6083,6084,6085,6086,6087,6088,6089,6090,6091,6092,6093,6094,6095,6096, # 1392
6097,6098,6099,6100,6101,6102,6103,6104,6105,6106,6107,6108,6109,6110,6111,6112, # 1408
6113,6114,2044,2060,4621, 997,1235, 473,1186,4622, 920,3378,6115,6116, 379,1108, # 1424
4313,2657,2735,3934,6117,3809, 636,3233, 573,1026,3693,3435,2974,3300,2298,4105, # 1440
 854,2937,2463, 393,2581,2417, 539, 752,1280,2750,2480, 140,1161, 440, 708,1569, # 1456
 665,2497,1746,1291,1523,3000, 164,1603, 847,1331, 537,1997, 486, 508,1693,2418, # 1472
1970,2227, 878,1220, 299,1030, 969, 652,2751, 624,1137,3301,2619,  65,3302,2045, # 1488
1761,1859,3120,1930,3694,3516, 663,1767, 852, 835,3695, 269, 767,2826,2339,1305, # 1504
 896,1150, 770,1616,6118, 506,1502,2075,1012,2519, 775,2520,2975,2340,2938,4314, # 1520
3028,2086,1224,1943,2286,6119,3072,4315,2240,1273,1987,3935,1557, 175, 597, 985, # 1536
3517,2419,2521,1416,3029, 585, 938,1931,1007,1052,1932,1685,6120,3379,4316,4623, # 1552
 804, 599,3121,1333,2128,2539,1159,1554,2032,3810, 687,2033,2904, 952, 675,1467, # 1568
3436,6121,2241,1096,1786,2440,1543,1924, 980,1813,2228, 781,2692,1879, 728,1918, # 1584
3696,4624, 548,1950,4625,1809,1088,1356,3303,2522,1944, 502, 972, 373, 513,2827, # 1600
 586,2377,2391,1003,1976,1631,6122,2464,1084, 648,1776,4626,2141, 324, 962,2012, # 1616
2177,2076,1384, 742,2178,1448,1173,1810, 222, 102, 301, 445, 125,2420, 662,2498, # 1632
 277, 200,1476,1165,1068, 224,2562,1378,1446, 450,1880, 659, 791, 582,4627,2939, # 1648
3936,1516,1274, 555,2099,3697,1020,1389,1526,3380,1762,1723,1787,2229, 412,2114, # 1664
1900,2392,3518, 512,2597, 427,1925,2341,3122,1653,1686,2465,2499, 697, 330, 273, # 1680
 380,2162, 951, 832, 780, 991,1301,3073, 965,2270,3519, 668,2523,2636,1286, 535, # 1696
1407, 518, 671, 957,2658,2378, 267, 611,2197,3030,6123, 248,2299, 967,1799,2356, # 1712
 850,1418,3437,1876,1256,1480,2828,1718,6124,6125,1755,1664,2405,6126,4628,2879, # 1728
2829, 499,2179, 676,4629, 557,2329,2214,2090, 325,3234, 464, 811,3001, 992,2342, # 1744
2481,1232,1469, 303,2242, 466,1070,2163, 603,1777,2091,4630,2752,4631,2714, 322, # 1760
2659,1964,1768, 481,2188,1463,2330,2857,3600,2092,3031,2421,4632,2318,2070,1849, # 1776
2598,4633,1302,2254,1668,1701,2422,3811,2905,3032,3123,2046,4106,1763,1694,4634, # 1792
1604, 943,1724,1454, 917, 868,2215,1169,2940, 552,1145,1800,1228,1823,1955, 316, # 1808
1080,2510, 361,1807,2830,4107,2660,3381,1346,1423,1134,4108,6127, 541,1263,1229, # 1824
1148,2540, 545, 465,1833,2880,3438,1901,3074,2482, 816,3937, 713,1788,2500, 122, # 1840
1575, 195,1451,2501,1111,6128, 859, 374,1225,2243,2483,4317, 390,1033,3439,3075, # 1856
2524,1687, 266, 793,1440,2599, 946, 779, 802, 507, 897,1081, 528,2189,1292, 711, # 1872
1866,1725,1167,1640, 753, 398,2661,1053, 246, 348,4318, 137,1024,3440,1600,2077, # 1888
2129, 825,4319, 698, 238, 521, 187,2300,1157,2423,1641,1605,1464,1610,1097,2541, # 1904
1260,1436, 759,2255,1814,2150, 705,3235, 409,2563,3304, 561,3033,2005,2564, 726, # 1920
1956,2343,3698,4109, 949,3812,3813,3520,1669, 653,1379,2525, 881,2198, 632,2256, # 1936
1027, 778,1074, 733,1957, 514,1481,2466, 554,2180, 702,3938,1606,1017,1398,6129, # 1952
1380,3521, 921, 993,1313, 594, 449,1489,1617,1166, 768,1426,1360, 495,1794,3601, # 1968
1177,3602,1170,4320,2344, 476, 425,3167,4635,3168,1424, 401,2662,1171,3382,1998, # 1984
1089,4110, 477,3169, 474,6130,1909, 596,2831,1842, 494, 693,1051,1028,1207,3076, # 2000
 606,2115, 727,2790,1473,1115, 743,3522, 630, 805,1532,4321,2021, 366,1057, 838, # 2016
 684,1114,2142,4322,2050,1492,1892,1808,2271,3814,2424,1971,1447,1373,3305,1090, # 2032
1536,3939,3523,3306,1455,2199, 336, 369,2331,1035, 584,2393, 902, 718,2600,6131, # 2048
2753, 463,2151,1149,1611,2467, 715,1308,3124,1268, 343,1413,3236,1517,1347,2663, # 2064
2093,3940,2022,1131,1553,2100,2941,1427,3441,2942,1323,2484,6132,1980, 872,2368, # 2080
2441,2943, 320,2369,2116,1082, 679,1933,3941,2791,3815, 625,1143,2023, 422,2200, # 2096
3816,6133, 730,1695, 356,2257,1626,2301,2858,2637,1627,1778, 937, 883,2906,2693, # 2112
3002,1769,1086, 400,1063,1325,3307,2792,4111,3077, 456,2345,1046, 747,6134,1524, # 2128
 884,1094,3383,1474,2164,1059, 974,1688,2181,2258,1047, 345,1665,1187, 358, 875, # 2144
3170, 305, 660,3524,2190,1334,1135,3171,1540,1649,2542,1527, 927, 968,2793, 885, # 2160
1972,1850, 482, 500,2638,1218,1109,1085,2543,1654,2034, 876,  78,2287,1482,1277, # 2176
 861,1675,1083,1779, 724,2754, 454, 397,1132,1612,2332, 893, 672,1237, 257,2259, # 2192
2370, 135,3384, 337,2244, 547, 352, 340, 709,2485,1400, 788,1138,2511, 540, 772, # 2208
1682,2260,2272,2544,2013,1843,1902,4636,1999,1562,2288,4637,2201,1403,1533, 407, # 2224
 576,3308,1254,2071, 978,3385, 170, 136,1201,3125,2664,3172,2394, 213, 912, 873, # 2240
3603,1713,2202, 699,3604,3699, 813,3442, 493, 531,1054, 468,2907,1483, 304, 281, # 2256
4112,1726,1252,2094, 339,2319,2130,2639, 756,1563,2944, 748, 571,2976,1588,2425, # 2272
2715,1851,1460,2426,1528,1392,1973,3237, 288,3309, 685,3386, 296, 892,2716,2216, # 2288
1570,2245, 722,1747,2217, 905,3238,1103,6135,1893,1441,1965, 251,1805,2371,3700, # 2304
2601,1919,1078,  75,2182,1509,1592,1270,2640,4638,2152,6136,3310,3817, 524, 706, # 2320
1075, 292,3818,1756,2602, 317,  98,3173,3605,3525,1844,2218,3819,2502, 814, 567, # 2336
 385,2908,1534,6137, 534,1642,3239, 797,6138,1670,1529, 953,4323, 188,1071, 538, # 2352
 178, 729,3240,2109,1226,1374,2000,2357,2977, 731,2468,1116,2014,2051,6139,1261, # 2368
1593, 803,2859,2736,3443, 556, 682, 823,1541,6140,1369,2289,1706,2794, 845, 462, # 2384
2603,2665,1361, 387, 162,2358,1740, 739,1770,1720,1304,1401,3241,1049, 627,1571, # 2400
2427,3526,1877,3942,1852,1500, 431,1910,1503, 677, 297,2795, 286,1433,1038,1198, # 2416
2290,1133,1596,4113,4639,2469,1510,1484,3943,6141,2442, 108, 712,4640,2372, 866, # 2432
3701,2755,3242,1348, 834,1945,1408,3527,2395,3243,1811, 824, 994,1179,2110,1548, # 2448
1453, 790,3003, 690,4324,4325,2832,2909,3820,1860,3821, 225,1748, 310, 346,1780, # 2464
2470, 821,1993,2717,2796, 828, 877,3528,2860,2471,1702,2165,2910,2486,1789, 453, # 2480
 359,2291,1676,  73,1164,1461,1127,3311, 421, 604, 314,1037, 589, 116,2487, 737, # 2496
 837,1180, 111, 244, 735,6142,2261,1861,1362, 986, 523, 418, 581,2666,3822, 103, # 2512
 855, 503,1414,1867,2488,1091, 657,1597, 979, 605,1316,4641,1021,2443,2078,2001, # 2528
1209,  96, 587,2166,1032, 260,1072,2153, 173,  94, 226,3244, 819,2006,4642,4114, # 2544
2203, 231,1744, 782,  97,2667, 786,3387, 887, 391, 442,2219,4326,1425,6143,2694, # 2560
 633,1544,1202, 483,2015, 592,2052,1958,2472,1655, 419, 129,4327,3444,3312,1714, # 2576
1257,3078,4328,1518,1098, 865,1310,1019,1885,1512,1734, 469,2444, 148, 773, 436, # 2592
1815,1868,1128,1055,4329,1245,2756,3445,2154,1934,1039,4643, 579,1238, 932,2320, # 2608
 353, 205, 801, 115,2428, 944,2321,1881, 399,2565,1211, 678, 766,3944, 335,2101, # 2624
1459,1781,1402,3945,2737,2131,1010, 844, 981,1326,1013, 550,1816,1545,2620,1335, # 2640
1008, 371,2881, 936,1419,1613,3529,1456,1395,2273,1834,2604,1317,2738,2503, 416, # 2656
1643,4330, 806,1126, 229, 591,3946,1314,1981,1576,1837,1666, 347,1790, 977,3313, # 2672
 764,2861,1853, 688,2429,1920,1462,  77, 595, 415,2002,3034, 798,1192,4115,6144, # 2688
2978,4331,3035,2695,2582,2072,2566, 430,2430,1727, 842,1396,3947,3702, 613, 377, # 2704
 278, 236,1417,3388,3314,3174, 757,1869, 107,3530,6145,1194, 623,2262, 207,1253, # 2720
2167,3446,3948, 492,1117,1935, 536,1838,2757,1246,4332, 696,2095,2406,1393,1572, # 2736
3175,1782, 583, 190, 253,1390,2230, 830,3126,3389, 934,3245,1703,1749,2979,1870, # 2752
2545,1656,2204, 869,2346,4116,3176,1817, 496,1764,4644, 942,1504, 404,1903,1122, # 2768
1580,3606,2945,1022, 515, 372,1735, 955,2431,3036,6146,2797,1110,2302,2798, 617, # 2784
6147, 441, 762,1771,3447,3607,3608,1904, 840,3037,  86, 939,1385, 572,1370,2445, # 2800
1336, 114,3703, 898, 294, 203,3315, 703,1583,2274, 429, 961,4333,1854,1951,3390, # 2816
2373,3704,4334,1318,1381, 966,1911,2322,1006,1155, 309, 989, 458,2718,1795,1372, # 2832
1203, 252,1689,1363,3177, 517,1936, 168,1490, 562, 193,3823,1042,4117,1835, 551, # 2848
 470,4645, 395, 489,3448,1871,1465,2583,2641, 417,1493, 279,1295, 511,1236,1119, # 2864
  72,1231,1982,1812,3004, 871,1564, 984,3449,1667,2696,2096,4646,2347,2833,1673, # 2880
3609, 695,3246,2668, 807,1183,4647, 890, 388,2333,1801,1457,2911,1765,1477,1031, # 2896
3316,3317,1278,3391,2799,2292,2526, 163,3450,4335,2669,1404,1802,6148,2323,2407, # 2912
1584,1728,1494,1824,1269, 298, 909,3318,1034,1632, 375, 776,1683,2061, 291, 210, # 2928
1123, 809,1249,1002,2642,3038, 206,1011,2132, 144, 975, 882,1565, 342, 667, 754, # 2944
1442,2143,1299,2303,2062, 447, 626,2205,1221,2739,2912,1144,1214,2206,2584, 760, # 2960
1715, 614, 950,1281,2670,2621, 810, 577,1287,2546,4648, 242,2168, 250,2643, 691, # 2976
 123,2644, 647, 313,1029, 689,1357,2946,1650, 216, 771,1339,1306, 808,2063, 549, # 2992
 913,1371,2913,2914,6149,1466,1092,1174,1196,1311,2605,2396,1783,1796,3079, 406, # 3008
2671,2117,3949,4649, 487,1825,2220,6150,2915, 448,2348,1073,6151,2397,1707, 130, # 3024
 900,1598, 329, 176,1959,2527,1620,6152,2275,4336,3319,1983,2191,3705,3610,2155, # 3040
3706,1912,1513,1614,6153,1988, 646, 392,2304,1589,3320,3039,1826,1239,1352,1340, # 3056
2916, 505,2567,1709,1437,2408,2547, 906,6154,2672, 384,1458,1594,1100,1329, 710, # 3072
 423,3531,2064,2231,2622,1989,2673,1087,1882, 333, 841,3005,1296,2882,2379, 580, # 3088
1937,1827,1293,2585, 601, 574, 249,1772,4118,2079,1120, 645, 901,1176,1690, 795, # 3104
2207, 478,1434, 516,1190,1530, 761,2080, 930,1264, 355, 435,1552, 644,1791, 987, # 3120
 220,1364,1163,1121,1538, 306,2169,1327,1222, 546,2645, 218, 241, 610,1704,3321, # 3136
1984,1839,1966,2528, 451,6155,2586,3707,2568, 907,3178, 254,2947, 186,1845,4650, # 3152
 745, 432,1757, 428,1633, 888,2246,2221,2489,3611,2118,1258,1265, 956,3127,1784, # 3168
4337,2490, 319, 510, 119, 457,3612, 274,2035,2007,4651,1409,3128, 970,2758, 590, # 3184
2800, 661,2247,4652,2008,3950,1420,1549,3080,3322,3951,1651,1375,2111, 485,2491, # 3200
1429,1156,6156,2548,2183,1495, 831,1840,2529,2446, 501,1657, 307,1894,3247,1341, # 3216
 666, 899,2156,1539,2549,1559, 886, 349,2208,3081,2305,1736,3824,2170,2759,1014, # 3232
1913,1386, 542,1397,2948, 490, 368, 716, 362, 159, 282,2569,1129,1658,1288,1750, # 3248
2674, 276, 649,2016, 751,1496, 658,1818,1284,1862,2209,2087,2512,3451, 622,2834, # 3264
 376, 117,1060,2053,1208,1721,1101,1443, 247,1250,3179,1792,3952,2760,2398,3953, # 3280
6157,2144,3708, 446,2432,1151,2570,3452,2447,2761,2835,1210,2448,3082, 424,2222, # 3296
1251,2449,2119,2836, 504,1581,4338, 602, 817, 857,3825,2349,2306, 357,3826,1470, # 3312
1883,2883, 255, 958, 929,2917,3248, 302,4653,1050,1271,1751,2307,1952,1430,2697, # 3328
2719,2359, 354,3180, 777, 158,2036,4339,1659,4340,4654,2308,2949,2248,1146,2232, # 3344
3532,2720,1696,2623,3827,6158,3129,1550,2698,1485,1297,1428, 637, 931,2721,2145, # 3360
 914,2550,2587,  81,2450, 612, 827,2646,1242,4655,1118,2884, 472,1855,3181,3533, # 3376
3534, 569,1353,2699,1244,1758,2588,4119,2009,2762,2171,3709,1312,1531,6159,1152, # 3392
1938, 134,1830, 471,3710,2276,1112,1535,3323,3453,3535, 982,1337,2950, 488, 826, # 3408
 674,1058,1628,4120,2017, 522,2399, 211, 568,1367,3454, 350, 293,1872,1139,3249, # 3424
1399,1946,3006,1300,2360,3324, 588, 736,6160,2606, 744, 669,3536,3828,6161,1358, # 3440
 199, 723, 848, 933, 851,1939,1505,1514,1338,1618,1831,4656,1634,3613, 443,2740, # 3456
3829, 717,1947, 491,1914,6162,2551,1542,4121,1025,6163,1099,1223, 198,3040,2722, # 3472
 370, 410,1905,2589, 998,1248,3182,2380, 519,1449,4122,1710, 947, 928,1153,4341, # 3488
2277, 344,2624,1511, 615, 105, 161,1212,1076,1960,3130,2054,1926,1175,1906,2473, # 3504
 414,1873,2801,6164,2309, 315,1319,3325, 318,2018,2146,2157, 963, 631, 223,4342, # 3520
4343,2675, 479,3711,1197,2625,3712,2676,2361,6165,4344,4123,6166,2451,3183,1886, # 3536
2184,1674,1330,1711,1635,1506, 799, 219,3250,3083,3954,1677,3713,3326,2081,3614, # 3552
1652,2073,4657,1147,3041,1752, 643,1961, 147,1974,3955,6167,1716,2037, 918,3007, # 3568
1994, 120,1537, 118, 609,3184,4345, 740,3455,1219, 332,1615,3830,6168,1621,2980, # 3584
1582, 783, 212, 553,2350,3714,1349,2433,2082,4124, 889,6169,2310,1275,1410, 973, # 3600
 166,1320,3456,1797,1215,3185,2885,1846,2590,2763,4658, 629, 822,3008, 763, 940, # 3616
1990,2862, 439,2409,1566,1240,1622, 926,1282,1907,2764, 654,2210,1607, 327,1130, # 3632
3956,1678,1623,6170,2434,2192, 686, 608,3831,3715, 903,3957,3042,6171,2741,1522, # 3648
1915,1105,1555,2552,1359, 323,3251,4346,3457, 738,1354,2553,2311,2334,1828,2003, # 3664
3832,1753,2351,1227,6172,1887,4125,1478,6173,2410,1874,1712,1847, 520,1204,2607, # 3680
 264,4659, 836,2677,2102, 600,4660,3833,2278,3084,6174,4347,3615,1342, 640, 532, # 3696
 543,2608,1888,2400,2591,1009,4348,1497, 341,1737,3616,2723,1394, 529,3252,1321, # 3712
 983,4661,1515,2120, 971,2592, 924, 287,1662,3186,4349,2700,4350,1519, 908,1948, # 3728
2452, 156, 796,1629,1486,2223,2055, 694,4126,1259,1036,3392,1213,2249,2742,1889, # 3744
1230,3958,1015, 910, 408, 559,3617,4662, 746, 725, 935,4663,3959,3009,1289, 563, # 3760
 867,4664,3960,1567,2981,2038,2626, 988,2263,2381,4351, 143,2374, 704,1895,6175, # 3776
1188,3716,2088, 673,3085,2362,4352, 484,1608,1921,2765,2918, 215, 904,3618,3537, # 3792
 894, 509, 976,3043,2701,3961,4353,2837,2982, 498,6176,6177,1102,3538,1332,3393, # 3808
1487,1636,1637, 233, 245,3962, 383, 650, 995,3044, 460,1520,1206,2352, 749,3327, # 3824
 530, 700, 389,1438,1560,1773,3963,2264, 719,2951,2724,3834, 870,1832,1644,1000, # 3840
 839,2474,3717, 197,1630,3394, 365,2886,3964,1285,2133, 734, 922, 818,1106, 732, # 3856
 480,2083,1774,3458, 923,2279,1350, 221,3086,  85,2233,2234,3835,1585,3010,2147, # 3872
1387,1705,2382,1619,2475, 133, 239,2802,1991,1016,2084,2383, 411,2838,1113, 651, # 3888
1985,1160,3328, 990,1863,3087,1048,1276,2647, 265,2627,1599,3253,2056, 150, 638, # 3904
2019, 656, 853, 326,1479, 680,1439,4354,1001,1759, 413,3459,3395,2492,1431, 459, # 3920
4355,1125,3329,2265,1953,1450,2065,2863, 849, 351,2678,3131,3254,3255,1104,1577, # 3936
 227,1351,1645,2453,2193,1421,2887, 812,2121, 634,  95,2435, 201,2312,4665,1646, # 3952
1671,2743,1601,2554,2702,2648,2280,1315,1366,2089,3132,1573,3718,3965,1729,1189, # 3968
 328,2679,1077,1940,1136, 558,1283, 964,1195, 621,2074,1199,1743,3460,3619,1896, # 3984
1916,1890,3836,2952,1154,2112,1064, 862, 378,3011,2066,2113,2803,1568,2839,6178, # 4000
3088,2919,1941,1660,2004,1992,2194, 142, 707,1590,1708,1624,1922,1023,1836,1233, # 4016
1004,2313, 789, 741,3620,6179,1609,2411,1200,4127,3719,3720,4666,2057,3721, 593, # 4032
2840, 367,2920,1878,6180,3461,1521, 628,1168, 692,2211,2649, 300, 720,2067,2571, # 4048
2953,3396, 959,2504,3966,3539,3462,1977, 701,6181, 954,1043, 800, 681, 183,3722, # 4064
1803,1730,3540,4128,2103, 815,2314, 174, 467, 230,2454,1093,2134, 755,3541,3397, # 4080
1141,1162,6182,1738,2039, 270,3256,2513,1005,1647,2185,3837, 858,1679,1897,1719, # 4096
2954,2324,1806, 402, 670, 167,4129,1498,2158,2104, 750,6183, 915, 189,1680,1551, # 4112
 455,4356,1501,2455, 405,1095,2955, 338,1586,1266,1819, 570, 641,1324, 237,1556, # 4128
2650,1388,3723,6184,1368,2384,1343,1978,3089,2436, 879,3724, 792,1191, 758,3012, # 4144
1411,2135,1322,4357, 240,4667,1848,3725,1574,6185, 420,3045,1546,1391, 714,4358, # 4160
1967, 941,1864, 863, 664, 426, 560,1731,2680,1785,2864,1949,2363, 403,3330,1415, # 4176
1279,2136,1697,2335, 204, 721,2097,3838,  90,6186,2085,2505, 191,3967, 124,2148, # 4192
1376,1798,1178,1107,1898,1405, 860,4359,1243,1272,2375,2983,1558,2456,1638, 113, # 4208
3621, 578,1923,2609, 880, 386,4130, 784,2186,2266,1422,2956,2172,1722, 497, 263, # 4224
2514,1267,2412,2610, 177,2703,3542, 774,1927,1344, 616,1432,1595,1018, 172,4360, # 4240
2325, 911,4361, 438,1468,3622, 794,3968,2024,2173,1681,1829,2957, 945, 895,3090, # 4256
 575,2212,2476, 475,2401,2681, 785,2744,1745,2293,2555,1975,3133,2865, 394,4668, # 4272
3839, 635,4131, 639, 202,1507,2195,2766,1345,1435,2572,3726,1908,1184,1181,2457, # 4288
3727,3134,4362, 843,2611, 437, 916,4669, 234, 769,1884,3046,3047,3623, 833,6187, # 4304
1639,2250,2402,1355,1185,2010,2047, 999, 525,1732,1290,1488,2612, 948,1578,3728, # 4320
2413,2477,1216,2725,2159, 334,3840,1328,3624,2921,1525,4132, 564,1056, 891,4363, # 4336
1444,1698,2385,2251,3729,1365,2281,2235,1717,6188, 864,3841,2515, 444, 527,2767, # 4352
2922,3625, 544, 461,6189, 566, 209,2437,3398,2098,1065,2068,3331,3626,3257,2137, # 4368  #last 512
)






############################################################
### File: jpcntx.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Communicator client code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################


# This is hiragana 2-char sequence table, the number in each cell represents its frequency category
jp2CharContext = (
(0,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1),
(2,4,0,4,0,3,0,4,0,3,4,4,4,2,4,3,3,4,3,2,3,3,4,2,3,3,3,2,4,1,4,3,3,1,5,4,3,4,3,4,3,5,3,0,3,5,4,2,0,3,1,0,3,3,0,3,3,0,1,1,0,4,3,0,3,3,0,4,0,2,0,3,5,5,5,5,4,0,4,1,0,3,4),
(0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2),
(0,4,0,5,0,5,0,4,0,4,5,4,4,3,5,3,5,1,5,3,4,3,4,4,3,4,3,3,4,3,5,4,4,3,5,5,3,5,5,5,3,5,5,3,4,5,5,3,1,3,2,0,3,4,0,4,2,0,4,2,1,5,3,2,3,5,0,4,0,2,0,5,4,4,5,4,5,0,4,0,0,4,4),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,3,0,4,0,3,0,3,0,4,5,4,3,3,3,3,4,3,5,4,4,3,5,4,4,3,4,3,4,4,4,4,5,3,4,4,3,4,5,5,4,5,5,1,4,5,4,3,0,3,3,1,3,3,0,4,4,0,3,3,1,5,3,3,3,5,0,4,0,3,0,4,4,3,4,3,3,0,4,1,1,3,4),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,4,0,3,0,3,0,4,0,3,4,4,3,2,2,1,2,1,3,1,3,3,3,3,3,4,3,1,3,3,5,3,3,0,4,3,0,5,4,3,3,5,4,4,3,4,4,5,0,1,2,0,1,2,0,2,2,0,1,0,0,5,2,2,1,4,0,3,0,1,0,4,4,3,5,4,3,0,2,1,0,4,3),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,3,0,5,0,4,0,2,1,4,4,2,4,1,4,2,4,2,4,3,3,3,4,3,3,3,3,1,4,2,3,3,3,1,4,4,1,1,1,4,3,3,2,0,2,4,3,2,0,3,3,0,3,1,1,0,0,0,3,3,0,4,2,2,3,4,0,4,0,3,0,4,4,5,3,4,4,0,3,0,0,1,4),
(1,4,0,4,0,4,0,4,0,3,5,4,4,3,4,3,5,4,3,3,4,3,5,4,4,4,4,3,4,2,4,3,3,1,5,4,3,2,4,5,4,5,5,4,4,5,4,4,0,3,2,2,3,3,0,4,3,1,3,2,1,4,3,3,4,5,0,3,0,2,0,4,5,5,4,5,4,0,4,0,0,5,4),
(0,5,0,5,0,4,0,3,0,4,4,3,4,3,3,3,4,0,4,4,4,3,4,3,4,3,3,1,4,2,4,3,4,0,5,4,1,4,5,4,4,5,3,2,4,3,4,3,2,4,1,3,3,3,2,3,2,0,4,3,3,4,3,3,3,4,0,4,0,3,0,4,5,4,4,4,3,0,4,1,0,1,3),
(0,3,1,4,0,3,0,2,0,3,4,4,3,1,4,2,3,3,4,3,4,3,4,3,4,4,3,2,3,1,5,4,4,1,4,4,3,5,4,4,3,5,5,4,3,4,4,3,1,2,3,1,2,2,0,3,2,0,3,1,0,5,3,3,3,4,3,3,3,3,4,4,4,4,5,4,2,0,3,3,2,4,3),
(0,2,0,3,0,1,0,1,0,0,3,2,0,0,2,0,1,0,2,1,3,3,3,1,2,3,1,0,1,0,4,2,1,1,3,3,0,4,3,3,1,4,3,3,0,3,3,2,0,0,0,0,1,0,0,2,0,0,0,0,0,4,1,0,2,3,2,2,2,1,3,3,3,4,4,3,2,0,3,1,0,3,3),
(0,4,0,4,0,3,0,3,0,4,4,4,3,3,3,3,3,3,4,3,4,2,4,3,4,3,3,2,4,3,4,5,4,1,4,5,3,5,4,5,3,5,4,0,3,5,5,3,1,3,3,2,2,3,0,3,4,1,3,3,2,4,3,3,3,4,0,4,0,3,0,4,5,4,4,5,3,0,4,1,0,3,4),
(0,2,0,3,0,3,0,0,0,2,2,2,1,0,1,0,0,0,3,0,3,0,3,0,1,3,1,0,3,1,3,3,3,1,3,3,3,0,1,3,1,3,4,0,0,3,1,1,0,3,2,0,0,0,0,1,3,0,1,0,0,3,3,2,0,3,0,0,0,0,0,3,4,3,4,3,3,0,3,0,0,2,3),
(2,3,0,3,0,2,0,1,0,3,3,4,3,1,3,1,1,1,3,1,4,3,4,3,3,3,0,0,3,1,5,4,3,1,4,3,2,5,5,4,4,4,4,3,3,4,4,4,0,2,1,1,3,2,0,1,2,0,0,1,0,4,1,3,3,3,0,3,0,1,0,4,4,4,5,5,3,0,2,0,0,4,4),
(0,2,0,1,0,3,1,3,0,2,3,3,3,0,3,1,0,0,3,0,3,2,3,1,3,2,1,1,0,0,4,2,1,0,2,3,1,4,3,2,0,4,4,3,1,3,1,3,0,1,0,0,1,0,0,0,1,0,0,0,0,4,1,1,1,2,0,3,0,0,0,3,4,2,4,3,2,0,1,0,0,3,3),
(0,1,0,4,0,5,0,4,0,2,4,4,2,3,3,2,3,3,5,3,3,3,4,3,4,2,3,0,4,3,3,3,4,1,4,3,2,1,5,5,3,4,5,1,3,5,4,2,0,3,3,0,1,3,0,4,2,0,1,3,1,4,3,3,3,3,0,3,0,1,0,3,4,4,4,5,5,0,3,0,1,4,5),
(0,2,0,3,0,3,0,0,0,2,3,1,3,0,4,0,1,1,3,0,3,4,3,2,3,1,0,3,3,2,3,1,3,0,2,3,0,2,1,4,1,2,2,0,0,3,3,0,0,2,0,0,0,1,0,0,0,0,2,2,0,3,2,1,3,3,0,2,0,2,0,0,3,3,1,2,4,0,3,0,2,2,3),
(2,4,0,5,0,4,0,4,0,2,4,4,4,3,4,3,3,3,1,2,4,3,4,3,4,4,5,0,3,3,3,3,2,0,4,3,1,4,3,4,1,4,4,3,3,4,4,3,1,2,3,0,4,2,0,4,1,0,3,3,0,4,3,3,3,4,0,4,0,2,0,3,5,3,4,5,2,0,3,0,0,4,5),
(0,3,0,4,0,1,0,1,0,1,3,2,2,1,3,0,3,0,2,0,2,0,3,0,2,0,0,0,1,0,1,1,0,0,3,1,0,0,0,4,0,3,1,0,2,1,3,0,0,0,0,0,0,3,0,0,0,0,0,0,0,4,2,2,3,1,0,3,0,0,0,1,4,4,4,3,0,0,4,0,0,1,4),
(1,4,1,5,0,3,0,3,0,4,5,4,4,3,5,3,3,4,4,3,4,1,3,3,3,3,2,1,4,1,5,4,3,1,4,4,3,5,4,4,3,5,4,3,3,4,4,4,0,3,3,1,2,3,0,3,1,0,3,3,0,5,4,4,4,4,4,4,3,3,5,4,4,3,3,5,4,0,3,2,0,4,4),
(0,2,0,3,0,1,0,0,0,1,3,3,3,2,4,1,3,0,3,1,3,0,2,2,1,1,0,0,2,0,4,3,1,0,4,3,0,4,4,4,1,4,3,1,1,3,3,1,0,2,0,0,1,3,0,0,0,0,2,0,0,4,3,2,4,3,5,4,3,3,3,4,3,3,4,3,3,0,2,1,0,3,3),
(0,2,0,4,0,3,0,2,0,2,5,5,3,4,4,4,4,1,4,3,3,0,4,3,4,3,1,3,3,2,4,3,0,3,4,3,0,3,4,4,2,4,4,0,4,5,3,3,2,2,1,1,1,2,0,1,5,0,3,3,2,4,3,3,3,4,0,3,0,2,0,4,4,3,5,5,0,0,3,0,2,3,3),
(0,3,0,4,0,3,0,1,0,3,4,3,3,1,3,3,3,0,3,1,3,0,4,3,3,1,1,0,3,0,3,3,0,0,4,4,0,1,5,4,3,3,5,0,3,3,4,3,0,2,0,1,1,1,0,1,3,0,1,2,1,3,3,2,3,3,0,3,0,1,0,1,3,3,4,4,1,0,1,2,2,1,3),
(0,1,0,4,0,4,0,3,0,1,3,3,3,2,3,1,1,0,3,0,3,3,4,3,2,4,2,0,1,0,4,3,2,0,4,3,0,5,3,3,2,4,4,4,3,3,3,4,0,1,3,0,0,1,0,0,1,0,0,0,0,4,2,3,3,3,0,3,0,0,0,4,4,4,5,3,2,0,3,3,0,3,5),
(0,2,0,3,0,0,0,3,0,1,3,0,2,0,0,0,1,0,3,1,1,3,3,0,0,3,0,0,3,0,2,3,1,0,3,1,0,3,3,2,0,4,2,2,0,2,0,0,0,4,0,0,0,0,0,0,0,0,0,0,0,2,1,2,0,1,0,1,0,0,0,1,3,1,2,0,0,0,1,0,0,1,4),
(0,3,0,3,0,5,0,1,0,2,4,3,1,3,3,2,1,1,5,2,1,0,5,1,2,0,0,0,3,3,2,2,3,2,4,3,0,0,3,3,1,3,3,0,2,5,3,4,0,3,3,0,1,2,0,2,2,0,3,2,0,2,2,3,3,3,0,2,0,1,0,3,4,4,2,5,4,0,3,0,0,3,5),
(0,3,0,3,0,3,0,1,0,3,3,3,3,0,3,0,2,0,2,1,1,0,2,0,1,0,0,0,2,1,0,0,1,0,3,2,0,0,3,3,1,2,3,1,0,3,3,0,0,1,0,0,0,0,0,2,0,0,0,0,0,2,3,1,2,3,0,3,0,1,0,3,2,1,0,4,3,0,1,1,0,3,3),
(0,4,0,5,0,3,0,3,0,4,5,5,4,3,5,3,4,3,5,3,3,2,5,3,4,4,4,3,4,3,4,5,5,3,4,4,3,4,4,5,4,4,4,3,4,5,5,4,2,3,4,2,3,4,0,3,3,1,4,3,2,4,3,3,5,5,0,3,0,3,0,5,5,5,5,4,4,0,4,0,1,4,4),
(0,4,0,4,0,3,0,3,0,3,5,4,4,2,3,2,5,1,3,2,5,1,4,2,3,2,3,3,4,3,3,3,3,2,5,4,1,3,3,5,3,4,4,0,4,4,3,1,1,3,1,0,2,3,0,2,3,0,3,0,0,4,3,1,3,4,0,3,0,2,0,4,4,4,3,4,5,0,4,0,0,3,4),
(0,3,0,3,0,3,1,2,0,3,4,4,3,3,3,0,2,2,4,3,3,1,3,3,3,1,1,0,3,1,4,3,2,3,4,4,2,4,4,4,3,4,4,3,2,4,4,3,1,3,3,1,3,3,0,4,1,0,2,2,1,4,3,2,3,3,5,4,3,3,5,4,4,3,3,0,4,0,3,2,2,4,4),
(0,2,0,1,0,0,0,0,0,1,2,1,3,0,0,0,0,0,2,0,1,2,1,0,0,1,0,0,0,0,3,0,0,1,0,1,1,3,1,0,0,0,1,1,0,1,1,0,0,0,0,0,2,0,0,0,0,0,0,0,0,1,1,2,2,0,3,4,0,0,0,1,1,0,0,1,0,0,0,0,0,1,1),
(0,1,0,0,0,1,0,0,0,0,4,0,4,1,4,0,3,0,4,0,3,0,4,0,3,0,3,0,4,1,5,1,4,0,0,3,0,5,0,5,2,0,1,0,0,0,2,1,4,0,1,3,0,0,3,0,0,3,1,1,4,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0),
(1,4,0,5,0,3,0,2,0,3,5,4,4,3,4,3,5,3,4,3,3,0,4,3,3,3,3,3,3,2,4,4,3,1,3,4,4,5,4,4,3,4,4,1,3,5,4,3,3,3,1,2,2,3,3,1,3,1,3,3,3,5,3,3,4,5,0,3,0,3,0,3,4,3,4,4,3,0,3,0,2,4,3),
(0,1,0,4,0,0,0,0,0,1,4,0,4,1,4,2,4,0,3,0,1,0,1,0,0,0,0,0,2,0,3,1,1,1,0,3,0,0,0,1,2,1,0,0,1,1,1,1,0,1,0,0,0,1,0,0,3,0,0,0,0,3,2,0,2,2,0,1,0,0,0,2,3,2,3,3,0,0,0,0,2,1,0),
(0,5,1,5,0,3,0,3,0,5,4,4,5,1,5,3,3,0,4,3,4,3,5,3,4,3,3,2,4,3,4,3,3,0,3,3,1,4,4,3,4,4,4,3,4,5,5,3,2,3,1,1,3,3,1,3,1,1,3,3,2,4,5,3,3,5,0,4,0,3,0,4,4,3,5,3,3,0,3,4,0,4,3),
(0,5,0,5,0,3,0,2,0,4,4,3,5,2,4,3,3,3,4,4,4,3,5,3,5,3,3,1,4,0,4,3,3,0,3,3,0,4,4,4,4,5,4,3,3,5,5,3,2,3,1,2,3,2,0,1,0,0,3,2,2,4,4,3,1,5,0,4,0,3,0,4,3,1,3,2,1,0,3,3,0,3,3),
(0,4,0,5,0,5,0,4,0,4,5,5,5,3,4,3,3,2,5,4,4,3,5,3,5,3,4,0,4,3,4,4,3,2,4,4,3,4,5,4,4,5,5,0,3,5,5,4,1,3,3,2,3,3,1,3,1,0,4,3,1,4,4,3,4,5,0,4,0,2,0,4,3,4,4,3,3,0,4,0,0,5,5),
(0,4,0,4,0,5,0,1,1,3,3,4,4,3,4,1,3,0,5,1,3,0,3,1,3,1,1,0,3,0,3,3,4,0,4,3,0,4,4,4,3,4,4,0,3,5,4,1,0,3,0,0,2,3,0,3,1,0,3,1,0,3,2,1,3,5,0,3,0,1,0,3,2,3,3,4,4,0,2,2,0,4,4),
(2,4,0,5,0,4,0,3,0,4,5,5,4,3,5,3,5,3,5,3,5,2,5,3,4,3,3,4,3,4,5,3,2,1,5,4,3,2,3,4,5,3,4,1,2,5,4,3,0,3,3,0,3,2,0,2,3,0,4,1,0,3,4,3,3,5,0,3,0,1,0,4,5,5,5,4,3,0,4,2,0,3,5),
(0,5,0,4,0,4,0,2,0,5,4,3,4,3,4,3,3,3,4,3,4,2,5,3,5,3,4,1,4,3,4,4,4,0,3,5,0,4,4,4,4,5,3,1,3,4,5,3,3,3,3,3,3,3,0,2,2,0,3,3,2,4,3,3,3,5,3,4,1,3,3,5,3,2,0,0,0,0,4,3,1,3,3),
(0,1,0,3,0,3,0,1,0,1,3,3,3,2,3,3,3,0,3,0,0,0,3,1,3,0,0,0,2,2,2,3,0,0,3,2,0,1,2,4,1,3,3,0,0,3,3,3,0,1,0,0,2,1,0,0,3,0,3,1,0,3,0,0,1,3,0,2,0,1,0,3,3,1,3,3,0,0,1,1,0,3,3),
(0,2,0,3,0,2,1,4,0,2,2,3,1,1,3,1,1,0,2,0,3,1,2,3,1,3,0,0,1,0,4,3,2,3,3,3,1,4,2,3,3,3,3,1,0,3,1,4,0,1,1,0,1,2,0,1,1,0,1,1,0,3,1,3,2,2,0,1,0,0,0,2,3,3,3,1,0,0,0,0,0,2,3),
(0,5,0,4,0,5,0,2,0,4,5,5,3,3,4,3,3,1,5,4,4,2,4,4,4,3,4,2,4,3,5,5,4,3,3,4,3,3,5,5,4,5,5,1,3,4,5,3,1,4,3,1,3,3,0,3,3,1,4,3,1,4,5,3,3,5,0,4,0,3,0,5,3,3,1,4,3,0,4,0,1,5,3),
(0,5,0,5,0,4,0,2,0,4,4,3,4,3,3,3,3,3,5,4,4,4,4,4,4,5,3,3,5,2,4,4,4,3,4,4,3,3,4,4,5,5,3,3,4,3,4,3,3,4,3,3,3,3,1,2,2,1,4,3,3,5,4,4,3,4,0,4,0,3,0,4,4,4,4,4,1,0,4,2,0,2,4),
(0,4,0,4,0,3,0,1,0,3,5,2,3,0,3,0,2,1,4,2,3,3,4,1,4,3,3,2,4,1,3,3,3,0,3,3,0,0,3,3,3,5,3,3,3,3,3,2,0,2,0,0,2,0,0,2,0,0,1,0,0,3,1,2,2,3,0,3,0,2,0,4,4,3,3,4,1,0,3,0,0,2,4),
(0,0,0,4,0,0,0,0,0,0,1,0,1,0,2,0,0,0,0,0,1,0,2,0,1,0,0,0,0,0,3,1,3,0,3,2,0,0,0,1,0,3,2,0,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,4,0,2,0,0,0,0,0,0,2),
(0,2,1,3,0,2,0,2,0,3,3,3,3,1,3,1,3,3,3,3,3,3,4,2,2,1,2,1,4,0,4,3,1,3,3,3,2,4,3,5,4,3,3,3,3,3,3,3,0,1,3,0,2,0,0,1,0,0,1,0,0,4,2,0,2,3,0,3,3,0,3,3,4,2,3,1,4,0,1,2,0,2,3),
(0,3,0,3,0,1,0,3,0,2,3,3,3,0,3,1,2,0,3,3,2,3,3,2,3,2,3,1,3,0,4,3,2,0,3,3,1,4,3,3,2,3,4,3,1,3,3,1,1,0,1,1,0,1,0,1,0,1,0,0,0,4,1,1,0,3,0,3,1,0,2,3,3,3,3,3,1,0,0,2,0,3,3),
(0,0,0,0,0,0,0,0,0,0,3,0,2,0,3,0,0,0,0,0,0,0,3,0,0,0,0,0,0,0,3,0,3,0,3,1,0,1,0,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,2,0,2,3,0,0,0,0,0,0,0,0,3),
(0,2,0,3,1,3,0,3,0,2,3,3,3,1,3,1,3,1,3,1,3,3,3,1,3,0,2,3,1,1,4,3,3,2,3,3,1,2,2,4,1,3,3,0,1,4,2,3,0,1,3,0,3,0,0,1,3,0,2,0,0,3,3,2,1,3,0,3,0,2,0,3,4,4,4,3,1,0,3,0,0,3,3),
(0,2,0,1,0,2,0,0,0,1,3,2,2,1,3,0,1,1,3,0,3,2,3,1,2,0,2,0,1,1,3,3,3,0,3,3,1,1,2,3,2,3,3,1,2,3,2,0,0,1,0,0,0,0,0,0,3,0,1,0,0,2,1,2,1,3,0,3,0,0,0,3,4,4,4,3,2,0,2,0,0,2,4),
(0,0,0,1,0,1,0,0,0,0,1,0,0,0,1,0,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,2,2,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,3,1,0,0,0,0,0,0,0,3),
(0,3,0,3,0,2,0,3,0,3,3,3,2,3,2,2,2,0,3,1,3,3,3,2,3,3,0,0,3,0,3,2,2,0,2,3,1,4,3,4,3,3,2,3,1,5,4,4,0,3,1,2,1,3,0,3,1,1,2,0,2,3,1,3,1,3,0,3,0,1,0,3,3,4,4,2,1,0,2,1,0,2,4),
(0,1,0,3,0,1,0,2,0,1,4,2,5,1,4,0,2,0,2,1,3,1,4,0,2,1,0,0,2,1,4,1,1,0,3,3,0,5,1,3,2,3,3,1,0,3,2,3,0,1,0,0,0,0,0,0,1,0,0,0,0,4,0,1,0,3,0,2,0,1,0,3,3,3,4,3,3,0,0,0,0,2,3),
(0,0,0,1,0,0,0,0,0,0,2,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,2,1,0,0,1,0,0,0,0,0,3),
(0,1,0,3,0,4,0,3,0,2,4,3,1,0,3,2,2,1,3,1,2,2,3,1,1,1,2,1,3,0,1,2,0,1,3,2,1,3,0,5,5,1,0,0,1,3,2,1,0,3,0,0,1,0,0,0,0,0,3,4,0,1,1,1,3,2,0,2,0,1,0,2,3,3,1,2,3,0,1,0,1,0,4),
(0,0,0,1,0,3,0,3,0,2,2,1,0,0,4,0,3,0,3,1,3,0,3,0,3,0,1,0,3,0,3,1,3,0,3,3,0,0,1,2,1,1,1,0,1,2,0,0,0,1,0,0,1,0,0,0,0,0,0,0,0,2,2,1,2,0,0,2,0,0,0,0,2,3,3,3,3,0,0,0,0,1,4),
(0,0,0,3,0,3,0,0,0,0,3,1,1,0,3,0,1,0,2,0,1,0,0,0,0,0,0,0,1,0,3,0,2,0,2,3,0,0,2,2,3,1,2,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,2,0,0,0,0,2,3),
(2,4,0,5,0,5,0,4,0,3,4,3,3,3,4,3,3,3,4,3,4,4,5,4,5,5,5,2,3,0,5,5,4,1,5,4,3,1,5,4,3,4,4,3,3,4,3,3,0,3,2,0,2,3,0,3,0,0,3,3,0,5,3,2,3,3,0,3,0,3,0,3,4,5,4,5,3,0,4,3,0,3,4),
(0,3,0,3,0,3,0,3,0,3,3,4,3,2,3,2,3,0,4,3,3,3,3,3,3,3,3,0,3,2,4,3,3,1,3,4,3,4,4,4,3,4,4,3,2,4,4,1,0,2,0,0,1,1,0,2,0,0,3,1,0,5,3,2,1,3,0,3,0,1,2,4,3,2,4,3,3,0,3,2,0,4,4),
(0,3,0,3,0,1,0,0,0,1,4,3,3,2,3,1,3,1,4,2,3,2,4,2,3,4,3,0,2,2,3,3,3,0,3,3,3,0,3,4,1,3,3,0,3,4,3,3,0,1,1,0,1,0,0,0,4,0,3,0,0,3,1,2,1,3,0,4,0,1,0,4,3,3,4,3,3,0,2,0,0,3,3),
(0,3,0,4,0,1,0,3,0,3,4,3,3,0,3,3,3,1,3,1,3,3,4,3,3,3,0,0,3,1,5,3,3,1,3,3,2,5,4,3,3,4,5,3,2,5,3,4,0,1,0,0,0,0,0,2,0,0,1,1,0,4,2,2,1,3,0,3,0,2,0,4,4,3,5,3,2,0,1,1,0,3,4),
(0,5,0,4,0,5,0,2,0,4,4,3,3,2,3,3,3,1,4,3,4,1,5,3,4,3,4,0,4,2,4,3,4,1,5,4,0,4,4,4,4,5,4,1,3,5,4,2,1,4,1,1,3,2,0,3,1,0,3,2,1,4,3,3,3,4,0,4,0,3,0,4,4,4,3,3,3,0,4,2,0,3,4),
(1,4,0,4,0,3,0,1,0,3,3,3,1,1,3,3,2,2,3,3,1,0,3,2,2,1,2,0,3,1,2,1,2,0,3,2,0,2,2,3,3,4,3,0,3,3,1,2,0,1,1,3,1,2,0,0,3,0,1,1,0,3,2,2,3,3,0,3,0,0,0,2,3,3,4,3,3,0,1,0,0,1,4),
(0,4,0,4,0,4,0,0,0,3,4,4,3,1,4,2,3,2,3,3,3,1,4,3,4,0,3,0,4,2,3,3,2,2,5,4,2,1,3,4,3,4,3,1,3,3,4,2,0,2,1,0,3,3,0,0,2,0,3,1,0,4,4,3,4,3,0,4,0,1,0,2,4,4,4,4,4,0,3,2,0,3,3),
(0,0,0,1,0,4,0,0,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,1,0,3,2,0,0,1,0,0,0,1,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,2),
(0,2,0,3,0,4,0,4,0,1,3,3,3,0,4,0,2,1,2,1,1,1,2,0,3,1,1,0,1,0,3,1,0,0,3,3,2,0,1,1,0,0,0,0,0,1,0,2,0,2,2,0,3,1,0,0,1,0,1,1,0,1,2,0,3,0,0,0,0,1,0,0,3,3,4,3,1,0,1,0,3,0,2),
(0,0,0,3,0,5,0,0,0,0,1,0,2,0,3,1,0,1,3,0,0,0,2,0,0,0,1,0,0,0,1,1,0,0,4,0,0,0,2,3,0,1,4,1,0,2,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,0,0,0,0,1,0,0,0,0,0,0,0,2,0,0,3,0,0,0,0,0,3),
(0,2,0,5,0,5,0,1,0,2,4,3,3,2,5,1,3,2,3,3,3,0,4,1,2,0,3,0,4,0,2,2,1,1,5,3,0,0,1,4,2,3,2,0,3,3,3,2,0,2,4,1,1,2,0,1,1,0,3,1,0,1,3,1,2,3,0,2,0,0,0,1,3,5,4,4,4,0,3,0,0,1,3),
(0,4,0,5,0,4,0,4,0,4,5,4,3,3,4,3,3,3,4,3,4,4,5,3,4,5,4,2,4,2,3,4,3,1,4,4,1,3,5,4,4,5,5,4,4,5,5,5,2,3,3,1,4,3,1,3,3,0,3,3,1,4,3,4,4,4,0,3,0,4,0,3,3,4,4,5,0,0,4,3,0,4,5),
(0,4,0,4,0,3,0,3,0,3,4,4,4,3,3,2,4,3,4,3,4,3,5,3,4,3,2,1,4,2,4,4,3,1,3,4,2,4,5,5,3,4,5,4,1,5,4,3,0,3,2,2,3,2,1,3,1,0,3,3,3,5,3,3,3,5,4,4,2,3,3,4,3,3,3,2,1,0,3,2,1,4,3),
(0,4,0,5,0,4,0,3,0,3,5,5,3,2,4,3,4,0,5,4,4,1,4,4,4,3,3,3,4,3,5,5,2,3,3,4,1,2,5,5,3,5,5,2,3,5,5,4,0,3,2,0,3,3,1,1,5,1,4,1,0,4,3,2,3,5,0,4,0,3,0,5,4,3,4,3,0,0,4,1,0,4,4),
(1,3,0,4,0,2,0,2,0,2,5,5,3,3,3,3,3,0,4,2,3,4,4,4,3,4,0,0,3,4,5,4,3,3,3,3,2,5,5,4,5,5,5,4,3,5,5,5,1,3,1,0,1,0,0,3,2,0,4,2,0,5,2,3,2,4,1,3,0,3,0,4,5,4,5,4,3,0,4,2,0,5,4),
(0,3,0,4,0,5,0,3,0,3,4,4,3,2,3,2,3,3,3,3,3,2,4,3,3,2,2,0,3,3,3,3,3,1,3,3,3,0,4,4,3,4,4,1,1,4,4,2,0,3,1,0,1,1,0,4,1,0,2,3,1,3,3,1,3,4,0,3,0,1,0,3,1,3,0,0,1,0,2,0,0,4,4),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0),
(0,3,0,3,0,2,0,3,0,1,5,4,3,3,3,1,4,2,1,2,3,4,4,2,4,4,5,0,3,1,4,3,4,0,4,3,3,3,2,3,2,5,3,4,3,2,2,3,0,0,3,0,2,1,0,1,2,0,0,0,0,2,1,1,3,1,0,2,0,4,0,3,4,4,4,5,2,0,2,0,0,1,3),
(0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,1,1,0,0,1,1,0,0,0,4,2,1,1,0,1,0,3,2,0,0,3,1,1,1,2,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,0,1,0,0,0,2,0,0,0,1,4,0,4,2,1,0,0,0,0,0,1),
(0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,0,1,0,0,0,0,0,0,1,0,1,0,0,0,0,3,1,0,0,0,2,0,2,1,0,0,1,2,1,0,1,1,0,0,3,0,0,0,0,0,0,0,0,0,0,0,1,3,1,0,0,0,0,0,1,0,0,2,1,0,0,0,0,0,0,0,0,2),
(0,4,0,4,0,4,0,3,0,4,4,3,4,2,4,3,2,0,4,4,4,3,5,3,5,3,3,2,4,2,4,3,4,3,1,4,0,2,3,4,4,4,3,3,3,4,4,4,3,4,1,3,4,3,2,1,2,1,3,3,3,4,4,3,3,5,0,4,0,3,0,4,3,3,3,2,1,0,3,0,0,3,3),
(0,4,0,3,0,3,0,3,0,3,5,5,3,3,3,3,4,3,4,3,3,3,4,4,4,3,3,3,3,4,3,5,3,3,1,3,2,4,5,5,5,5,4,3,4,5,5,3,2,2,3,3,3,3,2,3,3,1,2,3,2,4,3,3,3,4,0,4,0,2,0,4,3,2,2,1,2,0,3,0,0,4,1),
)

class JapaneseContextAnalysis(object):
    NUM_OF_CATEGORY = 6
    DONT_KNOW = -1
    ENOUGH_REL_THRESHOLD = 100
    MAX_REL_THRESHOLD = 1000
    MINIMUM_DATA_THRESHOLD = 4

    def __init__(self):
        self._total_rel = None
        self._rel_sample = None
        self._need_to_skip_char_num = None
        self._last_char_order = None
        self._done = None
        self.reset()

    def reset(self):
        self._total_rel = 0  # total sequence received
        # category counters, each integer counts sequence in its category
        self._rel_sample = [0] * self.NUM_OF_CATEGORY
        # if last byte in current buffer is not the last byte of a character,
        # we need to know how many bytes to skip in next buffer
        self._need_to_skip_char_num = 0
        self._last_char_order = -1  # The order of previous char
        # If this flag is set to True, detection is done and conclusion has
        # been made
        self._done = False

    def feed(self, byte_str, num_bytes):
        if self._done:
            return

        # The buffer we got is byte oriented, and a character may span in more than one
        # buffers. In case the last one or two byte in last buffer is not
        # complete, we record how many byte needed to complete that character
        # and skip these bytes here.  We can choose to record those bytes as
        # well and analyse the character once it is complete, but since a
        # character will not make much difference, by simply skipping
        # this character will simply our logic and improve performance.
        i = self._need_to_skip_char_num
        while i < num_bytes:
            order, char_len = self.get_order(byte_str[i:i + 2])
            i += char_len
            if i > num_bytes:
                self._need_to_skip_char_num = i - num_bytes
                self._last_char_order = -1
            else:
                if (order != -1) and (self._last_char_order != -1):
                    self._total_rel += 1
                    if self._total_rel > self.MAX_REL_THRESHOLD:
                        self._done = True
                        break
                    self._rel_sample[jp2CharContext[self._last_char_order][order]] += 1
                self._last_char_order = order

    def got_enough_data(self):
        return self._total_rel > self.ENOUGH_REL_THRESHOLD

    def get_confidence(self):
        # This is just one way to calculate confidence. It works well for me.
        if self._total_rel > self.MINIMUM_DATA_THRESHOLD:
            return (self._total_rel - self._rel_sample[0]) / self._total_rel
        else:
            return self.DONT_KNOW

    def get_order(self, byte_str):
        return -1, 1

class SJISContextAnalysis(JapaneseContextAnalysis):
    def __init__(self):
        super(SJISContextAnalysis, self).__init__()
        self._charset_name = "SHIFT_JIS"

    @property
    def charset_name(self):
        return self._charset_name

    def get_order(self, byte_str):
        if not byte_str:
            return -1, 1
        # find out current char's byte length
        first_char = byte_str[0]
        if (0x81 <= first_char <= 0x9F) or (0xE0 <= first_char <= 0xFC):
            char_len = 2
            if (first_char == 0x87) or (0xFA <= first_char <= 0xFC):
                self._charset_name = "CP932"
        else:
            char_len = 1

        # return its order if it is hiragana
        if len(byte_str) > 1:
            second_char = byte_str[1]
            if (first_char == 202) and (0x9F <= second_char <= 0xF1):
                return second_char - 0x9F, char_len

        return -1, char_len

class EUCJPContextAnalysis(JapaneseContextAnalysis):
    def get_order(self, byte_str):
        if not byte_str:
            return -1, 1
        # find out current char's byte length
        first_char = byte_str[0]
        if (first_char == 0x8E) or (0xA1 <= first_char <= 0xFE):
            char_len = 2
        elif first_char == 0x8F:
            char_len = 3
        else:
            char_len = 1

        # return its order if it is hiragana
        if len(byte_str) > 1:
            second_char = byte_str[1]
            if (first_char == 0xA4) and (0xA1 <= second_char <= 0xF3):
                return second_char - 0xA1, char_len

        return -1, char_len






############################################################
### File: langbulgarianmodel.py
############################################################
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

BULGARIAN_LANG_MODEL = {
    63: {  # 'e'
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 0,  # ''
        18: 1,  # ''
        9: 1,  # ''
        20: 1,  # ''
        11: 1,  # ''
        3: 1,  # ''
        23: 1,  # ''
        15: 1,  # ''
        2: 0,  # ''
        26: 1,  # ''
        12: 1,  # ''
        10: 1,  # ''
        14: 1,  # ''
        6: 1,  # ''
        4: 1,  # ''
        13: 1,  # ''
        7: 1,  # ''
        8: 1,  # ''
        5: 1,  # ''
        19: 0,  # ''
        29: 1,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 1,  # ''
        27: 1,  # ''
        24: 1,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    45: {  # '\xad'
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 0,  # ''
        37: 1,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        38: 1,  # ''
        36: 0,  # ''
        41: 1,  # ''
        30: 1,  # ''
        39: 1,  # ''
        28: 1,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 1,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 0,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 0,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 0,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 0,  # ''
        13: 0,  # ''
        7: 0,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 0,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    31: {  # ''
        63: 0,  # 'e'
        45: 1,  # '\xad'
        31: 1,  # ''
        32: 1,  # ''
        35: 2,  # ''
        43: 1,  # ''
        37: 2,  # ''
        44: 2,  # ''
        55: 1,  # ''
        47: 2,  # ''
        40: 1,  # ''
        59: 1,  # ''
        33: 1,  # ''
        46: 2,  # ''
        38: 1,  # ''
        36: 2,  # ''
        41: 1,  # ''
        30: 2,  # ''
        39: 2,  # ''
        28: 2,  # ''
        34: 2,  # ''
        51: 1,  # ''
        48: 2,  # ''
        49: 1,  # ''
        53: 1,  # ''
        50: 1,  # ''
        54: 1,  # ''
        57: 2,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 1,  # ''
        1: 1,  # ''
        18: 2,  # ''
        9: 2,  # ''
        20: 2,  # ''
        11: 2,  # ''
        3: 1,  # ''
        23: 1,  # ''
        15: 2,  # ''
        2: 0,  # ''
        26: 2,  # ''
        12: 2,  # ''
        10: 3,  # ''
        14: 2,  # ''
        6: 3,  # ''
        4: 0,  # ''
        13: 2,  # ''
        7: 2,  # ''
        8: 2,  # ''
        5: 2,  # ''
        19: 1,  # ''
        29: 2,  # ''
        25: 1,  # ''
        22: 1,  # ''
        21: 1,  # ''
        27: 1,  # ''
        24: 0,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    32: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 2,  # ''
        35: 1,  # ''
        43: 1,  # ''
        37: 2,  # ''
        44: 1,  # ''
        55: 1,  # ''
        47: 2,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 2,  # ''
        41: 2,  # ''
        30: 1,  # ''
        39: 1,  # ''
        28: 2,  # ''
        34: 2,  # ''
        51: 1,  # ''
        48: 2,  # ''
        49: 1,  # ''
        53: 1,  # ''
        50: 1,  # ''
        54: 0,  # ''
        57: 1,  # ''
        61: 2,  # ''
        60: 1,  # ''
        56: 1,  # ''
        1: 3,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 1,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 2,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 2,  # ''
        8: 1,  # ''
        5: 0,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 3,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 2,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    35: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 0,  # ''
        37: 1,  # ''
        44: 2,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 1,  # ''
        30: 1,  # ''
        39: 2,  # ''
        28: 2,  # ''
        34: 1,  # ''
        51: 1,  # ''
        48: 2,  # ''
        49: 0,  # ''
        53: 1,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 1,  # ''
        56: 2,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 1,  # ''
        3: 3,  # ''
        23: 1,  # ''
        15: 2,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 2,  # ''
        14: 1,  # ''
        6: 2,  # ''
        4: 2,  # ''
        13: 1,  # ''
        7: 2,  # ''
        8: 2,  # ''
        5: 2,  # ''
        19: 1,  # ''
        29: 0,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 2,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    43: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 1,  # ''
        44: 2,  # ''
        55: 0,  # ''
        47: 1,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 0,  # ''
        36: 1,  # ''
        41: 1,  # ''
        30: 0,  # ''
        39: 1,  # ''
        28: 1,  # ''
        34: 0,  # ''
        51: 1,  # ''
        48: 1,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 1,  # ''
        61: 1,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 2,  # ''
        18: 1,  # ''
        9: 1,  # ''
        20: 0,  # ''
        11: 1,  # ''
        3: 3,  # ''
        23: 1,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 2,  # ''
        14: 1,  # ''
        6: 1,  # ''
        4: 2,  # ''
        13: 0,  # ''
        7: 2,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 1,  # ''
        17: 2,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    37: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 2,  # ''
        43: 1,  # ''
        37: 2,  # ''
        44: 2,  # ''
        55: 2,  # ''
        47: 1,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 2,  # ''
        30: 2,  # ''
        39: 1,  # ''
        28: 2,  # ''
        34: 1,  # ''
        51: 1,  # ''
        48: 1,  # ''
        49: 0,  # ''
        53: 1,  # ''
        50: 1,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 1,  # ''
        56: 1,  # ''
        1: 3,  # ''
        18: 0,  # ''
        9: 2,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 3,  # ''
        23: 3,  # ''
        15: 1,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 1,  # ''
        14: 1,  # ''
        6: 2,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 2,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 1,  # ''
        42: 2,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    44: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 1,  # ''
        32: 1,  # ''
        35: 2,  # ''
        43: 1,  # ''
        37: 1,  # ''
        44: 1,  # ''
        55: 1,  # ''
        47: 1,  # ''
        40: 1,  # ''
        59: 1,  # ''
        33: 2,  # ''
        46: 2,  # ''
        38: 1,  # ''
        36: 2,  # ''
        41: 2,  # ''
        30: 1,  # ''
        39: 2,  # ''
        28: 2,  # ''
        34: 2,  # ''
        51: 1,  # ''
        48: 2,  # ''
        49: 1,  # ''
        53: 2,  # ''
        50: 1,  # ''
        54: 1,  # ''
        57: 1,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 1,  # ''
        1: 0,  # ''
        18: 1,  # ''
        9: 2,  # ''
        20: 1,  # ''
        11: 2,  # ''
        3: 0,  # ''
        23: 1,  # ''
        15: 1,  # ''
        2: 0,  # ''
        26: 1,  # ''
        12: 2,  # ''
        10: 2,  # ''
        14: 2,  # ''
        6: 2,  # ''
        4: 0,  # ''
        13: 1,  # ''
        7: 2,  # ''
        8: 2,  # ''
        5: 1,  # ''
        19: 1,  # ''
        29: 1,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 1,  # ''
        27: 1,  # ''
        24: 1,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    55: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 1,  # ''
        32: 0,  # ''
        35: 1,  # ''
        43: 0,  # ''
        37: 1,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 1,  # ''
        41: 1,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 1,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 2,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 1,  # ''
        3: 2,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 2,  # ''
        13: 1,  # ''
        7: 1,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 1,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    47: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 1,  # ''
        37: 1,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 1,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 2,  # ''
        41: 1,  # ''
        30: 1,  # ''
        39: 1,  # ''
        28: 1,  # ''
        34: 1,  # ''
        51: 1,  # ''
        48: 0,  # ''
        49: 1,  # ''
        53: 1,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 0,  # ''
        56: 1,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 2,  # ''
        20: 1,  # ''
        11: 2,  # ''
        3: 2,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 1,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 2,  # ''
        14: 1,  # ''
        6: 1,  # ''
        4: 1,  # ''
        13: 0,  # ''
        7: 1,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 1,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    40: {  # ''
        63: 0,  # 'e'
        45: 1,  # '\xad'
        31: 1,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 1,  # ''
        37: 1,  # ''
        44: 2,  # ''
        55: 1,  # ''
        47: 2,  # ''
        40: 1,  # ''
        59: 1,  # ''
        33: 2,  # ''
        46: 2,  # ''
        38: 2,  # ''
        36: 2,  # ''
        41: 1,  # ''
        30: 1,  # ''
        39: 2,  # ''
        28: 2,  # ''
        34: 2,  # ''
        51: 0,  # ''
        48: 1,  # ''
        49: 1,  # ''
        53: 1,  # ''
        50: 1,  # ''
        54: 1,  # ''
        57: 1,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 2,  # ''
        1: 1,  # ''
        18: 1,  # ''
        9: 3,  # ''
        20: 2,  # ''
        11: 1,  # ''
        3: 1,  # ''
        23: 0,  # ''
        15: 3,  # ''
        2: 0,  # ''
        26: 1,  # ''
        12: 1,  # ''
        10: 2,  # ''
        14: 2,  # ''
        6: 2,  # ''
        4: 0,  # ''
        13: 1,  # ''
        7: 2,  # ''
        8: 2,  # ''
        5: 2,  # ''
        19: 0,  # ''
        29: 1,  # ''
        25: 1,  # ''
        22: 1,  # ''
        21: 1,  # ''
        27: 1,  # ''
        24: 1,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    59: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 1,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 1,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 1,  # ''
        34: 1,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 1,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 1,  # ''
        1: 0,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 1,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 0,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 2,  # ''
        13: 0,  # ''
        7: 0,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 0,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    33: {  # ''
        63: 0,  # 'e'
        45: 1,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 1,  # ''
        37: 1,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 1,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 0,  # ''
        36: 2,  # ''
        41: 2,  # ''
        30: 2,  # ''
        39: 1,  # ''
        28: 2,  # ''
        34: 1,  # ''
        51: 1,  # ''
        48: 1,  # ''
        49: 1,  # ''
        53: 1,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 1,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 0,  # ''
        9: 1,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 2,  # ''
        23: 1,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 2,  # ''
        14: 1,  # ''
        6: 2,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 3,  # ''
        8: 1,  # ''
        5: 0,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 1,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 1,  # ''
        42: 2,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    46: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 2,  # ''
        37: 1,  # ''
        44: 2,  # ''
        55: 0,  # ''
        47: 1,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 0,  # ''
        36: 1,  # ''
        41: 2,  # ''
        30: 1,  # ''
        39: 0,  # ''
        28: 1,  # ''
        34: 1,  # ''
        51: 1,  # ''
        48: 0,  # ''
        49: 1,  # ''
        53: 1,  # ''
        50: 1,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 1,  # ''
        56: 1,  # ''
        1: 2,  # ''
        18: 0,  # ''
        9: 1,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 2,  # ''
        13: 0,  # ''
        7: 0,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 1,  # ''
        42: 2,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    38: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 2,  # ''
        43: 0,  # ''
        37: 1,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 1,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 2,  # ''
        30: 1,  # ''
        39: 1,  # ''
        28: 2,  # ''
        34: 1,  # ''
        51: 1,  # ''
        48: 1,  # ''
        49: 0,  # ''
        53: 1,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 0,  # ''
        56: 1,  # ''
        1: 3,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 2,  # ''
        14: 0,  # ''
        6: 2,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 1,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 1,  # ''
        42: 2,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    36: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 2,  # ''
        35: 1,  # ''
        43: 1,  # ''
        37: 2,  # ''
        44: 2,  # ''
        55: 1,  # ''
        47: 1,  # ''
        40: 2,  # ''
        59: 1,  # ''
        33: 2,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 2,  # ''
        30: 1,  # ''
        39: 1,  # ''
        28: 2,  # ''
        34: 2,  # ''
        51: 1,  # ''
        48: 1,  # ''
        49: 1,  # ''
        53: 1,  # ''
        50: 1,  # ''
        54: 1,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 1,  # ''
        56: 1,  # ''
        1: 3,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 1,  # ''
        11: 0,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 0,  # ''
        8: 0,  # ''
        5: 1,  # ''
        19: 1,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 1,  # ''
        24: 0,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 2,  # ''
        16: 2,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    41: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 1,  # ''
        32: 1,  # ''
        35: 2,  # ''
        43: 1,  # ''
        37: 2,  # ''
        44: 1,  # ''
        55: 1,  # ''
        47: 1,  # ''
        40: 1,  # ''
        59: 1,  # ''
        33: 2,  # ''
        46: 2,  # ''
        38: 2,  # ''
        36: 2,  # ''
        41: 2,  # ''
        30: 1,  # ''
        39: 2,  # ''
        28: 2,  # ''
        34: 2,  # ''
        51: 1,  # ''
        48: 1,  # ''
        49: 1,  # ''
        53: 0,  # ''
        50: 1,  # ''
        54: 1,  # ''
        57: 1,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 1,  # ''
        1: 1,  # ''
        18: 2,  # ''
        9: 2,  # ''
        20: 2,  # ''
        11: 1,  # ''
        3: 1,  # ''
        23: 1,  # ''
        15: 1,  # ''
        2: 0,  # ''
        26: 1,  # ''
        12: 2,  # ''
        10: 2,  # ''
        14: 1,  # ''
        6: 1,  # ''
        4: 0,  # ''
        13: 2,  # ''
        7: 2,  # ''
        8: 2,  # ''
        5: 3,  # ''
        19: 1,  # ''
        29: 1,  # ''
        25: 1,  # ''
        22: 1,  # ''
        21: 2,  # ''
        27: 0,  # ''
        24: 2,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    30: {  # ''
        63: 0,  # 'e'
        45: 1,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 1,  # ''
        37: 1,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 1,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 2,  # ''
        30: 2,  # ''
        39: 2,  # ''
        28: 2,  # ''
        34: 1,  # ''
        51: 2,  # ''
        48: 1,  # ''
        49: 0,  # ''
        53: 1,  # ''
        50: 1,  # ''
        54: 1,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 1,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 2,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 3,  # ''
        14: 0,  # ''
        6: 1,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 3,  # ''
        8: 1,  # ''
        5: 1,  # ''
        19: 2,  # ''
        29: 1,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 1,  # ''
        27: 1,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    39: {  # ''
        63: 0,  # 'e'
        45: 1,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 2,  # ''
        37: 2,  # ''
        44: 2,  # ''
        55: 0,  # ''
        47: 1,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 2,  # ''
        30: 2,  # ''
        39: 1,  # ''
        28: 1,  # ''
        34: 1,  # ''
        51: 1,  # ''
        48: 1,  # ''
        49: 1,  # ''
        53: 1,  # ''
        50: 1,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 1,  # ''
        56: 1,  # ''
        1: 3,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 2,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 1,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 0,  # ''
        8: 1,  # ''
        5: 0,  # ''
        19: 3,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    28: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 3,  # ''
        32: 2,  # ''
        35: 2,  # ''
        43: 1,  # ''
        37: 2,  # ''
        44: 2,  # ''
        55: 1,  # ''
        47: 1,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 2,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 2,  # ''
        30: 2,  # ''
        39: 1,  # ''
        28: 2,  # ''
        34: 2,  # ''
        51: 1,  # ''
        48: 1,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 1,  # ''
        56: 1,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 2,  # ''
        20: 1,  # ''
        11: 1,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 2,  # ''
        10: 3,  # ''
        14: 2,  # ''
        6: 1,  # ''
        4: 3,  # ''
        13: 3,  # ''
        7: 2,  # ''
        8: 0,  # ''
        5: 3,  # ''
        19: 2,  # ''
        29: 2,  # ''
        25: 1,  # ''
        22: 1,  # ''
        21: 1,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 3,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    34: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 2,  # ''
        35: 1,  # ''
        43: 0,  # ''
        37: 1,  # ''
        44: 2,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 2,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 2,  # ''
        30: 1,  # ''
        39: 2,  # ''
        28: 2,  # ''
        34: 1,  # ''
        51: 1,  # ''
        48: 1,  # ''
        49: 0,  # ''
        53: 1,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 1,  # ''
        60: 0,  # ''
        56: 1,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 1,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 1,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 3,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 2,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    51: {  # ''
        63: 0,  # 'e'
        45: 1,  # '\xad'
        31: 1,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 1,  # ''
        37: 1,  # ''
        44: 2,  # ''
        55: 1,  # ''
        47: 1,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 0,  # ''
        30: 1,  # ''
        39: 1,  # ''
        28: 1,  # ''
        34: 2,  # ''
        51: 0,  # ''
        48: 1,  # ''
        49: 1,  # ''
        53: 1,  # ''
        50: 1,  # ''
        54: 1,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 1,  # ''
        18: 1,  # ''
        9: 2,  # ''
        20: 1,  # ''
        11: 1,  # ''
        3: 2,  # ''
        23: 1,  # ''
        15: 1,  # ''
        2: 2,  # ''
        26: 1,  # ''
        12: 2,  # ''
        10: 1,  # ''
        14: 1,  # ''
        6: 2,  # ''
        4: 2,  # ''
        13: 1,  # ''
        7: 1,  # ''
        8: 2,  # ''
        5: 1,  # ''
        19: 1,  # ''
        29: 0,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 2,  # ''
        27: 1,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    48: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 0,  # ''
        36: 1,  # ''
        41: 1,  # ''
        30: 2,  # ''
        39: 1,  # ''
        28: 2,  # ''
        34: 1,  # ''
        51: 1,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 2,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 2,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 2,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 2,  # ''
        13: 0,  # ''
        7: 2,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 1,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    49: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 1,  # ''
        32: 0,  # ''
        35: 1,  # ''
        43: 1,  # ''
        37: 1,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 1,  # ''
        30: 1,  # ''
        39: 1,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 1,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 2,  # ''
        18: 0,  # ''
        9: 1,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 2,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 1,  # ''
        14: 1,  # ''
        6: 0,  # ''
        4: 2,  # ''
        13: 0,  # ''
        7: 2,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    53: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 1,  # ''
        32: 0,  # ''
        35: 1,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 2,  # ''
        59: 0,  # ''
        33: 2,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 1,  # ''
        28: 2,  # ''
        34: 0,  # ''
        51: 1,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 2,  # ''
        18: 0,  # ''
        9: 2,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 2,  # ''
        23: 0,  # ''
        15: 1,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 1,  # ''
        13: 0,  # ''
        7: 1,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 1,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    50: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 2,  # ''
        32: 1,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 1,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 0,  # ''
        36: 1,  # ''
        41: 1,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 1,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 2,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 3,  # ''
        23: 1,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 1,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 2,  # ''
        13: 0,  # ''
        7: 1,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 1,  # ''
        42: 0,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    54: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 1,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 1,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 1,  # ''
        41: 1,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 1,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 2,  # ''
        18: 0,  # ''
        9: 2,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 2,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 2,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 1,  # ''
        14: 1,  # ''
        6: 1,  # ''
        4: 2,  # ''
        13: 1,  # ''
        7: 1,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 1,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 1,  # ''
        42: 0,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    57: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 1,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 1,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 2,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 2,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 1,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 1,  # ''
        13: 0,  # ''
        7: 1,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 1,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    61: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 0,  # ''
        37: 1,  # ''
        44: 0,  # ''
        55: 1,  # ''
        47: 1,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 2,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 0,  # ''
        30: 1,  # ''
        39: 2,  # ''
        28: 1,  # ''
        34: 1,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 1,  # ''
        53: 1,  # ''
        50: 1,  # ''
        54: 1,  # ''
        57: 1,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 0,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 0,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 0,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 1,  # ''
        14: 0,  # ''
        6: 1,  # ''
        4: 0,  # ''
        13: 0,  # ''
        7: 1,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 0,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    60: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 1,  # ''
        32: 1,  # ''
        35: 0,  # ''
        43: 1,  # ''
        37: 1,  # ''
        44: 0,  # ''
        55: 1,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 0,  # ''
        36: 1,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 1,  # ''
        28: 1,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 0,  # ''
        18: 1,  # ''
        9: 1,  # ''
        20: 2,  # ''
        11: 1,  # ''
        3: 0,  # ''
        23: 2,  # ''
        15: 1,  # ''
        2: 1,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 1,  # ''
        14: 1,  # ''
        6: 1,  # ''
        4: 0,  # ''
        13: 1,  # ''
        7: 1,  # ''
        8: 1,  # ''
        5: 1,  # ''
        19: 0,  # ''
        29: 0,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    56: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 1,  # ''
        35: 1,  # ''
        43: 1,  # ''
        37: 1,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        38: 1,  # ''
        36: 1,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 1,  # ''
        34: 2,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 0,  # ''
        18: 1,  # ''
        9: 1,  # ''
        20: 1,  # ''
        11: 1,  # ''
        3: 0,  # ''
        23: 0,  # ''
        15: 1,  # ''
        2: 1,  # ''
        26: 1,  # ''
        12: 1,  # ''
        10: 1,  # ''
        14: 2,  # ''
        6: 2,  # ''
        4: 0,  # ''
        13: 2,  # ''
        7: 1,  # ''
        8: 1,  # ''
        5: 1,  # ''
        19: 0,  # ''
        29: 0,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 1,  # ''
        24: 0,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    1: {  # ''
        63: 1,  # 'e'
        45: 1,  # '\xad'
        31: 1,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 1,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 1,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 3,  # ''
        11: 3,  # ''
        3: 3,  # ''
        23: 3,  # ''
        15: 3,  # ''
        2: 3,  # ''
        26: 3,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 2,  # ''
        13: 3,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 3,  # ''
        29: 3,  # ''
        25: 3,  # ''
        22: 3,  # ''
        21: 3,  # ''
        27: 3,  # ''
        24: 3,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    18: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 0,  # ''
        9: 3,  # ''
        20: 1,  # ''
        11: 2,  # ''
        3: 3,  # ''
        23: 1,  # ''
        15: 1,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 3,  # ''
        14: 2,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 1,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 0,  # ''
        19: 3,  # ''
        29: 0,  # ''
        25: 2,  # ''
        22: 1,  # ''
        21: 1,  # ''
        27: 1,  # ''
        24: 3,  # ''
        17: 3,  # ''
        52: 1,  # ''
        42: 2,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    9: {  # ''
        63: 1,  # 'e'
        45: 1,  # '\xad'
        31: 0,  # ''
        32: 1,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 1,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 0,  # ''
        20: 2,  # ''
        11: 3,  # ''
        3: 3,  # ''
        23: 1,  # ''
        15: 3,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 2,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 2,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 2,  # ''
        22: 2,  # ''
        21: 3,  # ''
        27: 2,  # ''
        24: 1,  # ''
        17: 3,  # ''
        52: 1,  # ''
        42: 2,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    20: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 2,  # ''
        20: 1,  # ''
        11: 2,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 1,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 3,  # ''
        14: 1,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 1,  # ''
        7: 3,  # ''
        8: 2,  # ''
        5: 2,  # ''
        19: 3,  # ''
        29: 1,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 1,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 3,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    11: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 2,  # ''
        9: 3,  # ''
        20: 2,  # ''
        11: 2,  # ''
        3: 3,  # ''
        23: 3,  # ''
        15: 2,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 3,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 1,  # ''
        19: 3,  # ''
        29: 1,  # ''
        25: 2,  # ''
        22: 2,  # ''
        21: 2,  # ''
        27: 1,  # ''
        24: 1,  # ''
        17: 3,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    3: {  # ''
        63: 0,  # 'e'
        45: 1,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 2,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 3,  # ''
        11: 3,  # ''
        3: 2,  # ''
        23: 3,  # ''
        15: 3,  # ''
        2: 2,  # ''
        26: 3,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 3,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 2,  # ''
        29: 3,  # ''
        25: 3,  # ''
        22: 3,  # ''
        21: 3,  # ''
        27: 3,  # ''
        24: 3,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    23: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 3,  # ''
        9: 2,  # ''
        20: 1,  # ''
        11: 3,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 2,  # ''
        10: 1,  # ''
        14: 1,  # ''
        6: 3,  # ''
        4: 2,  # ''
        13: 1,  # ''
        7: 1,  # ''
        8: 1,  # ''
        5: 1,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 1,  # ''
        21: 1,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    15: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 3,  # ''
        11: 3,  # ''
        3: 3,  # ''
        23: 1,  # ''
        15: 1,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 3,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 3,  # ''
        29: 1,  # ''
        25: 2,  # ''
        22: 2,  # ''
        21: 2,  # ''
        27: 2,  # ''
        24: 1,  # ''
        17: 2,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 2,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    2: {  # ''
        63: 1,  # 'e'
        45: 1,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 1,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 1,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 1,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 3,  # ''
        11: 3,  # ''
        3: 3,  # ''
        23: 3,  # ''
        15: 3,  # ''
        2: 3,  # ''
        26: 3,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 3,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 2,  # ''
        29: 3,  # ''
        25: 3,  # ''
        22: 3,  # ''
        21: 3,  # ''
        27: 3,  # ''
        24: 3,  # ''
        17: 2,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    26: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 1,  # ''
        18: 2,  # ''
        9: 2,  # ''
        20: 1,  # ''
        11: 2,  # ''
        3: 2,  # ''
        23: 0,  # ''
        15: 2,  # ''
        2: 1,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 2,  # ''
        14: 2,  # ''
        6: 3,  # ''
        4: 2,  # ''
        13: 1,  # ''
        7: 2,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 1,  # ''
        29: 2,  # ''
        25: 1,  # ''
        22: 2,  # ''
        21: 2,  # ''
        27: 1,  # ''
        24: 1,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    12: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 1,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 1,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 3,  # ''
        20: 2,  # ''
        11: 1,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 2,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 3,  # ''
        14: 2,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 1,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 3,  # ''
        29: 1,  # ''
        25: 1,  # ''
        22: 3,  # ''
        21: 2,  # ''
        27: 1,  # ''
        24: 0,  # ''
        17: 3,  # ''
        52: 1,  # ''
        42: 2,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    10: {  # ''
        63: 1,  # 'e'
        45: 1,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 1,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 3,  # ''
        11: 2,  # ''
        3: 3,  # ''
        23: 3,  # ''
        15: 2,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 1,  # ''
        14: 2,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 2,  # ''
        7: 2,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 3,  # ''
        29: 2,  # ''
        25: 2,  # ''
        22: 2,  # ''
        21: 2,  # ''
        27: 2,  # ''
        24: 1,  # ''
        17: 3,  # ''
        52: 2,  # ''
        42: 3,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    14: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 1,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 1,  # ''
        11: 1,  # ''
        3: 3,  # ''
        23: 1,  # ''
        15: 1,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 2,  # ''
        10: 3,  # ''
        14: 1,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 3,  # ''
        7: 2,  # ''
        8: 2,  # ''
        5: 1,  # ''
        19: 3,  # ''
        29: 2,  # ''
        25: 1,  # ''
        22: 2,  # ''
        21: 2,  # ''
        27: 2,  # ''
        24: 1,  # ''
        17: 3,  # ''
        52: 1,  # ''
        42: 2,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    6: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 1,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 2,  # ''
        9: 2,  # ''
        20: 3,  # ''
        11: 3,  # ''
        3: 3,  # ''
        23: 2,  # ''
        15: 2,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 2,  # ''
        14: 1,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 1,  # ''
        7: 2,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 3,  # ''
        29: 3,  # ''
        25: 2,  # ''
        22: 3,  # ''
        21: 3,  # ''
        27: 2,  # ''
        24: 1,  # ''
        17: 3,  # ''
        52: 2,  # ''
        42: 2,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    4: {  # ''
        63: 0,  # 'e'
        45: 1,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 2,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 3,  # ''
        11: 3,  # ''
        3: 3,  # ''
        23: 3,  # ''
        15: 3,  # ''
        2: 3,  # ''
        26: 3,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 2,  # ''
        13: 3,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 2,  # ''
        29: 3,  # ''
        25: 3,  # ''
        22: 3,  # ''
        21: 3,  # ''
        27: 3,  # ''
        24: 3,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    13: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 2,  # ''
        20: 1,  # ''
        11: 1,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 1,  # ''
        2: 3,  # ''
        26: 1,  # ''
        12: 2,  # ''
        10: 3,  # ''
        14: 1,  # ''
        6: 2,  # ''
        4: 3,  # ''
        13: 1,  # ''
        7: 3,  # ''
        8: 2,  # ''
        5: 2,  # ''
        19: 3,  # ''
        29: 1,  # ''
        25: 1,  # ''
        22: 2,  # ''
        21: 2,  # ''
        27: 1,  # ''
        24: 1,  # ''
        17: 3,  # ''
        52: 1,  # ''
        42: 2,  # ''
        16: 2,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    7: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 3,  # ''
        11: 3,  # ''
        3: 3,  # ''
        23: 3,  # ''
        15: 2,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 2,  # ''
        7: 1,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 3,  # ''
        29: 2,  # ''
        25: 3,  # ''
        22: 3,  # ''
        21: 2,  # ''
        27: 3,  # ''
        24: 1,  # ''
        17: 3,  # ''
        52: 1,  # ''
        42: 2,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    8: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 2,  # ''
        9: 3,  # ''
        20: 2,  # ''
        11: 2,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 1,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 3,  # ''
        7: 3,  # ''
        8: 1,  # ''
        5: 3,  # ''
        19: 3,  # ''
        29: 2,  # ''
        25: 2,  # ''
        22: 2,  # ''
        21: 2,  # ''
        27: 2,  # ''
        24: 0,  # ''
        17: 3,  # ''
        52: 2,  # ''
        42: 2,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    5: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 2,  # ''
        11: 2,  # ''
        3: 3,  # ''
        23: 1,  # ''
        15: 1,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 2,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 2,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 3,  # ''
        29: 1,  # ''
        25: 2,  # ''
        22: 2,  # ''
        21: 2,  # ''
        27: 1,  # ''
        24: 1,  # ''
        17: 3,  # ''
        52: 2,  # ''
        42: 2,  # ''
        16: 3,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    19: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 3,  # ''
        11: 3,  # ''
        3: 2,  # ''
        23: 3,  # ''
        15: 3,  # ''
        2: 2,  # ''
        26: 2,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 2,  # ''
        13: 3,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 1,  # ''
        29: 2,  # ''
        25: 2,  # ''
        22: 2,  # ''
        21: 3,  # ''
        27: 3,  # ''
        24: 2,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    29: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 1,  # ''
        20: 1,  # ''
        11: 0,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 2,  # ''
        10: 2,  # ''
        14: 1,  # ''
        6: 1,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 2,  # ''
        8: 2,  # ''
        5: 2,  # ''
        19: 2,  # ''
        29: 0,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 1,  # ''
        27: 1,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 2,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    25: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 3,  # ''
        20: 0,  # ''
        11: 1,  # ''
        3: 2,  # ''
        23: 0,  # ''
        15: 1,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 2,  # ''
        14: 2,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 1,  # ''
        7: 3,  # ''
        8: 1,  # ''
        5: 2,  # ''
        19: 3,  # ''
        29: 0,  # ''
        25: 1,  # ''
        22: 0,  # ''
        21: 1,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    22: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 2,  # ''
        20: 1,  # ''
        11: 1,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 1,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 2,  # ''
        10: 1,  # ''
        14: 1,  # ''
        6: 1,  # ''
        4: 2,  # ''
        13: 1,  # ''
        7: 1,  # ''
        8: 1,  # ''
        5: 1,  # ''
        19: 2,  # ''
        29: 1,  # ''
        25: 1,  # ''
        22: 1,  # ''
        21: 1,  # ''
        27: 1,  # ''
        24: 1,  # ''
        17: 2,  # ''
        52: 1,  # ''
        42: 0,  # ''
        16: 2,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    21: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 1,  # ''
        9: 3,  # ''
        20: 1,  # ''
        11: 0,  # ''
        3: 3,  # ''
        23: 1,  # ''
        15: 0,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 2,  # ''
        14: 2,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 2,  # ''
        8: 0,  # ''
        5: 2,  # ''
        19: 3,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 1,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    27: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 0,  # ''
        9: 2,  # ''
        20: 0,  # ''
        11: 1,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 3,  # ''
        10: 2,  # ''
        14: 1,  # ''
        6: 3,  # ''
        4: 2,  # ''
        13: 2,  # ''
        7: 1,  # ''
        8: 0,  # ''
        5: 1,  # ''
        19: 2,  # ''
        29: 1,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 1,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 2,  # ''
        52: 1,  # ''
        42: 1,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    24: {  # ''
        63: 1,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 3,  # ''
        18: 0,  # ''
        9: 1,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 3,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 3,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 2,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 1,  # ''
        8: 0,  # ''
        5: 2,  # ''
        19: 3,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 1,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 2,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    17: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 1,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 3,  # ''
        11: 3,  # ''
        3: 2,  # ''
        23: 3,  # ''
        15: 3,  # ''
        2: 1,  # ''
        26: 2,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 3,  # ''
        13: 3,  # ''
        7: 3,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 1,  # ''
        29: 1,  # ''
        25: 2,  # ''
        22: 2,  # ''
        21: 3,  # ''
        27: 2,  # ''
        24: 3,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 2,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    52: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 0,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 1,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 0,  # ''
        26: 0,  # ''
        12: 1,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 1,  # ''
        4: 3,  # ''
        13: 0,  # ''
        7: 0,  # ''
        8: 0,  # ''
        5: 1,  # ''
        19: 0,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 1,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 1,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    42: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 1,  # ''
        18: 2,  # ''
        9: 1,  # ''
        20: 2,  # ''
        11: 2,  # ''
        3: 1,  # ''
        23: 2,  # ''
        15: 2,  # ''
        2: 1,  # ''
        26: 1,  # ''
        12: 2,  # ''
        10: 2,  # ''
        14: 2,  # ''
        6: 2,  # ''
        4: 1,  # ''
        13: 1,  # ''
        7: 2,  # ''
        8: 2,  # ''
        5: 2,  # ''
        19: 1,  # ''
        29: 1,  # ''
        25: 1,  # ''
        22: 2,  # ''
        21: 3,  # ''
        27: 1,  # ''
        24: 1,  # ''
        17: 1,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    16: {  # ''
        63: 0,  # 'e'
        45: 1,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 0,  # ''
        18: 3,  # ''
        9: 3,  # ''
        20: 2,  # ''
        11: 3,  # ''
        3: 2,  # ''
        23: 1,  # ''
        15: 2,  # ''
        2: 1,  # ''
        26: 2,  # ''
        12: 3,  # ''
        10: 3,  # ''
        14: 3,  # ''
        6: 3,  # ''
        4: 1,  # ''
        13: 2,  # ''
        7: 2,  # ''
        8: 3,  # ''
        5: 3,  # ''
        19: 1,  # ''
        29: 1,  # ''
        25: 3,  # ''
        22: 2,  # ''
        21: 1,  # ''
        27: 1,  # ''
        24: 2,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 1,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    58: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 0,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 0,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 0,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 0,  # ''
        13: 0,  # ''
        7: 0,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 0,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
    62: {  # ''
        63: 0,  # 'e'
        45: 0,  # '\xad'
        31: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        43: 0,  # ''
        37: 0,  # ''
        44: 0,  # ''
        55: 0,  # ''
        47: 0,  # ''
        40: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        38: 0,  # ''
        36: 0,  # ''
        41: 0,  # ''
        30: 0,  # ''
        39: 0,  # ''
        28: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        48: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        50: 0,  # ''
        54: 0,  # ''
        57: 0,  # ''
        61: 0,  # ''
        60: 0,  # ''
        56: 0,  # ''
        1: 0,  # ''
        18: 0,  # ''
        9: 0,  # ''
        20: 0,  # ''
        11: 0,  # ''
        3: 0,  # ''
        23: 0,  # ''
        15: 0,  # ''
        2: 0,  # ''
        26: 0,  # ''
        12: 0,  # ''
        10: 0,  # ''
        14: 0,  # ''
        6: 0,  # ''
        4: 0,  # ''
        13: 0,  # ''
        7: 0,  # ''
        8: 0,  # ''
        5: 0,  # ''
        19: 0,  # ''
        29: 0,  # ''
        25: 0,  # ''
        22: 0,  # ''
        21: 0,  # ''
        27: 0,  # ''
        24: 0,  # ''
        17: 0,  # ''
        52: 0,  # ''
        42: 0,  # ''
        16: 0,  # ''
        58: 0,  # ''
        62: 0,  # ''
    },
}

# 255: Undefined characters that did not exist in training text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9
# 251: Control characters

# Character Mapping Table(s):
ISO_8859_5_BULGARIAN_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 77,  # 'A'
     66: 90,  # 'B'
     67: 99,  # 'C'
     68: 100,  # 'D'
     69: 72,  # 'E'
     70: 109,  # 'F'
     71: 107,  # 'G'
     72: 101,  # 'H'
     73: 79,  # 'I'
     74: 185,  # 'J'
     75: 81,  # 'K'
     76: 102,  # 'L'
     77: 76,  # 'M'
     78: 94,  # 'N'
     79: 82,  # 'O'
     80: 110,  # 'P'
     81: 186,  # 'Q'
     82: 108,  # 'R'
     83: 91,  # 'S'
     84: 74,  # 'T'
     85: 119,  # 'U'
     86: 84,  # 'V'
     87: 96,  # 'W'
     88: 111,  # 'X'
     89: 187,  # 'Y'
     90: 115,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 65,  # 'a'
     98: 69,  # 'b'
     99: 70,  # 'c'
     100: 66,  # 'd'
     101: 63,  # 'e'
     102: 68,  # 'f'
     103: 112,  # 'g'
     104: 103,  # 'h'
     105: 92,  # 'i'
     106: 194,  # 'j'
     107: 104,  # 'k'
     108: 95,  # 'l'
     109: 86,  # 'm'
     110: 87,  # 'n'
     111: 71,  # 'o'
     112: 116,  # 'p'
     113: 195,  # 'q'
     114: 85,  # 'r'
     115: 93,  # 's'
     116: 97,  # 't'
     117: 113,  # 'u'
     118: 196,  # 'v'
     119: 197,  # 'w'
     120: 198,  # 'x'
     121: 199,  # 'y'
     122: 200,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 194,  # '\x80'
     129: 195,  # '\x81'
     130: 196,  # '\x82'
     131: 197,  # '\x83'
     132: 198,  # '\x84'
     133: 199,  # '\x85'
     134: 200,  # '\x86'
     135: 201,  # '\x87'
     136: 202,  # '\x88'
     137: 203,  # '\x89'
     138: 204,  # '\x8a'
     139: 205,  # '\x8b'
     140: 206,  # '\x8c'
     141: 207,  # '\x8d'
     142: 208,  # '\x8e'
     143: 209,  # '\x8f'
     144: 210,  # '\x90'
     145: 211,  # '\x91'
     146: 212,  # '\x92'
     147: 213,  # '\x93'
     148: 214,  # '\x94'
     149: 215,  # '\x95'
     150: 216,  # '\x96'
     151: 217,  # '\x97'
     152: 218,  # '\x98'
     153: 219,  # '\x99'
     154: 220,  # '\x9a'
     155: 221,  # '\x9b'
     156: 222,  # '\x9c'
     157: 223,  # '\x9d'
     158: 224,  # '\x9e'
     159: 225,  # '\x9f'
     160: 81,  # '\xa0'
     161: 226,  # ''
     162: 227,  # ''
     163: 228,  # ''
     164: 229,  # ''
     165: 230,  # ''
     166: 105,  # ''
     167: 231,  # ''
     168: 232,  # ''
     169: 233,  # ''
     170: 234,  # ''
     171: 235,  # ''
     172: 236,  # ''
     173: 45,  # '\xad'
     174: 237,  # ''
     175: 238,  # ''
     176: 31,  # ''
     177: 32,  # ''
     178: 35,  # ''
     179: 43,  # ''
     180: 37,  # ''
     181: 44,  # ''
     182: 55,  # ''
     183: 47,  # ''
     184: 40,  # ''
     185: 59,  # ''
     186: 33,  # ''
     187: 46,  # ''
     188: 38,  # ''
     189: 36,  # ''
     190: 41,  # ''
     191: 30,  # ''
     192: 39,  # ''
     193: 28,  # ''
     194: 34,  # ''
     195: 51,  # ''
     196: 48,  # ''
     197: 49,  # ''
     198: 53,  # ''
     199: 50,  # ''
     200: 54,  # ''
     201: 57,  # ''
     202: 61,  # ''
     203: 239,  # ''
     204: 67,  # ''
     205: 240,  # ''
     206: 60,  # ''
     207: 56,  # ''
     208: 1,  # ''
     209: 18,  # ''
     210: 9,  # ''
     211: 20,  # ''
     212: 11,  # ''
     213: 3,  # ''
     214: 23,  # ''
     215: 15,  # ''
     216: 2,  # ''
     217: 26,  # ''
     218: 12,  # ''
     219: 10,  # ''
     220: 14,  # ''
     221: 6,  # ''
     222: 4,  # ''
     223: 13,  # ''
     224: 7,  # ''
     225: 8,  # ''
     226: 5,  # ''
     227: 19,  # ''
     228: 29,  # ''
     229: 25,  # ''
     230: 22,  # ''
     231: 21,  # ''
     232: 27,  # ''
     233: 24,  # ''
     234: 17,  # ''
     235: 75,  # ''
     236: 52,  # ''
     237: 241,  # ''
     238: 42,  # ''
     239: 16,  # ''
     240: 62,  # ''
     241: 242,  # ''
     242: 243,  # ''
     243: 244,  # ''
     244: 58,  # ''
     245: 245,  # ''
     246: 98,  # ''
     247: 246,  # ''
     248: 247,  # ''
     249: 248,  # ''
     250: 249,  # ''
     251: 250,  # ''
     252: 251,  # ''
     253: 91,  # ''
     254: 252,  # ''
     255: 253,  # ''
}

ISO_8859_5_BULGARIAN_MODEL = SingleByteCharSetModel(charset_name='ISO-8859-5',
                                                    language='Bulgarian',
                                                    char_to_order_map=ISO_8859_5_BULGARIAN_CHAR_TO_ORDER,
                                                    language_model=BULGARIAN_LANG_MODEL,
                                                    typical_positive_ratio=0.969392,
                                                    keep_ascii_letters=False,
                                                    alphabet='')

WINDOWS_1251_BULGARIAN_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 77,  # 'A'
     66: 90,  # 'B'
     67: 99,  # 'C'
     68: 100,  # 'D'
     69: 72,  # 'E'
     70: 109,  # 'F'
     71: 107,  # 'G'
     72: 101,  # 'H'
     73: 79,  # 'I'
     74: 185,  # 'J'
     75: 81,  # 'K'
     76: 102,  # 'L'
     77: 76,  # 'M'
     78: 94,  # 'N'
     79: 82,  # 'O'
     80: 110,  # 'P'
     81: 186,  # 'Q'
     82: 108,  # 'R'
     83: 91,  # 'S'
     84: 74,  # 'T'
     85: 119,  # 'U'
     86: 84,  # 'V'
     87: 96,  # 'W'
     88: 111,  # 'X'
     89: 187,  # 'Y'
     90: 115,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 65,  # 'a'
     98: 69,  # 'b'
     99: 70,  # 'c'
     100: 66,  # 'd'
     101: 63,  # 'e'
     102: 68,  # 'f'
     103: 112,  # 'g'
     104: 103,  # 'h'
     105: 92,  # 'i'
     106: 194,  # 'j'
     107: 104,  # 'k'
     108: 95,  # 'l'
     109: 86,  # 'm'
     110: 87,  # 'n'
     111: 71,  # 'o'
     112: 116,  # 'p'
     113: 195,  # 'q'
     114: 85,  # 'r'
     115: 93,  # 's'
     116: 97,  # 't'
     117: 113,  # 'u'
     118: 196,  # 'v'
     119: 197,  # 'w'
     120: 198,  # 'x'
     121: 199,  # 'y'
     122: 200,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 206,  # ''
     129: 207,  # ''
     130: 208,  # ''
     131: 209,  # ''
     132: 210,  # ''
     133: 211,  # ''
     134: 212,  # ''
     135: 213,  # ''
     136: 120,  # ''
     137: 214,  # ''
     138: 215,  # ''
     139: 216,  # ''
     140: 217,  # ''
     141: 218,  # ''
     142: 219,  # ''
     143: 220,  # ''
     144: 221,  # ''
     145: 78,  # ''
     146: 64,  # ''
     147: 83,  # ''
     148: 121,  # ''
     149: 98,  # ''
     150: 117,  # ''
     151: 105,  # ''
     152: 222,  # None
     153: 223,  # ''
     154: 224,  # ''
     155: 225,  # ''
     156: 226,  # ''
     157: 227,  # ''
     158: 228,  # ''
     159: 229,  # ''
     160: 88,  # '\xa0'
     161: 230,  # ''
     162: 231,  # ''
     163: 232,  # ''
     164: 233,  # ''
     165: 122,  # ''
     166: 89,  # ''
     167: 106,  # ''
     168: 234,  # ''
     169: 235,  # ''
     170: 236,  # ''
     171: 237,  # ''
     172: 238,  # ''
     173: 45,  # '\xad'
     174: 239,  # ''
     175: 240,  # ''
     176: 73,  # ''
     177: 80,  # ''
     178: 118,  # ''
     179: 114,  # ''
     180: 241,  # ''
     181: 242,  # ''
     182: 243,  # ''
     183: 244,  # ''
     184: 245,  # ''
     185: 62,  # ''
     186: 58,  # ''
     187: 246,  # ''
     188: 247,  # ''
     189: 248,  # ''
     190: 249,  # ''
     191: 250,  # ''
     192: 31,  # ''
     193: 32,  # ''
     194: 35,  # ''
     195: 43,  # ''
     196: 37,  # ''
     197: 44,  # ''
     198: 55,  # ''
     199: 47,  # ''
     200: 40,  # ''
     201: 59,  # ''
     202: 33,  # ''
     203: 46,  # ''
     204: 38,  # ''
     205: 36,  # ''
     206: 41,  # ''
     207: 30,  # ''
     208: 39,  # ''
     209: 28,  # ''
     210: 34,  # ''
     211: 51,  # ''
     212: 48,  # ''
     213: 49,  # ''
     214: 53,  # ''
     215: 50,  # ''
     216: 54,  # ''
     217: 57,  # ''
     218: 61,  # ''
     219: 251,  # ''
     220: 67,  # ''
     221: 252,  # ''
     222: 60,  # ''
     223: 56,  # ''
     224: 1,  # ''
     225: 18,  # ''
     226: 9,  # ''
     227: 20,  # ''
     228: 11,  # ''
     229: 3,  # ''
     230: 23,  # ''
     231: 15,  # ''
     232: 2,  # ''
     233: 26,  # ''
     234: 12,  # ''
     235: 10,  # ''
     236: 14,  # ''
     237: 6,  # ''
     238: 4,  # ''
     239: 13,  # ''
     240: 7,  # ''
     241: 8,  # ''
     242: 5,  # ''
     243: 19,  # ''
     244: 29,  # ''
     245: 25,  # ''
     246: 22,  # ''
     247: 21,  # ''
     248: 27,  # ''
     249: 24,  # ''
     250: 17,  # ''
     251: 75,  # ''
     252: 52,  # ''
     253: 253,  # ''
     254: 42,  # ''
     255: 16,  # ''
}

WINDOWS_1251_BULGARIAN_MODEL = SingleByteCharSetModel(charset_name='windows-1251',
                                                      language='Bulgarian',
                                                      char_to_order_map=WINDOWS_1251_BULGARIAN_CHAR_TO_ORDER,
                                                      language_model=BULGARIAN_LANG_MODEL,
                                                      typical_positive_ratio=0.969392,
                                                      keep_ascii_letters=False,
                                                      alphabet='')





############################################################
### File: langgreekmodel.py
############################################################
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

GREEK_LANG_MODEL = {
    60: {  # 'e'
        60: 2,  # 'e'
        55: 1,  # 'o'
        58: 2,  # 't'
        36: 1,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 1,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    55: {  # 'o'
        60: 0,  # 'e'
        55: 2,  # 'o'
        58: 2,  # 't'
        36: 1,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 1,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 1,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    58: {  # 't'
        60: 2,  # 'e'
        55: 1,  # 'o'
        58: 1,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 2,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 1,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    36: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    61: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 1,  # ''
        21: 2,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 1,  # ''
        8: 2,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    46: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 2,  # ''
        20: 2,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 2,  # ''
        16: 2,  # ''
        10: 0,  # ''
        6: 3,  # ''
        30: 2,  # ''
        4: 0,  # ''
        9: 2,  # ''
        8: 2,  # ''
        14: 0,  # ''
        7: 1,  # ''
        2: 2,  # ''
        12: 0,  # ''
        28: 2,  # ''
        23: 3,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    54: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 2,  # ''
        6: 2,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 2,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 2,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 2,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    31: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 2,  # ''
        43: 2,  # ''
        41: 1,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 2,  # ''
        47: 2,  # ''
        44: 2,  # ''
        53: 2,  # ''
        38: 2,  # ''
        49: 2,  # ''
        59: 1,  # ''
        39: 0,  # ''
        35: 2,  # ''
        48: 2,  # ''
        37: 2,  # ''
        33: 2,  # ''
        45: 2,  # ''
        56: 2,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 2,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 1,  # ''
        5: 0,  # ''
        11: 2,  # ''
        16: 3,  # ''
        10: 2,  # ''
        6: 3,  # ''
        30: 2,  # ''
        4: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 2,  # ''
        7: 2,  # ''
        2: 0,  # ''
        12: 3,  # ''
        28: 2,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 2,  # ''
        27: 0,  # ''
    },
    51: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 1,  # ''
        40: 1,  # ''
        52: 0,  # ''
        47: 1,  # ''
        44: 0,  # ''
        53: 1,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 2,  # ''
        18: 2,  # ''
        22: 2,  # ''
        15: 0,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 2,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 2,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 0,  # ''
        8: 2,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    43: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 1,  # ''
        51: 0,  # ''
        43: 2,  # ''
        41: 0,  # ''
        34: 2,  # ''
        40: 1,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 1,  # ''
        53: 1,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 1,  # ''
        35: 0,  # ''
        48: 2,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 2,  # ''
        56: 0,  # ''
        50: 1,  # ''
        57: 2,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 2,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 2,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 0,  # ''
        6: 2,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 0,  # ''
        8: 2,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    41: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 2,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 2,  # ''
        15: 2,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 2,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 0,  # ''
        8: 2,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 2,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 2,  # ''
        19: 1,  # ''
        26: 2,  # ''
        27: 2,  # ''
    },
    34: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 0,  # ''
        43: 2,  # ''
        41: 2,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 2,  # ''
        53: 2,  # ''
        38: 2,  # ''
        49: 2,  # ''
        59: 1,  # ''
        39: 0,  # ''
        35: 2,  # ''
        48: 2,  # ''
        37: 2,  # ''
        33: 2,  # ''
        45: 2,  # ''
        56: 0,  # ''
        50: 2,  # ''
        57: 2,  # ''
        17: 3,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 3,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 3,  # ''
        21: 2,  # ''
        3: 1,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 1,  # ''
        5: 2,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 2,  # ''
        6: 3,  # ''
        30: 2,  # ''
        4: 0,  # ''
        9: 3,  # ''
        8: 2,  # ''
        14: 0,  # ''
        7: 2,  # ''
        2: 2,  # ''
        12: 2,  # ''
        28: 2,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 1,  # ''
        27: 0,  # ''
    },
    40: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 1,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 2,  # ''
        47: 0,  # ''
        44: 2,  # ''
        53: 0,  # ''
        38: 2,  # ''
        49: 2,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 2,  # ''
        48: 2,  # ''
        37: 2,  # ''
        33: 2,  # ''
        45: 1,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 0,  # ''
        6: 1,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 1,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    52: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 1,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 1,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 2,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 2,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 2,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 2,  # ''
        27: 0,  # ''
    },
    47: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 1,  # ''
        43: 1,  # ''
        41: 2,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 2,  # ''
        53: 2,  # ''
        38: 2,  # ''
        49: 2,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 2,  # ''
        37: 2,  # ''
        33: 2,  # ''
        45: 0,  # ''
        56: 2,  # ''
        50: 0,  # ''
        57: 2,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 2,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 1,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 2,  # ''
        2: 1,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 1,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    44: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 1,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 1,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 2,  # ''
        37: 0,  # ''
        33: 1,  # ''
        45: 2,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 1,  # ''
        17: 3,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 2,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 2,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 0,  # ''
        8: 2,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 2,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 2,  # ''
        26: 2,  # ''
        27: 2,  # ''
    },
    53: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 0,  # ''
        53: 2,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 2,  # ''
        33: 0,  # ''
        45: 2,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 2,  # ''
        17: 2,  # ''
        18: 2,  # ''
        22: 0,  # ''
        15: 2,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 2,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 1,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 2,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 2,  # ''
        26: 2,  # ''
        27: 0,  # ''
    },
    38: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 2,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 2,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 2,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 2,  # ''
        18: 2,  # ''
        22: 2,  # ''
        15: 2,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 2,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 3,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 2,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 2,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    49: {  # ''
        60: 2,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 2,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 2,  # ''
        17: 0,  # ''
        18: 2,  # ''
        22: 0,  # ''
        15: 2,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 1,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 1,  # ''
        19: 2,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    59: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 1,  # ''
        40: 1,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 1,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 2,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 2,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    39: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 1,  # ''
        43: 2,  # ''
        41: 2,  # ''
        34: 2,  # ''
        40: 1,  # ''
        52: 2,  # ''
        47: 2,  # ''
        44: 2,  # ''
        53: 2,  # ''
        38: 2,  # ''
        49: 2,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 2,  # ''
        48: 2,  # ''
        37: 2,  # ''
        33: 2,  # ''
        45: 2,  # ''
        56: 2,  # ''
        50: 2,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 2,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 2,  # ''
        16: 2,  # ''
        10: 2,  # ''
        6: 2,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 2,  # ''
        8: 2,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 2,  # ''
        12: 2,  # ''
        28: 1,  # ''
        23: 1,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 2,  # ''
        27: 0,  # ''
    },
    35: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 2,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 0,  # ''
        53: 2,  # ''
        38: 1,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 2,  # ''
        37: 0,  # ''
        33: 1,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 1,  # ''
        57: 2,  # ''
        17: 2,  # ''
        18: 1,  # ''
        22: 1,  # ''
        15: 2,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 2,  # ''
        25: 0,  # ''
        5: 2,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 0,  # ''
        6: 2,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 3,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 2,  # ''
        28: 0,  # ''
        23: 2,  # ''
        42: 0,  # ''
        24: 2,  # ''
        19: 2,  # ''
        26: 0,  # ''
        27: 3,  # ''
    },
    48: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 0,  # ''
        43: 1,  # ''
        41: 1,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 2,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 2,  # ''
        37: 0,  # ''
        33: 1,  # ''
        45: 1,  # ''
        56: 0,  # ''
        50: 1,  # ''
        57: 1,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 2,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 1,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 3,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 2,  # ''
        19: 0,  # ''
        26: 2,  # ''
        27: 0,  # ''
    },
    37: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 1,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 2,  # ''
        53: 0,  # ''
        38: 2,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 2,  # ''
        33: 2,  # ''
        45: 2,  # ''
        56: 0,  # ''
        50: 2,  # ''
        57: 2,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 2,  # ''
        15: 2,  # ''
        1: 2,  # ''
        29: 2,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 0,  # ''
        5: 2,  # ''
        11: 2,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 2,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 0,  # ''
        23: 2,  # ''
        42: 0,  # ''
        24: 2,  # ''
        19: 0,  # ''
        26: 2,  # ''
        27: 2,  # ''
    },
    33: {  # ''
        60: 0,  # 'e'
        55: 1,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 2,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 2,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 2,  # ''
        37: 0,  # ''
        33: 1,  # ''
        45: 1,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 2,  # ''
        17: 2,  # ''
        18: 2,  # ''
        22: 0,  # ''
        15: 2,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 2,  # ''
        32: 0,  # ''
        13: 2,  # ''
        25: 0,  # ''
        5: 2,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 2,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 2,  # ''
        14: 0,  # ''
        7: 2,  # ''
        2: 0,  # ''
        12: 2,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 2,  # ''
        26: 2,  # ''
        27: 3,  # ''
    },
    45: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 2,  # ''
        41: 0,  # ''
        34: 1,  # ''
        40: 2,  # ''
        52: 2,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 1,  # ''
        38: 2,  # ''
        49: 2,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 2,  # ''
        48: 1,  # ''
        37: 2,  # ''
        33: 2,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 1,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 3,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    56: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 1,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 1,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 2,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 2,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 2,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 2,  # ''
        12: 2,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 1,  # ''
        27: 1,  # ''
    },
    50: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 1,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 2,  # ''
        40: 2,  # ''
        52: 0,  # ''
        47: 2,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 1,  # ''
        59: 0,  # ''
        39: 1,  # ''
        35: 0,  # ''
        48: 2,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 1,  # ''
        57: 1,  # ''
        17: 2,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 2,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 0,  # ''
        8: 3,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 2,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 2,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    57: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 1,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 1,  # ''
        38: 0,  # ''
        49: 2,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 2,  # ''
        37: 2,  # ''
        33: 2,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 0,  # ''
        8: 2,  # ''
        14: 2,  # ''
        7: 2,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 1,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    17: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 2,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 3,  # ''
        20: 3,  # ''
        21: 3,  # ''
        3: 3,  # ''
        32: 3,  # ''
        13: 0,  # ''
        25: 3,  # ''
        5: 2,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 3,  # ''
        4: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 3,  # ''
        23: 3,  # ''
        42: 3,  # ''
        24: 2,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    18: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 3,  # ''
        29: 2,  # ''
        20: 3,  # ''
        21: 2,  # ''
        3: 3,  # ''
        32: 2,  # ''
        13: 0,  # ''
        25: 3,  # ''
        5: 0,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 3,  # ''
        4: 3,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 3,  # ''
        23: 3,  # ''
        42: 3,  # ''
        24: 2,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    22: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 1,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 3,  # ''
        21: 3,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 3,  # ''
        5: 0,  # ''
        11: 3,  # ''
        16: 2,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 2,  # ''
        4: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 2,  # ''
        23: 3,  # ''
        42: 2,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    15: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 3,  # ''
        29: 2,  # ''
        20: 3,  # ''
        21: 3,  # ''
        3: 3,  # ''
        32: 3,  # ''
        13: 3,  # ''
        25: 3,  # ''
        5: 0,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 3,  # ''
        4: 3,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 1,  # ''
        23: 3,  # ''
        42: 2,  # ''
        24: 3,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    1: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 2,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 2,  # ''
        22: 0,  # ''
        15: 3,  # ''
        1: 0,  # ''
        29: 3,  # ''
        20: 3,  # ''
        21: 3,  # ''
        3: 2,  # ''
        32: 3,  # ''
        13: 1,  # ''
        25: 3,  # ''
        5: 3,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 3,  # ''
        4: 2,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 3,  # ''
        23: 3,  # ''
        42: 2,  # ''
        24: 0,  # ''
        19: 2,  # ''
        26: 2,  # ''
        27: 0,  # ''
    },
    29: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 2,  # ''
        22: 3,  # ''
        15: 2,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 2,  # ''
        21: 2,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 2,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 3,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 3,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 2,  # ''
        19: 2,  # ''
        26: 2,  # ''
        27: 2,  # ''
    },
    20: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 3,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 3,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 3,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 2,  # ''
        28: 0,  # ''
        23: 3,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 2,  # ''
        27: 3,  # ''
    },
    21: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 2,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 3,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 3,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 3,  # ''
        27: 3,  # ''
    },
    3: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 2,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 3,  # ''
        1: 2,  # ''
        29: 3,  # ''
        20: 3,  # ''
        21: 3,  # ''
        3: 2,  # ''
        32: 2,  # ''
        13: 0,  # ''
        25: 3,  # ''
        5: 3,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 3,  # ''
        4: 2,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 3,  # ''
        23: 3,  # ''
        42: 2,  # ''
        24: 3,  # ''
        19: 2,  # ''
        26: 3,  # ''
        27: 2,  # ''
    },
    32: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 2,  # ''
        18: 2,  # ''
        22: 2,  # ''
        15: 2,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 0,  # ''
        5: 2,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 1,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 2,  # ''
        26: 0,  # ''
        27: 2,  # ''
    },
    13: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 2,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 3,  # ''
        21: 2,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 3,  # ''
        5: 0,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 2,  # ''
        4: 0,  # ''
        9: 2,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 2,  # ''
        23: 3,  # ''
        42: 2,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    25: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 2,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 2,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 1,  # ''
        10: 3,  # ''
        6: 2,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 3,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 3,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 3,  # ''
        27: 3,  # ''
    },
    5: {  # ''
        60: 0,  # 'e'
        55: 1,  # 'o'
        58: 0,  # 't'
        36: 2,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 1,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 0,  # ''
        1: 3,  # ''
        29: 3,  # ''
        20: 3,  # ''
        21: 3,  # ''
        3: 3,  # ''
        32: 2,  # ''
        13: 3,  # ''
        25: 3,  # ''
        5: 0,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 3,  # ''
        4: 3,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 2,  # ''
        23: 3,  # ''
        42: 2,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 0,  # ''
        27: 3,  # ''
    },
    11: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 3,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 2,  # ''
        5: 3,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 2,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 2,  # ''
        8: 3,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 2,  # ''
        23: 2,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 3,  # ''
        27: 3,  # ''
    },
    16: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 1,  # ''
        20: 2,  # ''
        21: 1,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 2,  # ''
        5: 3,  # ''
        11: 2,  # ''
        16: 3,  # ''
        10: 2,  # ''
        6: 2,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 3,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 2,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 3,  # ''
        27: 3,  # ''
    },
    10: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 1,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 3,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 3,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 2,  # ''
        28: 3,  # ''
        23: 0,  # ''
        42: 2,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 2,  # ''
        27: 2,  # ''
    },
    6: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 2,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 3,  # ''
        3: 3,  # ''
        32: 2,  # ''
        13: 3,  # ''
        25: 3,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 1,  # ''
        10: 0,  # ''
        6: 2,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 3,  # ''
        27: 3,  # ''
    },
    30: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 2,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 2,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 0,  # ''
        5: 2,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 3,  # ''
        12: 2,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 2,  # ''
        26: 3,  # ''
        27: 1,  # ''
    },
    4: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 2,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 2,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 2,  # ''
        29: 3,  # ''
        20: 3,  # ''
        21: 3,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 3,  # ''
        5: 3,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 2,  # ''
        4: 2,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 3,  # ''
        23: 3,  # ''
        42: 2,  # ''
        24: 2,  # ''
        19: 1,  # ''
        26: 3,  # ''
        27: 2,  # ''
    },
    9: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 3,  # ''
        10: 0,  # ''
        6: 2,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 3,  # ''
        14: 2,  # ''
        7: 0,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 0,  # ''
        23: 2,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 2,  # ''
        27: 3,  # ''
    },
    8: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 2,  # ''
        20: 3,  # ''
        21: 2,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 3,  # ''
        5: 3,  # ''
        11: 3,  # ''
        16: 1,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 2,  # ''
        4: 3,  # ''
        9: 2,  # ''
        8: 2,  # ''
        14: 0,  # ''
        7: 2,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 3,  # ''
        23: 3,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 3,  # ''
        27: 3,  # ''
    },
    14: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 2,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 0,  # ''
        5: 0,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 0,  # ''
        12: 0,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    7: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 2,  # ''
        18: 2,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 3,  # ''
        20: 0,  # ''
        21: 2,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 3,  # ''
        5: 3,  # ''
        11: 3,  # ''
        16: 2,  # ''
        10: 3,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 3,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 3,  # ''
        23: 3,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 3,  # ''
        27: 2,  # ''
    },
    2: {  # ''
        60: 0,  # 'e'
        55: 2,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 2,  # ''
        13: 3,  # ''
        25: 0,  # ''
        5: 3,  # ''
        11: 2,  # ''
        16: 2,  # ''
        10: 3,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 3,  # ''
        14: 0,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 2,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 3,  # ''
        27: 3,  # ''
    },
    12: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 2,  # ''
        18: 2,  # ''
        22: 3,  # ''
        15: 2,  # ''
        1: 3,  # ''
        29: 2,  # ''
        20: 3,  # ''
        21: 2,  # ''
        3: 2,  # ''
        32: 2,  # ''
        13: 2,  # ''
        25: 3,  # ''
        5: 2,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 3,  # ''
        4: 3,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 2,  # ''
        23: 3,  # ''
        42: 2,  # ''
        24: 2,  # ''
        19: 2,  # ''
        26: 0,  # ''
        27: 2,  # ''
    },
    28: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 3,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 2,  # ''
        25: 2,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 0,  # ''
        6: 1,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 3,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 1,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 2,  # ''
        27: 2,  # ''
    },
    23: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 3,  # ''
        18: 2,  # ''
        22: 3,  # ''
        15: 3,  # ''
        1: 3,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 2,  # ''
        25: 2,  # ''
        5: 3,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 2,  # ''
        6: 3,  # ''
        30: 0,  # ''
        4: 3,  # ''
        9: 0,  # ''
        8: 3,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 3,  # ''
        12: 3,  # ''
        28: 0,  # ''
        23: 2,  # ''
        42: 0,  # ''
        24: 3,  # ''
        19: 3,  # ''
        26: 3,  # ''
        27: 3,  # ''
    },
    42: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 2,  # ''
        18: 2,  # ''
        22: 1,  # ''
        15: 2,  # ''
        1: 2,  # ''
        29: 0,  # ''
        20: 0,  # ''
        21: 0,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 3,  # ''
        25: 0,  # ''
        5: 2,  # ''
        11: 0,  # ''
        16: 0,  # ''
        10: 0,  # ''
        6: 0,  # ''
        30: 0,  # ''
        4: 2,  # ''
        9: 0,  # ''
        8: 0,  # ''
        14: 0,  # ''
        7: 0,  # ''
        2: 2,  # ''
        12: 1,  # ''
        28: 0,  # ''
        23: 0,  # ''
        42: 0,  # ''
        24: 2,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    24: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 1,  # ''
        18: 0,  # ''
        22: 2,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 2,  # ''
        20: 3,  # ''
        21: 2,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 0,  # ''
        25: 3,  # ''
        5: 2,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 0,  # ''
        4: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 2,  # ''
        23: 2,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    19: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 3,  # ''
        20: 3,  # ''
        21: 3,  # ''
        3: 1,  # ''
        32: 2,  # ''
        13: 2,  # ''
        25: 2,  # ''
        5: 2,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 1,  # ''
        4: 2,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 2,  # ''
        23: 3,  # ''
        42: 2,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    26: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 2,  # ''
        29: 2,  # ''
        20: 2,  # ''
        21: 1,  # ''
        3: 3,  # ''
        32: 0,  # ''
        13: 2,  # ''
        25: 3,  # ''
        5: 0,  # ''
        11: 3,  # ''
        16: 3,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 2,  # ''
        4: 3,  # ''
        9: 3,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 2,  # ''
        23: 2,  # ''
        42: 2,  # ''
        24: 2,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
    27: {  # ''
        60: 0,  # 'e'
        55: 0,  # 'o'
        58: 0,  # 't'
        36: 0,  # ''
        61: 0,  # ''
        46: 0,  # ''
        54: 0,  # ''
        31: 0,  # ''
        51: 0,  # ''
        43: 0,  # ''
        41: 0,  # ''
        34: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        44: 0,  # ''
        53: 0,  # ''
        38: 0,  # ''
        49: 0,  # ''
        59: 0,  # ''
        39: 0,  # ''
        35: 0,  # ''
        48: 0,  # ''
        37: 0,  # ''
        33: 0,  # ''
        45: 0,  # ''
        56: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        17: 0,  # ''
        18: 0,  # ''
        22: 0,  # ''
        15: 0,  # ''
        1: 0,  # ''
        29: 1,  # ''
        20: 0,  # ''
        21: 3,  # ''
        3: 0,  # ''
        32: 0,  # ''
        13: 1,  # ''
        25: 2,  # ''
        5: 2,  # ''
        11: 0,  # ''
        16: 2,  # ''
        10: 3,  # ''
        6: 3,  # ''
        30: 1,  # ''
        4: 0,  # ''
        9: 2,  # ''
        8: 3,  # ''
        14: 3,  # ''
        7: 3,  # ''
        2: 3,  # ''
        12: 0,  # ''
        28: 1,  # ''
        23: 1,  # ''
        42: 0,  # ''
        24: 0,  # ''
        19: 0,  # ''
        26: 0,  # ''
        27: 0,  # ''
    },
}

# 255: Undefined characters that did not exist in training text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9
# 251: Control characters

# Character Mapping Table(s):
WINDOWS_1253_GREEK_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 82,  # 'A'
     66: 100,  # 'B'
     67: 104,  # 'C'
     68: 94,  # 'D'
     69: 98,  # 'E'
     70: 101,  # 'F'
     71: 116,  # 'G'
     72: 102,  # 'H'
     73: 111,  # 'I'
     74: 187,  # 'J'
     75: 117,  # 'K'
     76: 92,  # 'L'
     77: 88,  # 'M'
     78: 113,  # 'N'
     79: 85,  # 'O'
     80: 79,  # 'P'
     81: 118,  # 'Q'
     82: 105,  # 'R'
     83: 83,  # 'S'
     84: 67,  # 'T'
     85: 114,  # 'U'
     86: 119,  # 'V'
     87: 95,  # 'W'
     88: 99,  # 'X'
     89: 109,  # 'Y'
     90: 188,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 72,  # 'a'
     98: 70,  # 'b'
     99: 80,  # 'c'
     100: 81,  # 'd'
     101: 60,  # 'e'
     102: 96,  # 'f'
     103: 93,  # 'g'
     104: 89,  # 'h'
     105: 68,  # 'i'
     106: 120,  # 'j'
     107: 97,  # 'k'
     108: 77,  # 'l'
     109: 86,  # 'm'
     110: 69,  # 'n'
     111: 55,  # 'o'
     112: 78,  # 'p'
     113: 115,  # 'q'
     114: 65,  # 'r'
     115: 66,  # 's'
     116: 58,  # 't'
     117: 76,  # 'u'
     118: 106,  # 'v'
     119: 103,  # 'w'
     120: 87,  # 'x'
     121: 107,  # 'y'
     122: 112,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 255,  # ''
     129: 255,  # None
     130: 255,  # ''
     131: 255,  # ''
     132: 255,  # ''
     133: 255,  # ''
     134: 255,  # ''
     135: 255,  # ''
     136: 255,  # None
     137: 255,  # ''
     138: 255,  # None
     139: 255,  # ''
     140: 255,  # None
     141: 255,  # None
     142: 255,  # None
     143: 255,  # None
     144: 255,  # None
     145: 255,  # ''
     146: 255,  # ''
     147: 255,  # ''
     148: 255,  # ''
     149: 255,  # ''
     150: 255,  # ''
     151: 255,  # ''
     152: 255,  # None
     153: 255,  # ''
     154: 255,  # None
     155: 255,  # ''
     156: 255,  # None
     157: 255,  # None
     158: 255,  # None
     159: 255,  # None
     160: 253,  # '\xa0'
     161: 233,  # ''
     162: 61,  # ''
     163: 253,  # ''
     164: 253,  # ''
     165: 253,  # ''
     166: 253,  # ''
     167: 253,  # ''
     168: 253,  # ''
     169: 253,  # ''
     170: 253,  # None
     171: 253,  # ''
     172: 253,  # ''
     173: 74,  # '\xad'
     174: 253,  # ''
     175: 253,  # ''
     176: 253,  # ''
     177: 253,  # ''
     178: 253,  # ''
     179: 253,  # ''
     180: 247,  # ''
     181: 253,  # ''
     182: 253,  # ''
     183: 36,  # ''
     184: 46,  # ''
     185: 71,  # ''
     186: 73,  # ''
     187: 253,  # ''
     188: 54,  # ''
     189: 253,  # ''
     190: 108,  # ''
     191: 123,  # ''
     192: 110,  # ''
     193: 31,  # ''
     194: 51,  # ''
     195: 43,  # ''
     196: 41,  # ''
     197: 34,  # ''
     198: 91,  # ''
     199: 40,  # ''
     200: 52,  # ''
     201: 47,  # ''
     202: 44,  # ''
     203: 53,  # ''
     204: 38,  # ''
     205: 49,  # ''
     206: 59,  # ''
     207: 39,  # ''
     208: 35,  # ''
     209: 48,  # ''
     210: 250,  # None
     211: 37,  # ''
     212: 33,  # ''
     213: 45,  # ''
     214: 56,  # ''
     215: 50,  # ''
     216: 84,  # ''
     217: 57,  # ''
     218: 120,  # ''
     219: 121,  # ''
     220: 17,  # ''
     221: 18,  # ''
     222: 22,  # ''
     223: 15,  # ''
     224: 124,  # ''
     225: 1,  # ''
     226: 29,  # ''
     227: 20,  # ''
     228: 21,  # ''
     229: 3,  # ''
     230: 32,  # ''
     231: 13,  # ''
     232: 25,  # ''
     233: 5,  # ''
     234: 11,  # ''
     235: 16,  # ''
     236: 10,  # ''
     237: 6,  # ''
     238: 30,  # ''
     239: 4,  # ''
     240: 9,  # ''
     241: 8,  # ''
     242: 14,  # ''
     243: 7,  # ''
     244: 2,  # ''
     245: 12,  # ''
     246: 28,  # ''
     247: 23,  # ''
     248: 42,  # ''
     249: 24,  # ''
     250: 64,  # ''
     251: 75,  # ''
     252: 19,  # ''
     253: 26,  # ''
     254: 27,  # ''
     255: 253,  # None
}

WINDOWS_1253_GREEK_MODEL = SingleByteCharSetModel(charset_name='windows-1253',
                                                  language='Greek',
                                                  char_to_order_map=WINDOWS_1253_GREEK_CHAR_TO_ORDER,
                                                  language_model=GREEK_LANG_MODEL,
                                                  typical_positive_ratio=0.982851,
                                                  keep_ascii_letters=False,
                                                  alphabet='')

ISO_8859_7_GREEK_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 82,  # 'A'
     66: 100,  # 'B'
     67: 104,  # 'C'
     68: 94,  # 'D'
     69: 98,  # 'E'
     70: 101,  # 'F'
     71: 116,  # 'G'
     72: 102,  # 'H'
     73: 111,  # 'I'
     74: 187,  # 'J'
     75: 117,  # 'K'
     76: 92,  # 'L'
     77: 88,  # 'M'
     78: 113,  # 'N'
     79: 85,  # 'O'
     80: 79,  # 'P'
     81: 118,  # 'Q'
     82: 105,  # 'R'
     83: 83,  # 'S'
     84: 67,  # 'T'
     85: 114,  # 'U'
     86: 119,  # 'V'
     87: 95,  # 'W'
     88: 99,  # 'X'
     89: 109,  # 'Y'
     90: 188,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 72,  # 'a'
     98: 70,  # 'b'
     99: 80,  # 'c'
     100: 81,  # 'd'
     101: 60,  # 'e'
     102: 96,  # 'f'
     103: 93,  # 'g'
     104: 89,  # 'h'
     105: 68,  # 'i'
     106: 120,  # 'j'
     107: 97,  # 'k'
     108: 77,  # 'l'
     109: 86,  # 'm'
     110: 69,  # 'n'
     111: 55,  # 'o'
     112: 78,  # 'p'
     113: 115,  # 'q'
     114: 65,  # 'r'
     115: 66,  # 's'
     116: 58,  # 't'
     117: 76,  # 'u'
     118: 106,  # 'v'
     119: 103,  # 'w'
     120: 87,  # 'x'
     121: 107,  # 'y'
     122: 112,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 255,  # '\x80'
     129: 255,  # '\x81'
     130: 255,  # '\x82'
     131: 255,  # '\x83'
     132: 255,  # '\x84'
     133: 255,  # '\x85'
     134: 255,  # '\x86'
     135: 255,  # '\x87'
     136: 255,  # '\x88'
     137: 255,  # '\x89'
     138: 255,  # '\x8a'
     139: 255,  # '\x8b'
     140: 255,  # '\x8c'
     141: 255,  # '\x8d'
     142: 255,  # '\x8e'
     143: 255,  # '\x8f'
     144: 255,  # '\x90'
     145: 255,  # '\x91'
     146: 255,  # '\x92'
     147: 255,  # '\x93'
     148: 255,  # '\x94'
     149: 255,  # '\x95'
     150: 255,  # '\x96'
     151: 255,  # '\x97'
     152: 255,  # '\x98'
     153: 255,  # '\x99'
     154: 255,  # '\x9a'
     155: 255,  # '\x9b'
     156: 255,  # '\x9c'
     157: 255,  # '\x9d'
     158: 255,  # '\x9e'
     159: 255,  # '\x9f'
     160: 253,  # '\xa0'
     161: 233,  # ''
     162: 90,  # ''
     163: 253,  # ''
     164: 253,  # ''
     165: 253,  # ''
     166: 253,  # ''
     167: 253,  # ''
     168: 253,  # ''
     169: 253,  # ''
     170: 253,  # ''
     171: 253,  # ''
     172: 253,  # ''
     173: 74,  # '\xad'
     174: 253,  # None
     175: 253,  # ''
     176: 253,  # ''
     177: 253,  # ''
     178: 253,  # ''
     179: 253,  # ''
     180: 247,  # ''
     181: 248,  # ''
     182: 61,  # ''
     183: 36,  # ''
     184: 46,  # ''
     185: 71,  # ''
     186: 73,  # ''
     187: 253,  # ''
     188: 54,  # ''
     189: 253,  # ''
     190: 108,  # ''
     191: 123,  # ''
     192: 110,  # ''
     193: 31,  # ''
     194: 51,  # ''
     195: 43,  # ''
     196: 41,  # ''
     197: 34,  # ''
     198: 91,  # ''
     199: 40,  # ''
     200: 52,  # ''
     201: 47,  # ''
     202: 44,  # ''
     203: 53,  # ''
     204: 38,  # ''
     205: 49,  # ''
     206: 59,  # ''
     207: 39,  # ''
     208: 35,  # ''
     209: 48,  # ''
     210: 250,  # None
     211: 37,  # ''
     212: 33,  # ''
     213: 45,  # ''
     214: 56,  # ''
     215: 50,  # ''
     216: 84,  # ''
     217: 57,  # ''
     218: 120,  # ''
     219: 121,  # ''
     220: 17,  # ''
     221: 18,  # ''
     222: 22,  # ''
     223: 15,  # ''
     224: 124,  # ''
     225: 1,  # ''
     226: 29,  # ''
     227: 20,  # ''
     228: 21,  # ''
     229: 3,  # ''
     230: 32,  # ''
     231: 13,  # ''
     232: 25,  # ''
     233: 5,  # ''
     234: 11,  # ''
     235: 16,  # ''
     236: 10,  # ''
     237: 6,  # ''
     238: 30,  # ''
     239: 4,  # ''
     240: 9,  # ''
     241: 8,  # ''
     242: 14,  # ''
     243: 7,  # ''
     244: 2,  # ''
     245: 12,  # ''
     246: 28,  # ''
     247: 23,  # ''
     248: 42,  # ''
     249: 24,  # ''
     250: 64,  # ''
     251: 75,  # ''
     252: 19,  # ''
     253: 26,  # ''
     254: 27,  # ''
     255: 253,  # None
}

ISO_8859_7_GREEK_MODEL = SingleByteCharSetModel(charset_name='ISO-8859-7',
                                                language='Greek',
                                                char_to_order_map=ISO_8859_7_GREEK_CHAR_TO_ORDER,
                                                language_model=GREEK_LANG_MODEL,
                                                typical_positive_ratio=0.982851,
                                                keep_ascii_letters=False,
                                                alphabet='')





############################################################
### File: langhebrewmodel.py
############################################################
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

HEBREW_LANG_MODEL = {
    50: {  # 'a'
        50: 0,  # 'a'
        60: 1,  # 'c'
        61: 1,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 2,  # 'l'
        54: 2,  # 'n'
        49: 0,  # 'o'
        51: 2,  # 'r'
        43: 1,  # 's'
        44: 2,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 1,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 1,  # ''
        7: 0,  # ''
        10: 1,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    60: {  # 'c'
        50: 1,  # 'a'
        60: 1,  # 'c'
        61: 0,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 1,  # 'l'
        54: 0,  # 'n'
        49: 1,  # 'o'
        51: 1,  # 'r'
        43: 1,  # 's'
        44: 2,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 1,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 1,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    61: {  # 'd'
        50: 1,  # 'a'
        60: 0,  # 'c'
        61: 1,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 1,  # 'l'
        54: 1,  # 'n'
        49: 2,  # 'o'
        51: 1,  # 'r'
        43: 1,  # 's'
        44: 0,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 1,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 1,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    42: {  # 'e'
        50: 1,  # 'a'
        60: 1,  # 'c'
        61: 2,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 2,  # 'l'
        54: 2,  # 'n'
        49: 1,  # 'o'
        51: 2,  # 'r'
        43: 2,  # 's'
        44: 2,  # 't'
        63: 1,  # 'u'
        34: 1,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 1,  # ''
        52: 2,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    53: {  # 'i'
        50: 1,  # 'a'
        60: 2,  # 'c'
        61: 1,  # 'd'
        42: 1,  # 'e'
        53: 0,  # 'i'
        56: 1,  # 'l'
        54: 2,  # 'n'
        49: 2,  # 'o'
        51: 1,  # 'r'
        43: 2,  # 's'
        44: 2,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    56: {  # 'l'
        50: 1,  # 'a'
        60: 1,  # 'c'
        61: 1,  # 'd'
        42: 2,  # 'e'
        53: 2,  # 'i'
        56: 2,  # 'l'
        54: 1,  # 'n'
        49: 1,  # 'o'
        51: 0,  # 'r'
        43: 1,  # 's'
        44: 1,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    54: {  # 'n'
        50: 1,  # 'a'
        60: 1,  # 'c'
        61: 1,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 1,  # 'l'
        54: 1,  # 'n'
        49: 1,  # 'o'
        51: 0,  # 'r'
        43: 1,  # 's'
        44: 2,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 1,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 2,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    49: {  # 'o'
        50: 1,  # 'a'
        60: 1,  # 'c'
        61: 1,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 1,  # 'l'
        54: 2,  # 'n'
        49: 1,  # 'o'
        51: 2,  # 'r'
        43: 1,  # 's'
        44: 1,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    51: {  # 'r'
        50: 2,  # 'a'
        60: 1,  # 'c'
        61: 1,  # 'd'
        42: 2,  # 'e'
        53: 1,  # 'i'
        56: 1,  # 'l'
        54: 1,  # 'n'
        49: 2,  # 'o'
        51: 1,  # 'r'
        43: 1,  # 's'
        44: 1,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 2,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    43: {  # 's'
        50: 1,  # 'a'
        60: 1,  # 'c'
        61: 0,  # 'd'
        42: 2,  # 'e'
        53: 1,  # 'i'
        56: 1,  # 'l'
        54: 1,  # 'n'
        49: 1,  # 'o'
        51: 1,  # 'r'
        43: 1,  # 's'
        44: 2,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 2,  # ''
        58: 0,  # ''
        40: 2,  # ''
    },
    44: {  # 't'
        50: 1,  # 'a'
        60: 1,  # 'c'
        61: 0,  # 'd'
        42: 2,  # 'e'
        53: 2,  # 'i'
        56: 1,  # 'l'
        54: 0,  # 'n'
        49: 1,  # 'o'
        51: 1,  # 'r'
        43: 1,  # 's'
        44: 1,  # 't'
        63: 1,  # 'u'
        34: 1,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 2,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    63: {  # 'u'
        50: 1,  # 'a'
        60: 1,  # 'c'
        61: 1,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 1,  # 'l'
        54: 1,  # 'n'
        49: 0,  # 'o'
        51: 1,  # 'r'
        43: 2,  # 's'
        44: 1,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    34: {  # '\xa0'
        50: 1,  # 'a'
        60: 0,  # 'c'
        61: 1,  # 'd'
        42: 0,  # 'e'
        53: 1,  # 'i'
        56: 0,  # 'l'
        54: 1,  # 'n'
        49: 1,  # 'o'
        51: 0,  # 'r'
        43: 1,  # 's'
        44: 1,  # 't'
        63: 0,  # 'u'
        34: 2,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 1,  # ''
        20: 1,  # ''
        16: 1,  # ''
        3: 1,  # ''
        2: 1,  # ''
        24: 1,  # ''
        14: 1,  # ''
        22: 1,  # ''
        1: 2,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 2,  # ''
        23: 0,  # ''
        12: 1,  # ''
        19: 1,  # ''
        13: 1,  # ''
        26: 0,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 1,  # ''
        17: 1,  # ''
        7: 1,  # ''
        10: 1,  # ''
        5: 1,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    55: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 1,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 1,  # ''
        2: 1,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 2,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 1,  # ''
        12: 1,  # ''
        19: 1,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 1,  # ''
        10: 1,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    48: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 1,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    39: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 1,  # ''
        17: 1,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    57: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    30: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 1,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 1,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 2,  # ''
        20: 2,  # ''
        16: 2,  # ''
        3: 2,  # ''
        2: 2,  # ''
        24: 2,  # ''
        14: 2,  # ''
        22: 2,  # ''
        1: 2,  # ''
        25: 2,  # ''
        15: 2,  # ''
        4: 2,  # ''
        11: 1,  # ''
        6: 2,  # ''
        23: 0,  # ''
        12: 2,  # ''
        19: 2,  # ''
        13: 2,  # ''
        26: 0,  # ''
        18: 2,  # ''
        27: 0,  # ''
        21: 2,  # ''
        17: 2,  # ''
        7: 2,  # ''
        10: 2,  # ''
        5: 2,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    59: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 1,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 1,  # ''
        20: 1,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 1,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 1,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 2,  # ''
        11: 0,  # ''
        6: 2,  # ''
        23: 0,  # ''
        12: 1,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 1,  # ''
        10: 1,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    41: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 2,  # ''
        20: 1,  # ''
        16: 2,  # ''
        3: 1,  # ''
        2: 1,  # ''
        24: 1,  # ''
        14: 1,  # ''
        22: 1,  # ''
        1: 1,  # ''
        25: 1,  # ''
        15: 1,  # ''
        4: 2,  # ''
        11: 0,  # ''
        6: 2,  # ''
        23: 0,  # ''
        12: 2,  # ''
        19: 1,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 2,  # ''
        17: 1,  # ''
        7: 2,  # ''
        10: 2,  # ''
        5: 1,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    33: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 1,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 1,  # ''
        37: 0,  # ''
        36: 1,  # ''
        31: 0,  # ''
        29: 1,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 1,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 2,  # ''
        20: 2,  # ''
        16: 2,  # ''
        3: 1,  # ''
        2: 1,  # ''
        24: 2,  # ''
        14: 1,  # ''
        22: 1,  # ''
        1: 3,  # ''
        25: 1,  # ''
        15: 2,  # ''
        4: 2,  # ''
        11: 2,  # ''
        6: 2,  # ''
        23: 2,  # ''
        12: 2,  # ''
        19: 2,  # ''
        13: 1,  # ''
        26: 0,  # ''
        18: 2,  # ''
        27: 1,  # ''
        21: 2,  # ''
        17: 2,  # ''
        7: 2,  # ''
        10: 2,  # ''
        5: 2,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    37: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 2,  # ''
        20: 1,  # ''
        16: 2,  # ''
        3: 2,  # ''
        2: 1,  # ''
        24: 1,  # ''
        14: 2,  # ''
        22: 1,  # ''
        1: 3,  # ''
        25: 2,  # ''
        15: 1,  # ''
        4: 2,  # ''
        11: 2,  # ''
        6: 1,  # ''
        23: 2,  # ''
        12: 2,  # ''
        19: 1,  # ''
        13: 2,  # ''
        26: 1,  # ''
        18: 1,  # ''
        27: 1,  # ''
        21: 1,  # ''
        17: 1,  # ''
        7: 2,  # ''
        10: 2,  # ''
        5: 2,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    36: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 2,  # ''
        20: 1,  # ''
        16: 2,  # ''
        3: 2,  # ''
        2: 1,  # ''
        24: 1,  # ''
        14: 2,  # ''
        22: 1,  # ''
        1: 2,  # ''
        25: 2,  # ''
        15: 1,  # ''
        4: 2,  # ''
        11: 2,  # ''
        6: 2,  # ''
        23: 2,  # ''
        12: 2,  # ''
        19: 2,  # ''
        13: 1,  # ''
        26: 1,  # ''
        18: 1,  # ''
        27: 2,  # ''
        21: 1,  # ''
        17: 1,  # ''
        7: 2,  # ''
        10: 2,  # ''
        5: 2,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    31: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 1,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 1,  # ''
        31: 0,  # ''
        29: 2,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 2,  # ''
        20: 2,  # ''
        16: 2,  # ''
        3: 2,  # ''
        2: 1,  # ''
        24: 2,  # ''
        14: 2,  # ''
        22: 2,  # ''
        1: 3,  # ''
        25: 1,  # ''
        15: 2,  # ''
        4: 2,  # ''
        11: 2,  # ''
        6: 2,  # ''
        23: 2,  # ''
        12: 2,  # ''
        19: 2,  # ''
        13: 2,  # ''
        26: 2,  # ''
        18: 2,  # ''
        27: 1,  # ''
        21: 2,  # ''
        17: 2,  # ''
        7: 2,  # ''
        10: 2,  # ''
        5: 2,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    29: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 1,  # ''
        29: 2,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 1,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 2,  # ''
        20: 2,  # ''
        16: 2,  # ''
        3: 3,  # ''
        2: 2,  # ''
        24: 2,  # ''
        14: 2,  # ''
        22: 1,  # ''
        1: 2,  # ''
        25: 2,  # ''
        15: 2,  # ''
        4: 2,  # ''
        11: 2,  # ''
        6: 2,  # ''
        23: 2,  # ''
        12: 2,  # ''
        19: 1,  # ''
        13: 2,  # ''
        26: 1,  # ''
        18: 2,  # ''
        27: 1,  # ''
        21: 2,  # ''
        17: 2,  # ''
        7: 2,  # ''
        10: 2,  # ''
        5: 2,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    35: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 1,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 2,  # ''
        20: 1,  # ''
        16: 2,  # ''
        3: 2,  # ''
        2: 1,  # ''
        24: 1,  # ''
        14: 1,  # ''
        22: 1,  # ''
        1: 1,  # ''
        25: 1,  # ''
        15: 2,  # ''
        4: 2,  # ''
        11: 2,  # ''
        6: 2,  # ''
        23: 2,  # ''
        12: 2,  # ''
        19: 2,  # ''
        13: 2,  # ''
        26: 1,  # ''
        18: 2,  # ''
        27: 1,  # ''
        21: 2,  # ''
        17: 2,  # ''
        7: 2,  # ''
        10: 2,  # ''
        5: 2,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    62: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 1,  # ''
        20: 1,  # ''
        16: 1,  # ''
        3: 1,  # ''
        2: 1,  # ''
        24: 1,  # ''
        14: 1,  # ''
        22: 0,  # ''
        1: 1,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 2,  # ''
        11: 1,  # ''
        6: 1,  # ''
        23: 1,  # ''
        12: 1,  # ''
        19: 1,  # ''
        13: 1,  # ''
        26: 0,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 1,  # ''
        17: 1,  # ''
        7: 1,  # ''
        10: 1,  # ''
        5: 1,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    28: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 3,  # ''
        59: 0,  # ''
        41: 1,  # ''
        33: 3,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 3,  # ''
        29: 3,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 0,  # ''
        38: 2,  # ''
        45: 1,  # ''
        9: 2,  # ''
        8: 2,  # ''
        20: 1,  # ''
        16: 2,  # ''
        3: 1,  # ''
        2: 2,  # ''
        24: 1,  # ''
        14: 1,  # ''
        22: 1,  # ''
        1: 2,  # ''
        25: 2,  # ''
        15: 2,  # ''
        4: 2,  # ''
        11: 1,  # ''
        6: 2,  # ''
        23: 1,  # ''
        12: 2,  # ''
        19: 1,  # ''
        13: 2,  # ''
        26: 1,  # ''
        18: 1,  # ''
        27: 1,  # ''
        21: 1,  # ''
        17: 1,  # ''
        7: 2,  # ''
        10: 2,  # ''
        5: 2,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    38: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 1,  # ''
        62: 1,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 2,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 1,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 1,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    45: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 1,  # ''
        36: 2,  # ''
        31: 1,  # ''
        29: 2,  # ''
        35: 1,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 0,  # ''
        20: 1,  # ''
        16: 0,  # ''
        3: 1,  # ''
        2: 2,  # ''
        24: 0,  # ''
        14: 1,  # ''
        22: 0,  # ''
        1: 1,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 1,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 1,  # ''
        19: 0,  # ''
        13: 1,  # ''
        26: 0,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 1,  # ''
        10: 0,  # ''
        5: 1,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    9: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 1,  # ''
        48: 1,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 2,  # ''
        41: 2,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 3,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 2,  # ''
        26: 3,  # ''
        18: 3,  # ''
        27: 1,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    8: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 1,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 3,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 2,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 2,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        26: 1,  # ''
        18: 3,  # ''
        27: 2,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 1,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    20: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 2,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 1,  # ''
        37: 1,  # ''
        36: 1,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 1,  # ''
        62: 0,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 3,  # ''
        20: 2,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 2,  # ''
        22: 2,  # ''
        1: 3,  # ''
        25: 1,  # ''
        15: 1,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 2,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 2,  # ''
        27: 1,  # ''
        21: 1,  # ''
        17: 1,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    16: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 1,  # ''
        14: 2,  # ''
        22: 2,  # ''
        1: 3,  # ''
        25: 2,  # ''
        15: 2,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 2,  # ''
        12: 3,  # ''
        19: 2,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 3,  # ''
        27: 0,  # ''
        21: 2,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    3: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 1,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 0,  # ''
        48: 1,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 1,  # ''
        59: 1,  # ''
        41: 2,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 3,  # ''
        29: 2,  # ''
        35: 1,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 1,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        26: 0,  # ''
        18: 3,  # ''
        27: 1,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 1,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 2,  # ''
    },
    2: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 1,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 1,  # ''
        48: 1,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 1,  # ''
        36: 1,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 3,  # ''
        62: 0,  # ''
        28: 3,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 3,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        26: 3,  # ''
        18: 3,  # ''
        27: 3,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 1,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 2,  # ''
    },
    24: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 1,  # ''
        33: 1,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 1,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 2,  # ''
        20: 2,  # ''
        16: 2,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 2,  # ''
        14: 2,  # ''
        22: 1,  # ''
        1: 3,  # ''
        25: 1,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 2,  # ''
        6: 3,  # ''
        23: 2,  # ''
        12: 2,  # ''
        19: 1,  # ''
        13: 2,  # ''
        26: 1,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 2,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 1,  # ''
        5: 2,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    14: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 1,  # ''
        41: 2,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 3,  # ''
        20: 2,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 2,  # ''
        22: 2,  # ''
        1: 3,  # ''
        25: 1,  # ''
        15: 2,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 2,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 1,  # ''
        26: 2,  # ''
        18: 2,  # ''
        27: 2,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    22: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 1,  # ''
        36: 1,  # ''
        31: 2,  # ''
        29: 1,  # ''
        35: 1,  # ''
        62: 1,  # ''
        28: 1,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 1,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 2,  # ''
        14: 3,  # ''
        22: 2,  # ''
        1: 3,  # ''
        25: 1,  # ''
        15: 2,  # ''
        4: 3,  # ''
        11: 2,  # ''
        6: 2,  # ''
        23: 2,  # ''
        12: 3,  # ''
        19: 2,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 3,  # ''
        27: 1,  # ''
        21: 2,  # ''
        17: 2,  # ''
        7: 3,  # ''
        10: 2,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    1: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 1,  # ''
        48: 1,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 1,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 3,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        26: 3,  # ''
        18: 3,  # ''
        27: 3,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 1,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 2,  # ''
    },
    25: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 2,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 1,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 1,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 1,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 1,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    15: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 1,  # ''
        62: 1,  # ''
        28: 3,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 2,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 3,  # ''
        22: 2,  # ''
        1: 3,  # ''
        25: 3,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 2,  # ''
        26: 3,  # ''
        18: 3,  # ''
        27: 1,  # ''
        21: 2,  # ''
        17: 2,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    4: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 3,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 3,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 2,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 3,  # ''
        27: 2,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 1,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    11: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 1,  # ''
        20: 1,  # ''
        16: 0,  # ''
        3: 1,  # ''
        2: 1,  # ''
        24: 1,  # ''
        14: 1,  # ''
        22: 0,  # ''
        1: 1,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 1,  # ''
        11: 1,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 1,  # ''
        19: 0,  # ''
        13: 1,  # ''
        26: 0,  # ''
        18: 1,  # ''
        27: 1,  # ''
        21: 1,  # ''
        17: 1,  # ''
        7: 1,  # ''
        10: 1,  # ''
        5: 1,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 2,  # ''
    },
    6: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 2,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        26: 0,  # ''
        18: 3,  # ''
        27: 2,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    23: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 0,  # ''
        48: 1,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 1,  # ''
        20: 1,  # ''
        16: 1,  # ''
        3: 1,  # ''
        2: 1,  # ''
        24: 0,  # ''
        14: 1,  # ''
        22: 1,  # ''
        1: 1,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 1,  # ''
        11: 1,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 1,  # ''
        19: 1,  # ''
        13: 1,  # ''
        26: 1,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 1,  # ''
        7: 1,  # ''
        10: 1,  # ''
        5: 1,  # ''
        32: 1,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 2,  # ''
    },
    12: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 1,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 2,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 3,  # ''
        27: 2,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    19: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 1,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 1,  # ''
        35: 1,  # ''
        62: 2,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 1,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 2,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 2,  # ''
        6: 3,  # ''
        23: 2,  # ''
        12: 3,  # ''
        19: 2,  # ''
        13: 3,  # ''
        26: 3,  # ''
        18: 3,  # ''
        27: 0,  # ''
        21: 2,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 1,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    13: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 1,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 1,  # ''
        59: 1,  # ''
        41: 2,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 1,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 2,  # ''
        15: 2,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 2,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 2,  # ''
        26: 1,  # ''
        18: 2,  # ''
        27: 2,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    26: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 1,  # ''
        24: 0,  # ''
        14: 1,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 1,  # ''
        13: 0,  # ''
        26: 1,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 1,  # ''
        7: 1,  # ''
        10: 1,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    18: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 1,  # ''
        36: 2,  # ''
        31: 1,  # ''
        29: 2,  # ''
        35: 1,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 2,  # ''
        20: 3,  # ''
        16: 2,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 2,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 2,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 2,  # ''
        6: 2,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 2,  # ''
        27: 2,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    27: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 1,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 1,  # ''
        10: 0,  # ''
        5: 1,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    21: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 1,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 1,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 2,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 1,  # ''
        14: 3,  # ''
        22: 2,  # ''
        1: 3,  # ''
        25: 1,  # ''
        15: 1,  # ''
        4: 3,  # ''
        11: 2,  # ''
        6: 3,  # ''
        23: 2,  # ''
        12: 3,  # ''
        19: 1,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 3,  # ''
        27: 2,  # ''
        21: 2,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 0,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    17: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 1,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 1,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 2,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 2,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 1,  # ''
        15: 1,  # ''
        4: 3,  # ''
        11: 2,  # ''
        6: 3,  # ''
        23: 2,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 3,  # ''
        27: 2,  # ''
        21: 3,  # ''
        17: 2,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    7: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 2,  # ''
        48: 1,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 1,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 2,  # ''
        62: 1,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 3,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 3,  # ''
        27: 3,  # ''
        21: 3,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 2,  # ''
    },
    10: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 1,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 1,  # ''
        37: 1,  # ''
        36: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        35: 1,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 3,  # ''
        45: 2,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 3,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 2,  # ''
        14: 3,  # ''
        22: 3,  # ''
        1: 3,  # ''
        25: 3,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 2,  # ''
        12: 3,  # ''
        19: 2,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 3,  # ''
        27: 1,  # ''
        21: 2,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 1,  # ''
    },
    5: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 1,  # '\xa0'
        55: 0,  # ''
        48: 1,  # ''
        39: 1,  # ''
        57: 0,  # ''
        30: 2,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 2,  # ''
        37: 2,  # ''
        36: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        35: 1,  # ''
        62: 1,  # ''
        28: 2,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        8: 3,  # ''
        20: 3,  # ''
        16: 2,  # ''
        3: 3,  # ''
        2: 3,  # ''
        24: 2,  # ''
        14: 3,  # ''
        22: 2,  # ''
        1: 3,  # ''
        25: 2,  # ''
        15: 3,  # ''
        4: 3,  # ''
        11: 3,  # ''
        6: 3,  # ''
        23: 3,  # ''
        12: 3,  # ''
        19: 2,  # ''
        13: 3,  # ''
        26: 2,  # ''
        18: 3,  # ''
        27: 1,  # ''
        21: 2,  # ''
        17: 3,  # ''
        7: 3,  # ''
        10: 3,  # ''
        5: 3,  # ''
        32: 1,  # ''
        52: 1,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 2,  # ''
    },
    32: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 1,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 1,  # ''
        20: 1,  # ''
        16: 1,  # ''
        3: 1,  # ''
        2: 1,  # ''
        24: 0,  # ''
        14: 1,  # ''
        22: 0,  # ''
        1: 1,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 1,  # ''
        13: 1,  # ''
        26: 0,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 1,  # ''
        17: 0,  # ''
        7: 1,  # ''
        10: 1,  # ''
        5: 1,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    52: {  # ''
        50: 1,  # 'a'
        60: 0,  # 'c'
        61: 1,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 1,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 1,  # 'r'
        43: 2,  # 's'
        44: 2,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 1,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 1,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    47: {  # ''
        50: 1,  # 'a'
        60: 1,  # 'c'
        61: 1,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 1,  # 'l'
        54: 1,  # 'n'
        49: 1,  # 'o'
        51: 1,  # 'r'
        43: 1,  # 's'
        44: 1,  # 't'
        63: 1,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        8: 1,  # ''
        20: 1,  # ''
        16: 1,  # ''
        3: 1,  # ''
        2: 1,  # ''
        24: 1,  # ''
        14: 1,  # ''
        22: 1,  # ''
        1: 1,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 1,  # ''
        19: 1,  # ''
        13: 1,  # ''
        26: 0,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 1,  # ''
        17: 1,  # ''
        7: 1,  # ''
        10: 1,  # ''
        5: 1,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    46: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 1,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 1,  # ''
        20: 1,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 1,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 1,  # ''
        17: 0,  # ''
        7: 1,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 0,  # ''
        40: 0,  # ''
    },
    58: {  # ''
        50: 0,  # 'a'
        60: 0,  # 'c'
        61: 0,  # 'd'
        42: 0,  # 'e'
        53: 0,  # 'i'
        56: 0,  # 'l'
        54: 0,  # 'n'
        49: 0,  # 'o'
        51: 0,  # 'r'
        43: 0,  # 's'
        44: 0,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 0,  # ''
        25: 0,  # ''
        15: 0,  # ''
        4: 0,  # ''
        11: 0,  # ''
        6: 0,  # ''
        23: 0,  # ''
        12: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 0,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 0,  # ''
        10: 0,  # ''
        5: 0,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 0,  # ''
        58: 2,  # ''
        40: 0,  # ''
    },
    40: {  # ''
        50: 1,  # 'a'
        60: 1,  # 'c'
        61: 1,  # 'd'
        42: 1,  # 'e'
        53: 1,  # 'i'
        56: 0,  # 'l'
        54: 1,  # 'n'
        49: 0,  # 'o'
        51: 1,  # 'r'
        43: 1,  # 's'
        44: 1,  # 't'
        63: 0,  # 'u'
        34: 0,  # '\xa0'
        55: 0,  # ''
        48: 0,  # ''
        39: 0,  # ''
        57: 0,  # ''
        30: 0,  # ''
        59: 0,  # ''
        41: 0,  # ''
        33: 0,  # ''
        37: 0,  # ''
        36: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        35: 0,  # ''
        62: 0,  # ''
        28: 0,  # ''
        38: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        8: 0,  # ''
        20: 0,  # ''
        16: 0,  # ''
        3: 1,  # ''
        2: 1,  # ''
        24: 1,  # ''
        14: 0,  # ''
        22: 0,  # ''
        1: 1,  # ''
        25: 0,  # ''
        15: 1,  # ''
        4: 1,  # ''
        11: 0,  # ''
        6: 1,  # ''
        23: 0,  # ''
        12: 1,  # ''
        19: 0,  # ''
        13: 0,  # ''
        26: 0,  # ''
        18: 1,  # ''
        27: 0,  # ''
        21: 0,  # ''
        17: 0,  # ''
        7: 1,  # ''
        10: 1,  # ''
        5: 1,  # ''
        32: 0,  # ''
        52: 0,  # ''
        47: 0,  # ''
        46: 1,  # ''
        58: 0,  # ''
        40: 2,  # ''
    },
}

# 255: Undefined characters that did not exist in training text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9
# 251: Control characters

# Character Mapping Table(s):
WINDOWS_1255_HEBREW_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 69,  # 'A'
     66: 91,  # 'B'
     67: 79,  # 'C'
     68: 80,  # 'D'
     69: 92,  # 'E'
     70: 89,  # 'F'
     71: 97,  # 'G'
     72: 90,  # 'H'
     73: 68,  # 'I'
     74: 111,  # 'J'
     75: 112,  # 'K'
     76: 82,  # 'L'
     77: 73,  # 'M'
     78: 95,  # 'N'
     79: 85,  # 'O'
     80: 78,  # 'P'
     81: 121,  # 'Q'
     82: 86,  # 'R'
     83: 71,  # 'S'
     84: 67,  # 'T'
     85: 102,  # 'U'
     86: 107,  # 'V'
     87: 84,  # 'W'
     88: 114,  # 'X'
     89: 103,  # 'Y'
     90: 115,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 50,  # 'a'
     98: 74,  # 'b'
     99: 60,  # 'c'
     100: 61,  # 'd'
     101: 42,  # 'e'
     102: 76,  # 'f'
     103: 70,  # 'g'
     104: 64,  # 'h'
     105: 53,  # 'i'
     106: 105,  # 'j'
     107: 93,  # 'k'
     108: 56,  # 'l'
     109: 65,  # 'm'
     110: 54,  # 'n'
     111: 49,  # 'o'
     112: 66,  # 'p'
     113: 110,  # 'q'
     114: 51,  # 'r'
     115: 43,  # 's'
     116: 44,  # 't'
     117: 63,  # 'u'
     118: 81,  # 'v'
     119: 77,  # 'w'
     120: 98,  # 'x'
     121: 75,  # 'y'
     122: 108,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 124,  # ''
     129: 202,  # None
     130: 203,  # ''
     131: 204,  # ''
     132: 205,  # ''
     133: 40,  # ''
     134: 58,  # ''
     135: 206,  # ''
     136: 207,  # ''
     137: 208,  # ''
     138: 209,  # None
     139: 210,  # ''
     140: 211,  # None
     141: 212,  # None
     142: 213,  # None
     143: 214,  # None
     144: 215,  # None
     145: 83,  # ''
     146: 52,  # ''
     147: 47,  # ''
     148: 46,  # ''
     149: 72,  # ''
     150: 32,  # ''
     151: 94,  # ''
     152: 216,  # ''
     153: 113,  # ''
     154: 217,  # None
     155: 109,  # ''
     156: 218,  # None
     157: 219,  # None
     158: 220,  # None
     159: 221,  # None
     160: 34,  # '\xa0'
     161: 116,  # ''
     162: 222,  # ''
     163: 118,  # ''
     164: 100,  # ''
     165: 223,  # ''
     166: 224,  # ''
     167: 117,  # ''
     168: 119,  # ''
     169: 104,  # ''
     170: 125,  # ''
     171: 225,  # ''
     172: 226,  # ''
     173: 87,  # '\xad'
     174: 99,  # ''
     175: 227,  # ''
     176: 106,  # ''
     177: 122,  # ''
     178: 123,  # ''
     179: 228,  # ''
     180: 55,  # ''
     181: 229,  # ''
     182: 230,  # ''
     183: 101,  # ''
     184: 231,  # ''
     185: 232,  # ''
     186: 120,  # ''
     187: 233,  # ''
     188: 48,  # ''
     189: 39,  # ''
     190: 57,  # ''
     191: 234,  # ''
     192: 30,  # ''
     193: 59,  # ''
     194: 41,  # ''
     195: 88,  # ''
     196: 33,  # ''
     197: 37,  # ''
     198: 36,  # ''
     199: 31,  # ''
     200: 29,  # ''
     201: 35,  # ''
     202: 235,  # None
     203: 62,  # ''
     204: 28,  # ''
     205: 236,  # ''
     206: 126,  # ''
     207: 237,  # ''
     208: 238,  # ''
     209: 38,  # ''
     210: 45,  # ''
     211: 239,  # ''
     212: 240,  # ''
     213: 241,  # ''
     214: 242,  # ''
     215: 243,  # ''
     216: 127,  # ''
     217: 244,  # None
     218: 245,  # None
     219: 246,  # None
     220: 247,  # None
     221: 248,  # None
     222: 249,  # None
     223: 250,  # None
     224: 9,  # ''
     225: 8,  # ''
     226: 20,  # ''
     227: 16,  # ''
     228: 3,  # ''
     229: 2,  # ''
     230: 24,  # ''
     231: 14,  # ''
     232: 22,  # ''
     233: 1,  # ''
     234: 25,  # ''
     235: 15,  # ''
     236: 4,  # ''
     237: 11,  # ''
     238: 6,  # ''
     239: 23,  # ''
     240: 12,  # ''
     241: 19,  # ''
     242: 13,  # ''
     243: 26,  # ''
     244: 18,  # ''
     245: 27,  # ''
     246: 21,  # ''
     247: 17,  # ''
     248: 7,  # ''
     249: 10,  # ''
     250: 5,  # ''
     251: 251,  # None
     252: 252,  # None
     253: 128,  # '\u200e'
     254: 96,  # '\u200f'
     255: 253,  # None
}

WINDOWS_1255_HEBREW_MODEL = SingleByteCharSetModel(charset_name='windows-1255',
                                                   language='Hebrew',
                                                   char_to_order_map=WINDOWS_1255_HEBREW_CHAR_TO_ORDER,
                                                   language_model=HEBREW_LANG_MODEL,
                                                   typical_positive_ratio=0.984004,
                                                   keep_ascii_letters=False,
                                                   alphabet='')





############################################################
### File: langhungarianmodel.py
############################################################
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

HUNGARIAN_LANG_MODEL = {
    28: {  # 'A'
        28: 0,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 2,  # 'D'
        32: 1,  # 'E'
        50: 1,  # 'F'
        49: 2,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 2,  # 'K'
        41: 2,  # 'L'
        34: 1,  # 'M'
        35: 2,  # 'N'
        47: 1,  # 'O'
        46: 2,  # 'P'
        43: 2,  # 'R'
        33: 2,  # 'S'
        37: 2,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 2,  # 'Z'
        2: 0,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 2,  # 'd'
        1: 1,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 1,  # 'h'
        9: 1,  # 'i'
        22: 1,  # 'j'
        7: 2,  # 'k'
        6: 2,  # 'l'
        13: 2,  # 'm'
        4: 2,  # 'n'
        8: 0,  # 'o'
        23: 2,  # 'p'
        10: 2,  # 'r'
        5: 1,  # 's'
        3: 1,  # 't'
        21: 1,  # 'u'
        19: 1,  # 'v'
        62: 1,  # 'x'
        16: 0,  # 'y'
        11: 3,  # 'z'
        51: 1,  # ''
        44: 0,  # ''
        61: 1,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    40: {  # 'B'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 0,  # 'M'
        35: 1,  # 'N'
        47: 2,  # 'O'
        46: 0,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 3,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 2,  # 'i'
        22: 1,  # 'j'
        7: 0,  # 'k'
        6: 1,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 2,  # 'o'
        23: 1,  # 'p'
        10: 2,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 3,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 0,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 2,  # ''
        15: 2,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    54: {  # 'C'
        28: 1,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 1,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 0,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 2,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 0,  # 'V'
        55: 1,  # 'Y'
        52: 1,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 1,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 1,  # 'h'
        9: 1,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 1,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 2,  # 'o'
        23: 0,  # 'p'
        10: 1,  # 'r'
        5: 3,  # 's'
        3: 0,  # 't'
        21: 1,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 1,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 1,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    45: {  # 'D'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 0,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 0,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 2,  # 'O'
        46: 0,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 1,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 3,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 1,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 0,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 1,  # 'o'
        23: 0,  # 'p'
        10: 2,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 2,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 1,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 1,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 1,  # ''
        56: 0,  # ''
    },
    32: {  # 'E'
        28: 1,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 1,  # 'E'
        50: 1,  # 'F'
        49: 2,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 2,  # 'K'
        41: 2,  # 'L'
        34: 2,  # 'M'
        35: 2,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 2,  # 'R'
        33: 2,  # 'S'
        37: 2,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 1,  # 'Z'
        2: 1,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 2,  # 'd'
        1: 1,  # 'e'
        27: 1,  # 'f'
        12: 3,  # 'g'
        20: 1,  # 'h'
        9: 1,  # 'i'
        22: 1,  # 'j'
        7: 1,  # 'k'
        6: 2,  # 'l'
        13: 2,  # 'm'
        4: 2,  # 'n'
        8: 0,  # 'o'
        23: 1,  # 'p'
        10: 2,  # 'r'
        5: 2,  # 's'
        3: 1,  # 't'
        21: 2,  # 'u'
        19: 1,  # 'v'
        62: 1,  # 'x'
        16: 0,  # 'y'
        11: 3,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 0,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 0,  # ''
        63: 1,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 1,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    50: {  # 'F'
        28: 1,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 1,  # 'E'
        50: 1,  # 'F'
        49: 0,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 1,  # 'O'
        46: 0,  # 'P'
        43: 1,  # 'R'
        33: 0,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 0,  # 'V'
        55: 1,  # 'Y'
        52: 0,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 2,  # 'e'
        27: 1,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 2,  # 'i'
        22: 1,  # 'j'
        7: 0,  # 'k'
        6: 1,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 2,  # 'o'
        23: 0,  # 'p'
        10: 2,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 1,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 0,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 0,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 0,  # ''
        63: 1,  # ''
        14: 1,  # ''
        15: 1,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 2,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    49: {  # 'G'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 2,  # 'Y'
        52: 1,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 2,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 1,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 1,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 2,  # 'o'
        23: 0,  # 'p'
        10: 2,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 1,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 2,  # 'y'
        11: 0,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 1,  # ''
        15: 1,  # ''
        30: 0,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 1,  # ''
        56: 0,  # ''
    },
    38: {  # 'H'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 0,  # 'D'
        32: 1,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 1,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 1,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 1,  # 'O'
        46: 0,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 0,  # 'V'
        55: 1,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 2,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 2,  # 'i'
        22: 1,  # 'j'
        7: 0,  # 'k'
        6: 1,  # 'l'
        13: 1,  # 'm'
        4: 0,  # 'n'
        8: 3,  # 'o'
        23: 0,  # 'p'
        10: 1,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 2,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 0,  # 'z'
        51: 2,  # ''
        44: 2,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 2,  # ''
        15: 1,  # ''
        30: 2,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    39: {  # 'I'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 1,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 2,  # 'K'
        41: 2,  # 'L'
        34: 1,  # 'M'
        35: 2,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 2,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 2,  # 'Z'
        2: 0,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 2,  # 'd'
        1: 0,  # 'e'
        27: 1,  # 'f'
        12: 2,  # 'g'
        20: 1,  # 'h'
        9: 0,  # 'i'
        22: 1,  # 'j'
        7: 1,  # 'k'
        6: 2,  # 'l'
        13: 2,  # 'm'
        4: 1,  # 'n'
        8: 0,  # 'o'
        23: 1,  # 'p'
        10: 2,  # 'r'
        5: 2,  # 's'
        3: 2,  # 't'
        21: 0,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 1,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 0,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    53: {  # 'J'
        28: 2,  # 'A'
        40: 0,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 1,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 1,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 2,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 1,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 0,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 1,  # 'o'
        23: 0,  # 'p'
        10: 0,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 2,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 0,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 0,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 2,  # ''
        15: 1,  # ''
        30: 0,  # ''
        25: 2,  # ''
        24: 2,  # ''
        31: 1,  # ''
        29: 0,  # ''
        42: 1,  # ''
        56: 0,  # ''
    },
    36: {  # 'K'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 0,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 2,  # 'O'
        46: 0,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 0,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 2,  # 'e'
        27: 1,  # 'f'
        12: 0,  # 'g'
        20: 1,  # 'h'
        9: 3,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 1,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        8: 2,  # 'o'
        23: 0,  # 'p'
        10: 2,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 1,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 0,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 2,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 2,  # ''
        15: 2,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 2,  # ''
        31: 1,  # ''
        29: 2,  # ''
        42: 1,  # ''
        56: 0,  # ''
    },
    41: {  # 'L'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 2,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 2,  # 'O'
        46: 0,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 2,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 1,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 3,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 2,  # 'i'
        22: 1,  # 'j'
        7: 0,  # 'k'
        6: 1,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 2,  # 'o'
        23: 0,  # 'p'
        10: 0,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 2,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 0,  # 'z'
        51: 2,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 2,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 0,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    34: {  # 'M'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 0,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 1,  # 'Z'
        2: 3,  # 'a'
        18: 0,  # 'b'
        26: 1,  # 'c'
        17: 0,  # 'd'
        1: 3,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 3,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 0,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        8: 3,  # 'o'
        23: 0,  # 'p'
        10: 1,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 2,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 0,  # 'z'
        51: 2,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 2,  # ''
        15: 2,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 1,  # ''
    },
    35: {  # 'N'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 2,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 2,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 2,  # 'Y'
        52: 1,  # 'Z'
        2: 3,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 3,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 2,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 0,  # 'l'
        13: 0,  # 'm'
        4: 1,  # 'n'
        8: 2,  # 'o'
        23: 0,  # 'p'
        10: 0,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 1,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 2,  # 'y'
        11: 0,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 1,  # ''
        15: 2,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 1,  # ''
        56: 0,  # ''
    },
    47: {  # 'O'
        28: 1,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 1,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 2,  # 'K'
        41: 2,  # 'L'
        34: 2,  # 'M'
        35: 2,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 2,  # 'R'
        33: 2,  # 'S'
        37: 2,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 1,  # 'Z'
        2: 0,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 1,  # 'd'
        1: 1,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 1,  # 'h'
        9: 1,  # 'i'
        22: 1,  # 'j'
        7: 2,  # 'k'
        6: 2,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        8: 1,  # 'o'
        23: 1,  # 'p'
        10: 2,  # 'r'
        5: 1,  # 's'
        3: 2,  # 't'
        21: 1,  # 'u'
        19: 0,  # 'v'
        62: 1,  # 'x'
        16: 0,  # 'y'
        11: 1,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 0,  # ''
        58: 1,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    46: {  # 'P'
        28: 1,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 1,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 0,  # 'M'
        35: 1,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 2,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 1,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 2,  # 'e'
        27: 1,  # 'f'
        12: 0,  # 'g'
        20: 1,  # 'h'
        9: 2,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 1,  # 'l'
        13: 0,  # 'm'
        4: 1,  # 'n'
        8: 2,  # 'o'
        23: 0,  # 'p'
        10: 2,  # 'r'
        5: 1,  # 's'
        3: 0,  # 't'
        21: 1,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 0,  # 'z'
        51: 2,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 0,  # ''
        63: 1,  # ''
        14: 3,  # ''
        15: 2,  # ''
        30: 0,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 0,  # ''
        29: 1,  # ''
        42: 1,  # ''
        56: 0,  # ''
    },
    43: {  # 'R'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 2,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 2,  # 'S'
        37: 2,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 1,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 2,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 1,  # 'h'
        9: 2,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 0,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 2,  # 'o'
        23: 0,  # 'p'
        10: 0,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 1,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 0,  # 'z'
        51: 2,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 2,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 2,  # ''
        15: 2,  # ''
        30: 1,  # ''
        25: 2,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    33: {  # 'S'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 2,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 2,  # 'S'
        37: 2,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 3,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 1,  # 'c'
        17: 0,  # 'd'
        1: 2,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 1,  # 'h'
        9: 2,  # 'i'
        22: 0,  # 'j'
        7: 1,  # 'k'
        6: 1,  # 'l'
        13: 1,  # 'm'
        4: 0,  # 'n'
        8: 2,  # 'o'
        23: 1,  # 'p'
        10: 0,  # 'r'
        5: 0,  # 's'
        3: 1,  # 't'
        21: 1,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 3,  # 'z'
        51: 2,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 2,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    37: {  # 'T'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 2,  # 'O'
        46: 1,  # 'P'
        43: 2,  # 'R'
        33: 1,  # 'S'
        37: 2,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 1,  # 'Z'
        2: 2,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 2,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 1,  # 'h'
        9: 2,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 0,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 2,  # 'o'
        23: 0,  # 'p'
        10: 1,  # 'r'
        5: 1,  # 's'
        3: 0,  # 't'
        21: 2,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 1,  # 'z'
        51: 2,  # ''
        44: 2,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 2,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 2,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    57: {  # 'U'
        28: 1,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 1,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 2,  # 'S'
        37: 1,  # 'T'
        57: 0,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 1,  # 'Z'
        2: 0,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 1,  # 'd'
        1: 1,  # 'e'
        27: 0,  # 'f'
        12: 2,  # 'g'
        20: 0,  # 'h'
        9: 0,  # 'i'
        22: 1,  # 'j'
        7: 1,  # 'k'
        6: 1,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        8: 0,  # 'o'
        23: 1,  # 'p'
        10: 1,  # 'r'
        5: 1,  # 's'
        3: 1,  # 't'
        21: 0,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 1,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 1,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    48: {  # 'V'
        28: 2,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 0,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 2,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 2,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 1,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 2,  # 'o'
        23: 0,  # 'p'
        10: 0,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 1,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 0,  # 'z'
        51: 2,  # ''
        44: 2,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 0,  # ''
        63: 1,  # ''
        14: 2,  # ''
        15: 2,  # ''
        30: 1,  # ''
        25: 0,  # ''
        24: 1,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    55: {  # 'Y'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 1,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 2,  # 'Z'
        2: 1,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 1,  # 'd'
        1: 1,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 0,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 0,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        8: 1,  # 'o'
        23: 1,  # 'p'
        10: 0,  # 'r'
        5: 0,  # 's'
        3: 0,  # 't'
        21: 0,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 0,  # 'z'
        51: 1,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    52: {  # 'Z'
        28: 2,  # 'A'
        40: 1,  # 'B'
        54: 0,  # 'C'
        45: 1,  # 'D'
        32: 2,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 2,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 2,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 2,  # 'S'
        37: 1,  # 'T'
        57: 1,  # 'U'
        48: 1,  # 'V'
        55: 1,  # 'Y'
        52: 1,  # 'Z'
        2: 1,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 1,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 1,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 0,  # 'l'
        13: 0,  # 'm'
        4: 1,  # 'n'
        8: 1,  # 'o'
        23: 0,  # 'p'
        10: 1,  # 'r'
        5: 2,  # 's'
        3: 0,  # 't'
        21: 1,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 0,  # 'z'
        51: 2,  # ''
        44: 1,  # ''
        61: 1,  # ''
        58: 1,  # ''
        59: 1,  # ''
        60: 1,  # ''
        63: 1,  # ''
        14: 1,  # ''
        15: 1,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    2: {  # 'a'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 1,  # 'a'
        18: 3,  # 'b'
        26: 3,  # 'c'
        17: 3,  # 'd'
        1: 2,  # 'e'
        27: 2,  # 'f'
        12: 3,  # 'g'
        20: 3,  # 'h'
        9: 3,  # 'i'
        22: 3,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 2,  # 'o'
        23: 3,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 3,  # 'v'
        62: 1,  # 'x'
        16: 2,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 1,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    18: {  # 'b'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 3,  # 'b'
        26: 1,  # 'c'
        17: 1,  # 'd'
        1: 3,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 1,  # 'h'
        9: 3,  # 'i'
        22: 2,  # 'j'
        7: 2,  # 'k'
        6: 2,  # 'l'
        13: 1,  # 'm'
        4: 2,  # 'n'
        8: 3,  # 'o'
        23: 1,  # 'p'
        10: 3,  # 'r'
        5: 2,  # 's'
        3: 1,  # 't'
        21: 3,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 1,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 2,  # ''
        25: 3,  # ''
        24: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        42: 2,  # ''
        56: 1,  # ''
    },
    26: {  # 'c'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 1,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 1,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 2,  # 'a'
        18: 1,  # 'b'
        26: 2,  # 'c'
        17: 1,  # 'd'
        1: 3,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 3,  # 'h'
        9: 3,  # 'i'
        22: 1,  # 'j'
        7: 2,  # 'k'
        6: 1,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        8: 3,  # 'o'
        23: 1,  # 'p'
        10: 2,  # 'r'
        5: 3,  # 's'
        3: 2,  # 't'
        21: 2,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 2,  # ''
        15: 2,  # ''
        30: 2,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    17: {  # 'd'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 2,  # 'b'
        26: 1,  # 'c'
        17: 2,  # 'd'
        1: 3,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 2,  # 'h'
        9: 3,  # 'i'
        22: 3,  # 'j'
        7: 2,  # 'k'
        6: 1,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        8: 3,  # 'o'
        23: 1,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 3,  # 'v'
        62: 0,  # 'x'
        16: 2,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 3,  # ''
        25: 3,  # ''
        24: 3,  # ''
        31: 2,  # ''
        29: 2,  # ''
        42: 2,  # ''
        56: 1,  # ''
    },
    1: {  # 'e'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 2,  # 'a'
        18: 3,  # 'b'
        26: 3,  # 'c'
        17: 3,  # 'd'
        1: 2,  # 'e'
        27: 3,  # 'f'
        12: 3,  # 'g'
        20: 3,  # 'h'
        9: 3,  # 'i'
        22: 3,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 2,  # 'o'
        23: 3,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 2,  # 'u'
        19: 3,  # 'v'
        62: 2,  # 'x'
        16: 2,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    27: {  # 'f'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 1,  # 'd'
        1: 3,  # 'e'
        27: 2,  # 'f'
        12: 1,  # 'g'
        20: 1,  # 'h'
        9: 3,  # 'i'
        22: 2,  # 'j'
        7: 1,  # 'k'
        6: 1,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        8: 3,  # 'o'
        23: 0,  # 'p'
        10: 3,  # 'r'
        5: 1,  # 's'
        3: 1,  # 't'
        21: 2,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 0,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 3,  # ''
        31: 1,  # ''
        29: 2,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    12: {  # 'g'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 3,  # 'b'
        26: 2,  # 'c'
        17: 2,  # 'd'
        1: 3,  # 'e'
        27: 2,  # 'f'
        12: 3,  # 'g'
        20: 3,  # 'h'
        9: 3,  # 'i'
        22: 3,  # 'j'
        7: 2,  # 'k'
        6: 3,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        8: 3,  # 'o'
        23: 1,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 3,  # 'v'
        62: 0,  # 'x'
        16: 3,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 2,  # ''
        25: 3,  # ''
        24: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        42: 2,  # ''
        56: 1,  # ''
    },
    20: {  # 'h'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 0,  # 'd'
        1: 3,  # 'e'
        27: 0,  # 'f'
        12: 1,  # 'g'
        20: 2,  # 'h'
        9: 3,  # 'i'
        22: 1,  # 'j'
        7: 1,  # 'k'
        6: 1,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        8: 3,  # 'o'
        23: 0,  # 'p'
        10: 1,  # 'r'
        5: 2,  # 's'
        3: 1,  # 't'
        21: 3,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 2,  # 'y'
        11: 0,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 3,  # ''
        25: 2,  # ''
        24: 2,  # ''
        31: 2,  # ''
        29: 1,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    9: {  # 'i'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 3,  # 'b'
        26: 3,  # 'c'
        17: 3,  # 'd'
        1: 3,  # 'e'
        27: 3,  # 'f'
        12: 3,  # 'g'
        20: 3,  # 'h'
        9: 2,  # 'i'
        22: 2,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 2,  # 'o'
        23: 2,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 3,  # 'v'
        62: 1,  # 'x'
        16: 1,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 2,  # ''
        30: 1,  # ''
        25: 3,  # ''
        24: 1,  # ''
        31: 2,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 1,  # ''
    },
    22: {  # 'j'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 2,  # 'b'
        26: 1,  # 'c'
        17: 3,  # 'd'
        1: 3,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 2,  # 'h'
        9: 1,  # 'i'
        22: 2,  # 'j'
        7: 2,  # 'k'
        6: 2,  # 'l'
        13: 1,  # 'm'
        4: 2,  # 'n'
        8: 3,  # 'o'
        23: 1,  # 'p'
        10: 2,  # 'r'
        5: 2,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 1,  # ''
        25: 3,  # ''
        24: 3,  # ''
        31: 3,  # ''
        29: 2,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    7: {  # 'k'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 3,  # 'b'
        26: 2,  # 'c'
        17: 1,  # 'd'
        1: 3,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 2,  # 'h'
        9: 3,  # 'i'
        22: 2,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 1,  # 'm'
        4: 3,  # 'n'
        8: 3,  # 'o'
        23: 1,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 2,  # 'v'
        62: 0,  # 'x'
        16: 2,  # 'y'
        11: 1,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 3,  # ''
        25: 2,  # ''
        24: 3,  # ''
        31: 1,  # ''
        29: 3,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    6: {  # 'l'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 1,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 1,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 2,  # 'b'
        26: 3,  # 'c'
        17: 3,  # 'd'
        1: 3,  # 'e'
        27: 3,  # 'f'
        12: 3,  # 'g'
        20: 3,  # 'h'
        9: 3,  # 'i'
        22: 3,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 3,  # 'o'
        23: 2,  # 'p'
        10: 2,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 3,  # 'v'
        62: 0,  # 'x'
        16: 3,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 3,  # ''
        25: 3,  # ''
        24: 3,  # ''
        31: 2,  # ''
        29: 2,  # ''
        42: 3,  # ''
        56: 1,  # ''
    },
    13: {  # 'm'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 3,  # 'b'
        26: 2,  # 'c'
        17: 1,  # 'd'
        1: 3,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 2,  # 'h'
        9: 3,  # 'i'
        22: 2,  # 'j'
        7: 1,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 2,  # 'n'
        8: 3,  # 'o'
        23: 3,  # 'p'
        10: 2,  # 'r'
        5: 2,  # 's'
        3: 2,  # 't'
        21: 3,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 2,  # ''
        25: 2,  # ''
        24: 2,  # ''
        31: 2,  # ''
        29: 2,  # ''
        42: 1,  # ''
        56: 2,  # ''
    },
    4: {  # 'n'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 3,  # 'b'
        26: 3,  # 'c'
        17: 3,  # 'd'
        1: 3,  # 'e'
        27: 2,  # 'f'
        12: 3,  # 'g'
        20: 3,  # 'h'
        9: 3,  # 'i'
        22: 2,  # 'j'
        7: 3,  # 'k'
        6: 2,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        8: 3,  # 'o'
        23: 2,  # 'p'
        10: 2,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 2,  # 'v'
        62: 1,  # 'x'
        16: 3,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 2,  # ''
        25: 2,  # ''
        24: 3,  # ''
        31: 2,  # ''
        29: 3,  # ''
        42: 2,  # ''
        56: 1,  # ''
    },
    8: {  # 'o'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 1,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 2,  # 'a'
        18: 3,  # 'b'
        26: 3,  # 'c'
        17: 3,  # 'd'
        1: 2,  # 'e'
        27: 2,  # 'f'
        12: 3,  # 'g'
        20: 3,  # 'h'
        9: 2,  # 'i'
        22: 2,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 1,  # 'o'
        23: 3,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 2,  # 'u'
        19: 3,  # 'v'
        62: 1,  # 'x'
        16: 1,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 1,  # ''
        15: 2,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    23: {  # 'p'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 1,  # 'b'
        26: 2,  # 'c'
        17: 1,  # 'd'
        1: 3,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 2,  # 'h'
        9: 3,  # 'i'
        22: 2,  # 'j'
        7: 2,  # 'k'
        6: 3,  # 'l'
        13: 1,  # 'm'
        4: 2,  # 'n'
        8: 3,  # 'o'
        23: 3,  # 'p'
        10: 3,  # 'r'
        5: 2,  # 's'
        3: 2,  # 't'
        21: 3,  # 'u'
        19: 2,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 2,  # ''
        25: 2,  # ''
        24: 2,  # ''
        31: 1,  # ''
        29: 2,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    10: {  # 'r'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 3,  # 'b'
        26: 3,  # 'c'
        17: 3,  # 'd'
        1: 3,  # 'e'
        27: 2,  # 'f'
        12: 3,  # 'g'
        20: 2,  # 'h'
        9: 3,  # 'i'
        22: 3,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 3,  # 'o'
        23: 2,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 3,  # 'v'
        62: 1,  # 'x'
        16: 2,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 2,  # ''
        25: 3,  # ''
        24: 3,  # ''
        31: 3,  # ''
        29: 3,  # ''
        42: 2,  # ''
        56: 2,  # ''
    },
    5: {  # 's'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 3,  # 'b'
        26: 2,  # 'c'
        17: 2,  # 'd'
        1: 3,  # 'e'
        27: 2,  # 'f'
        12: 2,  # 'g'
        20: 2,  # 'h'
        9: 3,  # 'i'
        22: 1,  # 'j'
        7: 3,  # 'k'
        6: 2,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 3,  # 'o'
        23: 2,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 2,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 3,  # ''
        25: 3,  # ''
        24: 3,  # ''
        31: 3,  # ''
        29: 3,  # ''
        42: 2,  # ''
        56: 1,  # ''
    },
    3: {  # 't'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 3,  # 'b'
        26: 2,  # 'c'
        17: 1,  # 'd'
        1: 3,  # 'e'
        27: 2,  # 'f'
        12: 1,  # 'g'
        20: 3,  # 'h'
        9: 3,  # 'i'
        22: 3,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        8: 3,  # 'o'
        23: 1,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 3,  # 'v'
        62: 0,  # 'x'
        16: 3,  # 'y'
        11: 1,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 2,  # ''
        25: 3,  # ''
        24: 3,  # ''
        31: 3,  # ''
        29: 3,  # ''
        42: 3,  # ''
        56: 2,  # ''
    },
    21: {  # 'u'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 1,  # 'a'
        18: 2,  # 'b'
        26: 2,  # 'c'
        17: 3,  # 'd'
        1: 2,  # 'e'
        27: 1,  # 'f'
        12: 3,  # 'g'
        20: 2,  # 'h'
        9: 2,  # 'i'
        22: 2,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 1,  # 'o'
        23: 2,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 1,  # 'u'
        19: 3,  # 'v'
        62: 1,  # 'x'
        16: 1,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 2,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 0,  # ''
        31: 1,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    19: {  # 'v'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 2,  # 'b'
        26: 1,  # 'c'
        17: 1,  # 'd'
        1: 3,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 1,  # 'h'
        9: 3,  # 'i'
        22: 1,  # 'j'
        7: 1,  # 'k'
        6: 1,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        8: 3,  # 'o'
        23: 1,  # 'p'
        10: 1,  # 'r'
        5: 2,  # 's'
        3: 2,  # 't'
        21: 2,  # 'u'
        19: 2,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 1,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 2,  # ''
        25: 2,  # ''
        24: 2,  # ''
        31: 1,  # ''
        29: 2,  # ''
        42: 1,  # ''
        56: 1,  # ''
    },
    62: {  # 'x'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 1,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 0,  # 'd'
        1: 1,  # 'e'
        27: 1,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 1,  # 'i'
        22: 0,  # 'j'
        7: 1,  # 'k'
        6: 1,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        8: 1,  # 'o'
        23: 1,  # 'p'
        10: 1,  # 'r'
        5: 1,  # 's'
        3: 1,  # 't'
        21: 1,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 0,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 1,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 1,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    16: {  # 'y'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 2,  # 'b'
        26: 1,  # 'c'
        17: 1,  # 'd'
        1: 3,  # 'e'
        27: 2,  # 'f'
        12: 2,  # 'g'
        20: 2,  # 'h'
        9: 3,  # 'i'
        22: 2,  # 'j'
        7: 2,  # 'k'
        6: 2,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        8: 3,  # 'o'
        23: 2,  # 'p'
        10: 2,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 3,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 2,  # ''
        25: 2,  # ''
        24: 3,  # ''
        31: 2,  # ''
        29: 2,  # ''
        42: 1,  # ''
        56: 2,  # ''
    },
    11: {  # 'z'
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 3,  # 'a'
        18: 2,  # 'b'
        26: 1,  # 'c'
        17: 3,  # 'd'
        1: 3,  # 'e'
        27: 1,  # 'f'
        12: 2,  # 'g'
        20: 2,  # 'h'
        9: 3,  # 'i'
        22: 1,  # 'j'
        7: 3,  # 'k'
        6: 2,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 3,  # 'o'
        23: 1,  # 'p'
        10: 2,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 3,  # 'u'
        19: 2,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 3,  # ''
        15: 3,  # ''
        30: 3,  # ''
        25: 3,  # ''
        24: 3,  # ''
        31: 2,  # ''
        29: 3,  # ''
        42: 2,  # ''
        56: 1,  # ''
    },
    51: {  # ''
        28: 0,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 0,  # 'E'
        50: 1,  # 'F'
        49: 2,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 2,  # 'L'
        34: 1,  # 'M'
        35: 2,  # 'N'
        47: 0,  # 'O'
        46: 1,  # 'P'
        43: 2,  # 'R'
        33: 2,  # 'S'
        37: 1,  # 'T'
        57: 0,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 1,  # 'Z'
        2: 0,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 1,  # 'd'
        1: 0,  # 'e'
        27: 0,  # 'f'
        12: 1,  # 'g'
        20: 1,  # 'h'
        9: 0,  # 'i'
        22: 1,  # 'j'
        7: 1,  # 'k'
        6: 2,  # 'l'
        13: 2,  # 'm'
        4: 0,  # 'n'
        8: 0,  # 'o'
        23: 1,  # 'p'
        10: 1,  # 'r'
        5: 1,  # 's'
        3: 1,  # 't'
        21: 0,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 1,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 1,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    44: {  # ''
        28: 0,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 1,  # 'E'
        50: 0,  # 'F'
        49: 2,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 2,  # 'L'
        34: 1,  # 'M'
        35: 2,  # 'N'
        47: 0,  # 'O'
        46: 1,  # 'P'
        43: 2,  # 'R'
        33: 2,  # 'S'
        37: 2,  # 'T'
        57: 0,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 1,  # 'Z'
        2: 0,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 1,  # 'd'
        1: 0,  # 'e'
        27: 0,  # 'f'
        12: 1,  # 'g'
        20: 1,  # 'h'
        9: 0,  # 'i'
        22: 1,  # 'j'
        7: 1,  # 'k'
        6: 2,  # 'l'
        13: 1,  # 'm'
        4: 2,  # 'n'
        8: 0,  # 'o'
        23: 1,  # 'p'
        10: 2,  # 'r'
        5: 3,  # 's'
        3: 1,  # 't'
        21: 0,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 0,  # 'z'
        51: 0,  # ''
        44: 1,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    61: {  # ''
        28: 0,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 0,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 1,  # 'J'
        36: 0,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 0,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 0,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 1,  # 'Z'
        2: 0,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 0,  # 'e'
        27: 0,  # 'f'
        12: 2,  # 'g'
        20: 0,  # 'h'
        9: 0,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 0,  # 'l'
        13: 1,  # 'm'
        4: 0,  # 'n'
        8: 0,  # 'o'
        23: 0,  # 'p'
        10: 1,  # 'r'
        5: 0,  # 's'
        3: 1,  # 't'
        21: 0,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 1,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    58: {  # ''
        28: 1,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 0,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 1,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 2,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 0,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 0,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 1,  # 'Z'
        2: 0,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 1,  # 'd'
        1: 0,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 2,  # 'h'
        9: 0,  # 'i'
        22: 0,  # 'j'
        7: 1,  # 'k'
        6: 1,  # 'l'
        13: 0,  # 'm'
        4: 1,  # 'n'
        8: 0,  # 'o'
        23: 1,  # 'p'
        10: 1,  # 'r'
        5: 1,  # 's'
        3: 0,  # 't'
        21: 0,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 1,  # 'z'
        51: 0,  # ''
        44: 1,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    59: {  # ''
        28: 0,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 0,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 0,  # 'O'
        46: 1,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 0,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 1,  # 'Z'
        2: 0,  # 'a'
        18: 0,  # 'b'
        26: 1,  # 'c'
        17: 1,  # 'd'
        1: 0,  # 'e'
        27: 0,  # 'f'
        12: 0,  # 'g'
        20: 0,  # 'h'
        9: 0,  # 'i'
        22: 0,  # 'j'
        7: 1,  # 'k'
        6: 1,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        8: 0,  # 'o'
        23: 0,  # 'p'
        10: 2,  # 'r'
        5: 1,  # 's'
        3: 1,  # 't'
        21: 0,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 1,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    60: {  # ''
        28: 0,  # 'A'
        40: 1,  # 'B'
        54: 1,  # 'C'
        45: 1,  # 'D'
        32: 0,  # 'E'
        50: 1,  # 'F'
        49: 1,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 0,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 1,  # 'Z'
        2: 0,  # 'a'
        18: 0,  # 'b'
        26: 0,  # 'c'
        17: 0,  # 'd'
        1: 0,  # 'e'
        27: 0,  # 'f'
        12: 2,  # 'g'
        20: 0,  # 'h'
        9: 0,  # 'i'
        22: 2,  # 'j'
        7: 0,  # 'k'
        6: 0,  # 'l'
        13: 0,  # 'm'
        4: 1,  # 'n'
        8: 0,  # 'o'
        23: 0,  # 'p'
        10: 1,  # 'r'
        5: 1,  # 's'
        3: 1,  # 't'
        21: 0,  # 'u'
        19: 0,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 0,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    63: {  # ''
        28: 0,  # 'A'
        40: 1,  # 'B'
        54: 0,  # 'C'
        45: 1,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 1,  # 'G'
        38: 1,  # 'H'
        39: 0,  # 'I'
        53: 1,  # 'J'
        36: 1,  # 'K'
        41: 1,  # 'L'
        34: 1,  # 'M'
        35: 1,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 1,  # 'R'
        33: 1,  # 'S'
        37: 1,  # 'T'
        57: 0,  # 'U'
        48: 1,  # 'V'
        55: 0,  # 'Y'
        52: 1,  # 'Z'
        2: 0,  # 'a'
        18: 1,  # 'b'
        26: 0,  # 'c'
        17: 1,  # 'd'
        1: 0,  # 'e'
        27: 0,  # 'f'
        12: 1,  # 'g'
        20: 0,  # 'h'
        9: 0,  # 'i'
        22: 0,  # 'j'
        7: 0,  # 'k'
        6: 1,  # 'l'
        13: 0,  # 'm'
        4: 1,  # 'n'
        8: 0,  # 'o'
        23: 0,  # 'p'
        10: 1,  # 'r'
        5: 1,  # 's'
        3: 1,  # 't'
        21: 0,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 1,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    14: {  # ''
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 1,  # 'a'
        18: 3,  # 'b'
        26: 3,  # 'c'
        17: 3,  # 'd'
        1: 1,  # 'e'
        27: 2,  # 'f'
        12: 3,  # 'g'
        20: 2,  # 'h'
        9: 2,  # 'i'
        22: 3,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 1,  # 'o'
        23: 2,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 2,  # 'u'
        19: 3,  # 'v'
        62: 0,  # 'x'
        16: 1,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 1,  # ''
        15: 2,  # ''
        30: 1,  # ''
        25: 0,  # ''
        24: 1,  # ''
        31: 0,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    15: {  # ''
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 1,  # 'a'
        18: 3,  # 'b'
        26: 2,  # 'c'
        17: 3,  # 'd'
        1: 1,  # 'e'
        27: 1,  # 'f'
        12: 3,  # 'g'
        20: 3,  # 'h'
        9: 2,  # 'i'
        22: 2,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 1,  # 'o'
        23: 3,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 0,  # 'u'
        19: 3,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 1,  # ''
        15: 1,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    30: {  # ''
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 0,  # 'a'
        18: 1,  # 'b'
        26: 2,  # 'c'
        17: 1,  # 'd'
        1: 0,  # 'e'
        27: 1,  # 'f'
        12: 3,  # 'g'
        20: 0,  # 'h'
        9: 0,  # 'i'
        22: 1,  # 'j'
        7: 1,  # 'k'
        6: 2,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        8: 0,  # 'o'
        23: 1,  # 'p'
        10: 3,  # 'r'
        5: 2,  # 's'
        3: 3,  # 't'
        21: 0,  # 'u'
        19: 3,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    25: {  # ''
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 2,  # 'a'
        18: 3,  # 'b'
        26: 2,  # 'c'
        17: 3,  # 'd'
        1: 1,  # 'e'
        27: 2,  # 'f'
        12: 2,  # 'g'
        20: 2,  # 'h'
        9: 2,  # 'i'
        22: 2,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        8: 1,  # 'o'
        23: 2,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 1,  # 'u'
        19: 2,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 1,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 0,  # ''
        24: 1,  # ''
        31: 1,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    24: {  # ''
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 0,  # 'a'
        18: 3,  # 'b'
        26: 1,  # 'c'
        17: 2,  # 'd'
        1: 0,  # 'e'
        27: 1,  # 'f'
        12: 2,  # 'g'
        20: 1,  # 'h'
        9: 0,  # 'i'
        22: 1,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        8: 0,  # 'o'
        23: 2,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 3,  # 't'
        21: 0,  # 'u'
        19: 3,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 3,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    31: {  # ''
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 1,  # 'a'
        18: 1,  # 'b'
        26: 2,  # 'c'
        17: 1,  # 'd'
        1: 1,  # 'e'
        27: 2,  # 'f'
        12: 3,  # 'g'
        20: 1,  # 'h'
        9: 1,  # 'i'
        22: 3,  # 'j'
        7: 1,  # 'k'
        6: 3,  # 'l'
        13: 1,  # 'm'
        4: 2,  # 'n'
        8: 0,  # 'o'
        23: 1,  # 'p'
        10: 3,  # 'r'
        5: 3,  # 's'
        3: 2,  # 't'
        21: 1,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 1,  # ''
        15: 1,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    29: {  # ''
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 1,  # 'a'
        18: 1,  # 'b'
        26: 1,  # 'c'
        17: 2,  # 'd'
        1: 1,  # 'e'
        27: 1,  # 'f'
        12: 3,  # 'g'
        20: 2,  # 'h'
        9: 1,  # 'i'
        22: 1,  # 'j'
        7: 3,  # 'k'
        6: 3,  # 'l'
        13: 1,  # 'm'
        4: 3,  # 'n'
        8: 0,  # 'o'
        23: 1,  # 'p'
        10: 2,  # 'r'
        5: 2,  # 's'
        3: 2,  # 't'
        21: 0,  # 'u'
        19: 2,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 1,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    42: {  # ''
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 1,  # 'a'
        18: 2,  # 'b'
        26: 1,  # 'c'
        17: 2,  # 'd'
        1: 1,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 1,  # 'h'
        9: 1,  # 'i'
        22: 1,  # 'j'
        7: 2,  # 'k'
        6: 3,  # 'l'
        13: 1,  # 'm'
        4: 2,  # 'n'
        8: 1,  # 'o'
        23: 1,  # 'p'
        10: 2,  # 'r'
        5: 2,  # 's'
        3: 2,  # 't'
        21: 1,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 1,  # ''
        30: 1,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 1,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
    56: {  # ''
        28: 0,  # 'A'
        40: 0,  # 'B'
        54: 0,  # 'C'
        45: 0,  # 'D'
        32: 0,  # 'E'
        50: 0,  # 'F'
        49: 0,  # 'G'
        38: 0,  # 'H'
        39: 0,  # 'I'
        53: 0,  # 'J'
        36: 0,  # 'K'
        41: 0,  # 'L'
        34: 0,  # 'M'
        35: 0,  # 'N'
        47: 0,  # 'O'
        46: 0,  # 'P'
        43: 0,  # 'R'
        33: 0,  # 'S'
        37: 0,  # 'T'
        57: 0,  # 'U'
        48: 0,  # 'V'
        55: 0,  # 'Y'
        52: 0,  # 'Z'
        2: 1,  # 'a'
        18: 1,  # 'b'
        26: 0,  # 'c'
        17: 1,  # 'd'
        1: 1,  # 'e'
        27: 1,  # 'f'
        12: 1,  # 'g'
        20: 1,  # 'h'
        9: 1,  # 'i'
        22: 1,  # 'j'
        7: 1,  # 'k'
        6: 1,  # 'l'
        13: 0,  # 'm'
        4: 2,  # 'n'
        8: 0,  # 'o'
        23: 0,  # 'p'
        10: 1,  # 'r'
        5: 1,  # 's'
        3: 1,  # 't'
        21: 0,  # 'u'
        19: 1,  # 'v'
        62: 0,  # 'x'
        16: 0,  # 'y'
        11: 2,  # 'z'
        51: 0,  # ''
        44: 0,  # ''
        61: 0,  # ''
        58: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
        63: 0,  # ''
        14: 0,  # ''
        15: 0,  # ''
        30: 0,  # ''
        25: 0,  # ''
        24: 0,  # ''
        31: 0,  # ''
        29: 0,  # ''
        42: 0,  # ''
        56: 0,  # ''
    },
}

# 255: Undefined characters that did not exist in training text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9
# 251: Control characters

# Character Mapping Table(s):
WINDOWS_1250_HUNGARIAN_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 28,  # 'A'
     66: 40,  # 'B'
     67: 54,  # 'C'
     68: 45,  # 'D'
     69: 32,  # 'E'
     70: 50,  # 'F'
     71: 49,  # 'G'
     72: 38,  # 'H'
     73: 39,  # 'I'
     74: 53,  # 'J'
     75: 36,  # 'K'
     76: 41,  # 'L'
     77: 34,  # 'M'
     78: 35,  # 'N'
     79: 47,  # 'O'
     80: 46,  # 'P'
     81: 72,  # 'Q'
     82: 43,  # 'R'
     83: 33,  # 'S'
     84: 37,  # 'T'
     85: 57,  # 'U'
     86: 48,  # 'V'
     87: 64,  # 'W'
     88: 68,  # 'X'
     89: 55,  # 'Y'
     90: 52,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 2,  # 'a'
     98: 18,  # 'b'
     99: 26,  # 'c'
     100: 17,  # 'd'
     101: 1,  # 'e'
     102: 27,  # 'f'
     103: 12,  # 'g'
     104: 20,  # 'h'
     105: 9,  # 'i'
     106: 22,  # 'j'
     107: 7,  # 'k'
     108: 6,  # 'l'
     109: 13,  # 'm'
     110: 4,  # 'n'
     111: 8,  # 'o'
     112: 23,  # 'p'
     113: 67,  # 'q'
     114: 10,  # 'r'
     115: 5,  # 's'
     116: 3,  # 't'
     117: 21,  # 'u'
     118: 19,  # 'v'
     119: 65,  # 'w'
     120: 62,  # 'x'
     121: 16,  # 'y'
     122: 11,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 161,  # ''
     129: 162,  # None
     130: 163,  # ''
     131: 164,  # None
     132: 165,  # ''
     133: 166,  # ''
     134: 167,  # ''
     135: 168,  # ''
     136: 169,  # None
     137: 170,  # ''
     138: 171,  # ''
     139: 172,  # ''
     140: 173,  # ''
     141: 174,  # ''
     142: 175,  # ''
     143: 176,  # ''
     144: 177,  # None
     145: 178,  # ''
     146: 179,  # ''
     147: 180,  # ''
     148: 78,  # ''
     149: 181,  # ''
     150: 69,  # ''
     151: 182,  # ''
     152: 183,  # None
     153: 184,  # ''
     154: 185,  # ''
     155: 186,  # ''
     156: 187,  # ''
     157: 188,  # ''
     158: 189,  # ''
     159: 190,  # ''
     160: 191,  # '\xa0'
     161: 192,  # ''
     162: 193,  # ''
     163: 194,  # ''
     164: 195,  # ''
     165: 196,  # ''
     166: 197,  # ''
     167: 76,  # ''
     168: 198,  # ''
     169: 199,  # ''
     170: 200,  # ''
     171: 201,  # ''
     172: 202,  # ''
     173: 203,  # '\xad'
     174: 204,  # ''
     175: 205,  # ''
     176: 81,  # ''
     177: 206,  # ''
     178: 207,  # ''
     179: 208,  # ''
     180: 209,  # ''
     181: 210,  # ''
     182: 211,  # ''
     183: 212,  # ''
     184: 213,  # ''
     185: 214,  # ''
     186: 215,  # ''
     187: 216,  # ''
     188: 217,  # ''
     189: 218,  # ''
     190: 219,  # ''
     191: 220,  # ''
     192: 221,  # ''
     193: 51,  # ''
     194: 83,  # ''
     195: 222,  # ''
     196: 80,  # ''
     197: 223,  # ''
     198: 224,  # ''
     199: 225,  # ''
     200: 226,  # ''
     201: 44,  # ''
     202: 227,  # ''
     203: 228,  # ''
     204: 229,  # ''
     205: 61,  # ''
     206: 230,  # ''
     207: 231,  # ''
     208: 232,  # ''
     209: 233,  # ''
     210: 234,  # ''
     211: 58,  # ''
     212: 235,  # ''
     213: 66,  # ''
     214: 59,  # ''
     215: 236,  # ''
     216: 237,  # ''
     217: 238,  # ''
     218: 60,  # ''
     219: 70,  # ''
     220: 63,  # ''
     221: 239,  # ''
     222: 240,  # ''
     223: 241,  # ''
     224: 84,  # ''
     225: 14,  # ''
     226: 75,  # ''
     227: 242,  # ''
     228: 71,  # ''
     229: 82,  # ''
     230: 243,  # ''
     231: 73,  # ''
     232: 244,  # ''
     233: 15,  # ''
     234: 85,  # ''
     235: 79,  # ''
     236: 86,  # ''
     237: 30,  # ''
     238: 77,  # ''
     239: 87,  # ''
     240: 245,  # ''
     241: 246,  # ''
     242: 247,  # ''
     243: 25,  # ''
     244: 74,  # ''
     245: 42,  # ''
     246: 24,  # ''
     247: 248,  # ''
     248: 249,  # ''
     249: 250,  # ''
     250: 31,  # ''
     251: 56,  # ''
     252: 29,  # ''
     253: 251,  # ''
     254: 252,  # ''
     255: 253,  # ''
}

WINDOWS_1250_HUNGARIAN_MODEL = SingleByteCharSetModel(charset_name='windows-1250',
                                                      language='Hungarian',
                                                      char_to_order_map=WINDOWS_1250_HUNGARIAN_CHAR_TO_ORDER,
                                                      language_model=HUNGARIAN_LANG_MODEL,
                                                      typical_positive_ratio=0.947368,
                                                      keep_ascii_letters=True,
                                                      alphabet='ABCDEFGHIJKLMNOPRSTUVZabcdefghijklmnoprstuvz')

ISO_8859_2_HUNGARIAN_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 28,  # 'A'
     66: 40,  # 'B'
     67: 54,  # 'C'
     68: 45,  # 'D'
     69: 32,  # 'E'
     70: 50,  # 'F'
     71: 49,  # 'G'
     72: 38,  # 'H'
     73: 39,  # 'I'
     74: 53,  # 'J'
     75: 36,  # 'K'
     76: 41,  # 'L'
     77: 34,  # 'M'
     78: 35,  # 'N'
     79: 47,  # 'O'
     80: 46,  # 'P'
     81: 71,  # 'Q'
     82: 43,  # 'R'
     83: 33,  # 'S'
     84: 37,  # 'T'
     85: 57,  # 'U'
     86: 48,  # 'V'
     87: 64,  # 'W'
     88: 68,  # 'X'
     89: 55,  # 'Y'
     90: 52,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 2,  # 'a'
     98: 18,  # 'b'
     99: 26,  # 'c'
     100: 17,  # 'd'
     101: 1,  # 'e'
     102: 27,  # 'f'
     103: 12,  # 'g'
     104: 20,  # 'h'
     105: 9,  # 'i'
     106: 22,  # 'j'
     107: 7,  # 'k'
     108: 6,  # 'l'
     109: 13,  # 'm'
     110: 4,  # 'n'
     111: 8,  # 'o'
     112: 23,  # 'p'
     113: 67,  # 'q'
     114: 10,  # 'r'
     115: 5,  # 's'
     116: 3,  # 't'
     117: 21,  # 'u'
     118: 19,  # 'v'
     119: 65,  # 'w'
     120: 62,  # 'x'
     121: 16,  # 'y'
     122: 11,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 159,  # '\x80'
     129: 160,  # '\x81'
     130: 161,  # '\x82'
     131: 162,  # '\x83'
     132: 163,  # '\x84'
     133: 164,  # '\x85'
     134: 165,  # '\x86'
     135: 166,  # '\x87'
     136: 167,  # '\x88'
     137: 168,  # '\x89'
     138: 169,  # '\x8a'
     139: 170,  # '\x8b'
     140: 171,  # '\x8c'
     141: 172,  # '\x8d'
     142: 173,  # '\x8e'
     143: 174,  # '\x8f'
     144: 175,  # '\x90'
     145: 176,  # '\x91'
     146: 177,  # '\x92'
     147: 178,  # '\x93'
     148: 179,  # '\x94'
     149: 180,  # '\x95'
     150: 181,  # '\x96'
     151: 182,  # '\x97'
     152: 183,  # '\x98'
     153: 184,  # '\x99'
     154: 185,  # '\x9a'
     155: 186,  # '\x9b'
     156: 187,  # '\x9c'
     157: 188,  # '\x9d'
     158: 189,  # '\x9e'
     159: 190,  # '\x9f'
     160: 191,  # '\xa0'
     161: 192,  # ''
     162: 193,  # ''
     163: 194,  # ''
     164: 195,  # ''
     165: 196,  # ''
     166: 197,  # ''
     167: 75,  # ''
     168: 198,  # ''
     169: 199,  # ''
     170: 200,  # ''
     171: 201,  # ''
     172: 202,  # ''
     173: 203,  # '\xad'
     174: 204,  # ''
     175: 205,  # ''
     176: 79,  # ''
     177: 206,  # ''
     178: 207,  # ''
     179: 208,  # ''
     180: 209,  # ''
     181: 210,  # ''
     182: 211,  # ''
     183: 212,  # ''
     184: 213,  # ''
     185: 214,  # ''
     186: 215,  # ''
     187: 216,  # ''
     188: 217,  # ''
     189: 218,  # ''
     190: 219,  # ''
     191: 220,  # ''
     192: 221,  # ''
     193: 51,  # ''
     194: 81,  # ''
     195: 222,  # ''
     196: 78,  # ''
     197: 223,  # ''
     198: 224,  # ''
     199: 225,  # ''
     200: 226,  # ''
     201: 44,  # ''
     202: 227,  # ''
     203: 228,  # ''
     204: 229,  # ''
     205: 61,  # ''
     206: 230,  # ''
     207: 231,  # ''
     208: 232,  # ''
     209: 233,  # ''
     210: 234,  # ''
     211: 58,  # ''
     212: 235,  # ''
     213: 66,  # ''
     214: 59,  # ''
     215: 236,  # ''
     216: 237,  # ''
     217: 238,  # ''
     218: 60,  # ''
     219: 69,  # ''
     220: 63,  # ''
     221: 239,  # ''
     222: 240,  # ''
     223: 241,  # ''
     224: 82,  # ''
     225: 14,  # ''
     226: 74,  # ''
     227: 242,  # ''
     228: 70,  # ''
     229: 80,  # ''
     230: 243,  # ''
     231: 72,  # ''
     232: 244,  # ''
     233: 15,  # ''
     234: 83,  # ''
     235: 77,  # ''
     236: 84,  # ''
     237: 30,  # ''
     238: 76,  # ''
     239: 85,  # ''
     240: 245,  # ''
     241: 246,  # ''
     242: 247,  # ''
     243: 25,  # ''
     244: 73,  # ''
     245: 42,  # ''
     246: 24,  # ''
     247: 248,  # ''
     248: 249,  # ''
     249: 250,  # ''
     250: 31,  # ''
     251: 56,  # ''
     252: 29,  # ''
     253: 251,  # ''
     254: 252,  # ''
     255: 253,  # ''
}

ISO_8859_2_HUNGARIAN_MODEL = SingleByteCharSetModel(charset_name='ISO-8859-2',
                                                    language='Hungarian',
                                                    char_to_order_map=ISO_8859_2_HUNGARIAN_CHAR_TO_ORDER,
                                                    language_model=HUNGARIAN_LANG_MODEL,
                                                    typical_positive_ratio=0.947368,
                                                    keep_ascii_letters=True,
                                                    alphabet='ABCDEFGHIJKLMNOPRSTUVZabcdefghijklmnoprstuvz')





############################################################
### File: langrussianmodel.py
############################################################
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

RUSSIAN_LANG_MODEL = {
    37: {  # ''
        37: 0,  # ''
        44: 1,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 1,  # ''
        48: 1,  # ''
        56: 1,  # ''
        51: 1,  # ''
        42: 1,  # ''
        60: 1,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 2,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 1,  # ''
        55: 1,  # ''
        58: 1,  # ''
        50: 1,  # ''
        57: 1,  # ''
        63: 1,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 1,  # ''
        43: 1,  # ''
        3: 1,  # ''
        21: 2,  # ''
        10: 2,  # ''
        19: 2,  # ''
        13: 2,  # ''
        2: 0,  # ''
        24: 1,  # ''
        20: 1,  # ''
        4: 0,  # ''
        23: 1,  # ''
        11: 2,  # ''
        8: 3,  # ''
        12: 2,  # ''
        5: 2,  # ''
        1: 0,  # ''
        15: 2,  # ''
        9: 2,  # ''
        7: 2,  # ''
        6: 2,  # ''
        14: 2,  # ''
        39: 2,  # ''
        26: 2,  # ''
        28: 0,  # ''
        22: 1,  # ''
        25: 2,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    44: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 0,  # ''
        45: 1,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 1,  # ''
        3: 2,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 1,  # ''
        2: 3,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 2,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 2,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 2,  # ''
        17: 1,  # ''
        30: 2,  # ''
        27: 1,  # ''
        16: 1,  # ''
    },
    33: {  # ''
        37: 2,  # ''
        44: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        41: 1,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 1,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 1,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 1,  # ''
        3: 2,  # ''
        21: 1,  # ''
        10: 1,  # ''
        19: 1,  # ''
        13: 2,  # ''
        2: 3,  # ''
        24: 0,  # ''
        20: 2,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 1,  # ''
        8: 2,  # ''
        12: 2,  # ''
        5: 2,  # ''
        1: 3,  # ''
        15: 2,  # ''
        9: 2,  # ''
        7: 3,  # ''
        6: 2,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 1,  # ''
        28: 1,  # ''
        22: 2,  # ''
        25: 1,  # ''
        29: 0,  # ''
        54: 1,  # ''
        18: 3,  # ''
        17: 1,  # ''
        30: 2,  # ''
        27: 0,  # ''
        16: 1,  # ''
    },
    46: {  # ''
        37: 1,  # ''
        44: 1,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 1,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 1,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 0,  # ''
        10: 1,  # ''
        19: 0,  # ''
        13: 2,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 2,  # ''
        12: 1,  # ''
        5: 1,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 2,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 1,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 0,  # ''
    },
    41: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 2,  # ''
        56: 1,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 0,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 0,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 1,  # ''
        50: 1,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 1,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 1,  # ''
        3: 3,  # ''
        21: 0,  # ''
        10: 2,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 3,  # ''
        20: 1,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 2,  # ''
        12: 1,  # ''
        5: 1,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 2,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 1,  # ''
        17: 1,  # ''
        30: 2,  # ''
        27: 1,  # ''
        16: 1,  # ''
    },
    48: {  # ''
        37: 1,  # ''
        44: 1,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 1,  # ''
        48: 1,  # ''
        56: 1,  # ''
        51: 1,  # ''
        42: 1,  # ''
        60: 1,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 2,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 2,  # ''
        32: 2,  # ''
        40: 1,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 1,  # ''
        58: 1,  # ''
        50: 1,  # ''
        57: 1,  # ''
        63: 1,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 1,  # ''
        3: 0,  # ''
        21: 0,  # ''
        10: 2,  # ''
        19: 2,  # ''
        13: 2,  # ''
        2: 2,  # ''
        24: 1,  # ''
        20: 1,  # ''
        4: 0,  # ''
        23: 2,  # ''
        11: 1,  # ''
        8: 2,  # ''
        12: 2,  # ''
        5: 1,  # ''
        1: 0,  # ''
        15: 1,  # ''
        9: 1,  # ''
        7: 3,  # ''
        6: 0,  # ''
        14: 0,  # ''
        39: 1,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 1,  # ''
        29: 2,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 1,  # ''
        16: 0,  # ''
    },
    56: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 1,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 1,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 1,  # ''
        10: 0,  # ''
        19: 1,  # ''
        13: 1,  # ''
        2: 2,  # ''
        24: 1,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 0,  # ''
        12: 1,  # ''
        5: 0,  # ''
        1: 2,  # ''
        15: 0,  # ''
        9: 1,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 2,  # ''
        16: 0,  # ''
    },
    51: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 1,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 0,  # ''
        45: 1,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 1,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 1,  # ''
        10: 2,  # ''
        19: 0,  # ''
        13: 2,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 1,  # ''
        12: 1,  # ''
        5: 2,  # ''
        1: 2,  # ''
        15: 0,  # ''
        9: 1,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 1,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 1,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 1,  # ''
    },
    42: {  # ''
        37: 1,  # ''
        44: 1,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 1,  # ''
        48: 2,  # ''
        56: 1,  # ''
        51: 1,  # ''
        42: 1,  # ''
        60: 1,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 1,  # ''
        32: 2,  # ''
        40: 1,  # ''
        52: 0,  # ''
        53: 1,  # ''
        55: 1,  # ''
        58: 1,  # ''
        50: 1,  # ''
        57: 0,  # ''
        63: 1,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 1,  # ''
        43: 1,  # ''
        3: 1,  # ''
        21: 2,  # ''
        10: 2,  # ''
        19: 2,  # ''
        13: 2,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 2,  # ''
        4: 1,  # ''
        23: 0,  # ''
        11: 1,  # ''
        8: 2,  # ''
        12: 2,  # ''
        5: 2,  # ''
        1: 1,  # ''
        15: 1,  # ''
        9: 2,  # ''
        7: 2,  # ''
        6: 2,  # ''
        14: 1,  # ''
        39: 1,  # ''
        26: 2,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 1,  # ''
        29: 1,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 1,  # ''
        16: 0,  # ''
    },
    60: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 1,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 1,  # ''
        58: 1,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 0,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 1,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 0,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 0,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 2,  # ''
        15: 0,  # ''
        9: 0,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 0,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    36: {  # ''
        37: 2,  # ''
        44: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 1,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 1,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 2,  # ''
        35: 1,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 1,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 0,  # ''
        10: 1,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 2,  # ''
        12: 0,  # ''
        5: 1,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 2,  # ''
        7: 2,  # ''
        6: 2,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 1,  # ''
        17: 1,  # ''
        30: 2,  # ''
        27: 1,  # ''
        16: 0,  # ''
    },
    49: {  # ''
        37: 2,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 1,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 1,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 0,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 0,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 1,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 1,  # ''
        47: 0,  # ''
        59: 1,  # ''
        43: 1,  # ''
        3: 2,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 1,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 1,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 1,  # ''
        12: 0,  # ''
        5: 1,  # ''
        1: 2,  # ''
        15: 0,  # ''
        9: 0,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 1,  # ''
        17: 1,  # ''
        30: 2,  # ''
        27: 2,  # ''
        16: 1,  # ''
    },
    38: {  # ''
        37: 1,  # ''
        44: 1,  # ''
        33: 1,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 1,  # ''
        55: 1,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 0,  # ''
        47: 1,  # ''
        59: 0,  # ''
        43: 1,  # ''
        3: 3,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 1,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 1,  # ''
        12: 1,  # ''
        5: 2,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 1,  # ''
        7: 1,  # ''
        6: 0,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 3,  # ''
        17: 1,  # ''
        30: 2,  # ''
        27: 1,  # ''
        16: 1,  # ''
    },
    31: {  # ''
        37: 2,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 1,  # ''
        41: 1,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 1,  # ''
        42: 2,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 0,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 1,  # ''
        55: 1,  # ''
        58: 1,  # ''
        50: 1,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 1,  # ''
        47: 1,  # ''
        59: 0,  # ''
        43: 1,  # ''
        3: 3,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 3,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 0,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 1,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 3,  # ''
        39: 0,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 1,  # ''
        17: 2,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 1,  # ''
    },
    34: {  # ''
        37: 0,  # ''
        44: 1,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 2,  # ''
        48: 1,  # ''
        56: 1,  # ''
        51: 1,  # ''
        42: 1,  # ''
        60: 1,  # ''
        36: 1,  # ''
        49: 2,  # ''
        38: 1,  # ''
        31: 2,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 2,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 1,  # ''
        55: 1,  # ''
        58: 0,  # ''
        50: 1,  # ''
        57: 1,  # ''
        63: 1,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 1,  # ''
        3: 1,  # ''
        21: 2,  # ''
        10: 1,  # ''
        19: 2,  # ''
        13: 2,  # ''
        2: 0,  # ''
        24: 1,  # ''
        20: 1,  # ''
        4: 0,  # ''
        23: 1,  # ''
        11: 2,  # ''
        8: 2,  # ''
        12: 1,  # ''
        5: 3,  # ''
        1: 0,  # ''
        15: 2,  # ''
        9: 2,  # ''
        7: 2,  # ''
        6: 2,  # ''
        14: 1,  # ''
        39: 1,  # ''
        26: 2,  # ''
        28: 1,  # ''
        22: 2,  # ''
        25: 2,  # ''
        29: 1,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    35: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 1,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 2,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 1,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 1,  # ''
        3: 2,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 2,  # ''
        12: 0,  # ''
        5: 1,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 3,  # ''
        7: 1,  # ''
        6: 1,  # ''
        14: 2,  # ''
        39: 1,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 1,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 1,  # ''
        17: 2,  # ''
        30: 1,  # ''
        27: 0,  # ''
        16: 2,  # ''
    },
    45: {  # ''
        37: 2,  # ''
        44: 1,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 1,  # ''
        48: 2,  # ''
        56: 1,  # ''
        51: 0,  # ''
        42: 2,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 2,  # ''
        35: 0,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 1,  # ''
        58: 1,  # ''
        50: 1,  # ''
        57: 1,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 1,  # ''
        47: 1,  # ''
        59: 1,  # ''
        43: 1,  # ''
        3: 3,  # ''
        21: 0,  # ''
        10: 1,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 1,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 0,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 1,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 2,  # ''
        17: 0,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 2,  # ''
    },
    32: {  # ''
        37: 1,  # ''
        44: 1,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 1,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 2,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 1,  # ''
        58: 1,  # ''
        50: 1,  # ''
        57: 1,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 1,  # ''
        47: 1,  # ''
        59: 1,  # ''
        43: 1,  # ''
        3: 2,  # ''
        21: 1,  # ''
        10: 2,  # ''
        19: 1,  # ''
        13: 2,  # ''
        2: 3,  # ''
        24: 1,  # ''
        20: 1,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 2,  # ''
        8: 2,  # ''
        12: 2,  # ''
        5: 2,  # ''
        1: 2,  # ''
        15: 2,  # ''
        9: 2,  # ''
        7: 1,  # ''
        6: 3,  # ''
        14: 2,  # ''
        39: 1,  # ''
        26: 1,  # ''
        28: 1,  # ''
        22: 1,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 1,  # ''
        18: 1,  # ''
        17: 1,  # ''
        30: 2,  # ''
        27: 1,  # ''
        16: 1,  # ''
    },
    40: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 2,  # ''
        35: 0,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 1,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 1,  # ''
        47: 1,  # ''
        59: 1,  # ''
        43: 1,  # ''
        3: 3,  # ''
        21: 1,  # ''
        10: 2,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 3,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 1,  # ''
        8: 1,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 2,  # ''
        7: 1,  # ''
        6: 0,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 1,  # ''
        54: 0,  # ''
        18: 3,  # ''
        17: 1,  # ''
        30: 2,  # ''
        27: 1,  # ''
        16: 1,  # ''
    },
    52: {  # ''
        37: 1,  # ''
        44: 1,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 1,  # ''
        48: 1,  # ''
        56: 1,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 1,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 1,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 1,  # ''
        58: 0,  # ''
        50: 1,  # ''
        57: 1,  # ''
        63: 1,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 1,  # ''
        43: 0,  # ''
        3: 1,  # ''
        21: 2,  # ''
        10: 2,  # ''
        19: 1,  # ''
        13: 2,  # ''
        2: 1,  # ''
        24: 2,  # ''
        20: 2,  # ''
        4: 2,  # ''
        23: 1,  # ''
        11: 1,  # ''
        8: 2,  # ''
        12: 2,  # ''
        5: 1,  # ''
        1: 2,  # ''
        15: 1,  # ''
        9: 2,  # ''
        7: 2,  # ''
        6: 2,  # ''
        14: 0,  # ''
        39: 1,  # ''
        26: 1,  # ''
        28: 1,  # ''
        22: 2,  # ''
        25: 1,  # ''
        29: 1,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 2,  # ''
        27: 1,  # ''
        16: 0,  # ''
    },
    53: {  # ''
        37: 1,  # ''
        44: 1,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 1,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 1,  # ''
        35: 0,  # ''
        45: 1,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 2,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 2,  # ''
        15: 0,  # ''
        9: 2,  # ''
        7: 0,  # ''
        6: 1,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 1,  # ''
        30: 2,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    55: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 0,  # ''
        10: 2,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 2,  # ''
        12: 1,  # ''
        5: 0,  # ''
        1: 2,  # ''
        15: 0,  # ''
        9: 2,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 1,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 1,  # ''
        30: 1,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    58: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 1,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 1,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 1,  # ''
        21: 0,  # ''
        10: 1,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 0,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 0,  # ''
        15: 0,  # ''
        9: 0,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 1,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 1,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 1,  # ''
        16: 0,  # ''
    },
    50: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 0,  # ''
        35: 1,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 1,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 1,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 1,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 1,  # ''
        15: 0,  # ''
        9: 1,  # ''
        7: 0,  # ''
        6: 3,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 1,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    57: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 0,  # ''
        10: 1,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 1,  # ''
        23: 0,  # ''
        11: 1,  # ''
        8: 2,  # ''
        12: 1,  # ''
        5: 1,  # ''
        1: 2,  # ''
        15: 2,  # ''
        9: 1,  # ''
        7: 0,  # ''
        6: 2,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 1,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    63: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 1,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 1,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 1,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 1,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 0,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 1,  # ''
        15: 0,  # ''
        9: 0,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 1,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    62: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 1,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 0,  # ''
        35: 1,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 1,  # ''
        58: 1,  # ''
        50: 0,  # ''
        57: 1,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 0,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 0,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 0,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 0,  # ''
        15: 0,  # ''
        9: 0,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 0,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    61: {  # ''
        37: 0,  # ''
        44: 1,  # ''
        33: 1,  # ''
        46: 0,  # ''
        41: 1,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 0,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 1,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 1,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 1,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 1,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 1,  # ''
        43: 1,  # ''
        3: 0,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 0,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 0,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 0,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 0,  # ''
        15: 0,  # ''
        9: 0,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 0,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    47: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 1,  # ''
        46: 0,  # ''
        41: 1,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 1,  # ''
        36: 1,  # ''
        49: 1,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 0,  # ''
        35: 1,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 1,  # ''
        21: 1,  # ''
        10: 2,  # ''
        19: 1,  # ''
        13: 2,  # ''
        2: 0,  # ''
        24: 1,  # ''
        20: 0,  # ''
        4: 0,  # ''
        23: 2,  # ''
        11: 2,  # ''
        8: 2,  # ''
        12: 2,  # ''
        5: 2,  # ''
        1: 0,  # ''
        15: 1,  # ''
        9: 2,  # ''
        7: 1,  # ''
        6: 3,  # ''
        14: 1,  # ''
        39: 1,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 1,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    59: {  # ''
        37: 1,  # ''
        44: 1,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 1,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 1,  # ''
        32: 0,  # ''
        40: 1,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 1,  # ''
        57: 0,  # ''
        63: 1,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 0,  # ''
        21: 1,  # ''
        10: 0,  # ''
        19: 1,  # ''
        13: 1,  # ''
        2: 0,  # ''
        24: 1,  # ''
        20: 0,  # ''
        4: 0,  # ''
        23: 0,  # ''
        11: 1,  # ''
        8: 2,  # ''
        12: 1,  # ''
        5: 2,  # ''
        1: 0,  # ''
        15: 1,  # ''
        9: 1,  # ''
        7: 1,  # ''
        6: 0,  # ''
        14: 0,  # ''
        39: 0,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    43: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 1,  # ''
        46: 1,  # ''
        41: 0,  # ''
        48: 1,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 1,  # ''
        40: 1,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 1,  # ''
        58: 0,  # ''
        50: 1,  # ''
        57: 0,  # ''
        63: 1,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 1,  # ''
        43: 1,  # ''
        3: 0,  # ''
        21: 1,  # ''
        10: 1,  # ''
        19: 1,  # ''
        13: 1,  # ''
        2: 0,  # ''
        24: 0,  # ''
        20: 1,  # ''
        4: 0,  # ''
        23: 1,  # ''
        11: 1,  # ''
        8: 1,  # ''
        12: 1,  # ''
        5: 2,  # ''
        1: 0,  # ''
        15: 1,  # ''
        9: 1,  # ''
        7: 1,  # ''
        6: 0,  # ''
        14: 0,  # ''
        39: 0,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 1,  # ''
        29: 1,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    3: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 1,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 3,  # ''
        10: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        20: 3,  # ''
        4: 3,  # ''
        23: 3,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 2,  # ''
        15: 3,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 3,  # ''
        39: 2,  # ''
        26: 3,  # ''
        28: 3,  # ''
        22: 3,  # ''
        25: 3,  # ''
        29: 3,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 2,  # ''
        27: 3,  # ''
        16: 3,  # ''
    },
    21: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 1,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 2,  # ''
        10: 2,  # ''
        19: 1,  # ''
        13: 2,  # ''
        2: 3,  # ''
        24: 2,  # ''
        20: 1,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 2,  # ''
        8: 3,  # ''
        12: 2,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 1,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 2,  # ''
        14: 3,  # ''
        39: 0,  # ''
        26: 2,  # ''
        28: 1,  # ''
        22: 1,  # ''
        25: 2,  # ''
        29: 3,  # ''
        54: 2,  # ''
        18: 3,  # ''
        17: 2,  # ''
        30: 1,  # ''
        27: 2,  # ''
        16: 3,  # ''
    },
    10: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 2,  # ''
        10: 2,  # ''
        19: 2,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 1,  # ''
        20: 3,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 2,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 3,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 3,  # ''
        39: 1,  # ''
        26: 2,  # ''
        28: 2,  # ''
        22: 2,  # ''
        25: 3,  # ''
        29: 2,  # ''
        54: 2,  # ''
        18: 3,  # ''
        17: 3,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 3,  # ''
    },
    19: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 1,  # ''
        10: 2,  # ''
        19: 1,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 0,  # ''
        20: 1,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 2,  # ''
        8: 3,  # ''
        12: 2,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 3,  # ''
        7: 2,  # ''
        6: 2,  # ''
        14: 3,  # ''
        39: 1,  # ''
        26: 1,  # ''
        28: 1,  # ''
        22: 2,  # ''
        25: 1,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 1,  # ''
        17: 1,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 0,  # ''
    },
    13: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 2,  # ''
        10: 3,  # ''
        19: 2,  # ''
        13: 2,  # ''
        2: 3,  # ''
        24: 2,  # ''
        20: 2,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 2,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 2,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 3,  # ''
        39: 1,  # ''
        26: 2,  # ''
        28: 3,  # ''
        22: 2,  # ''
        25: 2,  # ''
        29: 1,  # ''
        54: 2,  # ''
        18: 3,  # ''
        17: 3,  # ''
        30: 1,  # ''
        27: 2,  # ''
        16: 3,  # ''
    },
    2: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 3,  # ''
        10: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        20: 3,  # ''
        4: 2,  # ''
        23: 3,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 3,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 2,  # ''
        39: 2,  # ''
        26: 3,  # ''
        28: 3,  # ''
        22: 3,  # ''
        25: 3,  # ''
        29: 3,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        27: 2,  # ''
        16: 3,  # ''
    },
    24: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 2,  # ''
        10: 1,  # ''
        19: 2,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 2,  # ''
        20: 1,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 2,  # ''
        8: 2,  # ''
        12: 1,  # ''
        5: 3,  # ''
        1: 2,  # ''
        15: 1,  # ''
        9: 2,  # ''
        7: 2,  # ''
        6: 1,  # ''
        14: 3,  # ''
        39: 1,  # ''
        26: 0,  # ''
        28: 1,  # ''
        22: 2,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 1,  # ''
        17: 2,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 1,  # ''
    },
    20: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 3,  # ''
        10: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 2,  # ''
        20: 2,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 3,  # ''
        7: 2,  # ''
        6: 2,  # ''
        14: 3,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 1,  # ''
        22: 2,  # ''
        25: 1,  # ''
        29: 0,  # ''
        54: 2,  # ''
        18: 3,  # ''
        17: 2,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 3,  # ''
    },
    4: {  # ''
        37: 1,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 1,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 3,  # ''
        10: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        20: 3,  # ''
        4: 3,  # ''
        23: 3,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 3,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 2,  # ''
        39: 2,  # ''
        26: 3,  # ''
        28: 3,  # ''
        22: 3,  # ''
        25: 3,  # ''
        29: 3,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 2,  # ''
        27: 3,  # ''
        16: 3,  # ''
    },
    23: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 1,  # ''
        21: 1,  # ''
        10: 1,  # ''
        19: 2,  # ''
        13: 3,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 2,  # ''
        4: 1,  # ''
        23: 0,  # ''
        11: 2,  # ''
        8: 2,  # ''
        12: 2,  # ''
        5: 3,  # ''
        1: 2,  # ''
        15: 1,  # ''
        9: 2,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 1,  # ''
        39: 2,  # ''
        26: 1,  # ''
        28: 2,  # ''
        22: 3,  # ''
        25: 2,  # ''
        29: 1,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 2,  # ''
    },
    11: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 1,  # ''
        10: 3,  # ''
        19: 1,  # ''
        13: 1,  # ''
        2: 3,  # ''
        24: 2,  # ''
        20: 2,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 2,  # ''
        8: 3,  # ''
        12: 1,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 3,  # ''
        39: 1,  # ''
        26: 2,  # ''
        28: 2,  # ''
        22: 1,  # ''
        25: 2,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 1,  # ''
        17: 1,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 1,  # ''
    },
    8: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 2,  # ''
        10: 2,  # ''
        19: 3,  # ''
        13: 2,  # ''
        2: 3,  # ''
        24: 3,  # ''
        20: 2,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 2,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 2,  # ''
        9: 1,  # ''
        7: 3,  # ''
        6: 2,  # ''
        14: 3,  # ''
        39: 2,  # ''
        26: 2,  # ''
        28: 1,  # ''
        22: 3,  # ''
        25: 2,  # ''
        29: 1,  # ''
        54: 0,  # ''
        18: 3,  # ''
        17: 3,  # ''
        30: 1,  # ''
        27: 3,  # ''
        16: 3,  # ''
    },
    12: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 2,  # ''
        10: 2,  # ''
        19: 2,  # ''
        13: 1,  # ''
        2: 3,  # ''
        24: 1,  # ''
        20: 1,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 2,  # ''
        8: 3,  # ''
        12: 2,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 2,  # ''
        9: 2,  # ''
        7: 3,  # ''
        6: 2,  # ''
        14: 3,  # ''
        39: 2,  # ''
        26: 2,  # ''
        28: 2,  # ''
        22: 2,  # ''
        25: 1,  # ''
        29: 1,  # ''
        54: 0,  # ''
        18: 3,  # ''
        17: 2,  # ''
        30: 2,  # ''
        27: 1,  # ''
        16: 3,  # ''
    },
    5: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 2,  # ''
        10: 2,  # ''
        19: 3,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 2,  # ''
        20: 2,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 2,  # ''
        12: 1,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 1,  # ''
        9: 2,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 3,  # ''
        39: 2,  # ''
        26: 2,  # ''
        28: 3,  # ''
        22: 3,  # ''
        25: 2,  # ''
        29: 2,  # ''
        54: 1,  # ''
        18: 3,  # ''
        17: 3,  # ''
        30: 1,  # ''
        27: 3,  # ''
        16: 3,  # ''
    },
    1: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 3,  # ''
        10: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        20: 3,  # ''
        4: 3,  # ''
        23: 3,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 3,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 2,  # ''
        39: 2,  # ''
        26: 3,  # ''
        28: 2,  # ''
        22: 3,  # ''
        25: 3,  # ''
        29: 3,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 2,  # ''
        27: 3,  # ''
        16: 3,  # ''
    },
    15: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 1,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 3,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 2,  # ''
        8: 3,  # ''
        12: 1,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 2,  # ''
        9: 3,  # ''
        7: 2,  # ''
        6: 2,  # ''
        14: 3,  # ''
        39: 1,  # ''
        26: 0,  # ''
        28: 2,  # ''
        22: 2,  # ''
        25: 1,  # ''
        29: 1,  # ''
        54: 0,  # ''
        18: 3,  # ''
        17: 2,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 3,  # ''
    },
    9: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 2,  # ''
        10: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        20: 2,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 2,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 2,  # ''
        9: 2,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 3,  # ''
        39: 2,  # ''
        26: 3,  # ''
        28: 2,  # ''
        22: 2,  # ''
        25: 3,  # ''
        29: 2,  # ''
        54: 0,  # ''
        18: 3,  # ''
        17: 3,  # ''
        30: 2,  # ''
        27: 2,  # ''
        16: 3,  # ''
    },
    7: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 1,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 2,  # ''
        10: 3,  # ''
        19: 2,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 2,  # ''
        20: 2,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 3,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 3,  # ''
        39: 2,  # ''
        26: 3,  # ''
        28: 2,  # ''
        22: 3,  # ''
        25: 2,  # ''
        29: 1,  # ''
        54: 2,  # ''
        18: 3,  # ''
        17: 3,  # ''
        30: 2,  # ''
        27: 3,  # ''
        16: 3,  # ''
    },
    6: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 2,  # ''
        10: 3,  # ''
        19: 2,  # ''
        13: 2,  # ''
        2: 3,  # ''
        24: 1,  # ''
        20: 1,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 2,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 2,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 2,  # ''
        14: 3,  # ''
        39: 2,  # ''
        26: 2,  # ''
        28: 2,  # ''
        22: 2,  # ''
        25: 2,  # ''
        29: 2,  # ''
        54: 2,  # ''
        18: 3,  # ''
        17: 3,  # ''
        30: 2,  # ''
        27: 2,  # ''
        16: 3,  # ''
    },
    14: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 3,  # ''
        10: 3,  # ''
        19: 3,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        20: 3,  # ''
        4: 2,  # ''
        23: 2,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 2,  # ''
        15: 3,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 1,  # ''
        39: 2,  # ''
        26: 3,  # ''
        28: 2,  # ''
        22: 3,  # ''
        25: 3,  # ''
        29: 3,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 2,  # ''
        27: 3,  # ''
        16: 2,  # ''
    },
    39: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 1,  # ''
        10: 0,  # ''
        19: 1,  # ''
        13: 0,  # ''
        2: 3,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 1,  # ''
        8: 2,  # ''
        12: 1,  # ''
        5: 1,  # ''
        1: 3,  # ''
        15: 1,  # ''
        9: 2,  # ''
        7: 2,  # ''
        6: 2,  # ''
        14: 2,  # ''
        39: 2,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 1,  # ''
        25: 1,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 2,  # ''
        17: 1,  # ''
        30: 2,  # ''
        27: 1,  # ''
        16: 1,  # ''
    },
    26: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 0,  # ''
        10: 3,  # ''
        19: 1,  # ''
        13: 1,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 1,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 1,  # ''
        8: 2,  # ''
        12: 2,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 1,  # ''
        9: 3,  # ''
        7: 2,  # ''
        6: 2,  # ''
        14: 2,  # ''
        39: 1,  # ''
        26: 1,  # ''
        28: 1,  # ''
        22: 1,  # ''
        25: 2,  # ''
        29: 0,  # ''
        54: 1,  # ''
        18: 0,  # ''
        17: 1,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 0,  # ''
    },
    28: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 1,  # ''
        10: 2,  # ''
        19: 1,  # ''
        13: 1,  # ''
        2: 3,  # ''
        24: 0,  # ''
        20: 1,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 2,  # ''
        8: 1,  # ''
        12: 1,  # ''
        5: 1,  # ''
        1: 3,  # ''
        15: 0,  # ''
        9: 1,  # ''
        7: 0,  # ''
        6: 1,  # ''
        14: 3,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 1,  # ''
        22: 0,  # ''
        25: 1,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 3,  # ''
        17: 1,  # ''
        30: 0,  # ''
        27: 1,  # ''
        16: 0,  # ''
    },
    22: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 1,  # ''
        10: 1,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 3,  # ''
        24: 1,  # ''
        20: 0,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 2,  # ''
        12: 1,  # ''
        5: 3,  # ''
        1: 2,  # ''
        15: 0,  # ''
        9: 2,  # ''
        7: 1,  # ''
        6: 3,  # ''
        14: 3,  # ''
        39: 1,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 1,  # ''
        25: 2,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 3,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    25: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 1,  # ''
        10: 2,  # ''
        19: 1,  # ''
        13: 0,  # ''
        2: 3,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 2,  # ''
        5: 3,  # ''
        1: 3,  # ''
        15: 2,  # ''
        9: 2,  # ''
        7: 1,  # ''
        6: 2,  # ''
        14: 3,  # ''
        39: 2,  # ''
        26: 1,  # ''
        28: 1,  # ''
        22: 1,  # ''
        25: 1,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 3,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 0,  # ''
    },
    29: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 3,  # ''
        21: 0,  # ''
        10: 1,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 3,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 3,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 0,  # ''
        12: 1,  # ''
        5: 2,  # ''
        1: 1,  # ''
        15: 0,  # ''
        9: 2,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 2,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 2,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 0,  # ''
    },
    54: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 0,  # ''
        21: 0,  # ''
        10: 0,  # ''
        19: 0,  # ''
        13: 0,  # ''
        2: 2,  # ''
        24: 0,  # ''
        20: 0,  # ''
        4: 0,  # ''
        23: 0,  # ''
        11: 0,  # ''
        8: 0,  # ''
        12: 0,  # ''
        5: 0,  # ''
        1: 0,  # ''
        15: 0,  # ''
        9: 0,  # ''
        7: 0,  # ''
        6: 0,  # ''
        14: 0,  # ''
        39: 0,  # ''
        26: 0,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 0,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 1,  # ''
        16: 2,  # ''
    },
    18: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 0,  # ''
        21: 3,  # ''
        10: 3,  # ''
        19: 2,  # ''
        13: 2,  # ''
        2: 3,  # ''
        24: 2,  # ''
        20: 2,  # ''
        4: 2,  # ''
        23: 3,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 1,  # ''
        15: 3,  # ''
        9: 3,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 1,  # ''
        39: 0,  # ''
        26: 3,  # ''
        28: 2,  # ''
        22: 3,  # ''
        25: 3,  # ''
        29: 2,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 0,  # ''
        16: 2,  # ''
    },
    17: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 0,  # ''
        21: 2,  # ''
        10: 2,  # ''
        19: 2,  # ''
        13: 2,  # ''
        2: 3,  # ''
        24: 1,  # ''
        20: 3,  # ''
        4: 2,  # ''
        23: 0,  # ''
        11: 3,  # ''
        8: 0,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 2,  # ''
        15: 2,  # ''
        9: 1,  # ''
        7: 3,  # ''
        6: 2,  # ''
        14: 0,  # ''
        39: 2,  # ''
        26: 1,  # ''
        28: 2,  # ''
        22: 2,  # ''
        25: 3,  # ''
        29: 2,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        27: 3,  # ''
        16: 3,  # ''
    },
    30: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 1,  # ''
        31: 1,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 1,  # ''
        32: 1,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 1,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 0,  # ''
        21: 1,  # ''
        10: 1,  # ''
        19: 1,  # ''
        13: 2,  # ''
        2: 1,  # ''
        24: 0,  # ''
        20: 1,  # ''
        4: 0,  # ''
        23: 2,  # ''
        11: 2,  # ''
        8: 2,  # ''
        12: 2,  # ''
        5: 2,  # ''
        1: 0,  # ''
        15: 2,  # ''
        9: 2,  # ''
        7: 2,  # ''
        6: 3,  # ''
        14: 1,  # ''
        39: 2,  # ''
        26: 1,  # ''
        28: 0,  # ''
        22: 0,  # ''
        25: 1,  # ''
        29: 0,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        27: 1,  # ''
        16: 1,  # ''
    },
    27: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 2,  # ''
        21: 3,  # ''
        10: 1,  # ''
        19: 2,  # ''
        13: 3,  # ''
        2: 1,  # ''
        24: 2,  # ''
        20: 2,  # ''
        4: 1,  # ''
        23: 1,  # ''
        11: 2,  # ''
        8: 2,  # ''
        12: 2,  # ''
        5: 2,  # ''
        1: 1,  # ''
        15: 2,  # ''
        9: 2,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 0,  # ''
        39: 1,  # ''
        26: 2,  # ''
        28: 2,  # ''
        22: 2,  # ''
        25: 2,  # ''
        29: 3,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        27: 2,  # ''
        16: 1,  # ''
    },
    16: {  # ''
        37: 0,  # ''
        44: 0,  # ''
        33: 0,  # ''
        46: 0,  # ''
        41: 0,  # ''
        48: 0,  # ''
        56: 0,  # ''
        51: 0,  # ''
        42: 0,  # ''
        60: 0,  # ''
        36: 0,  # ''
        49: 0,  # ''
        38: 0,  # ''
        31: 0,  # ''
        34: 0,  # ''
        35: 0,  # ''
        45: 0,  # ''
        32: 0,  # ''
        40: 0,  # ''
        52: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        58: 0,  # ''
        50: 0,  # ''
        57: 0,  # ''
        63: 0,  # ''
        62: 0,  # ''
        61: 0,  # ''
        47: 0,  # ''
        59: 0,  # ''
        43: 0,  # ''
        3: 0,  # ''
        21: 2,  # ''
        10: 3,  # ''
        19: 2,  # ''
        13: 3,  # ''
        2: 3,  # ''
        24: 3,  # ''
        20: 3,  # ''
        4: 2,  # ''
        23: 2,  # ''
        11: 3,  # ''
        8: 3,  # ''
        12: 3,  # ''
        5: 3,  # ''
        1: 0,  # ''
        15: 2,  # ''
        9: 2,  # ''
        7: 3,  # ''
        6: 3,  # ''
        14: 1,  # ''
        39: 1,  # ''
        26: 3,  # ''
        28: 2,  # ''
        22: 2,  # ''
        25: 2,  # ''
        29: 3,  # ''
        54: 0,  # ''
        18: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        27: 2,  # ''
        16: 2,  # ''
    },
}

# 255: Undefined characters that did not exist in training text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9
# 251: Control characters

# Character Mapping Table(s):
IBM866_RUSSIAN_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 142,  # 'A'
     66: 143,  # 'B'
     67: 144,  # 'C'
     68: 145,  # 'D'
     69: 146,  # 'E'
     70: 147,  # 'F'
     71: 148,  # 'G'
     72: 149,  # 'H'
     73: 150,  # 'I'
     74: 151,  # 'J'
     75: 152,  # 'K'
     76: 74,  # 'L'
     77: 153,  # 'M'
     78: 75,  # 'N'
     79: 154,  # 'O'
     80: 155,  # 'P'
     81: 156,  # 'Q'
     82: 157,  # 'R'
     83: 158,  # 'S'
     84: 159,  # 'T'
     85: 160,  # 'U'
     86: 161,  # 'V'
     87: 162,  # 'W'
     88: 163,  # 'X'
     89: 164,  # 'Y'
     90: 165,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 71,  # 'a'
     98: 172,  # 'b'
     99: 66,  # 'c'
     100: 173,  # 'd'
     101: 65,  # 'e'
     102: 174,  # 'f'
     103: 76,  # 'g'
     104: 175,  # 'h'
     105: 64,  # 'i'
     106: 176,  # 'j'
     107: 177,  # 'k'
     108: 77,  # 'l'
     109: 72,  # 'm'
     110: 178,  # 'n'
     111: 69,  # 'o'
     112: 67,  # 'p'
     113: 179,  # 'q'
     114: 78,  # 'r'
     115: 73,  # 's'
     116: 180,  # 't'
     117: 181,  # 'u'
     118: 79,  # 'v'
     119: 182,  # 'w'
     120: 183,  # 'x'
     121: 184,  # 'y'
     122: 185,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 37,  # ''
     129: 44,  # ''
     130: 33,  # ''
     131: 46,  # ''
     132: 41,  # ''
     133: 48,  # ''
     134: 56,  # ''
     135: 51,  # ''
     136: 42,  # ''
     137: 60,  # ''
     138: 36,  # ''
     139: 49,  # ''
     140: 38,  # ''
     141: 31,  # ''
     142: 34,  # ''
     143: 35,  # ''
     144: 45,  # ''
     145: 32,  # ''
     146: 40,  # ''
     147: 52,  # ''
     148: 53,  # ''
     149: 55,  # ''
     150: 58,  # ''
     151: 50,  # ''
     152: 57,  # ''
     153: 63,  # ''
     154: 70,  # ''
     155: 62,  # ''
     156: 61,  # ''
     157: 47,  # ''
     158: 59,  # ''
     159: 43,  # ''
     160: 3,  # ''
     161: 21,  # ''
     162: 10,  # ''
     163: 19,  # ''
     164: 13,  # ''
     165: 2,  # ''
     166: 24,  # ''
     167: 20,  # ''
     168: 4,  # ''
     169: 23,  # ''
     170: 11,  # ''
     171: 8,  # ''
     172: 12,  # ''
     173: 5,  # ''
     174: 1,  # ''
     175: 15,  # ''
     176: 191,  # ''
     177: 192,  # ''
     178: 193,  # ''
     179: 194,  # ''
     180: 195,  # ''
     181: 196,  # ''
     182: 197,  # ''
     183: 198,  # ''
     184: 199,  # ''
     185: 200,  # ''
     186: 201,  # ''
     187: 202,  # ''
     188: 203,  # ''
     189: 204,  # ''
     190: 205,  # ''
     191: 206,  # ''
     192: 207,  # ''
     193: 208,  # ''
     194: 209,  # ''
     195: 210,  # ''
     196: 211,  # ''
     197: 212,  # ''
     198: 213,  # ''
     199: 214,  # ''
     200: 215,  # ''
     201: 216,  # ''
     202: 217,  # ''
     203: 218,  # ''
     204: 219,  # ''
     205: 220,  # ''
     206: 221,  # ''
     207: 222,  # ''
     208: 223,  # ''
     209: 224,  # ''
     210: 225,  # ''
     211: 226,  # ''
     212: 227,  # ''
     213: 228,  # ''
     214: 229,  # ''
     215: 230,  # ''
     216: 231,  # ''
     217: 232,  # ''
     218: 233,  # ''
     219: 234,  # ''
     220: 235,  # ''
     221: 236,  # ''
     222: 237,  # ''
     223: 238,  # ''
     224: 9,  # ''
     225: 7,  # ''
     226: 6,  # ''
     227: 14,  # ''
     228: 39,  # ''
     229: 26,  # ''
     230: 28,  # ''
     231: 22,  # ''
     232: 25,  # ''
     233: 29,  # ''
     234: 54,  # ''
     235: 18,  # ''
     236: 17,  # ''
     237: 30,  # ''
     238: 27,  # ''
     239: 16,  # ''
     240: 239,  # ''
     241: 68,  # ''
     242: 240,  # ''
     243: 241,  # ''
     244: 242,  # ''
     245: 243,  # ''
     246: 244,  # ''
     247: 245,  # ''
     248: 246,  # ''
     249: 247,  # ''
     250: 248,  # ''
     251: 249,  # ''
     252: 250,  # ''
     253: 251,  # ''
     254: 252,  # ''
     255: 255,  # '\xa0'
}

IBM866_RUSSIAN_MODEL = SingleByteCharSetModel(charset_name='IBM866',
                                              language='Russian',
                                              char_to_order_map=IBM866_RUSSIAN_CHAR_TO_ORDER,
                                              language_model=RUSSIAN_LANG_MODEL,
                                              typical_positive_ratio=0.976601,
                                              keep_ascii_letters=False,
                                              alphabet='')

WINDOWS_1251_RUSSIAN_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 142,  # 'A'
     66: 143,  # 'B'
     67: 144,  # 'C'
     68: 145,  # 'D'
     69: 146,  # 'E'
     70: 147,  # 'F'
     71: 148,  # 'G'
     72: 149,  # 'H'
     73: 150,  # 'I'
     74: 151,  # 'J'
     75: 152,  # 'K'
     76: 74,  # 'L'
     77: 153,  # 'M'
     78: 75,  # 'N'
     79: 154,  # 'O'
     80: 155,  # 'P'
     81: 156,  # 'Q'
     82: 157,  # 'R'
     83: 158,  # 'S'
     84: 159,  # 'T'
     85: 160,  # 'U'
     86: 161,  # 'V'
     87: 162,  # 'W'
     88: 163,  # 'X'
     89: 164,  # 'Y'
     90: 165,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 71,  # 'a'
     98: 172,  # 'b'
     99: 66,  # 'c'
     100: 173,  # 'd'
     101: 65,  # 'e'
     102: 174,  # 'f'
     103: 76,  # 'g'
     104: 175,  # 'h'
     105: 64,  # 'i'
     106: 176,  # 'j'
     107: 177,  # 'k'
     108: 77,  # 'l'
     109: 72,  # 'm'
     110: 178,  # 'n'
     111: 69,  # 'o'
     112: 67,  # 'p'
     113: 179,  # 'q'
     114: 78,  # 'r'
     115: 73,  # 's'
     116: 180,  # 't'
     117: 181,  # 'u'
     118: 79,  # 'v'
     119: 182,  # 'w'
     120: 183,  # 'x'
     121: 184,  # 'y'
     122: 185,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 191,  # ''
     129: 192,  # ''
     130: 193,  # ''
     131: 194,  # ''
     132: 195,  # ''
     133: 196,  # ''
     134: 197,  # ''
     135: 198,  # ''
     136: 199,  # ''
     137: 200,  # ''
     138: 201,  # ''
     139: 202,  # ''
     140: 203,  # ''
     141: 204,  # ''
     142: 205,  # ''
     143: 206,  # ''
     144: 207,  # ''
     145: 208,  # ''
     146: 209,  # ''
     147: 210,  # ''
     148: 211,  # ''
     149: 212,  # ''
     150: 213,  # ''
     151: 214,  # ''
     152: 215,  # None
     153: 216,  # ''
     154: 217,  # ''
     155: 218,  # ''
     156: 219,  # ''
     157: 220,  # ''
     158: 221,  # ''
     159: 222,  # ''
     160: 223,  # '\xa0'
     161: 224,  # ''
     162: 225,  # ''
     163: 226,  # ''
     164: 227,  # ''
     165: 228,  # ''
     166: 229,  # ''
     167: 230,  # ''
     168: 231,  # ''
     169: 232,  # ''
     170: 233,  # ''
     171: 234,  # ''
     172: 235,  # ''
     173: 236,  # '\xad'
     174: 237,  # ''
     175: 238,  # ''
     176: 239,  # ''
     177: 240,  # ''
     178: 241,  # ''
     179: 242,  # ''
     180: 243,  # ''
     181: 244,  # ''
     182: 245,  # ''
     183: 246,  # ''
     184: 68,  # ''
     185: 247,  # ''
     186: 248,  # ''
     187: 249,  # ''
     188: 250,  # ''
     189: 251,  # ''
     190: 252,  # ''
     191: 253,  # ''
     192: 37,  # ''
     193: 44,  # ''
     194: 33,  # ''
     195: 46,  # ''
     196: 41,  # ''
     197: 48,  # ''
     198: 56,  # ''
     199: 51,  # ''
     200: 42,  # ''
     201: 60,  # ''
     202: 36,  # ''
     203: 49,  # ''
     204: 38,  # ''
     205: 31,  # ''
     206: 34,  # ''
     207: 35,  # ''
     208: 45,  # ''
     209: 32,  # ''
     210: 40,  # ''
     211: 52,  # ''
     212: 53,  # ''
     213: 55,  # ''
     214: 58,  # ''
     215: 50,  # ''
     216: 57,  # ''
     217: 63,  # ''
     218: 70,  # ''
     219: 62,  # ''
     220: 61,  # ''
     221: 47,  # ''
     222: 59,  # ''
     223: 43,  # ''
     224: 3,  # ''
     225: 21,  # ''
     226: 10,  # ''
     227: 19,  # ''
     228: 13,  # ''
     229: 2,  # ''
     230: 24,  # ''
     231: 20,  # ''
     232: 4,  # ''
     233: 23,  # ''
     234: 11,  # ''
     235: 8,  # ''
     236: 12,  # ''
     237: 5,  # ''
     238: 1,  # ''
     239: 15,  # ''
     240: 9,  # ''
     241: 7,  # ''
     242: 6,  # ''
     243: 14,  # ''
     244: 39,  # ''
     245: 26,  # ''
     246: 28,  # ''
     247: 22,  # ''
     248: 25,  # ''
     249: 29,  # ''
     250: 54,  # ''
     251: 18,  # ''
     252: 17,  # ''
     253: 30,  # ''
     254: 27,  # ''
     255: 16,  # ''
}

WINDOWS_1251_RUSSIAN_MODEL = SingleByteCharSetModel(charset_name='windows-1251',
                                                    language='Russian',
                                                    char_to_order_map=WINDOWS_1251_RUSSIAN_CHAR_TO_ORDER,
                                                    language_model=RUSSIAN_LANG_MODEL,
                                                    typical_positive_ratio=0.976601,
                                                    keep_ascii_letters=False,
                                                    alphabet='')

IBM855_RUSSIAN_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 142,  # 'A'
     66: 143,  # 'B'
     67: 144,  # 'C'
     68: 145,  # 'D'
     69: 146,  # 'E'
     70: 147,  # 'F'
     71: 148,  # 'G'
     72: 149,  # 'H'
     73: 150,  # 'I'
     74: 151,  # 'J'
     75: 152,  # 'K'
     76: 74,  # 'L'
     77: 153,  # 'M'
     78: 75,  # 'N'
     79: 154,  # 'O'
     80: 155,  # 'P'
     81: 156,  # 'Q'
     82: 157,  # 'R'
     83: 158,  # 'S'
     84: 159,  # 'T'
     85: 160,  # 'U'
     86: 161,  # 'V'
     87: 162,  # 'W'
     88: 163,  # 'X'
     89: 164,  # 'Y'
     90: 165,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 71,  # 'a'
     98: 172,  # 'b'
     99: 66,  # 'c'
     100: 173,  # 'd'
     101: 65,  # 'e'
     102: 174,  # 'f'
     103: 76,  # 'g'
     104: 175,  # 'h'
     105: 64,  # 'i'
     106: 176,  # 'j'
     107: 177,  # 'k'
     108: 77,  # 'l'
     109: 72,  # 'm'
     110: 178,  # 'n'
     111: 69,  # 'o'
     112: 67,  # 'p'
     113: 179,  # 'q'
     114: 78,  # 'r'
     115: 73,  # 's'
     116: 180,  # 't'
     117: 181,  # 'u'
     118: 79,  # 'v'
     119: 182,  # 'w'
     120: 183,  # 'x'
     121: 184,  # 'y'
     122: 185,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 191,  # ''
     129: 192,  # ''
     130: 193,  # ''
     131: 194,  # ''
     132: 68,  # ''
     133: 195,  # ''
     134: 196,  # ''
     135: 197,  # ''
     136: 198,  # ''
     137: 199,  # ''
     138: 200,  # ''
     139: 201,  # ''
     140: 202,  # ''
     141: 203,  # ''
     142: 204,  # ''
     143: 205,  # ''
     144: 206,  # ''
     145: 207,  # ''
     146: 208,  # ''
     147: 209,  # ''
     148: 210,  # ''
     149: 211,  # ''
     150: 212,  # ''
     151: 213,  # ''
     152: 214,  # ''
     153: 215,  # ''
     154: 216,  # ''
     155: 217,  # ''
     156: 27,  # ''
     157: 59,  # ''
     158: 54,  # ''
     159: 70,  # ''
     160: 3,  # ''
     161: 37,  # ''
     162: 21,  # ''
     163: 44,  # ''
     164: 28,  # ''
     165: 58,  # ''
     166: 13,  # ''
     167: 41,  # ''
     168: 2,  # ''
     169: 48,  # ''
     170: 39,  # ''
     171: 53,  # ''
     172: 19,  # ''
     173: 46,  # ''
     174: 218,  # ''
     175: 219,  # ''
     176: 220,  # ''
     177: 221,  # ''
     178: 222,  # ''
     179: 223,  # ''
     180: 224,  # ''
     181: 26,  # ''
     182: 55,  # ''
     183: 4,  # ''
     184: 42,  # ''
     185: 225,  # ''
     186: 226,  # ''
     187: 227,  # ''
     188: 228,  # ''
     189: 23,  # ''
     190: 60,  # ''
     191: 229,  # ''
     192: 230,  # ''
     193: 231,  # ''
     194: 232,  # ''
     195: 233,  # ''
     196: 234,  # ''
     197: 235,  # ''
     198: 11,  # ''
     199: 36,  # ''
     200: 236,  # ''
     201: 237,  # ''
     202: 238,  # ''
     203: 239,  # ''
     204: 240,  # ''
     205: 241,  # ''
     206: 242,  # ''
     207: 243,  # ''
     208: 8,  # ''
     209: 49,  # ''
     210: 12,  # ''
     211: 38,  # ''
     212: 5,  # ''
     213: 31,  # ''
     214: 1,  # ''
     215: 34,  # ''
     216: 15,  # ''
     217: 244,  # ''
     218: 245,  # ''
     219: 246,  # ''
     220: 247,  # ''
     221: 35,  # ''
     222: 16,  # ''
     223: 248,  # ''
     224: 43,  # ''
     225: 9,  # ''
     226: 45,  # ''
     227: 7,  # ''
     228: 32,  # ''
     229: 6,  # ''
     230: 40,  # ''
     231: 14,  # ''
     232: 52,  # ''
     233: 24,  # ''
     234: 56,  # ''
     235: 10,  # ''
     236: 33,  # ''
     237: 17,  # ''
     238: 61,  # ''
     239: 249,  # ''
     240: 250,  # '\xad'
     241: 18,  # ''
     242: 62,  # ''
     243: 20,  # ''
     244: 51,  # ''
     245: 25,  # ''
     246: 57,  # ''
     247: 30,  # ''
     248: 47,  # ''
     249: 29,  # ''
     250: 63,  # ''
     251: 22,  # ''
     252: 50,  # ''
     253: 251,  # ''
     254: 252,  # ''
     255: 255,  # '\xa0'
}

IBM855_RUSSIAN_MODEL = SingleByteCharSetModel(charset_name='IBM855',
                                              language='Russian',
                                              char_to_order_map=IBM855_RUSSIAN_CHAR_TO_ORDER,
                                              language_model=RUSSIAN_LANG_MODEL,
                                              typical_positive_ratio=0.976601,
                                              keep_ascii_letters=False,
                                              alphabet='')

KOI8_R_RUSSIAN_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 142,  # 'A'
     66: 143,  # 'B'
     67: 144,  # 'C'
     68: 145,  # 'D'
     69: 146,  # 'E'
     70: 147,  # 'F'
     71: 148,  # 'G'
     72: 149,  # 'H'
     73: 150,  # 'I'
     74: 151,  # 'J'
     75: 152,  # 'K'
     76: 74,  # 'L'
     77: 153,  # 'M'
     78: 75,  # 'N'
     79: 154,  # 'O'
     80: 155,  # 'P'
     81: 156,  # 'Q'
     82: 157,  # 'R'
     83: 158,  # 'S'
     84: 159,  # 'T'
     85: 160,  # 'U'
     86: 161,  # 'V'
     87: 162,  # 'W'
     88: 163,  # 'X'
     89: 164,  # 'Y'
     90: 165,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 71,  # 'a'
     98: 172,  # 'b'
     99: 66,  # 'c'
     100: 173,  # 'd'
     101: 65,  # 'e'
     102: 174,  # 'f'
     103: 76,  # 'g'
     104: 175,  # 'h'
     105: 64,  # 'i'
     106: 176,  # 'j'
     107: 177,  # 'k'
     108: 77,  # 'l'
     109: 72,  # 'm'
     110: 178,  # 'n'
     111: 69,  # 'o'
     112: 67,  # 'p'
     113: 179,  # 'q'
     114: 78,  # 'r'
     115: 73,  # 's'
     116: 180,  # 't'
     117: 181,  # 'u'
     118: 79,  # 'v'
     119: 182,  # 'w'
     120: 183,  # 'x'
     121: 184,  # 'y'
     122: 185,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 191,  # ''
     129: 192,  # ''
     130: 193,  # ''
     131: 194,  # ''
     132: 195,  # ''
     133: 196,  # ''
     134: 197,  # ''
     135: 198,  # ''
     136: 199,  # ''
     137: 200,  # ''
     138: 201,  # ''
     139: 202,  # ''
     140: 203,  # ''
     141: 204,  # ''
     142: 205,  # ''
     143: 206,  # ''
     144: 207,  # ''
     145: 208,  # ''
     146: 209,  # ''
     147: 210,  # ''
     148: 211,  # ''
     149: 212,  # ''
     150: 213,  # ''
     151: 214,  # ''
     152: 215,  # ''
     153: 216,  # ''
     154: 217,  # '\xa0'
     155: 218,  # ''
     156: 219,  # ''
     157: 220,  # ''
     158: 221,  # ''
     159: 222,  # ''
     160: 223,  # ''
     161: 224,  # ''
     162: 225,  # ''
     163: 68,  # ''
     164: 226,  # ''
     165: 227,  # ''
     166: 228,  # ''
     167: 229,  # ''
     168: 230,  # ''
     169: 231,  # ''
     170: 232,  # ''
     171: 233,  # ''
     172: 234,  # ''
     173: 235,  # ''
     174: 236,  # ''
     175: 237,  # ''
     176: 238,  # ''
     177: 239,  # ''
     178: 240,  # ''
     179: 241,  # ''
     180: 242,  # ''
     181: 243,  # ''
     182: 244,  # ''
     183: 245,  # ''
     184: 246,  # ''
     185: 247,  # ''
     186: 248,  # ''
     187: 249,  # ''
     188: 250,  # ''
     189: 251,  # ''
     190: 252,  # ''
     191: 253,  # ''
     192: 27,  # ''
     193: 3,  # ''
     194: 21,  # ''
     195: 28,  # ''
     196: 13,  # ''
     197: 2,  # ''
     198: 39,  # ''
     199: 19,  # ''
     200: 26,  # ''
     201: 4,  # ''
     202: 23,  # ''
     203: 11,  # ''
     204: 8,  # ''
     205: 12,  # ''
     206: 5,  # ''
     207: 1,  # ''
     208: 15,  # ''
     209: 16,  # ''
     210: 9,  # ''
     211: 7,  # ''
     212: 6,  # ''
     213: 14,  # ''
     214: 24,  # ''
     215: 10,  # ''
     216: 17,  # ''
     217: 18,  # ''
     218: 20,  # ''
     219: 25,  # ''
     220: 30,  # ''
     221: 29,  # ''
     222: 22,  # ''
     223: 54,  # ''
     224: 59,  # ''
     225: 37,  # ''
     226: 44,  # ''
     227: 58,  # ''
     228: 41,  # ''
     229: 48,  # ''
     230: 53,  # ''
     231: 46,  # ''
     232: 55,  # ''
     233: 42,  # ''
     234: 60,  # ''
     235: 36,  # ''
     236: 49,  # ''
     237: 38,  # ''
     238: 31,  # ''
     239: 34,  # ''
     240: 35,  # ''
     241: 43,  # ''
     242: 45,  # ''
     243: 32,  # ''
     244: 40,  # ''
     245: 52,  # ''
     246: 56,  # ''
     247: 33,  # ''
     248: 61,  # ''
     249: 62,  # ''
     250: 51,  # ''
     251: 57,  # ''
     252: 47,  # ''
     253: 63,  # ''
     254: 50,  # ''
     255: 70,  # ''
}

KOI8_R_RUSSIAN_MODEL = SingleByteCharSetModel(charset_name='KOI8-R',
                                              language='Russian',
                                              char_to_order_map=KOI8_R_RUSSIAN_CHAR_TO_ORDER,
                                              language_model=RUSSIAN_LANG_MODEL,
                                              typical_positive_ratio=0.976601,
                                              keep_ascii_letters=False,
                                              alphabet='')

MACCYRILLIC_RUSSIAN_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 142,  # 'A'
     66: 143,  # 'B'
     67: 144,  # 'C'
     68: 145,  # 'D'
     69: 146,  # 'E'
     70: 147,  # 'F'
     71: 148,  # 'G'
     72: 149,  # 'H'
     73: 150,  # 'I'
     74: 151,  # 'J'
     75: 152,  # 'K'
     76: 74,  # 'L'
     77: 153,  # 'M'
     78: 75,  # 'N'
     79: 154,  # 'O'
     80: 155,  # 'P'
     81: 156,  # 'Q'
     82: 157,  # 'R'
     83: 158,  # 'S'
     84: 159,  # 'T'
     85: 160,  # 'U'
     86: 161,  # 'V'
     87: 162,  # 'W'
     88: 163,  # 'X'
     89: 164,  # 'Y'
     90: 165,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 71,  # 'a'
     98: 172,  # 'b'
     99: 66,  # 'c'
     100: 173,  # 'd'
     101: 65,  # 'e'
     102: 174,  # 'f'
     103: 76,  # 'g'
     104: 175,  # 'h'
     105: 64,  # 'i'
     106: 176,  # 'j'
     107: 177,  # 'k'
     108: 77,  # 'l'
     109: 72,  # 'm'
     110: 178,  # 'n'
     111: 69,  # 'o'
     112: 67,  # 'p'
     113: 179,  # 'q'
     114: 78,  # 'r'
     115: 73,  # 's'
     116: 180,  # 't'
     117: 181,  # 'u'
     118: 79,  # 'v'
     119: 182,  # 'w'
     120: 183,  # 'x'
     121: 184,  # 'y'
     122: 185,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 37,  # ''
     129: 44,  # ''
     130: 33,  # ''
     131: 46,  # ''
     132: 41,  # ''
     133: 48,  # ''
     134: 56,  # ''
     135: 51,  # ''
     136: 42,  # ''
     137: 60,  # ''
     138: 36,  # ''
     139: 49,  # ''
     140: 38,  # ''
     141: 31,  # ''
     142: 34,  # ''
     143: 35,  # ''
     144: 45,  # ''
     145: 32,  # ''
     146: 40,  # ''
     147: 52,  # ''
     148: 53,  # ''
     149: 55,  # ''
     150: 58,  # ''
     151: 50,  # ''
     152: 57,  # ''
     153: 63,  # ''
     154: 70,  # ''
     155: 62,  # ''
     156: 61,  # ''
     157: 47,  # ''
     158: 59,  # ''
     159: 43,  # ''
     160: 191,  # ''
     161: 192,  # ''
     162: 193,  # ''
     163: 194,  # ''
     164: 195,  # ''
     165: 196,  # ''
     166: 197,  # ''
     167: 198,  # ''
     168: 199,  # ''
     169: 200,  # ''
     170: 201,  # ''
     171: 202,  # ''
     172: 203,  # ''
     173: 204,  # ''
     174: 205,  # ''
     175: 206,  # ''
     176: 207,  # ''
     177: 208,  # ''
     178: 209,  # ''
     179: 210,  # ''
     180: 211,  # ''
     181: 212,  # ''
     182: 213,  # ''
     183: 214,  # ''
     184: 215,  # ''
     185: 216,  # ''
     186: 217,  # ''
     187: 218,  # ''
     188: 219,  # ''
     189: 220,  # ''
     190: 221,  # ''
     191: 222,  # ''
     192: 223,  # ''
     193: 224,  # ''
     194: 225,  # ''
     195: 226,  # ''
     196: 227,  # ''
     197: 228,  # ''
     198: 229,  # ''
     199: 230,  # ''
     200: 231,  # ''
     201: 232,  # ''
     202: 233,  # '\xa0'
     203: 234,  # ''
     204: 235,  # ''
     205: 236,  # ''
     206: 237,  # ''
     207: 238,  # ''
     208: 239,  # ''
     209: 240,  # ''
     210: 241,  # ''
     211: 242,  # ''
     212: 243,  # ''
     213: 244,  # ''
     214: 245,  # ''
     215: 246,  # ''
     216: 247,  # ''
     217: 248,  # ''
     218: 249,  # ''
     219: 250,  # ''
     220: 251,  # ''
     221: 252,  # ''
     222: 68,  # ''
     223: 16,  # ''
     224: 3,  # ''
     225: 21,  # ''
     226: 10,  # ''
     227: 19,  # ''
     228: 13,  # ''
     229: 2,  # ''
     230: 24,  # ''
     231: 20,  # ''
     232: 4,  # ''
     233: 23,  # ''
     234: 11,  # ''
     235: 8,  # ''
     236: 12,  # ''
     237: 5,  # ''
     238: 1,  # ''
     239: 15,  # ''
     240: 9,  # ''
     241: 7,  # ''
     242: 6,  # ''
     243: 14,  # ''
     244: 39,  # ''
     245: 26,  # ''
     246: 28,  # ''
     247: 22,  # ''
     248: 25,  # ''
     249: 29,  # ''
     250: 54,  # ''
     251: 18,  # ''
     252: 17,  # ''
     253: 30,  # ''
     254: 27,  # ''
     255: 255,  # ''
}

MACCYRILLIC_RUSSIAN_MODEL = SingleByteCharSetModel(charset_name='MacCyrillic',
                                                   language='Russian',
                                                   char_to_order_map=MACCYRILLIC_RUSSIAN_CHAR_TO_ORDER,
                                                   language_model=RUSSIAN_LANG_MODEL,
                                                   typical_positive_ratio=0.976601,
                                                   keep_ascii_letters=False,
                                                   alphabet='')

ISO_8859_5_RUSSIAN_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 142,  # 'A'
     66: 143,  # 'B'
     67: 144,  # 'C'
     68: 145,  # 'D'
     69: 146,  # 'E'
     70: 147,  # 'F'
     71: 148,  # 'G'
     72: 149,  # 'H'
     73: 150,  # 'I'
     74: 151,  # 'J'
     75: 152,  # 'K'
     76: 74,  # 'L'
     77: 153,  # 'M'
     78: 75,  # 'N'
     79: 154,  # 'O'
     80: 155,  # 'P'
     81: 156,  # 'Q'
     82: 157,  # 'R'
     83: 158,  # 'S'
     84: 159,  # 'T'
     85: 160,  # 'U'
     86: 161,  # 'V'
     87: 162,  # 'W'
     88: 163,  # 'X'
     89: 164,  # 'Y'
     90: 165,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 71,  # 'a'
     98: 172,  # 'b'
     99: 66,  # 'c'
     100: 173,  # 'd'
     101: 65,  # 'e'
     102: 174,  # 'f'
     103: 76,  # 'g'
     104: 175,  # 'h'
     105: 64,  # 'i'
     106: 176,  # 'j'
     107: 177,  # 'k'
     108: 77,  # 'l'
     109: 72,  # 'm'
     110: 178,  # 'n'
     111: 69,  # 'o'
     112: 67,  # 'p'
     113: 179,  # 'q'
     114: 78,  # 'r'
     115: 73,  # 's'
     116: 180,  # 't'
     117: 181,  # 'u'
     118: 79,  # 'v'
     119: 182,  # 'w'
     120: 183,  # 'x'
     121: 184,  # 'y'
     122: 185,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 191,  # '\x80'
     129: 192,  # '\x81'
     130: 193,  # '\x82'
     131: 194,  # '\x83'
     132: 195,  # '\x84'
     133: 196,  # '\x85'
     134: 197,  # '\x86'
     135: 198,  # '\x87'
     136: 199,  # '\x88'
     137: 200,  # '\x89'
     138: 201,  # '\x8a'
     139: 202,  # '\x8b'
     140: 203,  # '\x8c'
     141: 204,  # '\x8d'
     142: 205,  # '\x8e'
     143: 206,  # '\x8f'
     144: 207,  # '\x90'
     145: 208,  # '\x91'
     146: 209,  # '\x92'
     147: 210,  # '\x93'
     148: 211,  # '\x94'
     149: 212,  # '\x95'
     150: 213,  # '\x96'
     151: 214,  # '\x97'
     152: 215,  # '\x98'
     153: 216,  # '\x99'
     154: 217,  # '\x9a'
     155: 218,  # '\x9b'
     156: 219,  # '\x9c'
     157: 220,  # '\x9d'
     158: 221,  # '\x9e'
     159: 222,  # '\x9f'
     160: 223,  # '\xa0'
     161: 224,  # ''
     162: 225,  # ''
     163: 226,  # ''
     164: 227,  # ''
     165: 228,  # ''
     166: 229,  # ''
     167: 230,  # ''
     168: 231,  # ''
     169: 232,  # ''
     170: 233,  # ''
     171: 234,  # ''
     172: 235,  # ''
     173: 236,  # '\xad'
     174: 237,  # ''
     175: 238,  # ''
     176: 37,  # ''
     177: 44,  # ''
     178: 33,  # ''
     179: 46,  # ''
     180: 41,  # ''
     181: 48,  # ''
     182: 56,  # ''
     183: 51,  # ''
     184: 42,  # ''
     185: 60,  # ''
     186: 36,  # ''
     187: 49,  # ''
     188: 38,  # ''
     189: 31,  # ''
     190: 34,  # ''
     191: 35,  # ''
     192: 45,  # ''
     193: 32,  # ''
     194: 40,  # ''
     195: 52,  # ''
     196: 53,  # ''
     197: 55,  # ''
     198: 58,  # ''
     199: 50,  # ''
     200: 57,  # ''
     201: 63,  # ''
     202: 70,  # ''
     203: 62,  # ''
     204: 61,  # ''
     205: 47,  # ''
     206: 59,  # ''
     207: 43,  # ''
     208: 3,  # ''
     209: 21,  # ''
     210: 10,  # ''
     211: 19,  # ''
     212: 13,  # ''
     213: 2,  # ''
     214: 24,  # ''
     215: 20,  # ''
     216: 4,  # ''
     217: 23,  # ''
     218: 11,  # ''
     219: 8,  # ''
     220: 12,  # ''
     221: 5,  # ''
     222: 1,  # ''
     223: 15,  # ''
     224: 9,  # ''
     225: 7,  # ''
     226: 6,  # ''
     227: 14,  # ''
     228: 39,  # ''
     229: 26,  # ''
     230: 28,  # ''
     231: 22,  # ''
     232: 25,  # ''
     233: 29,  # ''
     234: 54,  # ''
     235: 18,  # ''
     236: 17,  # ''
     237: 30,  # ''
     238: 27,  # ''
     239: 16,  # ''
     240: 239,  # ''
     241: 68,  # ''
     242: 240,  # ''
     243: 241,  # ''
     244: 242,  # ''
     245: 243,  # ''
     246: 244,  # ''
     247: 245,  # ''
     248: 246,  # ''
     249: 247,  # ''
     250: 248,  # ''
     251: 249,  # ''
     252: 250,  # ''
     253: 251,  # ''
     254: 252,  # ''
     255: 255,  # ''
}

ISO_8859_5_RUSSIAN_MODEL = SingleByteCharSetModel(charset_name='ISO-8859-5',
                                                  language='Russian',
                                                  char_to_order_map=ISO_8859_5_RUSSIAN_CHAR_TO_ORDER,
                                                  language_model=RUSSIAN_LANG_MODEL,
                                                  typical_positive_ratio=0.976601,
                                                  keep_ascii_letters=False,
                                                  alphabet='')





############################################################
### File: langthaimodel.py
############################################################
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

THAI_LANG_MODEL = {
    5: {  # ''
        5: 2,  # ''
        30: 2,  # ''
        24: 2,  # ''
        8: 2,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 3,  # ''
        57: 2,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 2,  # ''
        20: 2,  # ''
        19: 3,  # ''
        44: 0,  # ''
        14: 2,  # ''
        48: 0,  # ''
        3: 2,  # ''
        17: 1,  # ''
        25: 2,  # ''
        39: 1,  # ''
        62: 1,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 1,  # ''
        9: 2,  # ''
        16: 1,  # ''
        2: 3,  # ''
        61: 2,  # ''
        15: 3,  # ''
        12: 3,  # ''
        42: 2,  # ''
        46: 3,  # ''
        18: 2,  # ''
        21: 2,  # ''
        4: 3,  # ''
        63: 1,  # ''
        22: 2,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 3,  # ''
        23: 3,  # ''
        13: 3,  # ''
        40: 0,  # ''
        27: 2,  # ''
        32: 2,  # ''
        35: 1,  # ''
        11: 2,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 1,  # ''
        33: 2,  # ''
        50: 1,  # ''
        37: 3,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 2,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    30: {  # ''
        5: 1,  # ''
        30: 0,  # ''
        24: 1,  # ''
        8: 1,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 2,  # ''
        20: 0,  # ''
        19: 2,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 2,  # ''
        17: 1,  # ''
        25: 1,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 2,  # ''
        2: 1,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 2,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 1,  # ''
        4: 3,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 2,  # ''
        40: 3,  # ''
        27: 1,  # ''
        32: 1,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 1,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 1,  # ''
        6: 2,  # ''
        7: 3,  # ''
        38: 1,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    24: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 2,  # ''
        8: 2,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 2,  # ''
        20: 2,  # ''
        19: 2,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 0,  # ''
        25: 1,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        16: 2,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 3,  # ''
        12: 3,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 0,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 2,  # ''
        10: 3,  # ''
        1: 2,  # ''
        36: 3,  # ''
        23: 3,  # ''
        13: 2,  # ''
        40: 0,  # ''
        27: 3,  # ''
        32: 3,  # ''
        35: 2,  # ''
        11: 1,  # ''
        28: 0,  # ''
        41: 3,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 1,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 3,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    8: {  # ''
        5: 3,  # ''
        30: 2,  # ''
        24: 3,  # ''
        8: 2,  # ''
        26: 2,  # ''
        52: 1,  # ''
        34: 2,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 2,  # ''
        19: 2,  # ''
        44: 1,  # ''
        14: 3,  # ''
        48: 1,  # ''
        3: 3,  # ''
        17: 2,  # ''
        25: 2,  # ''
        39: 2,  # ''
        62: 1,  # ''
        31: 2,  # ''
        54: 0,  # ''
        45: 1,  # ''
        9: 2,  # ''
        16: 1,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 2,  # ''
        42: 2,  # ''
        46: 1,  # ''
        18: 3,  # ''
        21: 3,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 1,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 2,  # ''
        13: 1,  # ''
        40: 0,  # ''
        27: 1,  # ''
        32: 1,  # ''
        35: 0,  # ''
        11: 3,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 3,  # ''
        37: 0,  # ''
        6: 2,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    26: {  # ''
        5: 2,  # ''
        30: 1,  # ''
        24: 0,  # ''
        8: 2,  # ''
        26: 3,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 2,  # ''
        19: 1,  # ''
        44: 1,  # ''
        14: 2,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 1,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        16: 1,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 1,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 3,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 3,  # ''
        23: 2,  # ''
        13: 1,  # ''
        40: 3,  # ''
        27: 1,  # ''
        32: 3,  # ''
        35: 2,  # ''
        11: 1,  # ''
        28: 1,  # ''
        41: 0,  # ''
        29: 1,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 2,  # ''
        7: 2,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    52: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 3,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 3,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        16: 1,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 1,  # ''
        10: 1,  # ''
        1: 1,  # ''
        36: 0,  # ''
        23: 1,  # ''
        13: 1,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 1,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    34: {  # ''
        5: 1,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 1,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 1,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 2,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        16: 1,  # ''
        2: 1,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 2,  # ''
        1: 3,  # ''
        36: 1,  # ''
        23: 3,  # ''
        13: 2,  # ''
        40: 0,  # ''
        27: 3,  # ''
        32: 3,  # ''
        35: 1,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 1,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    51: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 1,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 1,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 0,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 1,  # ''
        1: 1,  # ''
        36: 0,  # ''
        23: 1,  # ''
        13: 2,  # ''
        40: 3,  # ''
        27: 2,  # ''
        32: 1,  # ''
        35: 1,  # ''
        11: 1,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 1,  # ''
        6: 1,  # ''
        7: 2,  # ''
        38: 1,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    47: {  # ''
        5: 1,  # ''
        30: 1,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 3,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 1,  # ''
        25: 1,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 1,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 2,  # ''
        4: 1,  # ''
        63: 0,  # ''
        22: 1,  # ''
        10: 2,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 1,  # ''
        13: 1,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 1,  # ''
        28: 1,  # ''
        41: 0,  # ''
        29: 1,  # ''
        33: 0,  # ''
        50: 1,  # ''
        37: 0,  # ''
        6: 2,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    58: {  # ''
        5: 2,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 1,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 1,  # ''
        13: 2,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    57: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 3,  # ''
        13: 1,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    49: {  # ''
        5: 1,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 2,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 1,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 1,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 1,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    53: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 2,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 3,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    55: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 1,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    43: {  # ''
        5: 1,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 3,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 3,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 1,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 1,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 3,  # ''
        10: 0,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 1,  # ''
        13: 2,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 1,  # ''
        28: 1,  # ''
        41: 0,  # ''
        29: 1,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 3,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    20: {  # ''
        5: 2,  # ''
        30: 2,  # ''
        24: 2,  # ''
        8: 3,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 2,  # ''
        44: 1,  # ''
        14: 2,  # ''
        48: 0,  # ''
        3: 1,  # ''
        17: 1,  # ''
        25: 1,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 1,  # ''
        9: 2,  # ''
        16: 3,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 2,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 2,  # ''
        4: 1,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 3,  # ''
        1: 2,  # ''
        36: 2,  # ''
        23: 3,  # ''
        13: 3,  # ''
        40: 1,  # ''
        27: 2,  # ''
        32: 3,  # ''
        35: 2,  # ''
        11: 2,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 2,  # ''
        37: 2,  # ''
        6: 1,  # ''
        7: 3,  # ''
        38: 1,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    19: {  # ''
        5: 2,  # ''
        30: 1,  # ''
        24: 1,  # ''
        8: 0,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 1,  # ''
        44: 2,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 2,  # ''
        17: 1,  # ''
        25: 1,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 2,  # ''
        9: 1,  # ''
        16: 1,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 3,  # ''
        21: 0,  # ''
        4: 3,  # ''
        63: 1,  # ''
        22: 2,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 2,  # ''
        23: 3,  # ''
        13: 2,  # ''
        40: 1,  # ''
        27: 1,  # ''
        32: 3,  # ''
        35: 2,  # ''
        11: 1,  # ''
        28: 1,  # ''
        41: 1,  # ''
        29: 1,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 2,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 2,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    44: {  # ''
        5: 1,  # ''
        30: 0,  # ''
        24: 1,  # ''
        8: 0,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 1,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 1,  # ''
        17: 2,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 1,  # ''
        61: 0,  # ''
        15: 1,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 0,  # ''
        4: 1,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 2,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 2,  # ''
        13: 1,  # ''
        40: 3,  # ''
        27: 2,  # ''
        32: 2,  # ''
        35: 3,  # ''
        11: 1,  # ''
        28: 1,  # ''
        41: 0,  # ''
        29: 1,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 2,  # ''
        7: 3,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    14: {  # ''
        5: 1,  # ''
        30: 1,  # ''
        24: 3,  # ''
        8: 1,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 2,  # ''
        19: 1,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 3,  # ''
        3: 3,  # ''
        17: 2,  # ''
        25: 2,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 2,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        16: 3,  # ''
        2: 3,  # ''
        61: 1,  # ''
        15: 1,  # ''
        12: 2,  # ''
        42: 3,  # ''
        46: 1,  # ''
        18: 1,  # ''
        21: 0,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 2,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 3,  # ''
        23: 2,  # ''
        13: 3,  # ''
        40: 2,  # ''
        27: 1,  # ''
        32: 3,  # ''
        35: 1,  # ''
        11: 0,  # ''
        28: 1,  # ''
        41: 0,  # ''
        29: 1,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 1,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 2,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    48: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 1,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 1,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 2,  # ''
        36: 0,  # ''
        23: 3,  # ''
        13: 3,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 2,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 3,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    3: {  # ''
        5: 3,  # ''
        30: 2,  # ''
        24: 3,  # ''
        8: 1,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 3,  # ''
        19: 3,  # ''
        44: 2,  # ''
        14: 3,  # ''
        48: 3,  # ''
        3: 2,  # ''
        17: 2,  # ''
        25: 2,  # ''
        39: 2,  # ''
        62: 0,  # ''
        31: 2,  # ''
        54: 1,  # ''
        45: 1,  # ''
        9: 2,  # ''
        16: 2,  # ''
        2: 2,  # ''
        61: 1,  # ''
        15: 2,  # ''
        12: 3,  # ''
        42: 1,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 2,  # ''
        4: 3,  # ''
        63: 1,  # ''
        22: 2,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 3,  # ''
        23: 3,  # ''
        13: 3,  # ''
        40: 3,  # ''
        27: 3,  # ''
        32: 3,  # ''
        35: 2,  # ''
        11: 3,  # ''
        28: 2,  # ''
        41: 3,  # ''
        29: 3,  # ''
        33: 3,  # ''
        50: 2,  # ''
        37: 1,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 2,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    17: {  # ''
        5: 3,  # ''
        30: 2,  # ''
        24: 2,  # ''
        8: 1,  # ''
        26: 1,  # ''
        52: 1,  # ''
        34: 1,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 2,  # ''
        44: 1,  # ''
        14: 3,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 3,  # ''
        25: 2,  # ''
        39: 2,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 1,  # ''
        45: 1,  # ''
        9: 1,  # ''
        16: 0,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 3,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 2,  # ''
        4: 2,  # ''
        63: 1,  # ''
        22: 0,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 2,  # ''
        23: 2,  # ''
        13: 2,  # ''
        40: 0,  # ''
        27: 2,  # ''
        32: 3,  # ''
        35: 2,  # ''
        11: 2,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 0,  # ''
        37: 1,  # ''
        6: 2,  # ''
        7: 2,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    25: {  # ''
        5: 2,  # ''
        30: 0,  # ''
        24: 1,  # ''
        8: 0,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 1,  # ''
        57: 3,  # ''
        49: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 1,  # ''
        44: 1,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 2,  # ''
        17: 0,  # ''
        25: 1,  # ''
        39: 1,  # ''
        62: 1,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        16: 0,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 3,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 1,  # ''
        18: 2,  # ''
        21: 1,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 1,  # ''
        10: 3,  # ''
        1: 1,  # ''
        36: 0,  # ''
        23: 2,  # ''
        13: 3,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 1,  # ''
        35: 0,  # ''
        11: 1,  # ''
        28: 2,  # ''
        41: 0,  # ''
        29: 1,  # ''
        33: 2,  # ''
        50: 0,  # ''
        37: 3,  # ''
        6: 1,  # ''
        7: 2,  # ''
        38: 1,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    39: {  # ''
        5: 1,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 1,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 2,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        16: 2,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 3,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 1,  # ''
        10: 1,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 2,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 1,  # ''
        32: 0,  # ''
        35: 3,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 3,  # ''
        7: 1,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    62: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 1,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 1,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 1,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 1,  # ''
        40: 2,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 2,  # ''
        7: 1,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    31: {  # ''
        5: 1,  # ''
        30: 1,  # ''
        24: 1,  # ''
        8: 1,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 1,  # ''
        20: 1,  # ''
        19: 1,  # ''
        44: 0,  # ''
        14: 2,  # ''
        48: 1,  # ''
        3: 3,  # ''
        17: 2,  # ''
        25: 0,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        16: 2,  # ''
        2: 3,  # ''
        61: 2,  # ''
        15: 2,  # ''
        12: 2,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 1,  # ''
        4: 2,  # ''
        63: 1,  # ''
        22: 0,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 3,  # ''
        13: 2,  # ''
        40: 1,  # ''
        27: 3,  # ''
        32: 1,  # ''
        35: 2,  # ''
        11: 1,  # ''
        28: 1,  # ''
        41: 0,  # ''
        29: 1,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 1,  # ''
        6: 0,  # ''
        7: 1,  # ''
        38: 3,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    54: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 1,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 2,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 1,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 0,  # ''
        4: 1,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 2,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 1,  # ''
        13: 1,  # ''
        40: 0,  # ''
        27: 1,  # ''
        32: 1,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 1,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 2,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    45: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 1,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 3,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 1,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 1,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 2,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 1,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    9: {  # ''
        5: 2,  # ''
        30: 2,  # ''
        24: 2,  # ''
        8: 2,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 1,  # ''
        20: 2,  # ''
        19: 2,  # ''
        44: 1,  # ''
        14: 2,  # ''
        48: 1,  # ''
        3: 3,  # ''
        17: 2,  # ''
        25: 2,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 3,  # ''
        54: 0,  # ''
        45: 1,  # ''
        9: 2,  # ''
        16: 1,  # ''
        2: 2,  # ''
        61: 2,  # ''
        15: 2,  # ''
        12: 2,  # ''
        42: 1,  # ''
        46: 1,  # ''
        18: 3,  # ''
        21: 3,  # ''
        4: 3,  # ''
        63: 0,  # ''
        22: 1,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 3,  # ''
        13: 3,  # ''
        40: 0,  # ''
        27: 3,  # ''
        32: 3,  # ''
        35: 3,  # ''
        11: 2,  # ''
        28: 2,  # ''
        41: 2,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 1,  # ''
        37: 1,  # ''
        6: 3,  # ''
        7: 2,  # ''
        38: 1,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    16: {  # ''
        5: 3,  # ''
        30: 1,  # ''
        24: 2,  # ''
        8: 3,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 2,  # ''
        51: 0,  # ''
        47: 2,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 2,  # ''
        19: 2,  # ''
        44: 1,  # ''
        14: 2,  # ''
        48: 1,  # ''
        3: 3,  # ''
        17: 3,  # ''
        25: 1,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 1,  # ''
        9: 2,  # ''
        16: 0,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 1,  # ''
        12: 3,  # ''
        42: 1,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 1,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 2,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 2,  # ''
        13: 3,  # ''
        40: 1,  # ''
        27: 2,  # ''
        32: 2,  # ''
        35: 3,  # ''
        11: 2,  # ''
        28: 1,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 2,  # ''
        37: 1,  # ''
        6: 3,  # ''
        7: 2,  # ''
        38: 3,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    2: {  # ''
        5: 3,  # ''
        30: 2,  # ''
        24: 2,  # ''
        8: 3,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 2,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 3,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 3,  # ''
        20: 2,  # ''
        19: 2,  # ''
        44: 3,  # ''
        14: 3,  # ''
        48: 1,  # ''
        3: 2,  # ''
        17: 2,  # ''
        25: 3,  # ''
        39: 2,  # ''
        62: 1,  # ''
        31: 2,  # ''
        54: 1,  # ''
        45: 1,  # ''
        9: 3,  # ''
        16: 2,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 3,  # ''
        42: 2,  # ''
        46: 2,  # ''
        18: 2,  # ''
        21: 2,  # ''
        4: 3,  # ''
        63: 1,  # ''
        22: 3,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 3,  # ''
        13: 3,  # ''
        40: 2,  # ''
        27: 3,  # ''
        32: 3,  # ''
        35: 3,  # ''
        11: 3,  # ''
        28: 3,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 3,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 3,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    61: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 2,  # ''
        44: 0,  # ''
        14: 2,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 2,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    15: {  # ''
        5: 2,  # ''
        30: 3,  # ''
        24: 1,  # ''
        8: 3,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 2,  # ''
        19: 2,  # ''
        44: 1,  # ''
        14: 2,  # ''
        48: 0,  # ''
        3: 1,  # ''
        17: 2,  # ''
        25: 2,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 1,  # ''
        9: 1,  # ''
        16: 3,  # ''
        2: 1,  # ''
        61: 0,  # ''
        15: 1,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 1,  # ''
        4: 3,  # ''
        63: 2,  # ''
        22: 3,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 2,  # ''
        23: 3,  # ''
        13: 3,  # ''
        40: 2,  # ''
        27: 3,  # ''
        32: 2,  # ''
        35: 3,  # ''
        11: 2,  # ''
        28: 1,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 2,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 2,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    12: {  # ''
        5: 3,  # ''
        30: 2,  # ''
        24: 1,  # ''
        8: 3,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 1,  # ''
        20: 2,  # ''
        19: 1,  # ''
        44: 1,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 2,  # ''
        25: 1,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 1,  # ''
        45: 0,  # ''
        9: 3,  # ''
        16: 3,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 3,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 2,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 2,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 3,  # ''
        13: 2,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 2,  # ''
        35: 0,  # ''
        11: 3,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 1,  # ''
        33: 2,  # ''
        50: 1,  # ''
        37: 0,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 1,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    42: {  # ''
        5: 1,  # ''
        30: 0,  # ''
        24: 1,  # ''
        8: 0,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 1,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 1,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 2,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 2,  # ''
        42: 1,  # ''
        46: 2,  # ''
        18: 1,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 2,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 2,  # ''
        13: 0,  # ''
        40: 3,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 2,  # ''
        11: 0,  # ''
        28: 1,  # ''
        41: 0,  # ''
        29: 1,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 1,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    46: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 2,  # ''
        57: 1,  # ''
        49: 2,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 3,  # ''
        20: 0,  # ''
        19: 1,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 1,  # ''
        9: 1,  # ''
        16: 2,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 1,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 2,  # ''
        10: 2,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 1,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 1,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 2,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    18: {  # ''
        5: 2,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 2,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 3,  # ''
        19: 3,  # ''
        44: 3,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 2,  # ''
        25: 1,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 2,  # ''
        9: 3,  # ''
        16: 1,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 1,  # ''
        12: 2,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 2,  # ''
        4: 3,  # ''
        63: 0,  # ''
        22: 2,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 3,  # ''
        23: 3,  # ''
        13: 3,  # ''
        40: 2,  # ''
        27: 3,  # ''
        32: 3,  # ''
        35: 3,  # ''
        11: 2,  # ''
        28: 0,  # ''
        41: 1,  # ''
        29: 0,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 3,  # ''
        7: 1,  # ''
        38: 2,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    21: {  # ''
        5: 3,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 1,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 2,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 3,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 0,  # ''
        25: 1,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        16: 2,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 3,  # ''
        12: 2,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 3,  # ''
        63: 0,  # ''
        22: 1,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 0,  # ''
        23: 1,  # ''
        13: 1,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 1,  # ''
        35: 1,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 3,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 2,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    4: {  # ''
        5: 3,  # ''
        30: 1,  # ''
        24: 2,  # ''
        8: 3,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 3,  # ''
        19: 2,  # ''
        44: 1,  # ''
        14: 2,  # ''
        48: 1,  # ''
        3: 3,  # ''
        17: 3,  # ''
        25: 1,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 1,  # ''
        45: 1,  # ''
        9: 3,  # ''
        16: 3,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 2,  # ''
        42: 1,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 2,  # ''
        4: 3,  # ''
        63: 0,  # ''
        22: 2,  # ''
        10: 3,  # ''
        1: 3,  # ''
        36: 2,  # ''
        23: 2,  # ''
        13: 3,  # ''
        40: 0,  # ''
        27: 3,  # ''
        32: 3,  # ''
        35: 0,  # ''
        11: 3,  # ''
        28: 1,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 1,  # ''
        37: 1,  # ''
        6: 2,  # ''
        7: 2,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    63: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    22: {  # ''
        5: 3,  # ''
        30: 1,  # ''
        24: 2,  # ''
        8: 1,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 3,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 3,  # ''
        19: 3,  # ''
        44: 1,  # ''
        14: 3,  # ''
        48: 1,  # ''
        3: 2,  # ''
        17: 3,  # ''
        25: 2,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 2,  # ''
        54: 0,  # ''
        45: 1,  # ''
        9: 3,  # ''
        16: 2,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 2,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 3,  # ''
        21: 3,  # ''
        4: 2,  # ''
        63: 1,  # ''
        22: 1,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 3,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    10: {  # ''
        5: 3,  # ''
        30: 0,  # ''
        24: 1,  # ''
        8: 3,  # ''
        26: 3,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 3,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 2,  # ''
        53: 0,  # ''
        55: 3,  # ''
        43: 3,  # ''
        20: 3,  # ''
        19: 3,  # ''
        44: 0,  # ''
        14: 2,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 3,  # ''
        25: 1,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 2,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        16: 3,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 3,  # ''
        42: 2,  # ''
        46: 0,  # ''
        18: 3,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    1: {  # ''
        5: 3,  # ''
        30: 2,  # ''
        24: 3,  # ''
        8: 3,  # ''
        26: 3,  # ''
        52: 0,  # ''
        34: 3,  # ''
        51: 1,  # ''
        47: 2,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 3,  # ''
        20: 3,  # ''
        19: 3,  # ''
        44: 1,  # ''
        14: 3,  # ''
        48: 2,  # ''
        3: 3,  # ''
        17: 3,  # ''
        25: 2,  # ''
        39: 1,  # ''
        62: 1,  # ''
        31: 3,  # ''
        54: 1,  # ''
        45: 1,  # ''
        9: 3,  # ''
        16: 3,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 3,  # ''
        12: 3,  # ''
        42: 2,  # ''
        46: 3,  # ''
        18: 3,  # ''
        21: 3,  # ''
        4: 2,  # ''
        63: 1,  # ''
        22: 3,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 3,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 1,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    36: {  # ''
        5: 2,  # ''
        30: 1,  # ''
        24: 3,  # ''
        8: 2,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 1,  # ''
        44: 1,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 1,  # ''
        25: 1,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 1,  # ''
        9: 1,  # ''
        16: 0,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 3,  # ''
        4: 1,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 3,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    23: {  # ''
        5: 3,  # ''
        30: 1,  # ''
        24: 2,  # ''
        8: 3,  # ''
        26: 3,  # ''
        52: 0,  # ''
        34: 3,  # ''
        51: 0,  # ''
        47: 2,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 3,  # ''
        19: 3,  # ''
        44: 1,  # ''
        14: 3,  # ''
        48: 3,  # ''
        3: 3,  # ''
        17: 3,  # ''
        25: 2,  # ''
        39: 2,  # ''
        62: 0,  # ''
        31: 3,  # ''
        54: 1,  # ''
        45: 2,  # ''
        9: 3,  # ''
        16: 2,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 3,  # ''
        42: 3,  # ''
        46: 2,  # ''
        18: 2,  # ''
        21: 3,  # ''
        4: 1,  # ''
        63: 1,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 3,  # ''
        28: 1,  # ''
        41: 1,  # ''
        29: 1,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 3,  # ''
        7: 2,  # ''
        38: 2,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    13: {  # ''
        5: 3,  # ''
        30: 2,  # ''
        24: 2,  # ''
        8: 0,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 2,  # ''
        19: 1,  # ''
        44: 0,  # ''
        14: 2,  # ''
        48: 0,  # ''
        3: 1,  # ''
        17: 2,  # ''
        25: 2,  # ''
        39: 1,  # ''
        62: 0,  # ''
        31: 2,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        16: 3,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 1,  # ''
        12: 2,  # ''
        42: 1,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 1,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 2,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 1,  # ''
        33: 1,  # ''
        50: 1,  # ''
        37: 0,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    40: {  # ''
        5: 3,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 3,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 1,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    27: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 2,  # ''
        17: 3,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 3,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    32: {  # ''
        5: 3,  # ''
        30: 2,  # ''
        24: 3,  # ''
        8: 3,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 2,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 1,  # ''
        43: 3,  # ''
        20: 3,  # ''
        19: 3,  # ''
        44: 1,  # ''
        14: 2,  # ''
        48: 1,  # ''
        3: 2,  # ''
        17: 2,  # ''
        25: 2,  # ''
        39: 2,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 1,  # ''
        9: 3,  # ''
        16: 1,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 1,  # ''
        42: 1,  # ''
        46: 2,  # ''
        18: 1,  # ''
        21: 1,  # ''
        4: 1,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 1,  # ''
        28: 0,  # ''
        41: 1,  # ''
        29: 0,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 3,  # ''
        7: 2,  # ''
        38: 1,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    35: {  # ''
        5: 3,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 2,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 2,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 1,  # ''
        20: 2,  # ''
        19: 2,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 2,  # ''
        17: 0,  # ''
        25: 3,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        16: 0,  # ''
        2: 1,  # ''
        61: 0,  # ''
        15: 3,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 1,  # ''
        28: 1,  # ''
        41: 1,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 3,  # ''
        7: 3,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    11: {  # ''
        5: 3,  # ''
        30: 3,  # ''
        24: 3,  # ''
        8: 2,  # ''
        26: 3,  # ''
        52: 3,  # ''
        34: 3,  # ''
        51: 2,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 1,  # ''
        20: 3,  # ''
        19: 3,  # ''
        44: 1,  # ''
        14: 3,  # ''
        48: 1,  # ''
        3: 3,  # ''
        17: 3,  # ''
        25: 3,  # ''
        39: 2,  # ''
        62: 1,  # ''
        31: 3,  # ''
        54: 1,  # ''
        45: 3,  # ''
        9: 3,  # ''
        16: 2,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 3,  # ''
        12: 3,  # ''
        42: 2,  # ''
        46: 0,  # ''
        18: 3,  # ''
        21: 3,  # ''
        4: 3,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    28: {  # ''
        5: 3,  # ''
        30: 2,  # ''
        24: 2,  # ''
        8: 1,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 2,  # ''
        19: 3,  # ''
        44: 2,  # ''
        14: 3,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 3,  # ''
        25: 2,  # ''
        39: 3,  # ''
        62: 0,  # ''
        31: 2,  # ''
        54: 2,  # ''
        45: 0,  # ''
        9: 2,  # ''
        16: 2,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 3,  # ''
        12: 2,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 3,  # ''
        21: 3,  # ''
        4: 1,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    41: {  # ''
        5: 2,  # ''
        30: 1,  # ''
        24: 2,  # ''
        8: 0,  # ''
        26: 1,  # ''
        52: 1,  # ''
        34: 1,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 3,  # ''
        19: 2,  # ''
        44: 0,  # ''
        14: 2,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 1,  # ''
        25: 3,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 1,  # ''
        45: 1,  # ''
        9: 1,  # ''
        16: 2,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 3,  # ''
        12: 0,  # ''
        42: 1,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 0,  # ''
        4: 2,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    29: {  # ''
        5: 2,  # ''
        30: 0,  # ''
        24: 1,  # ''
        8: 0,  # ''
        26: 3,  # ''
        52: 0,  # ''
        34: 3,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 3,  # ''
        19: 1,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 2,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 1,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 3,  # ''
        21: 3,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    33: {  # ''
        5: 1,  # ''
        30: 2,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 3,  # ''
        19: 1,  # ''
        44: 0,  # ''
        14: 3,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 1,  # ''
        25: 3,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 2,  # ''
        45: 0,  # ''
        9: 3,  # ''
        16: 0,  # ''
        2: 3,  # ''
        61: 0,  # ''
        15: 1,  # ''
        12: 3,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 2,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    50: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    37: {  # ''
        5: 2,  # ''
        30: 1,  # ''
        24: 2,  # ''
        8: 2,  # ''
        26: 3,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 1,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 2,  # ''
        44: 0,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 3,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 2,  # ''
        16: 1,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 2,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 0,  # ''
        4: 1,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 1,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    6: {  # ''
        5: 2,  # ''
        30: 1,  # ''
        24: 2,  # ''
        8: 3,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 1,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 2,  # ''
        44: 1,  # ''
        14: 2,  # ''
        48: 1,  # ''
        3: 3,  # ''
        17: 1,  # ''
        25: 2,  # ''
        39: 2,  # ''
        62: 1,  # ''
        31: 1,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 3,  # ''
        16: 3,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 2,  # ''
        12: 3,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 1,  # ''
        4: 3,  # ''
        63: 0,  # ''
        22: 1,  # ''
        10: 0,  # ''
        1: 3,  # ''
        36: 2,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 3,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 1,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    7: {  # ''
        5: 2,  # ''
        30: 1,  # ''
        24: 2,  # ''
        8: 3,  # ''
        26: 2,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 1,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 1,  # ''
        19: 2,  # ''
        44: 1,  # ''
        14: 2,  # ''
        48: 0,  # ''
        3: 3,  # ''
        17: 2,  # ''
        25: 2,  # ''
        39: 2,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 1,  # ''
        45: 0,  # ''
        9: 3,  # ''
        16: 2,  # ''
        2: 2,  # ''
        61: 0,  # ''
        15: 1,  # ''
        12: 3,  # ''
        42: 1,  # ''
        46: 0,  # ''
        18: 2,  # ''
        21: 2,  # ''
        4: 3,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 3,  # ''
        36: 2,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 2,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 2,  # ''
        33: 2,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    38: {  # ''
        5: 2,  # ''
        30: 1,  # ''
        24: 1,  # ''
        8: 0,  # ''
        26: 1,  # ''
        52: 0,  # ''
        34: 1,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 2,  # ''
        19: 1,  # ''
        44: 1,  # ''
        14: 1,  # ''
        48: 0,  # ''
        3: 1,  # ''
        17: 1,  # ''
        25: 1,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 1,  # ''
        54: 1,  # ''
        45: 0,  # ''
        9: 2,  # ''
        16: 0,  # ''
        2: 1,  # ''
        61: 1,  # ''
        15: 1,  # ''
        12: 1,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 1,  # ''
        21: 1,  # ''
        4: 2,  # ''
        63: 1,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 2,  # ''
        28: 2,  # ''
        41: 1,  # ''
        29: 1,  # ''
        33: 1,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 0,  # ''
        59: 0,  # ''
        60: 0,  # ''
    },
    56: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 2,  # ''
        59: 1,  # ''
        60: 1,  # ''
    },
    59: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 1,  # ''
        59: 1,  # ''
        60: 3,  # ''
    },
    60: {  # ''
        5: 0,  # ''
        30: 0,  # ''
        24: 0,  # ''
        8: 0,  # ''
        26: 0,  # ''
        52: 0,  # ''
        34: 0,  # ''
        51: 0,  # ''
        47: 0,  # ''
        58: 0,  # ''
        57: 0,  # ''
        49: 0,  # ''
        53: 0,  # ''
        55: 0,  # ''
        43: 0,  # ''
        20: 0,  # ''
        19: 0,  # ''
        44: 0,  # ''
        14: 0,  # ''
        48: 0,  # ''
        3: 0,  # ''
        17: 0,  # ''
        25: 0,  # ''
        39: 0,  # ''
        62: 0,  # ''
        31: 0,  # ''
        54: 0,  # ''
        45: 0,  # ''
        9: 0,  # ''
        16: 0,  # ''
        2: 0,  # ''
        61: 0,  # ''
        15: 0,  # ''
        12: 0,  # ''
        42: 0,  # ''
        46: 0,  # ''
        18: 0,  # ''
        21: 0,  # ''
        4: 0,  # ''
        63: 0,  # ''
        22: 0,  # ''
        10: 0,  # ''
        1: 0,  # ''
        36: 0,  # ''
        23: 0,  # ''
        13: 0,  # ''
        40: 0,  # ''
        27: 0,  # ''
        32: 0,  # ''
        35: 0,  # ''
        11: 0,  # ''
        28: 0,  # ''
        41: 0,  # ''
        29: 0,  # ''
        33: 0,  # ''
        50: 0,  # ''
        37: 0,  # ''
        6: 0,  # ''
        7: 0,  # ''
        38: 0,  # ''
        56: 2,  # ''
        59: 1,  # ''
        60: 0,  # ''
    },
}

# 255: Undefined characters that did not exist in training text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9
# 251: Control characters

# Character Mapping Table(s):
TIS_620_THAI_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 254,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 254,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 253,  # ' '
     33: 253,  # '!'
     34: 253,  # '"'
     35: 253,  # '#'
     36: 253,  # '$'
     37: 253,  # '%'
     38: 253,  # '&'
     39: 253,  # "'"
     40: 253,  # '('
     41: 253,  # ')'
     42: 253,  # '*'
     43: 253,  # '+'
     44: 253,  # ','
     45: 253,  # '-'
     46: 253,  # '.'
     47: 253,  # '/'
     48: 252,  # '0'
     49: 252,  # '1'
     50: 252,  # '2'
     51: 252,  # '3'
     52: 252,  # '4'
     53: 252,  # '5'
     54: 252,  # '6'
     55: 252,  # '7'
     56: 252,  # '8'
     57: 252,  # '9'
     58: 253,  # ':'
     59: 253,  # ';'
     60: 253,  # '<'
     61: 253,  # '='
     62: 253,  # '>'
     63: 253,  # '?'
     64: 253,  # '@'
     65: 182,  # 'A'
     66: 106,  # 'B'
     67: 107,  # 'C'
     68: 100,  # 'D'
     69: 183,  # 'E'
     70: 184,  # 'F'
     71: 185,  # 'G'
     72: 101,  # 'H'
     73: 94,  # 'I'
     74: 186,  # 'J'
     75: 187,  # 'K'
     76: 108,  # 'L'
     77: 109,  # 'M'
     78: 110,  # 'N'
     79: 111,  # 'O'
     80: 188,  # 'P'
     81: 189,  # 'Q'
     82: 190,  # 'R'
     83: 89,  # 'S'
     84: 95,  # 'T'
     85: 112,  # 'U'
     86: 113,  # 'V'
     87: 191,  # 'W'
     88: 192,  # 'X'
     89: 193,  # 'Y'
     90: 194,  # 'Z'
     91: 253,  # '['
     92: 253,  # '\\'
     93: 253,  # ']'
     94: 253,  # '^'
     95: 253,  # '_'
     96: 253,  # '`'
     97: 64,  # 'a'
     98: 72,  # 'b'
     99: 73,  # 'c'
     100: 114,  # 'd'
     101: 74,  # 'e'
     102: 115,  # 'f'
     103: 116,  # 'g'
     104: 102,  # 'h'
     105: 81,  # 'i'
     106: 201,  # 'j'
     107: 117,  # 'k'
     108: 90,  # 'l'
     109: 103,  # 'm'
     110: 78,  # 'n'
     111: 82,  # 'o'
     112: 96,  # 'p'
     113: 202,  # 'q'
     114: 91,  # 'r'
     115: 79,  # 's'
     116: 84,  # 't'
     117: 104,  # 'u'
     118: 105,  # 'v'
     119: 97,  # 'w'
     120: 98,  # 'x'
     121: 92,  # 'y'
     122: 203,  # 'z'
     123: 253,  # '{'
     124: 253,  # '|'
     125: 253,  # '}'
     126: 253,  # '~'
     127: 253,  # '\x7f'
     128: 209,  # '\x80'
     129: 210,  # '\x81'
     130: 211,  # '\x82'
     131: 212,  # '\x83'
     132: 213,  # '\x84'
     133: 88,  # '\x85'
     134: 214,  # '\x86'
     135: 215,  # '\x87'
     136: 216,  # '\x88'
     137: 217,  # '\x89'
     138: 218,  # '\x8a'
     139: 219,  # '\x8b'
     140: 220,  # '\x8c'
     141: 118,  # '\x8d'
     142: 221,  # '\x8e'
     143: 222,  # '\x8f'
     144: 223,  # '\x90'
     145: 224,  # '\x91'
     146: 99,  # '\x92'
     147: 85,  # '\x93'
     148: 83,  # '\x94'
     149: 225,  # '\x95'
     150: 226,  # '\x96'
     151: 227,  # '\x97'
     152: 228,  # '\x98'
     153: 229,  # '\x99'
     154: 230,  # '\x9a'
     155: 231,  # '\x9b'
     156: 232,  # '\x9c'
     157: 233,  # '\x9d'
     158: 234,  # '\x9e'
     159: 235,  # '\x9f'
     160: 236,  # None
     161: 5,  # ''
     162: 30,  # ''
     163: 237,  # ''
     164: 24,  # ''
     165: 238,  # ''
     166: 75,  # ''
     167: 8,  # ''
     168: 26,  # ''
     169: 52,  # ''
     170: 34,  # ''
     171: 51,  # ''
     172: 119,  # ''
     173: 47,  # ''
     174: 58,  # ''
     175: 57,  # ''
     176: 49,  # ''
     177: 53,  # ''
     178: 55,  # ''
     179: 43,  # ''
     180: 20,  # ''
     181: 19,  # ''
     182: 44,  # ''
     183: 14,  # ''
     184: 48,  # ''
     185: 3,  # ''
     186: 17,  # ''
     187: 25,  # ''
     188: 39,  # ''
     189: 62,  # ''
     190: 31,  # ''
     191: 54,  # ''
     192: 45,  # ''
     193: 9,  # ''
     194: 16,  # ''
     195: 2,  # ''
     196: 61,  # ''
     197: 15,  # ''
     198: 239,  # ''
     199: 12,  # ''
     200: 42,  # ''
     201: 46,  # ''
     202: 18,  # ''
     203: 21,  # ''
     204: 76,  # ''
     205: 4,  # ''
     206: 66,  # ''
     207: 63,  # ''
     208: 22,  # ''
     209: 10,  # ''
     210: 1,  # ''
     211: 36,  # ''
     212: 23,  # ''
     213: 13,  # ''
     214: 40,  # ''
     215: 27,  # ''
     216: 32,  # ''
     217: 35,  # ''
     218: 86,  # ''
     219: 240,  # None
     220: 241,  # None
     221: 242,  # None
     222: 243,  # None
     223: 244,  # ''
     224: 11,  # ''
     225: 28,  # ''
     226: 41,  # ''
     227: 29,  # ''
     228: 33,  # ''
     229: 245,  # ''
     230: 50,  # ''
     231: 37,  # ''
     232: 6,  # ''
     233: 7,  # ''
     234: 67,  # ''
     235: 77,  # ''
     236: 38,  # ''
     237: 93,  # ''
     238: 246,  # ''
     239: 247,  # ''
     240: 68,  # ''
     241: 56,  # ''
     242: 59,  # ''
     243: 65,  # ''
     244: 69,  # ''
     245: 60,  # ''
     246: 70,  # ''
     247: 80,  # ''
     248: 71,  # ''
     249: 87,  # ''
     250: 248,  # ''
     251: 249,  # ''
     252: 250,  # None
     253: 251,  # None
     254: 252,  # None
     255: 253,  # None
}

TIS_620_THAI_MODEL = SingleByteCharSetModel(charset_name='TIS-620',
                                            language='Thai',
                                            char_to_order_map=TIS_620_THAI_CHAR_TO_ORDER,
                                            language_model=THAI_LANG_MODEL,
                                            typical_positive_ratio=0.926386,
                                            keep_ascii_letters=False,
                                            alphabet='')





############################################################
### File: langturkishmodel.py
############################################################
#!/usr/bin/env python
# -*- coding: utf-8 -*-

from chardet.sbcharsetprober import SingleByteCharSetModel


# 3: Positive
# 2: Likely
# 1: Unlikely
# 0: Negative

TURKISH_LANG_MODEL = {
    23: {  # 'A'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 2,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 1,  # 'g'
        25: 1,  # 'h'
        3: 1,  # 'i'
        24: 0,  # 'j'
        10: 2,  # 'k'
        5: 1,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 1,  # 'r'
        8: 1,  # 's'
        9: 1,  # 't'
        14: 1,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 3,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 0,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    37: {  # 'B'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 2,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 2,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 1,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 1,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 0,  # 'Z'
        1: 2,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 0,  # 'k'
        5: 0,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 1,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 1,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 0,  # ''
        40: 1,  # ''
        19: 1,  # ''
    },
    47: {  # 'C'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 1,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 1,  # 'L'
        20: 0,  # 'M'
        46: 1,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 1,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 2,  # 'j'
        10: 1,  # 'k'
        5: 2,  # 'l'
        13: 2,  # 'm'
        4: 2,  # 'n'
        15: 1,  # 'o'
        26: 0,  # 'p'
        7: 2,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 1,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 1,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    39: {  # 'D'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 1,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 1,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 2,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 0,  # 'k'
        5: 1,  # 'l'
        13: 3,  # 'm'
        4: 0,  # 'n'
        15: 1,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 1,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 1,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 0,  # ''
        6: 1,  # ''
        40: 1,  # ''
        19: 0,  # ''
    },
    29: {  # 'E'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 1,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 2,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 1,  # 'g'
        25: 0,  # 'h'
        3: 1,  # 'i'
        24: 1,  # 'j'
        10: 0,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 1,  # 's'
        9: 1,  # 't'
        14: 1,  # 'u'
        32: 1,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 2,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    52: {  # 'F'
        23: 0,  # 'A'
        37: 1,  # 'B'
        47: 1,  # 'C'
        39: 1,  # 'D'
        29: 1,  # 'E'
        52: 2,  # 'F'
        36: 0,  # 'G'
        45: 2,  # 'H'
        53: 1,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 1,  # 'N'
        42: 1,  # 'O'
        48: 2,  # 'P'
        44: 1,  # 'R'
        35: 1,  # 'S'
        31: 1,  # 'T'
        51: 1,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 2,  # 'Y'
        56: 0,  # 'Z'
        1: 0,  # 'a'
        21: 1,  # 'b'
        28: 1,  # 'c'
        12: 1,  # 'd'
        2: 0,  # 'e'
        18: 1,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 2,  # 'i'
        24: 1,  # 'j'
        10: 0,  # 'k'
        5: 0,  # 'l'
        13: 1,  # 'm'
        4: 2,  # 'n'
        15: 1,  # 'o'
        26: 0,  # 'p'
        7: 2,  # 'r'
        8: 1,  # 's'
        9: 1,  # 't'
        14: 1,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 1,  # 'y'
        22: 1,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 1,  # ''
        55: 2,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 2,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 1,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 2,  # ''
    },
    36: {  # 'G'
        23: 1,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 1,  # 'F'
        36: 2,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 2,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 2,  # 'N'
        42: 1,  # 'O'
        48: 1,  # 'P'
        44: 1,  # 'R'
        35: 1,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 2,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 1,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 1,  # 'j'
        10: 1,  # 'k'
        5: 0,  # 'l'
        13: 3,  # 'm'
        4: 2,  # 'n'
        15: 0,  # 'o'
        26: 1,  # 'p'
        7: 0,  # 'r'
        8: 1,  # 's'
        9: 1,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 1,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 2,  # ''
        55: 0,  # ''
        59: 1,  # ''
        33: 2,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 1,  # ''
        6: 2,  # ''
        40: 2,  # ''
        19: 1,  # ''
    },
    45: {  # 'H'
        23: 0,  # 'A'
        37: 1,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 2,  # 'F'
        36: 2,  # 'G'
        45: 1,  # 'H'
        53: 1,  # 'I'
        60: 0,  # 'J'
        16: 2,  # 'K'
        49: 1,  # 'L'
        20: 0,  # 'M'
        46: 1,  # 'N'
        42: 1,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 2,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 2,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 2,  # 'i'
        24: 0,  # 'j'
        10: 1,  # 'k'
        5: 0,  # 'l'
        13: 2,  # 'm'
        4: 0,  # 'n'
        15: 1,  # 'o'
        26: 1,  # 'p'
        7: 1,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 1,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 2,  # ''
        41: 1,  # ''
        6: 0,  # ''
        40: 2,  # ''
        19: 1,  # ''
    },
    53: {  # 'I'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 1,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 2,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 2,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 0,  # 'k'
        5: 2,  # 'l'
        13: 2,  # 'm'
        4: 0,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 2,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 0,  # ''
        40: 1,  # ''
        19: 1,  # ''
    },
    60: {  # 'J'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 0,  # 'a'
        21: 1,  # 'b'
        28: 0,  # 'c'
        12: 1,  # 'd'
        2: 0,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 1,  # 'i'
        24: 0,  # 'j'
        10: 0,  # 'k'
        5: 0,  # 'l'
        13: 0,  # 'm'
        4: 1,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 1,  # 's'
        9: 0,  # 't'
        14: 0,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 0,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    16: {  # 'K'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 3,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 2,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 2,  # 'a'
        21: 3,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 1,  # 'e'
        18: 3,  # 'f'
        27: 3,  # 'g'
        25: 3,  # 'h'
        3: 3,  # 'i'
        24: 2,  # 'j'
        10: 3,  # 'k'
        5: 0,  # 'l'
        13: 0,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 1,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 0,  # 'u'
        32: 3,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 2,  # 'y'
        22: 1,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 2,  # ''
        30: 0,  # ''
        41: 1,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    49: {  # 'L'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 2,  # 'E'
        52: 0,  # 'F'
        36: 1,  # 'G'
        45: 1,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 2,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 0,  # 'Z'
        1: 0,  # 'a'
        21: 3,  # 'b'
        28: 0,  # 'c'
        12: 2,  # 'd'
        2: 0,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 2,  # 'i'
        24: 0,  # 'j'
        10: 1,  # 'k'
        5: 0,  # 'l'
        13: 0,  # 'm'
        4: 2,  # 'n'
        15: 1,  # 'o'
        26: 1,  # 'p'
        7: 1,  # 'r'
        8: 1,  # 's'
        9: 1,  # 't'
        14: 0,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 2,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 2,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 1,  # ''
        30: 1,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    20: {  # 'M'
        23: 1,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 1,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 1,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 2,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 1,  # 'g'
        25: 1,  # 'h'
        3: 2,  # 'i'
        24: 2,  # 'j'
        10: 2,  # 'k'
        5: 2,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 1,  # 'p'
        7: 3,  # 'r'
        8: 0,  # 's'
        9: 2,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 2,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 3,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    46: {  # 'N'
        23: 0,  # 'A'
        37: 1,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 1,  # 'F'
        36: 1,  # 'G'
        45: 1,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 2,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 1,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 1,  # 'R'
        35: 1,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 2,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 1,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 2,  # 'j'
        10: 1,  # 'k'
        5: 1,  # 'l'
        13: 3,  # 'm'
        4: 2,  # 'n'
        15: 1,  # 'o'
        26: 1,  # 'p'
        7: 1,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 1,  # 'x'
        11: 1,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 1,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 1,  # ''
        6: 2,  # ''
        40: 1,  # ''
        19: 1,  # ''
    },
    42: {  # 'O'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 1,  # 'F'
        36: 0,  # 'G'
        45: 1,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 2,  # 'K'
        49: 1,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 2,  # 'P'
        44: 1,  # 'R'
        35: 1,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 0,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 0,  # 'n'
        15: 1,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 2,  # ''
        50: 1,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 2,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 2,  # ''
        6: 1,  # ''
        40: 1,  # ''
        19: 1,  # ''
    },
    48: {  # 'P'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 2,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 2,  # 'F'
        36: 1,  # 'G'
        45: 1,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 2,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 1,  # 'N'
        42: 1,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 1,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 2,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 1,  # 'k'
        5: 0,  # 'l'
        13: 2,  # 'm'
        4: 0,  # 'n'
        15: 2,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 2,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 2,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 2,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 1,  # ''
        6: 0,  # ''
        40: 2,  # ''
        19: 1,  # ''
    },
    44: {  # 'R'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 1,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 1,  # 'b'
        28: 1,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 1,  # 'k'
        5: 2,  # 'l'
        13: 2,  # 'm'
        4: 0,  # 'n'
        15: 1,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 1,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 1,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 1,  # ''
        30: 1,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 1,  # ''
        19: 1,  # ''
    },
    35: {  # 'S'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 1,  # 'F'
        36: 1,  # 'G'
        45: 1,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 1,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 1,  # 'k'
        5: 1,  # 'l'
        13: 2,  # 'm'
        4: 1,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 1,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 1,  # 'z'
        63: 0,  # ''
        54: 2,  # ''
        50: 2,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 3,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 2,  # ''
        19: 1,  # ''
    },
    31: {  # 'T'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 1,  # 'J'
        16: 2,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 2,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 2,  # 'b'
        28: 0,  # 'c'
        12: 1,  # 'd'
        2: 3,  # 'e'
        18: 2,  # 'f'
        27: 2,  # 'g'
        25: 0,  # 'h'
        3: 1,  # 'i'
        24: 1,  # 'j'
        10: 2,  # 'k'
        5: 2,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 2,  # 'p'
        7: 2,  # 'r'
        8: 0,  # 's'
        9: 2,  # 't'
        14: 2,  # 'u'
        32: 1,  # 'v'
        57: 1,  # 'w'
        58: 1,  # 'x'
        11: 2,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 1,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    51: {  # 'U'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 1,  # 'F'
        36: 1,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 1,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 1,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 1,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 2,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 1,  # 'k'
        5: 1,  # 'l'
        13: 3,  # 'm'
        4: 2,  # 'n'
        15: 0,  # 'o'
        26: 1,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 1,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 1,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 1,  # ''
    },
    38: {  # 'V'
        23: 1,  # 'A'
        37: 1,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 2,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 1,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 0,  # 'k'
        5: 2,  # 'l'
        13: 2,  # 'm'
        4: 0,  # 'n'
        15: 2,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 1,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 1,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 1,  # ''
        55: 0,  # ''
        59: 1,  # ''
        33: 2,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 1,  # ''
        6: 3,  # ''
        40: 2,  # ''
        19: 1,  # ''
    },
    62: {  # 'W'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 0,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 0,  # 'd'
        2: 0,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 0,  # 'k'
        5: 0,  # 'l'
        13: 0,  # 'm'
        4: 0,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 0,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 0,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    43: {  # 'Y'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 2,  # 'F'
        36: 0,  # 'G'
        45: 1,  # 'H'
        53: 1,  # 'I'
        60: 0,  # 'J'
        16: 2,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 2,  # 'N'
        42: 0,  # 'O'
        48: 2,  # 'P'
        44: 1,  # 'R'
        35: 1,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 2,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 1,  # 'j'
        10: 1,  # 'k'
        5: 1,  # 'l'
        13: 3,  # 'm'
        4: 0,  # 'n'
        15: 2,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 1,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 2,  # ''
        55: 1,  # ''
        59: 1,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 1,  # ''
        6: 0,  # ''
        40: 2,  # ''
        19: 1,  # ''
    },
    56: {  # 'Z'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 2,  # 'Z'
        1: 2,  # 'a'
        21: 1,  # 'b'
        28: 0,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 2,  # 'i'
        24: 1,  # 'j'
        10: 0,  # 'k'
        5: 0,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 1,  # 'r'
        8: 1,  # 's'
        9: 0,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 1,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 1,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    1: {  # 'a'
        23: 3,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 3,  # 'E'
        52: 0,  # 'F'
        36: 1,  # 'G'
        45: 1,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 1,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 3,  # 'T'
        51: 0,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 2,  # 'Z'
        1: 2,  # 'a'
        21: 3,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 2,  # 'e'
        18: 3,  # 'f'
        27: 3,  # 'g'
        25: 3,  # 'h'
        3: 3,  # 'i'
        24: 3,  # 'j'
        10: 3,  # 'k'
        5: 0,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        15: 1,  # 'o'
        26: 3,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 3,  # 'v'
        57: 2,  # 'w'
        58: 0,  # 'x'
        11: 3,  # 'y'
        22: 0,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 1,  # ''
        34: 1,  # ''
        17: 3,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 1,  # ''
    },
    21: {  # 'b'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 1,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 1,  # 'J'
        16: 2,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 1,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 2,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 3,  # 'g'
        25: 1,  # 'h'
        3: 3,  # 'i'
        24: 2,  # 'j'
        10: 3,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 3,  # 'p'
        7: 1,  # 'r'
        8: 2,  # 's'
        9: 2,  # 't'
        14: 2,  # 'u'
        32: 1,  # 'v'
        57: 0,  # 'w'
        58: 1,  # 'x'
        11: 3,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    28: {  # 'c'
        23: 0,  # 'A'
        37: 1,  # 'B'
        47: 1,  # 'C'
        39: 1,  # 'D'
        29: 2,  # 'E'
        52: 0,  # 'F'
        36: 2,  # 'G'
        45: 2,  # 'H'
        53: 1,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 1,  # 'N'
        42: 1,  # 'O'
        48: 2,  # 'P'
        44: 1,  # 'R'
        35: 1,  # 'S'
        31: 2,  # 'T'
        51: 2,  # 'U'
        38: 2,  # 'V'
        62: 0,  # 'W'
        43: 3,  # 'Y'
        56: 0,  # 'Z'
        1: 1,  # 'a'
        21: 1,  # 'b'
        28: 2,  # 'c'
        12: 2,  # 'd'
        2: 1,  # 'e'
        18: 1,  # 'f'
        27: 2,  # 'g'
        25: 2,  # 'h'
        3: 3,  # 'i'
        24: 1,  # 'j'
        10: 3,  # 'k'
        5: 0,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        15: 2,  # 'o'
        26: 2,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 1,  # 'u'
        32: 0,  # 'v'
        57: 1,  # 'w'
        58: 0,  # 'x'
        11: 2,  # 'y'
        22: 1,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 1,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 1,  # ''
        34: 2,  # ''
        17: 2,  # ''
        30: 2,  # ''
        41: 1,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 2,  # ''
    },
    12: {  # 'd'
        23: 1,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 2,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 1,  # 'S'
        31: 1,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 2,  # 'b'
        28: 1,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 1,  # 'f'
        27: 3,  # 'g'
        25: 3,  # 'h'
        3: 2,  # 'i'
        24: 3,  # 'j'
        10: 2,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 1,  # 'o'
        26: 2,  # 'p'
        7: 3,  # 'r'
        8: 2,  # 's'
        9: 2,  # 't'
        14: 3,  # 'u'
        32: 1,  # 'v'
        57: 0,  # 'w'
        58: 1,  # 'x'
        11: 3,  # 'y'
        22: 1,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 1,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    2: {  # 'e'
        23: 2,  # 'A'
        37: 0,  # 'B'
        47: 2,  # 'C'
        39: 0,  # 'D'
        29: 3,  # 'E'
        52: 1,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 1,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 1,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 1,  # 'R'
        35: 0,  # 'S'
        31: 3,  # 'T'
        51: 0,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 3,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 2,  # 'e'
        18: 3,  # 'f'
        27: 3,  # 'g'
        25: 3,  # 'h'
        3: 3,  # 'i'
        24: 3,  # 'j'
        10: 3,  # 'k'
        5: 0,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        15: 1,  # 'o'
        26: 3,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 3,  # 'v'
        57: 2,  # 'w'
        58: 0,  # 'x'
        11: 3,  # 'y'
        22: 1,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 3,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    18: {  # 'f'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 2,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 2,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 1,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 2,  # 'f'
        27: 1,  # 'g'
        25: 1,  # 'h'
        3: 1,  # 'i'
        24: 1,  # 'j'
        10: 1,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 2,  # 'p'
        7: 1,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 1,  # 'u'
        32: 2,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 1,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 1,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 1,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    27: {  # 'g'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 1,  # 'S'
        31: 1,  # 'T'
        51: 0,  # 'U'
        38: 2,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 1,  # 'b'
        28: 0,  # 'c'
        12: 1,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 2,  # 'g'
        25: 1,  # 'h'
        3: 2,  # 'i'
        24: 3,  # 'j'
        10: 2,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 2,  # 'n'
        15: 0,  # 'o'
        26: 1,  # 'p'
        7: 2,  # 'r'
        8: 2,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 1,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 1,  # 'y'
        22: 0,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    25: {  # 'h'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 2,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 2,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 1,  # 'g'
        25: 2,  # 'h'
        3: 2,  # 'i'
        24: 3,  # 'j'
        10: 3,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 1,  # 'o'
        26: 1,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 2,  # 't'
        14: 3,  # 'u'
        32: 2,  # 'v'
        57: 1,  # 'w'
        58: 0,  # 'x'
        11: 1,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    3: {  # 'i'
        23: 2,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 1,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 0,  # 'N'
        42: 1,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 1,  # 'S'
        31: 2,  # 'T'
        51: 0,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 2,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 2,  # 'f'
        27: 3,  # 'g'
        25: 1,  # 'h'
        3: 3,  # 'i'
        24: 2,  # 'j'
        10: 3,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 1,  # 'o'
        26: 3,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 2,  # 'v'
        57: 1,  # 'w'
        58: 1,  # 'x'
        11: 3,  # 'y'
        22: 1,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 1,  # ''
        59: 0,  # ''
        33: 2,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 3,  # ''
        30: 0,  # ''
        41: 1,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    24: {  # 'j'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 1,  # 'J'
        16: 2,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 1,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 1,  # 'Z'
        1: 3,  # 'a'
        21: 1,  # 'b'
        28: 1,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 2,  # 'f'
        27: 1,  # 'g'
        25: 1,  # 'h'
        3: 2,  # 'i'
        24: 1,  # 'j'
        10: 2,  # 'k'
        5: 2,  # 'l'
        13: 3,  # 'm'
        4: 2,  # 'n'
        15: 0,  # 'o'
        26: 1,  # 'p'
        7: 2,  # 'r'
        8: 3,  # 's'
        9: 2,  # 't'
        14: 3,  # 'u'
        32: 2,  # 'v'
        57: 0,  # 'w'
        58: 2,  # 'x'
        11: 1,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 1,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    10: {  # 'k'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 3,  # 'T'
        51: 0,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 1,  # 'Z'
        1: 3,  # 'a'
        21: 2,  # 'b'
        28: 0,  # 'c'
        12: 2,  # 'd'
        2: 3,  # 'e'
        18: 1,  # 'f'
        27: 2,  # 'g'
        25: 2,  # 'h'
        3: 3,  # 'i'
        24: 2,  # 'j'
        10: 2,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 3,  # 'p'
        7: 2,  # 'r'
        8: 2,  # 's'
        9: 2,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 1,  # 'x'
        11: 3,  # 'y'
        22: 0,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 3,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 3,  # ''
        30: 1,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 1,  # ''
    },
    5: {  # 'l'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 3,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 1,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 0,  # 'a'
        21: 3,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 1,  # 'e'
        18: 3,  # 'f'
        27: 3,  # 'g'
        25: 2,  # 'h'
        3: 3,  # 'i'
        24: 2,  # 'j'
        10: 3,  # 'k'
        5: 1,  # 'l'
        13: 1,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 2,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 2,  # 'u'
        32: 2,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 3,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 2,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    13: {  # 'm'
        23: 1,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 3,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 3,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 0,  # 'Z'
        1: 2,  # 'a'
        21: 3,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 2,  # 'e'
        18: 3,  # 'f'
        27: 3,  # 'g'
        25: 3,  # 'h'
        3: 3,  # 'i'
        24: 3,  # 'j'
        10: 3,  # 'k'
        5: 0,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        15: 1,  # 'o'
        26: 2,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 2,  # 'u'
        32: 2,  # 'v'
        57: 1,  # 'w'
        58: 0,  # 'x'
        11: 3,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 3,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 1,  # ''
    },
    4: {  # 'n'
        23: 1,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 1,  # 'H'
        53: 0,  # 'I'
        60: 2,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 2,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 2,  # 'b'
        28: 1,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 1,  # 'f'
        27: 2,  # 'g'
        25: 3,  # 'h'
        3: 2,  # 'i'
        24: 2,  # 'j'
        10: 3,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 1,  # 'o'
        26: 3,  # 'p'
        7: 2,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 2,  # 'v'
        57: 0,  # 'w'
        58: 2,  # 'x'
        11: 3,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 2,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 1,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    15: {  # 'o'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 2,  # 'F'
        36: 1,  # 'G'
        45: 1,  # 'H'
        53: 1,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 2,  # 'L'
        20: 0,  # 'M'
        46: 2,  # 'N'
        42: 1,  # 'O'
        48: 2,  # 'P'
        44: 1,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 1,  # 'i'
        24: 2,  # 'j'
        10: 1,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 2,  # 'n'
        15: 2,  # 'o'
        26: 0,  # 'p'
        7: 1,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 2,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 2,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 3,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 2,  # ''
        41: 2,  # ''
        6: 3,  # ''
        40: 2,  # ''
        19: 2,  # ''
    },
    26: {  # 'p'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 1,  # 'b'
        28: 0,  # 'c'
        12: 1,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 1,  # 'g'
        25: 1,  # 'h'
        3: 2,  # 'i'
        24: 3,  # 'j'
        10: 1,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 2,  # 'n'
        15: 0,  # 'o'
        26: 2,  # 'p'
        7: 2,  # 'r'
        8: 1,  # 's'
        9: 1,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 1,  # 'x'
        11: 1,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 3,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 1,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    7: {  # 'r'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 1,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 2,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 2,  # 'T'
        51: 1,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 1,  # 'Z'
        1: 3,  # 'a'
        21: 1,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 2,  # 'g'
        25: 3,  # 'h'
        3: 2,  # 'i'
        24: 2,  # 'j'
        10: 3,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 2,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 2,  # 'v'
        57: 0,  # 'w'
        58: 1,  # 'x'
        11: 2,  # 'y'
        22: 0,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 2,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 3,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    8: {  # 's'
        23: 1,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 1,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 2,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 1,  # 'Z'
        1: 3,  # 'a'
        21: 2,  # 'b'
        28: 1,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 2,  # 'g'
        25: 2,  # 'h'
        3: 2,  # 'i'
        24: 3,  # 'j'
        10: 3,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 3,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 2,  # 'v'
        57: 0,  # 'w'
        58: 1,  # 'x'
        11: 2,  # 'y'
        22: 1,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 2,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 2,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 1,  # ''
    },
    9: {  # 't'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 1,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 2,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 1,  # 'Z'
        1: 3,  # 'a'
        21: 3,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 2,  # 'f'
        27: 2,  # 'g'
        25: 2,  # 'h'
        3: 2,  # 'i'
        24: 2,  # 'j'
        10: 3,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 2,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 3,  # 'v'
        57: 0,  # 'w'
        58: 2,  # 'x'
        11: 2,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 3,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 2,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    14: {  # 'u'
        23: 3,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 3,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 1,  # 'H'
        53: 0,  # 'I'
        60: 1,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 2,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 3,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 2,  # 'Z'
        1: 2,  # 'a'
        21: 3,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 2,  # 'e'
        18: 2,  # 'f'
        27: 3,  # 'g'
        25: 3,  # 'h'
        3: 3,  # 'i'
        24: 2,  # 'j'
        10: 3,  # 'k'
        5: 0,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 3,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 2,  # 'v'
        57: 2,  # 'w'
        58: 0,  # 'x'
        11: 3,  # 'y'
        22: 0,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 3,  # ''
        30: 1,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    32: {  # 'v'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 1,  # 'j'
        10: 1,  # 'k'
        5: 3,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 1,  # 'p'
        7: 1,  # 'r'
        8: 2,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 1,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 2,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 1,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    57: {  # 'w'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 1,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 1,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 1,  # 'k'
        5: 0,  # 'l'
        13: 0,  # 'm'
        4: 1,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 1,  # 's'
        9: 0,  # 't'
        14: 1,  # 'u'
        32: 0,  # 'v'
        57: 2,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 0,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 1,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 0,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    58: {  # 'x'
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 1,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 1,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 0,  # 'a'
        21: 1,  # 'b'
        28: 0,  # 'c'
        12: 2,  # 'd'
        2: 1,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 2,  # 'i'
        24: 2,  # 'j'
        10: 1,  # 'k'
        5: 0,  # 'l'
        13: 0,  # 'm'
        4: 2,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 1,  # 'r'
        8: 2,  # 's'
        9: 1,  # 't'
        14: 0,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 2,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 1,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    11: {  # 'y'
        23: 1,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 1,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 1,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 1,  # 'Z'
        1: 3,  # 'a'
        21: 1,  # 'b'
        28: 0,  # 'c'
        12: 2,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 2,  # 'g'
        25: 2,  # 'h'
        3: 2,  # 'i'
        24: 1,  # 'j'
        10: 2,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 1,  # 'p'
        7: 2,  # 'r'
        8: 1,  # 's'
        9: 2,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 1,  # 'x'
        11: 3,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 3,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 2,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    22: {  # 'z'
        23: 2,  # 'A'
        37: 2,  # 'B'
        47: 1,  # 'C'
        39: 2,  # 'D'
        29: 3,  # 'E'
        52: 1,  # 'F'
        36: 2,  # 'G'
        45: 2,  # 'H'
        53: 1,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 2,  # 'N'
        42: 2,  # 'O'
        48: 2,  # 'P'
        44: 1,  # 'R'
        35: 1,  # 'S'
        31: 3,  # 'T'
        51: 2,  # 'U'
        38: 2,  # 'V'
        62: 0,  # 'W'
        43: 2,  # 'Y'
        56: 1,  # 'Z'
        1: 1,  # 'a'
        21: 2,  # 'b'
        28: 1,  # 'c'
        12: 2,  # 'd'
        2: 2,  # 'e'
        18: 3,  # 'f'
        27: 2,  # 'g'
        25: 2,  # 'h'
        3: 3,  # 'i'
        24: 2,  # 'j'
        10: 3,  # 'k'
        5: 0,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        15: 2,  # 'o'
        26: 2,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 0,  # 'u'
        32: 2,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 3,  # 'y'
        22: 2,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 2,  # ''
        59: 1,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 2,  # ''
        17: 2,  # ''
        30: 2,  # ''
        41: 1,  # ''
        6: 3,  # ''
        40: 1,  # ''
        19: 2,  # ''
    },
    63: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 0,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 0,  # 'd'
        2: 1,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 0,  # 'k'
        5: 0,  # 'l'
        13: 2,  # 'm'
        4: 0,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 0,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    54: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 1,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 1,  # 'G'
        45: 1,  # 'H'
        53: 1,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 1,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 2,  # 'Y'
        56: 0,  # 'Z'
        1: 0,  # 'a'
        21: 1,  # 'b'
        28: 0,  # 'c'
        12: 1,  # 'd'
        2: 0,  # 'e'
        18: 0,  # 'f'
        27: 1,  # 'g'
        25: 0,  # 'h'
        3: 3,  # 'i'
        24: 0,  # 'j'
        10: 1,  # 'k'
        5: 0,  # 'l'
        13: 0,  # 'm'
        4: 2,  # 'n'
        15: 1,  # 'o'
        26: 0,  # 'p'
        7: 2,  # 'r'
        8: 0,  # 's'
        9: 1,  # 't'
        14: 0,  # 'u'
        32: 2,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 2,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 1,  # ''
    },
    50: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 1,  # 'D'
        29: 2,  # 'E'
        52: 0,  # 'F'
        36: 1,  # 'G'
        45: 2,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 1,  # 'N'
        42: 2,  # 'O'
        48: 2,  # 'P'
        44: 1,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 2,  # 'Y'
        56: 0,  # 'Z'
        1: 0,  # 'a'
        21: 2,  # 'b'
        28: 1,  # 'c'
        12: 2,  # 'd'
        2: 0,  # 'e'
        18: 1,  # 'f'
        27: 1,  # 'g'
        25: 1,  # 'h'
        3: 2,  # 'i'
        24: 0,  # 'j'
        10: 2,  # 'k'
        5: 0,  # 'l'
        13: 0,  # 'm'
        4: 3,  # 'n'
        15: 2,  # 'o'
        26: 2,  # 'p'
        7: 3,  # 'r'
        8: 1,  # 's'
        9: 2,  # 't'
        14: 0,  # 'u'
        32: 1,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 1,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 2,  # ''
        17: 2,  # ''
        30: 1,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 1,  # ''
    },
    55: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 2,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 1,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 1,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 2,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 1,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 0,  # 'k'
        5: 1,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 1,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 1,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 1,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 1,  # ''
        6: 0,  # ''
        40: 0,  # ''
        19: 1,  # ''
    },
    59: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 1,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 1,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 2,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 0,  # 'j'
        10: 0,  # 'k'
        5: 0,  # 'l'
        13: 2,  # 'm'
        4: 0,  # 'n'
        15: 1,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 2,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 1,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 1,  # ''
        40: 1,  # ''
        19: 0,  # ''
    },
    33: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 3,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 2,  # 'T'
        51: 0,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 0,  # 'Z'
        1: 0,  # 'a'
        21: 3,  # 'b'
        28: 0,  # 'c'
        12: 2,  # 'd'
        2: 0,  # 'e'
        18: 2,  # 'f'
        27: 1,  # 'g'
        25: 3,  # 'h'
        3: 3,  # 'i'
        24: 0,  # 'j'
        10: 3,  # 'k'
        5: 0,  # 'l'
        13: 0,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 1,  # 'p'
        7: 3,  # 'r'
        8: 2,  # 's'
        9: 3,  # 't'
        14: 0,  # 'u'
        32: 2,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 2,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 1,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    61: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 0,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 0,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 1,  # 'Z'
        1: 2,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 1,  # 'j'
        10: 0,  # 'k'
        5: 0,  # 'l'
        13: 1,  # 'm'
        4: 1,  # 'n'
        15: 0,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 1,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 1,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 1,  # ''
        34: 0,  # ''
        17: 0,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 1,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    34: {  # ''
        23: 0,  # 'A'
        37: 1,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 2,  # 'F'
        36: 1,  # 'G'
        45: 1,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 1,  # 'L'
        20: 0,  # 'M'
        46: 1,  # 'N'
        42: 1,  # 'O'
        48: 2,  # 'P'
        44: 1,  # 'R'
        35: 1,  # 'S'
        31: 1,  # 'T'
        51: 1,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 1,  # 'Z'
        1: 3,  # 'a'
        21: 1,  # 'b'
        28: 2,  # 'c'
        12: 1,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 2,  # 'g'
        25: 2,  # 'h'
        3: 1,  # 'i'
        24: 2,  # 'j'
        10: 1,  # 'k'
        5: 2,  # 'l'
        13: 3,  # 'm'
        4: 2,  # 'n'
        15: 2,  # 'o'
        26: 0,  # 'p'
        7: 0,  # 'r'
        8: 3,  # 's'
        9: 1,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 1,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 2,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 2,  # ''
        61: 0,  # ''
        34: 2,  # ''
        17: 0,  # ''
        30: 2,  # ''
        41: 1,  # ''
        6: 1,  # ''
        40: 2,  # ''
        19: 1,  # ''
    },
    17: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 0,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 1,  # 'J'
        16: 1,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 0,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 1,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 0,  # 'Y'
        56: 1,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 0,  # 'c'
        12: 1,  # 'd'
        2: 3,  # 'e'
        18: 1,  # 'f'
        27: 2,  # 'g'
        25: 0,  # 'h'
        3: 1,  # 'i'
        24: 1,  # 'j'
        10: 2,  # 'k'
        5: 3,  # 'l'
        13: 2,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 2,  # 'p'
        7: 2,  # 'r'
        8: 3,  # 's'
        9: 2,  # 't'
        14: 3,  # 'u'
        32: 1,  # 'v'
        57: 1,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 2,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    30: {  # ''
        23: 0,  # 'A'
        37: 2,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 2,  # 'F'
        36: 1,  # 'G'
        45: 0,  # 'H'
        53: 1,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 1,  # 'M'
        46: 2,  # 'N'
        42: 2,  # 'O'
        48: 1,  # 'P'
        44: 1,  # 'R'
        35: 0,  # 'S'
        31: 1,  # 'T'
        51: 0,  # 'U'
        38: 2,  # 'V'
        62: 0,  # 'W'
        43: 2,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 0,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 2,  # 'e'
        18: 0,  # 'f'
        27: 0,  # 'g'
        25: 0,  # 'h'
        3: 0,  # 'i'
        24: 3,  # 'j'
        10: 1,  # 'k'
        5: 2,  # 'l'
        13: 3,  # 'm'
        4: 0,  # 'n'
        15: 1,  # 'o'
        26: 0,  # 'p'
        7: 1,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 2,  # ''
        50: 2,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 0,  # ''
        34: 2,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 2,  # ''
        6: 2,  # ''
        40: 2,  # ''
        19: 1,  # ''
    },
    41: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 1,  # 'D'
        29: 1,  # 'E'
        52: 0,  # 'F'
        36: 2,  # 'G'
        45: 2,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 1,  # 'N'
        42: 1,  # 'O'
        48: 2,  # 'P'
        44: 0,  # 'R'
        35: 1,  # 'S'
        31: 1,  # 'T'
        51: 1,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 2,  # 'Y'
        56: 0,  # 'Z'
        1: 1,  # 'a'
        21: 2,  # 'b'
        28: 1,  # 'c'
        12: 2,  # 'd'
        2: 1,  # 'e'
        18: 0,  # 'f'
        27: 3,  # 'g'
        25: 2,  # 'h'
        3: 2,  # 'i'
        24: 2,  # 'j'
        10: 2,  # 'k'
        5: 0,  # 'l'
        13: 1,  # 'm'
        4: 3,  # 'n'
        15: 1,  # 'o'
        26: 1,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 2,  # 't'
        14: 0,  # 'u'
        32: 0,  # 'v'
        57: 1,  # 'w'
        58: 0,  # 'x'
        11: 2,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 1,  # ''
        59: 1,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 1,  # ''
        17: 1,  # ''
        30: 2,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 1,  # ''
    },
    6: {  # ''
        23: 2,  # 'A'
        37: 0,  # 'B'
        47: 0,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 0,  # 'F'
        36: 1,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 2,  # 'J'
        16: 3,  # 'K'
        49: 0,  # 'L'
        20: 3,  # 'M'
        46: 1,  # 'N'
        42: 0,  # 'O'
        48: 0,  # 'P'
        44: 0,  # 'R'
        35: 0,  # 'S'
        31: 2,  # 'T'
        51: 0,  # 'U'
        38: 0,  # 'V'
        62: 0,  # 'W'
        43: 2,  # 'Y'
        56: 1,  # 'Z'
        1: 3,  # 'a'
        21: 2,  # 'b'
        28: 1,  # 'c'
        12: 3,  # 'd'
        2: 3,  # 'e'
        18: 3,  # 'f'
        27: 3,  # 'g'
        25: 2,  # 'h'
        3: 3,  # 'i'
        24: 3,  # 'j'
        10: 3,  # 'k'
        5: 3,  # 'l'
        13: 3,  # 'm'
        4: 3,  # 'n'
        15: 0,  # 'o'
        26: 3,  # 'p'
        7: 3,  # 'r'
        8: 3,  # 's'
        9: 3,  # 't'
        14: 3,  # 'u'
        32: 3,  # 'v'
        57: 1,  # 'w'
        58: 1,  # 'x'
        11: 3,  # 'y'
        22: 0,  # 'z'
        63: 1,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 2,  # ''
        61: 0,  # ''
        34: 0,  # ''
        17: 3,  # ''
        30: 0,  # ''
        41: 0,  # ''
        6: 3,  # ''
        40: 0,  # ''
        19: 0,  # ''
    },
    40: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 1,  # 'D'
        29: 1,  # 'E'
        52: 0,  # 'F'
        36: 1,  # 'G'
        45: 2,  # 'H'
        53: 1,  # 'I'
        60: 0,  # 'J'
        16: 0,  # 'K'
        49: 0,  # 'L'
        20: 2,  # 'M'
        46: 1,  # 'N'
        42: 1,  # 'O'
        48: 2,  # 'P'
        44: 2,  # 'R'
        35: 1,  # 'S'
        31: 1,  # 'T'
        51: 0,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 2,  # 'Y'
        56: 1,  # 'Z'
        1: 0,  # 'a'
        21: 2,  # 'b'
        28: 0,  # 'c'
        12: 2,  # 'd'
        2: 0,  # 'e'
        18: 3,  # 'f'
        27: 0,  # 'g'
        25: 2,  # 'h'
        3: 3,  # 'i'
        24: 2,  # 'j'
        10: 1,  # 'k'
        5: 0,  # 'l'
        13: 1,  # 'm'
        4: 3,  # 'n'
        15: 2,  # 'o'
        26: 0,  # 'p'
        7: 3,  # 'r'
        8: 2,  # 's'
        9: 2,  # 't'
        14: 1,  # 'u'
        32: 3,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 2,  # 'y'
        22: 0,  # 'z'
        63: 0,  # ''
        54: 0,  # ''
        50: 0,  # ''
        55: 1,  # ''
        59: 0,  # ''
        33: 0,  # ''
        61: 0,  # ''
        34: 2,  # ''
        17: 1,  # ''
        30: 2,  # ''
        41: 0,  # ''
        6: 2,  # ''
        40: 1,  # ''
        19: 2,  # ''
    },
    19: {  # ''
        23: 0,  # 'A'
        37: 0,  # 'B'
        47: 1,  # 'C'
        39: 0,  # 'D'
        29: 0,  # 'E'
        52: 2,  # 'F'
        36: 1,  # 'G'
        45: 0,  # 'H'
        53: 0,  # 'I'
        60: 0,  # 'J'
        16: 3,  # 'K'
        49: 2,  # 'L'
        20: 0,  # 'M'
        46: 1,  # 'N'
        42: 1,  # 'O'
        48: 1,  # 'P'
        44: 1,  # 'R'
        35: 1,  # 'S'
        31: 0,  # 'T'
        51: 1,  # 'U'
        38: 1,  # 'V'
        62: 0,  # 'W'
        43: 1,  # 'Y'
        56: 0,  # 'Z'
        1: 3,  # 'a'
        21: 1,  # 'b'
        28: 2,  # 'c'
        12: 0,  # 'd'
        2: 3,  # 'e'
        18: 0,  # 'f'
        27: 2,  # 'g'
        25: 1,  # 'h'
        3: 1,  # 'i'
        24: 0,  # 'j'
        10: 2,  # 'k'
        5: 2,  # 'l'
        13: 3,  # 'm'
        4: 0,  # 'n'
        15: 0,  # 'o'
        26: 1,  # 'p'
        7: 3,  # 'r'
        8: 0,  # 's'
        9: 0,  # 't'
        14: 3,  # 'u'
        32: 0,  # 'v'
        57: 0,  # 'w'
        58: 0,  # 'x'
        11: 0,  # 'y'
        22: 2,  # 'z'
        63: 0,  # ''
        54: 1,  # ''
        50: 2,  # ''
        55: 0,  # ''
        59: 0,  # ''
        33: 1,  # ''
        61: 1,  # ''
        34: 2,  # ''
        17: 0,  # ''
        30: 1,  # ''
        41: 1,  # ''
        6: 1,  # ''
        40: 1,  # ''
        19: 1,  # ''
    },
}

# 255: Undefined characters that did not exist in training text
# 254: Carriage/Return
# 253: symbol (punctuation) that does not belong to word
# 252: 0 - 9
# 251: Control characters

# Character Mapping Table(s):
ISO_8859_9_TURKISH_CHAR_TO_ORDER = {
     0: 255,  # '\x00'
     1: 255,  # '\x01'
     2: 255,  # '\x02'
     3: 255,  # '\x03'
     4: 255,  # '\x04'
     5: 255,  # '\x05'
     6: 255,  # '\x06'
     7: 255,  # '\x07'
     8: 255,  # '\x08'
     9: 255,  # '\t'
     10: 255,  # '\n'
     11: 255,  # '\x0b'
     12: 255,  # '\x0c'
     13: 255,  # '\r'
     14: 255,  # '\x0e'
     15: 255,  # '\x0f'
     16: 255,  # '\x10'
     17: 255,  # '\x11'
     18: 255,  # '\x12'
     19: 255,  # '\x13'
     20: 255,  # '\x14'
     21: 255,  # '\x15'
     22: 255,  # '\x16'
     23: 255,  # '\x17'
     24: 255,  # '\x18'
     25: 255,  # '\x19'
     26: 255,  # '\x1a'
     27: 255,  # '\x1b'
     28: 255,  # '\x1c'
     29: 255,  # '\x1d'
     30: 255,  # '\x1e'
     31: 255,  # '\x1f'
     32: 255,  # ' '
     33: 255,  # '!'
     34: 255,  # '"'
     35: 255,  # '#'
     36: 255,  # '$'
     37: 255,  # '%'
     38: 255,  # '&'
     39: 255,  # "'"
     40: 255,  # '('
     41: 255,  # ')'
     42: 255,  # '*'
     43: 255,  # '+'
     44: 255,  # ','
     45: 255,  # '-'
     46: 255,  # '.'
     47: 255,  # '/'
     48: 255,  # '0'
     49: 255,  # '1'
     50: 255,  # '2'
     51: 255,  # '3'
     52: 255,  # '4'
     53: 255,  # '5'
     54: 255,  # '6'
     55: 255,  # '7'
     56: 255,  # '8'
     57: 255,  # '9'
     58: 255,  # ':'
     59: 255,  # ';'
     60: 255,  # '<'
     61: 255,  # '='
     62: 255,  # '>'
     63: 255,  # '?'
     64: 255,  # '@'
     65: 23,  # 'A'
     66: 37,  # 'B'
     67: 47,  # 'C'
     68: 39,  # 'D'
     69: 29,  # 'E'
     70: 52,  # 'F'
     71: 36,  # 'G'
     72: 45,  # 'H'
     73: 53,  # 'I'
     74: 60,  # 'J'
     75: 16,  # 'K'
     76: 49,  # 'L'
     77: 20,  # 'M'
     78: 46,  # 'N'
     79: 42,  # 'O'
     80: 48,  # 'P'
     81: 69,  # 'Q'
     82: 44,  # 'R'
     83: 35,  # 'S'
     84: 31,  # 'T'
     85: 51,  # 'U'
     86: 38,  # 'V'
     87: 62,  # 'W'
     88: 65,  # 'X'
     89: 43,  # 'Y'
     90: 56,  # 'Z'
     91: 255,  # '['
     92: 255,  # '\\'
     93: 255,  # ']'
     94: 255,  # '^'
     95: 255,  # '_'
     96: 255,  # '`'
     97: 1,  # 'a'
     98: 21,  # 'b'
     99: 28,  # 'c'
     100: 12,  # 'd'
     101: 2,  # 'e'
     102: 18,  # 'f'
     103: 27,  # 'g'
     104: 25,  # 'h'
     105: 3,  # 'i'
     106: 24,  # 'j'
     107: 10,  # 'k'
     108: 5,  # 'l'
     109: 13,  # 'm'
     110: 4,  # 'n'
     111: 15,  # 'o'
     112: 26,  # 'p'
     113: 64,  # 'q'
     114: 7,  # 'r'
     115: 8,  # 's'
     116: 9,  # 't'
     117: 14,  # 'u'
     118: 32,  # 'v'
     119: 57,  # 'w'
     120: 58,  # 'x'
     121: 11,  # 'y'
     122: 22,  # 'z'
     123: 255,  # '{'
     124: 255,  # '|'
     125: 255,  # '}'
     126: 255,  # '~'
     127: 255,  # '\x7f'
     128: 180,  # '\x80'
     129: 179,  # '\x81'
     130: 178,  # '\x82'
     131: 177,  # '\x83'
     132: 176,  # '\x84'
     133: 175,  # '\x85'
     134: 174,  # '\x86'
     135: 173,  # '\x87'
     136: 172,  # '\x88'
     137: 171,  # '\x89'
     138: 170,  # '\x8a'
     139: 169,  # '\x8b'
     140: 168,  # '\x8c'
     141: 167,  # '\x8d'
     142: 166,  # '\x8e'
     143: 165,  # '\x8f'
     144: 164,  # '\x90'
     145: 163,  # '\x91'
     146: 162,  # '\x92'
     147: 161,  # '\x93'
     148: 160,  # '\x94'
     149: 159,  # '\x95'
     150: 101,  # '\x96'
     151: 158,  # '\x97'
     152: 157,  # '\x98'
     153: 156,  # '\x99'
     154: 155,  # '\x9a'
     155: 154,  # '\x9b'
     156: 153,  # '\x9c'
     157: 152,  # '\x9d'
     158: 151,  # '\x9e'
     159: 106,  # '\x9f'
     160: 150,  # '\xa0'
     161: 149,  # ''
     162: 148,  # ''
     163: 147,  # ''
     164: 146,  # ''
     165: 145,  # ''
     166: 144,  # ''
     167: 100,  # ''
     168: 143,  # ''
     169: 142,  # ''
     170: 141,  # ''
     171: 140,  # ''
     172: 139,  # ''
     173: 138,  # '\xad'
     174: 137,  # ''
     175: 136,  # ''
     176: 94,  # ''
     177: 80,  # ''
     178: 93,  # ''
     179: 135,  # ''
     180: 105,  # ''
     181: 134,  # ''
     182: 133,  # ''
     183: 63,  # ''
     184: 132,  # ''
     185: 131,  # ''
     186: 130,  # ''
     187: 129,  # ''
     188: 128,  # ''
     189: 127,  # ''
     190: 126,  # ''
     191: 125,  # ''
     192: 124,  # ''
     193: 104,  # ''
     194: 73,  # ''
     195: 99,  # ''
     196: 79,  # ''
     197: 85,  # ''
     198: 123,  # ''
     199: 54,  # ''
     200: 122,  # ''
     201: 98,  # ''
     202: 92,  # ''
     203: 121,  # ''
     204: 120,  # ''
     205: 91,  # ''
     206: 103,  # ''
     207: 119,  # ''
     208: 68,  # ''
     209: 118,  # ''
     210: 117,  # ''
     211: 97,  # ''
     212: 116,  # ''
     213: 115,  # ''
     214: 50,  # ''
     215: 90,  # ''
     216: 114,  # ''
     217: 113,  # ''
     218: 112,  # ''
     219: 111,  # ''
     220: 55,  # ''
     221: 41,  # ''
     222: 40,  # ''
     223: 86,  # ''
     224: 89,  # ''
     225: 70,  # ''
     226: 59,  # ''
     227: 78,  # ''
     228: 71,  # ''
     229: 82,  # ''
     230: 88,  # ''
     231: 33,  # ''
     232: 77,  # ''
     233: 66,  # ''
     234: 84,  # ''
     235: 83,  # ''
     236: 110,  # ''
     237: 75,  # ''
     238: 61,  # ''
     239: 96,  # ''
     240: 30,  # ''
     241: 67,  # ''
     242: 109,  # ''
     243: 74,  # ''
     244: 87,  # ''
     245: 102,  # ''
     246: 34,  # ''
     247: 95,  # ''
     248: 81,  # ''
     249: 108,  # ''
     250: 76,  # ''
     251: 72,  # ''
     252: 17,  # ''
     253: 6,  # ''
     254: 19,  # ''
     255: 107,  # ''
}

ISO_8859_9_TURKISH_MODEL = SingleByteCharSetModel(charset_name='ISO-8859-9',
                                                  language='Turkish',
                                                  char_to_order_map=ISO_8859_9_TURKISH_CHAR_TO_ORDER,
                                                  language_model=TURKISH_LANG_MODEL,
                                                  typical_positive_ratio=0.97029,
                                                  keep_ascii_letters=True,
                                                  alphabet='ABCDEFGHIJKLMNOPRSTUVYZabcdefghijklmnoprstuvyz')





############################################################
### File: language.py
############################################################
from slyguy.language import BaseLanguage


class Language(BaseLanguage):
    LAT_LONG              = 30001
    HIDE_CLIPS            = 30002
    NEWS                  = 30008
    CATEGORIES            = 30009
    FEATURED              = 30012
    SHOWS_LETTER          = 30013
    HIDE_SUGGESTED        = 30014
    FLATTEN_SINGLE_SEASON = 30015
    SUGGESTED             = 30016
    NO_VIDEO              = 30018
    SEASON                = 30019


_ = Language()




############################################################
### File: latin1prober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetprober import CharSetProber
from .enums import ProbingState

FREQ_CAT_NUM = 4

UDF = 0  # undefined
OTH = 1  # other
ASC = 2  # ascii capital letter
ASS = 3  # ascii small letter
ACV = 4  # accent capital vowel
ACO = 5  # accent capital other
ASV = 6  # accent small vowel
ASO = 7  # accent small other
CLASS_NUM = 8  # total classes

Latin1_CharToClass = (
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 00 - 07
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 08 - 0F
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 10 - 17
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 18 - 1F
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 20 - 27
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 28 - 2F
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 30 - 37
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 38 - 3F
    OTH, ASC, ASC, ASC, ASC, ASC, ASC, ASC,   # 40 - 47
    ASC, ASC, ASC, ASC, ASC, ASC, ASC, ASC,   # 48 - 4F
    ASC, ASC, ASC, ASC, ASC, ASC, ASC, ASC,   # 50 - 57
    ASC, ASC, ASC, OTH, OTH, OTH, OTH, OTH,   # 58 - 5F
    OTH, ASS, ASS, ASS, ASS, ASS, ASS, ASS,   # 60 - 67
    ASS, ASS, ASS, ASS, ASS, ASS, ASS, ASS,   # 68 - 6F
    ASS, ASS, ASS, ASS, ASS, ASS, ASS, ASS,   # 70 - 77
    ASS, ASS, ASS, OTH, OTH, OTH, OTH, OTH,   # 78 - 7F
    OTH, UDF, OTH, ASO, OTH, OTH, OTH, OTH,   # 80 - 87
    OTH, OTH, ACO, OTH, ACO, UDF, ACO, UDF,   # 88 - 8F
    UDF, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # 90 - 97
    OTH, OTH, ASO, OTH, ASO, UDF, ASO, ACO,   # 98 - 9F
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # A0 - A7
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # A8 - AF
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # B0 - B7
    OTH, OTH, OTH, OTH, OTH, OTH, OTH, OTH,   # B8 - BF
    ACV, ACV, ACV, ACV, ACV, ACV, ACO, ACO,   # C0 - C7
    ACV, ACV, ACV, ACV, ACV, ACV, ACV, ACV,   # C8 - CF
    ACO, ACO, ACV, ACV, ACV, ACV, ACV, OTH,   # D0 - D7
    ACV, ACV, ACV, ACV, ACV, ACO, ACO, ACO,   # D8 - DF
    ASV, ASV, ASV, ASV, ASV, ASV, ASO, ASO,   # E0 - E7
    ASV, ASV, ASV, ASV, ASV, ASV, ASV, ASV,   # E8 - EF
    ASO, ASO, ASV, ASV, ASV, ASV, ASV, OTH,   # F0 - F7
    ASV, ASV, ASV, ASV, ASV, ASO, ASO, ASO,   # F8 - FF
)

# 0 : illegal
# 1 : very unlikely
# 2 : normal
# 3 : very likely
Latin1ClassModel = (
# UDF OTH ASC ASS ACV ACO ASV ASO
    0,  0,  0,  0,  0,  0,  0,  0,  # UDF
    0,  3,  3,  3,  3,  3,  3,  3,  # OTH
    0,  3,  3,  3,  3,  3,  3,  3,  # ASC
    0,  3,  3,  3,  1,  1,  3,  3,  # ASS
    0,  3,  3,  3,  1,  2,  1,  2,  # ACV
    0,  3,  3,  3,  3,  3,  3,  3,  # ACO
    0,  3,  1,  3,  1,  1,  1,  3,  # ASV
    0,  3,  1,  3,  1,  1,  3,  3,  # ASO
)


class Latin1Prober(CharSetProber):
    def __init__(self):
        super(Latin1Prober, self).__init__()
        self._last_char_class = None
        self._freq_counter = None
        self.reset()

    def reset(self):
        self._last_char_class = OTH
        self._freq_counter = [0] * FREQ_CAT_NUM
        CharSetProber.reset(self)

    @property
    def charset_name(self):
        return "ISO-8859-1"

    @property
    def language(self):
        return ""

    def feed(self, byte_str):
        byte_str = self.filter_with_english_letters(byte_str)
        for c in byte_str:
            char_class = Latin1_CharToClass[c]
            freq = Latin1ClassModel[(self._last_char_class * CLASS_NUM)
                                    + char_class]
            if freq == 0:
                self._state = ProbingState.NOT_ME
                break
            self._freq_counter[freq] += 1
            self._last_char_class = char_class

        return self.state

    def get_confidence(self):
        if self.state == ProbingState.NOT_ME:
            return 0.01

        total = sum(self._freq_counter)
        if total < 0.01:
            confidence = 0.0
        else:
            confidence = ((self._freq_counter[3] - self._freq_counter[1] * 20.0)
                          / total)
        if confidence < 0.0:
            confidence = 0.0
        # lower the confidence of latin1 so that other more accurate
        # detector can take priority.
        confidence = confidence * 0.73
        return confidence




############################################################
### File: lazy.py
############################################################
from threading import RLock
try:
    from collections.abc import Mapping as DictMixin
except ImportError:  # Python < 3.3
    try:
        from UserDict import DictMixin  # Python 2
    except ImportError:  # Python 3.0-3.3
        from collections import Mapping as DictMixin


# With lazy loading, we might end up with multiple threads triggering
# it at the same time. We need a lock.
_fill_lock = RLock()


class LazyDict(DictMixin):
    """Dictionary populated on first use."""
    data = None

    def __getitem__(self, key):
        if self.data is None:
            _fill_lock.acquire()
            try:
                if self.data is None:
                    self._fill()
            finally:
                _fill_lock.release()
        return self.data[key.upper()]

    def __contains__(self, key):
        if self.data is None:
            _fill_lock.acquire()
            try:
                if self.data is None:
                    self._fill()
            finally:
                _fill_lock.release()
        return key in self.data

    def __iter__(self):
        if self.data is None:
            _fill_lock.acquire()
            try:
                if self.data is None:
                    self._fill()
            finally:
                _fill_lock.release()
        return iter(self.data)

    def __len__(self):
        if self.data is None:
            _fill_lock.acquire()
            try:
                if self.data is None:
                    self._fill()
            finally:
                _fill_lock.release()
        return len(self.data)

    def keys(self):
        if self.data is None:
            _fill_lock.acquire()
            try:
                if self.data is None:
                    self._fill()
            finally:
                _fill_lock.release()
        return self.data.keys()


class LazyList(list):
    """List populated on first use."""

    _props = [
        '__str__', '__repr__', '__unicode__',
        '__hash__', '__sizeof__', '__cmp__',
        '__lt__', '__le__', '__eq__', '__ne__', '__gt__', '__ge__',
        'append', 'count', 'index', 'extend', 'insert', 'pop', 'remove',
        'reverse', 'sort', '__add__', '__radd__', '__iadd__', '__mul__',
        '__rmul__', '__imul__', '__contains__', '__len__', '__nonzero__',
        '__getitem__', '__setitem__', '__delitem__', '__iter__',
        '__reversed__', '__getslice__', '__setslice__', '__delslice__']

    def __new__(cls, fill_iter=None):

        if fill_iter is None:
            return list()

        # We need a new class as we will be dynamically messing with its
        # methods.
        class LazyList(list):
            pass

        fill_iter = [fill_iter]

        def lazy(name):
            def _lazy(self, *args, **kw):
                _fill_lock.acquire()
                try:
                    if len(fill_iter) > 0:
                        list.extend(self, fill_iter.pop())
                        for method_name in cls._props:
                            delattr(LazyList, method_name)
                finally:
                    _fill_lock.release()
                return getattr(list, name)(self, *args, **kw)
            return _lazy

        for name in cls._props:
            setattr(LazyList, name, lazy(name))

        new_list = LazyList()
        return new_list

# Not all versions of Python declare the same magic methods.
# Filter out properties that don't exist in this version of Python
# from the list.
LazyList._props = [prop for prop in LazyList._props if hasattr(list, prop)]


class LazySet(set):
    """Set populated on first use."""

    _props = (
        '__str__', '__repr__', '__unicode__',
        '__hash__', '__sizeof__', '__cmp__',
        '__lt__', '__le__', '__eq__', '__ne__', '__gt__', '__ge__',
        '__contains__', '__len__', '__nonzero__',
        '__getitem__', '__setitem__', '__delitem__', '__iter__',
        '__sub__', '__and__', '__xor__', '__or__',
        '__rsub__', '__rand__', '__rxor__', '__ror__',
        '__isub__', '__iand__', '__ixor__', '__ior__',
        'add', 'clear', 'copy', 'difference', 'difference_update',
        'discard', 'intersection', 'intersection_update', 'isdisjoint',
        'issubset', 'issuperset', 'pop', 'remove',
        'symmetric_difference', 'symmetric_difference_update',
        'union', 'update')

    def __new__(cls, fill_iter=None):

        if fill_iter is None:
            return set()

        class LazySet(set):
            pass

        fill_iter = [fill_iter]

        def lazy(name):
            def _lazy(self, *args, **kw):
                _fill_lock.acquire()
                try:
                    if len(fill_iter) > 0:
                        for i in fill_iter.pop():
                            set.add(self, i)
                        for method_name in cls._props:
                            delattr(LazySet, method_name)
                finally:
                    _fill_lock.release()
                return getattr(set, name)(self, *args, **kw)
            return _lazy

        for name in cls._props:
            setattr(LazySet, name, lazy(name))

        new_set = LazySet()
        return new_set

# Not all versions of Python declare the same magic methods.
# Filter out properties that don't exist in this version of Python
# from the list.
LazySet._props = [prop for prop in LazySet._props if hasattr(set, prop)]




############################################################
### File: locales.py
############################################################
# -*- coding: utf-8 -*-
from __future__ import absolute_import, unicode_literals

import inspect
import sys
from math import trunc


def get_locale(name):
    """Returns an appropriate :class:`Locale <arrow.locales.Locale>`
    corresponding to an inpute locale name.

    :param name: the name of the locale.

    """

    locale_cls = _locales.get(name.lower())

    if locale_cls is None:
        raise ValueError("Unsupported locale '{}'".format(name))

    return locale_cls()


def get_locale_by_class_name(name):
    """Returns an appropriate :class:`Locale <arrow.locales.Locale>`
    corresponding to an locale class name.

    :param name: the name of the locale class.

    """
    locale_cls = globals().get(name)

    if locale_cls is None:
        raise ValueError("Unsupported locale '{}'".format(name))

    return locale_cls()


# base locale type.


class Locale(object):
    """ Represents locale-specific data and functionality. """

    names = []

    timeframes = {
        "now": "",
        "second": "",
        "seconds": "",
        "minute": "",
        "minutes": "",
        "hour": "",
        "hours": "",
        "day": "",
        "days": "",
        "week": "",
        "weeks": "",
        "month": "",
        "months": "",
        "year": "",
        "years": "",
    }

    meridians = {"am": "", "pm": "", "AM": "", "PM": ""}

    past = None
    future = None
    and_word = None

    month_names = []
    month_abbreviations = []

    day_names = []
    day_abbreviations = []

    ordinal_day_re = r"(\d+)"

    def __init__(self):

        self._month_name_to_ordinal = None

    def describe(self, timeframe, delta=0, only_distance=False):
        """ Describes a delta within a timeframe in plain language.

        :param timeframe: a string representing a timeframe.
        :param delta: a quantity representing a delta in a timeframe.
        :param only_distance: return only distance eg: "11 seconds" without "in" or "ago" keywords
        """

        humanized = self._format_timeframe(timeframe, delta)
        if not only_distance:
            humanized = self._format_relative(humanized, timeframe, delta)

        return humanized

    def describe_multi(self, timeframes, only_distance=False):
        """ Describes a delta within multiple timeframes in plain language.

        :param timeframes: a list of string, quantity pairs each representing a timeframe and delta.
        :param only_distance: return only distance eg: "2 hours and 11 seconds" without "in" or "ago" keywords
        """

        humanized = ""
        for index, (timeframe, delta) in enumerate(timeframes):
            humanized += self._format_timeframe(timeframe, delta)
            if index == len(timeframes) - 2 and self.and_word:
                humanized += " " + self.and_word + " "
            elif index < len(timeframes) - 1:
                humanized += " "

        if not only_distance:
            humanized = self._format_relative(humanized, timeframe, delta)

        return humanized

    def day_name(self, day):
        """ Returns the day name for a specified day of the week.

        :param day: the ``int`` day of the week (1-7).

        """

        return self.day_names[day]

    def day_abbreviation(self, day):
        """ Returns the day abbreviation for a specified day of the week.

        :param day: the ``int`` day of the week (1-7).

        """

        return self.day_abbreviations[day]

    def month_name(self, month):
        """ Returns the month name for a specified month of the year.

        :param month: the ``int`` month of the year (1-12).

        """

        return self.month_names[month]

    def month_abbreviation(self, month):
        """ Returns the month abbreviation for a specified month of the year.

        :param month: the ``int`` month of the year (1-12).

        """

        return self.month_abbreviations[month]

    def month_number(self, name):
        """ Returns the month number for a month specified by name or abbreviation.

        :param name: the month name or abbreviation.

        """

        if self._month_name_to_ordinal is None:
            self._month_name_to_ordinal = self._name_to_ordinal(self.month_names)
            self._month_name_to_ordinal.update(
                self._name_to_ordinal(self.month_abbreviations)
            )

        return self._month_name_to_ordinal.get(name)

    def year_full(self, year):
        """  Returns the year for specific locale if available

        :param name: the ``int`` year (4-digit)
        """
        return "{:04d}".format(year)

    def year_abbreviation(self, year):
        """ Returns the year for specific locale if available

        :param name: the ``int`` year (4-digit)
        """
        return "{:04d}".format(year)[2:]

    def meridian(self, hour, token):
        """ Returns the meridian indicator for a specified hour and format token.

        :param hour: the ``int`` hour of the day.
        :param token: the format token.
        """

        if token == "a":
            return self.meridians["am"] if hour < 12 else self.meridians["pm"]
        if token == "A":
            return self.meridians["AM"] if hour < 12 else self.meridians["PM"]

    def ordinal_number(self, n):
        """ Returns the ordinal format of a given integer

        :param n: an integer
        """
        return self._ordinal_number(n)

    def _ordinal_number(self, n):
        return "{}".format(n)

    def _name_to_ordinal(self, lst):
        return dict(map(lambda i: (i[1].lower(), i[0] + 1), enumerate(lst[1:])))

    def _format_timeframe(self, timeframe, delta):
        return self.timeframes[timeframe].format(trunc(abs(delta)))

    def _format_relative(self, humanized, timeframe, delta):

        if timeframe == "now":
            return humanized

        direction = self.past if delta < 0 else self.future

        return direction.format(humanized)


# base locale type implementations.


class EnglishLocale(Locale):

    names = [
        "en",
        "en_us",
        "en_gb",
        "en_au",
        "en_be",
        "en_jp",
        "en_za",
        "en_ca",
        "en_ph",
    ]

    past = "{0} ago"
    future = "in {0}"
    and_word = "and"

    timeframes = {
        "now": "just now",
        "second": "a second",
        "seconds": "{0} seconds",
        "minute": "a minute",
        "minutes": "{0} minutes",
        "hour": "an hour",
        "hours": "{0} hours",
        "day": "a day",
        "days": "{0} days",
        "week": "a week",
        "weeks": "{0} weeks",
        "month": "a month",
        "months": "{0} months",
        "year": "a year",
        "years": "{0} years",
    }

    meridians = {"am": "am", "pm": "pm", "AM": "AM", "PM": "PM"}

    month_names = [
        "",
        "January",
        "February",
        "March",
        "April",
        "May",
        "June",
        "July",
        "August",
        "September",
        "October",
        "November",
        "December",
    ]
    month_abbreviations = [
        "",
        "Jan",
        "Feb",
        "Mar",
        "Apr",
        "May",
        "Jun",
        "Jul",
        "Aug",
        "Sep",
        "Oct",
        "Nov",
        "Dec",
    ]

    day_names = [
        "",
        "Monday",
        "Tuesday",
        "Wednesday",
        "Thursday",
        "Friday",
        "Saturday",
        "Sunday",
    ]
    day_abbreviations = ["", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]

    ordinal_day_re = r"((?P<value>[2-3]?1(?=st)|[2-3]?2(?=nd)|[2-3]?3(?=rd)|[1-3]?[04-9](?=th)|1[1-3](?=th))(st|nd|rd|th))"

    def _ordinal_number(self, n):
        if n % 100 not in (11, 12, 13):
            remainder = abs(n) % 10
            if remainder == 1:
                return "{}st".format(n)
            elif remainder == 2:
                return "{}nd".format(n)
            elif remainder == 3:
                return "{}rd".format(n)
        return "{}th".format(n)

    def describe(self, timeframe, delta=0, only_distance=False):
        """ Describes a delta within a timeframe in plain language.

        :param timeframe: a string representing a timeframe.
        :param delta: a quantity representing a delta in a timeframe.
        :param only_distance: return only distance eg: "11 seconds" without "in" or "ago" keywords
        """

        humanized = super(EnglishLocale, self).describe(timeframe, delta, only_distance)
        if only_distance and timeframe == "now":
            humanized = "instantly"

        return humanized


class ItalianLocale(Locale):
    names = ["it", "it_it"]
    past = "{0} fa"
    future = "tra {0}"
    and_word = "e"

    timeframes = {
        "now": "adesso",
        "second": "un secondo",
        "seconds": "{0} qualche secondo",
        "minute": "un minuto",
        "minutes": "{0} minuti",
        "hour": "un'ora",
        "hours": "{0} ore",
        "day": "un giorno",
        "days": "{0} giorni",
        "week": "una settimana,",
        "weeks": "{0} settimane",
        "month": "un mese",
        "months": "{0} mesi",
        "year": "un anno",
        "years": "{0} anni",
    }

    month_names = [
        "",
        "gennaio",
        "febbraio",
        "marzo",
        "aprile",
        "maggio",
        "giugno",
        "luglio",
        "agosto",
        "settembre",
        "ottobre",
        "novembre",
        "dicembre",
    ]
    month_abbreviations = [
        "",
        "gen",
        "feb",
        "mar",
        "apr",
        "mag",
        "giu",
        "lug",
        "ago",
        "set",
        "ott",
        "nov",
        "dic",
    ]

    day_names = [
        "",
        "luned",
        "marted",
        "mercoled",
        "gioved",
        "venerd",
        "sabato",
        "domenica",
    ]
    day_abbreviations = ["", "lun", "mar", "mer", "gio", "ven", "sab", "dom"]

    ordinal_day_re = r"((?P<value>[1-3]?[0-9](?=[]))[])"

    def _ordinal_number(self, n):
        return "{}".format(n)


class SpanishLocale(Locale):
    names = ["es", "es_es"]
    past = "hace {0}"
    future = "en {0}"
    and_word = "y"

    timeframes = {
        "now": "ahora",
        "second": "un segundo",
        "seconds": "{0} segundos",
        "minute": "un minuto",
        "minutes": "{0} minutos",
        "hour": "una hora",
        "hours": "{0} horas",
        "day": "un da",
        "days": "{0} das",
        "week": "una semana",
        "weeks": "{0} semanas",
        "month": "un mes",
        "months": "{0} meses",
        "year": "un ao",
        "years": "{0} aos",
    }

    meridians = {"am": "am", "pm": "pm", "AM": "AM", "PM": "PM"}

    month_names = [
        "",
        "enero",
        "febrero",
        "marzo",
        "abril",
        "mayo",
        "junio",
        "julio",
        "agosto",
        "septiembre",
        "octubre",
        "noviembre",
        "diciembre",
    ]
    month_abbreviations = [
        "",
        "ene",
        "feb",
        "mar",
        "abr",
        "may",
        "jun",
        "jul",
        "ago",
        "sep",
        "oct",
        "nov",
        "dic",
    ]

    day_names = [
        "",
        "lunes",
        "martes",
        "mircoles",
        "jueves",
        "viernes",
        "sbado",
        "domingo",
    ]
    day_abbreviations = ["", "lun", "mar", "mie", "jue", "vie", "sab", "dom"]

    ordinal_day_re = r"((?P<value>[1-3]?[0-9](?=[]))[])"

    def _ordinal_number(self, n):
        return "{}".format(n)


class FrenchBaseLocale(Locale):

    past = "il y a {0}"
    future = "dans {0}"
    and_word = "et"

    timeframes = {
        "now": "maintenant",
        "second": "une seconde",
        "seconds": "{0} quelques secondes",
        "minute": "une minute",
        "minutes": "{0} minutes",
        "hour": "une heure",
        "hours": "{0} heures",
        "day": "un jour",
        "days": "{0} jours",
        "week": "une semaine",
        "weeks": "{0} semaines",
        "month": "un mois",
        "months": "{0} mois",
        "year": "un an",
        "years": "{0} ans",
    }

    month_names = [
        "",
        "janvier",
        "fvrier",
        "mars",
        "avril",
        "mai",
        "juin",
        "juillet",
        "aot",
        "septembre",
        "octobre",
        "novembre",
        "dcembre",
    ]

    day_names = [
        "",
        "lundi",
        "mardi",
        "mercredi",
        "jeudi",
        "vendredi",
        "samedi",
        "dimanche",
    ]
    day_abbreviations = ["", "lun", "mar", "mer", "jeu", "ven", "sam", "dim"]

    ordinal_day_re = (
        r"((?P<value>\b1(?=er\b)|[1-3]?[02-9](?=e\b)|[1-3]1(?=e\b))(er|e)\b)"
    )

    def _ordinal_number(self, n):
        if abs(n) == 1:
            return "{}er".format(n)
        return "{}e".format(n)


class FrenchLocale(FrenchBaseLocale, Locale):

    names = ["fr", "fr_fr"]

    month_abbreviations = [
        "",
        "janv",
        "fvr",
        "mars",
        "avr",
        "mai",
        "juin",
        "juil",
        "aot",
        "sept",
        "oct",
        "nov",
        "dc",
    ]


class FrenchCanadianLocale(FrenchBaseLocale, Locale):

    names = ["fr_ca"]

    month_abbreviations = [
        "",
        "janv",
        "fvr",
        "mars",
        "avr",
        "mai",
        "juin",
        "juill",
        "aot",
        "sept",
        "oct",
        "nov",
        "dc",
    ]


class GreekLocale(Locale):

    names = ["el", "el_gr"]

    past = "{0} "
    future = " {0}"
    and_word = ""

    timeframes = {
        "now": "",
        "second": " ",
        "seconds": "{0} ",
        "minute": " ",
        "minutes": "{0} ",
        "hour": " ",
        "hours": "{0} ",
        "day": " ",
        "days": "{0} ",
        "month": " ",
        "months": "{0} ",
        "year": " ",
        "years": "{0} ",
    }

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


class JapaneseLocale(Locale):

    names = ["ja", "ja_jp"]

    past = "{0}"
    future = "{0}"

    timeframes = {
        "now": "",
        "second": "",
        "seconds": "{0}",
        "minute": "1",
        "minutes": "{0}",
        "hour": "1",
        "hours": "{0}",
        "day": "1",
        "days": "{0}",
        "week": "1",
        "weeks": "{0}",
        "month": "1",
        "months": "{0}",
        "year": "1",
        "years": "{0}",
    }

    month_names = [
        "",
        "1",
        "2",
        "3",
        "4",
        "5",
        "6",
        "7",
        "8",
        "9",
        "10",
        "11",
        "12",
    ]
    month_abbreviations = [
        "",
        " 1",
        " 2",
        " 3",
        " 4",
        " 5",
        " 6",
        " 7",
        " 8",
        " 9",
        "10",
        "11",
        "12",
    ]

    day_names = ["", "", "", "", "", "", "", ""]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


class SwedishLocale(Locale):

    names = ["sv", "sv_se"]

    past = "fr {0} sen"
    future = "om {0}"
    and_word = "och"

    timeframes = {
        "now": "just nu",
        "second": "en sekund",
        "seconds": "{0} ngra sekunder",
        "minute": "en minut",
        "minutes": "{0} minuter",
        "hour": "en timme",
        "hours": "{0} timmar",
        "day": "en dag",
        "days": "{0} dagar",
        "week": "en vecka",
        "weeks": "{0} veckor",
        "month": "en mnad",
        "months": "{0} mnader",
        "year": "ett r",
        "years": "{0} r",
    }

    month_names = [
        "",
        "januari",
        "februari",
        "mars",
        "april",
        "maj",
        "juni",
        "juli",
        "augusti",
        "september",
        "oktober",
        "november",
        "december",
    ]
    month_abbreviations = [
        "",
        "jan",
        "feb",
        "mar",
        "apr",
        "maj",
        "jun",
        "jul",
        "aug",
        "sep",
        "okt",
        "nov",
        "dec",
    ]

    day_names = [
        "",
        "mndag",
        "tisdag",
        "onsdag",
        "torsdag",
        "fredag",
        "lrdag",
        "sndag",
    ]
    day_abbreviations = ["", "mn", "tis", "ons", "tor", "fre", "lr", "sn"]


class FinnishLocale(Locale):

    names = ["fi", "fi_fi"]

    # The finnish grammar is very complex, and its hard to convert
    # 1-to-1 to something like English.

    past = "{0} sitten"
    future = "{0} kuluttua"

    timeframes = {
        "now": ["juuri nyt", "juuri nyt"],
        "second": ["sekunti", "sekunti"],
        "seconds": ["{0} muutama sekunti", "{0} muutaman sekunnin"],
        "minute": ["minuutti", "minuutin"],
        "minutes": ["{0} minuuttia", "{0} minuutin"],
        "hour": ["tunti", "tunnin"],
        "hours": ["{0} tuntia", "{0} tunnin"],
        "day": ["piv", "piv"],
        "days": ["{0} piv", "{0} pivn"],
        "month": ["kuukausi", "kuukauden"],
        "months": ["{0} kuukautta", "{0} kuukauden"],
        "year": ["vuosi", "vuoden"],
        "years": ["{0} vuotta", "{0} vuoden"],
    }

    # Months and days are lowercase in Finnish
    month_names = [
        "",
        "tammikuu",
        "helmikuu",
        "maaliskuu",
        "huhtikuu",
        "toukokuu",
        "keskuu",
        "heinkuu",
        "elokuu",
        "syyskuu",
        "lokakuu",
        "marraskuu",
        "joulukuu",
    ]

    month_abbreviations = [
        "",
        "tammi",
        "helmi",
        "maalis",
        "huhti",
        "touko",
        "kes",
        "hein",
        "elo",
        "syys",
        "loka",
        "marras",
        "joulu",
    ]

    day_names = [
        "",
        "maanantai",
        "tiistai",
        "keskiviikko",
        "torstai",
        "perjantai",
        "lauantai",
        "sunnuntai",
    ]

    day_abbreviations = ["", "ma", "ti", "ke", "to", "pe", "la", "su"]

    def _format_timeframe(self, timeframe, delta):
        return (
            self.timeframes[timeframe][0].format(abs(delta)),
            self.timeframes[timeframe][1].format(abs(delta)),
        )

    def _format_relative(self, humanized, timeframe, delta):
        if timeframe == "now":
            return humanized[0]

        direction = self.past if delta < 0 else self.future
        which = 0 if delta < 0 else 1

        return direction.format(humanized[which])

    def _ordinal_number(self, n):
        return "{}.".format(n)


class ChineseCNLocale(Locale):

    names = ["zh", "zh_cn"]

    past = "{0}"
    future = "{0}"

    timeframes = {
        "now": "",
        "second": "",
        "seconds": "{0}",
        "minute": "1",
        "minutes": "{0}",
        "hour": "1",
        "hours": "{0}",
        "day": "1",
        "days": "{0}",
        "week": "",
        "weeks": "{0}",
        "month": "1",
        "months": "{0}",
        "year": "1",
        "years": "{0}",
    }

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        " 1",
        " 2",
        " 3",
        " 4",
        " 5",
        " 6",
        " 7",
        " 8",
        " 9",
        "10",
        "11",
        "12",
    ]

    day_names = ["", "", "", "", "", "", "", ""]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


class ChineseTWLocale(Locale):

    names = ["zh_tw"]

    past = "{0}"
    future = "{0}"
    and_word = ""

    timeframes = {
        "now": "",
        "second": "1",
        "seconds": "{0}",
        "minute": "1",
        "minutes": "{0}",
        "hour": "1",
        "hours": "{0}",
        "day": "1",
        "days": "{0}",
        "week": "1",
        "weeks": "{0}",
        "month": "1",
        "months": "{0}",
        "year": "1",
        "years": "{0}",
    }

    month_names = [
        "",
        "1",
        "2",
        "3",
        "4",
        "5",
        "6",
        "7",
        "8",
        "9",
        "10",
        "11",
        "12",
    ]
    month_abbreviations = [
        "",
        " 1",
        " 2",
        " 3",
        " 4",
        " 5",
        " 6",
        " 7",
        " 8",
        " 9",
        "10",
        "11",
        "12",
    ]

    day_names = ["", "", "", "", "", "", "", ""]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


class HongKongLocale(Locale):

    names = ["zh_hk"]

    past = "{0}"
    future = "{0}"

    timeframes = {
        "now": "",
        "second": "1",
        "seconds": "{0}",
        "minute": "1",
        "minutes": "{0}",
        "hour": "1",
        "hours": "{0}",
        "day": "1",
        "days": "{0}",
        "week": "1",
        "weeks": "{0}",
        "month": "1",
        "months": "{0}",
        "year": "1",
        "years": "{0}",
    }

    month_names = [
        "",
        "1",
        "2",
        "3",
        "4",
        "5",
        "6",
        "7",
        "8",
        "9",
        "10",
        "11",
        "12",
    ]
    month_abbreviations = [
        "",
        " 1",
        " 2",
        " 3",
        " 4",
        " 5",
        " 6",
        " 7",
        " 8",
        " 9",
        "10",
        "11",
        "12",
    ]

    day_names = ["", "", "", "", "", "", "", ""]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


class KoreanLocale(Locale):

    names = ["ko", "ko_kr"]

    past = "{0} "
    future = "{0} "

    timeframes = {
        "now": "",
        "second": "1",
        "seconds": "{0}",
        "minute": "1",
        "minutes": "{0}",
        "hour": "",
        "hours": "{0}",
        "day": "",
        "days": "{0}",
        "week": "1",
        "weeks": "{0}",
        "month": "",
        "months": "{0}",
        "year": "1",
        "years": "{0}",
    }

    special_dayframes = {
        -3: "",
        -2: "",
        -1: "",
        1: "",
        2: "",
        3: "",
        4: "",
    }

    special_yearframes = {-2: "", -1: "", 1: "", 2: ""}

    month_names = [
        "",
        "1",
        "2",
        "3",
        "4",
        "5",
        "6",
        "7",
        "8",
        "9",
        "10",
        "11",
        "12",
    ]
    month_abbreviations = [
        "",
        " 1",
        " 2",
        " 3",
        " 4",
        " 5",
        " 6",
        " 7",
        " 8",
        " 9",
        "10",
        "11",
        "12",
    ]

    day_names = ["", "", "", "", "", "", "", ""]
    day_abbreviations = ["", "", "", "", "", "", "", ""]

    def _ordinal_number(self, n):
        ordinals = ["0", "", "", "", "", "", "", "", "", "", ""]
        if n < len(ordinals):
            return "{}".format(ordinals[n])
        return "{}".format(n)

    def _format_relative(self, humanized, timeframe, delta):
        if timeframe in ("day", "days"):
            special = self.special_dayframes.get(delta)
            if special:
                return special
        elif timeframe in ("year", "years"):
            special = self.special_yearframes.get(delta)
            if special:
                return special

        return super(KoreanLocale, self)._format_relative(humanized, timeframe, delta)


# derived locale types & implementations.
class DutchLocale(Locale):

    names = ["nl", "nl_nl"]

    past = "{0} geleden"
    future = "over {0}"

    timeframes = {
        "now": "nu",
        "second": "een seconde",
        "seconds": "{0} seconden",
        "minute": "een minuut",
        "minutes": "{0} minuten",
        "hour": "een uur",
        "hours": "{0} uur",
        "day": "een dag",
        "days": "{0} dagen",
        "week": "een week",
        "weeks": "{0} weken",
        "month": "een maand",
        "months": "{0} maanden",
        "year": "een jaar",
        "years": "{0} jaar",
    }

    # In Dutch names of months and days are not starting with a capital letter
    # like in the English language.
    month_names = [
        "",
        "januari",
        "februari",
        "maart",
        "april",
        "mei",
        "juni",
        "juli",
        "augustus",
        "september",
        "oktober",
        "november",
        "december",
    ]
    month_abbreviations = [
        "",
        "jan",
        "feb",
        "mrt",
        "apr",
        "mei",
        "jun",
        "jul",
        "aug",
        "sep",
        "okt",
        "nov",
        "dec",
    ]

    day_names = [
        "",
        "maandag",
        "dinsdag",
        "woensdag",
        "donderdag",
        "vrijdag",
        "zaterdag",
        "zondag",
    ]
    day_abbreviations = ["", "ma", "di", "wo", "do", "vr", "za", "zo"]


class SlavicBaseLocale(Locale):
    def _format_timeframe(self, timeframe, delta):

        form = self.timeframes[timeframe]
        delta = abs(delta)

        if isinstance(form, list):

            if delta % 10 == 1 and delta % 100 != 11:
                form = form[0]
            elif 2 <= delta % 10 <= 4 and (delta % 100 < 10 or delta % 100 >= 20):
                form = form[1]
            else:
                form = form[2]

        return form.format(delta)


class BelarusianLocale(SlavicBaseLocale):

    names = ["be", "be_by"]

    past = "{0} "
    future = " {0}"

    timeframes = {
        "now": "",
        "second": "",
        "seconds": "{0}  ",
        "minute": "",
        "minutes": ["{0} ", "{0} ", "{0} "],
        "hour": "",
        "hours": ["{0} ", "{0} ", "{0} "],
        "day": "",
        "days": ["{0} ", "{0} ", "{0} "],
        "month": "",
        "months": ["{0} ", "{0} ", "{0} "],
        "year": "",
        "years": ["{0} ", "{0} ", "{0} "],
    }

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


class PolishLocale(SlavicBaseLocale):

    names = ["pl", "pl_pl"]

    past = "{0} temu"
    future = "za {0}"

    # The nouns should be in genitive case (Polish: "dopeniacz")
    # in order to correctly form `past` & `future` expressions.
    timeframes = {
        "now": "teraz",
        "second": "sekund",
        "seconds": ["{0} sekund", "{0} sekundy", "{0} sekund"],
        "minute": "minut",
        "minutes": ["{0} minut", "{0} minuty", "{0} minut"],
        "hour": "godzin",
        "hours": ["{0} godzin", "{0} godziny", "{0} godzin"],
        "day": "dzie",
        "days": "{0} dni",
        "week": "tydzie",
        "weeks": ["{0} tygodni", "{0} tygodnie", "{0} tygodni"],
        "month": "miesic",
        "months": ["{0} miesicy", "{0} miesice", "{0} miesicy"],
        "year": "rok",
        "years": ["{0} lat", "{0} lata", "{0} lat"],
    }

    month_names = [
        "",
        "stycze",
        "luty",
        "marzec",
        "kwiecie",
        "maj",
        "czerwiec",
        "lipiec",
        "sierpie",
        "wrzesie",
        "padziernik",
        "listopad",
        "grudzie",
    ]
    month_abbreviations = [
        "",
        "sty",
        "lut",
        "mar",
        "kwi",
        "maj",
        "cze",
        "lip",
        "sie",
        "wrz",
        "pa",
        "lis",
        "gru",
    ]

    day_names = [
        "",
        "poniedziaek",
        "wtorek",
        "roda",
        "czwartek",
        "pitek",
        "sobota",
        "niedziela",
    ]
    day_abbreviations = ["", "Pn", "Wt", "r", "Czw", "Pt", "So", "Nd"]


class RussianLocale(SlavicBaseLocale):

    names = ["ru", "ru_ru"]

    past = "{0} "
    future = " {0}"

    timeframes = {
        "now": "",
        "second": "",
        "seconds": "{0}  ",
        "minute": "",
        "minutes": ["{0} ", "{0} ", "{0} "],
        "hour": "",
        "hours": ["{0} ", "{0} ", "{0} "],
        "day": "",
        "days": ["{0} ", "{0} ", "{0} "],
        "week": "",
        "weeks": ["{0} ", "{0} ", "{0} "],
        "month": "",
        "months": ["{0} ", "{0} ", "{0} "],
        "year": "",
        "years": ["{0} ", "{0} ", "{0} "],
    }

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


class AfrikaansLocale(Locale):

    names = ["af", "af_nl"]

    past = "{0} gelede"
    future = "in {0}"

    timeframes = {
        "now": "nou",
        "second": "n sekonde",
        "seconds": "{0} sekondes",
        "minute": "minuut",
        "minutes": "{0} minute",
        "hour": "uur",
        "hours": "{0} ure",
        "day": "een dag",
        "days": "{0} dae",
        "month": "een maand",
        "months": "{0} maande",
        "year": "een jaar",
        "years": "{0} jaar",
    }

    month_names = [
        "",
        "Januarie",
        "Februarie",
        "Maart",
        "April",
        "Mei",
        "Junie",
        "Julie",
        "Augustus",
        "September",
        "Oktober",
        "November",
        "Desember",
    ]
    month_abbreviations = [
        "",
        "Jan",
        "Feb",
        "Mrt",
        "Apr",
        "Mei",
        "Jun",
        "Jul",
        "Aug",
        "Sep",
        "Okt",
        "Nov",
        "Des",
    ]

    day_names = [
        "",
        "Maandag",
        "Dinsdag",
        "Woensdag",
        "Donderdag",
        "Vrydag",
        "Saterdag",
        "Sondag",
    ]
    day_abbreviations = ["", "Ma", "Di", "Wo", "Do", "Vr", "Za", "So"]


class BulgarianLocale(SlavicBaseLocale):

    names = ["bg", "bg_BG"]

    past = "{0} "
    future = " {0}"

    timeframes = {
        "now": "",
        "second": "",
        "seconds": "{0}  ",
        "minute": "",
        "minutes": ["{0} ", "{0} ", "{0} "],
        "hour": "",
        "hours": ["{0} ", "{0} ", "{0} "],
        "day": "",
        "days": ["{0} ", "{0} ", "{0} "],
        "month": "",
        "months": ["{0} ", "{0} ", "{0} "],
        "year": "",
        "years": ["{0} ", "{0} ", "{0} "],
    }

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


class UkrainianLocale(SlavicBaseLocale):

    names = ["ua", "uk_ua"]

    past = "{0} "
    future = " {0}"

    timeframes = {
        "now": "",
        "second": "",
        "seconds": "{0}  ",
        "minute": "",
        "minutes": ["{0} ", "{0} ", "{0} "],
        "hour": "",
        "hours": ["{0} ", "{0} ", "{0} "],
        "day": "",
        "days": ["{0} ", "{0} ", "{0} "],
        "month": "",
        "months": ["{0} ", "{0} ", "{0} "],
        "year": "",
        "years": ["{0} ", "{0} ", "{0} "],
    }

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


class MacedonianLocale(SlavicBaseLocale):
    names = ["mk", "mk_mk"]

    past = " {0}"
    future = " {0}"

    timeframes = {
        "now": "",
        "second": " ",
        "seconds": ["{0} ", "{0} ", "{0} "],
        "minute": " ",
        "minutes": ["{0} ", "{0} ", "{0} "],
        "hour": " ",
        "hours": ["{0} ", "{0} ", "{0} "],
        "day": " ",
        "days": ["{0} ", "{0} ", "{0} "],
        "week": " ",
        "weeks": ["{0} ", "{0} ", "{0} "],
        "month": " ",
        "months": ["{0} ", "{0} ", "{0} "],
        "year": " ",
        "years": ["{0} ", "{0} ", "{0} "],
    }

    meridians = {"am": "", "pm": "", "AM": "", "PM": ""}

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]


class GermanBaseLocale(Locale):

    past = "vor {0}"
    future = "in {0}"
    and_word = "und"

    timeframes = {
        "now": "gerade eben",
        "second": "eine Sekunde",
        "seconds": "{0} Sekunden",
        "minute": "einer Minute",
        "minutes": "{0} Minuten",
        "hour": "einer Stunde",
        "hours": "{0} Stunden",
        "day": "einem Tag",
        "days": "{0} Tagen",
        "week": "einer Woche",
        "weeks": "{0} Wochen",
        "month": "einem Monat",
        "months": "{0} Monaten",
        "year": "einem Jahr",
        "years": "{0} Jahren",
    }

    timeframes_only_distance = timeframes.copy()
    timeframes_only_distance["minute"] = "eine Minute"
    timeframes_only_distance["hour"] = "eine Stunde"
    timeframes_only_distance["day"] = "ein Tag"
    timeframes_only_distance["week"] = "eine Woche"
    timeframes_only_distance["month"] = "ein Monat"
    timeframes_only_distance["year"] = "ein Jahr"

    month_names = [
        "",
        "Januar",
        "Februar",
        "Mrz",
        "April",
        "Mai",
        "Juni",
        "Juli",
        "August",
        "September",
        "Oktober",
        "November",
        "Dezember",
    ]

    month_abbreviations = [
        "",
        "Jan",
        "Feb",
        "Mr",
        "Apr",
        "Mai",
        "Jun",
        "Jul",
        "Aug",
        "Sep",
        "Okt",
        "Nov",
        "Dez",
    ]

    day_names = [
        "",
        "Montag",
        "Dienstag",
        "Mittwoch",
        "Donnerstag",
        "Freitag",
        "Samstag",
        "Sonntag",
    ]

    day_abbreviations = ["", "Mo", "Di", "Mi", "Do", "Fr", "Sa", "So"]

    def _ordinal_number(self, n):
        return "{}.".format(n)

    def describe(self, timeframe, delta=0, only_distance=False):
        """ Describes a delta within a timeframe in plain language.

        :param timeframe: a string representing a timeframe.
        :param delta: a quantity representing a delta in a timeframe.
        :param only_distance: return only distance eg: "11 seconds" without "in" or "ago" keywords
        """

        if not only_distance:
            return super(GermanBaseLocale, self).describe(
                timeframe, delta, only_distance
            )

        # German uses a different case without 'in' or 'ago'
        humanized = self.timeframes_only_distance[timeframe].format(trunc(abs(delta)))

        return humanized


class GermanLocale(GermanBaseLocale, Locale):

    names = ["de", "de_de"]


class SwissLocale(GermanBaseLocale, Locale):

    names = ["de_ch"]


class AustrianLocale(GermanBaseLocale, Locale):

    names = ["de_at"]

    month_names = [
        "",
        "Jnner",
        "Februar",
        "Mrz",
        "April",
        "Mai",
        "Juni",
        "Juli",
        "August",
        "September",
        "Oktober",
        "November",
        "Dezember",
    ]


class NorwegianLocale(Locale):

    names = ["nb", "nb_no"]

    past = "for {0} siden"
    future = "om {0}"

    timeframes = {
        "now": "n nettopp",
        "second": "et sekund",
        "seconds": "{0} noen sekunder",
        "minute": "ett minutt",
        "minutes": "{0} minutter",
        "hour": "en time",
        "hours": "{0} timer",
        "day": "en dag",
        "days": "{0} dager",
        "month": "en mned",
        "months": "{0} mneder",
        "year": "ett r",
        "years": "{0} r",
    }

    month_names = [
        "",
        "januar",
        "februar",
        "mars",
        "april",
        "mai",
        "juni",
        "juli",
        "august",
        "september",
        "oktober",
        "november",
        "desember",
    ]
    month_abbreviations = [
        "",
        "jan",
        "feb",
        "mar",
        "apr",
        "mai",
        "jun",
        "jul",
        "aug",
        "sep",
        "okt",
        "nov",
        "des",
    ]

    day_names = [
        "",
        "mandag",
        "tirsdag",
        "onsdag",
        "torsdag",
        "fredag",
        "lrdag",
        "sndag",
    ]
    day_abbreviations = ["", "ma", "ti", "on", "to", "fr", "l", "s"]


class NewNorwegianLocale(Locale):

    names = ["nn", "nn_no"]

    past = "for {0} sidan"
    future = "om {0}"

    timeframes = {
        "now": "no nettopp",
        "second": "et sekund",
        "seconds": "{0} nokre sekund",
        "minute": "ett minutt",
        "minutes": "{0} minutt",
        "hour": "ein time",
        "hours": "{0} timar",
        "day": "ein dag",
        "days": "{0} dagar",
        "month": "en mnad",
        "months": "{0} mnader",
        "year": "eit r",
        "years": "{0} r",
    }

    month_names = [
        "",
        "januar",
        "februar",
        "mars",
        "april",
        "mai",
        "juni",
        "juli",
        "august",
        "september",
        "oktober",
        "november",
        "desember",
    ]
    month_abbreviations = [
        "",
        "jan",
        "feb",
        "mar",
        "apr",
        "mai",
        "jun",
        "jul",
        "aug",
        "sep",
        "okt",
        "nov",
        "des",
    ]

    day_names = [
        "",
        "mndag",
        "tysdag",
        "onsdag",
        "torsdag",
        "fredag",
        "laurdag",
        "sundag",
    ]
    day_abbreviations = ["", "m", "ty", "on", "to", "fr", "la", "su"]


class PortugueseLocale(Locale):
    names = ["pt", "pt_pt"]

    past = "h {0}"
    future = "em {0}"
    and_word = "e"

    timeframes = {
        "now": "agora",
        "second": "um segundo",
        "seconds": "{0} segundos",
        "minute": "um minuto",
        "minutes": "{0} minutos",
        "hour": "uma hora",
        "hours": "{0} horas",
        "day": "um dia",
        "days": "{0} dias",
        "week": "uma semana",
        "weeks": "{0} semanas",
        "month": "um ms",
        "months": "{0} meses",
        "year": "um ano",
        "years": "{0} anos",
    }

    month_names = [
        "",
        "Janeiro",
        "Fevereiro",
        "Maro",
        "Abril",
        "Maio",
        "Junho",
        "Julho",
        "Agosto",
        "Setembro",
        "Outubro",
        "Novembro",
        "Dezembro",
    ]
    month_abbreviations = [
        "",
        "Jan",
        "Fev",
        "Mar",
        "Abr",
        "Mai",
        "Jun",
        "Jul",
        "Ago",
        "Set",
        "Out",
        "Nov",
        "Dez",
    ]

    day_names = [
        "",
        "Segunda-feira",
        "Tera-feira",
        "Quarta-feira",
        "Quinta-feira",
        "Sexta-feira",
        "Sbado",
        "Domingo",
    ]
    day_abbreviations = ["", "Seg", "Ter", "Qua", "Qui", "Sex", "Sab", "Dom"]


class BrazilianPortugueseLocale(PortugueseLocale):
    names = ["pt_br"]

    past = "faz {0}"


class TagalogLocale(Locale):

    names = ["tl", "tl_ph"]

    past = "nakaraang {0}"
    future = "{0} mula ngayon"

    timeframes = {
        "now": "ngayon lang",
        "second": "isang segundo",
        "seconds": "{0} segundo",
        "minute": "isang minuto",
        "minutes": "{0} minuto",
        "hour": "isang oras",
        "hours": "{0} oras",
        "day": "isang araw",
        "days": "{0} araw",
        "month": "isang buwan",
        "months": "{0} buwan",
        "year": "isang taon",
        "years": "{0} taon",
    }

    month_names = [
        "",
        "Enero",
        "Pebrero",
        "Marso",
        "Abril",
        "Mayo",
        "Hunyo",
        "Hulyo",
        "Agosto",
        "Setyembre",
        "Oktubre",
        "Nobyembre",
        "Disyembre",
    ]
    month_abbreviations = [
        "",
        "Ene",
        "Peb",
        "Mar",
        "Abr",
        "May",
        "Hun",
        "Hul",
        "Ago",
        "Set",
        "Okt",
        "Nob",
        "Dis",
    ]

    day_names = [
        "",
        "Lunes",
        "Martes",
        "Miyerkules",
        "Huwebes",
        "Biyernes",
        "Sabado",
        "Linggo",
    ]
    day_abbreviations = ["", "Lun", "Mar", "Miy", "Huw", "Biy", "Sab", "Lin"]

    def _ordinal_number(self, n):
        return "ika-{}".format(n)


class VietnameseLocale(Locale):

    names = ["vi", "vi_vn"]

    past = "{0} trc"
    future = "{0} na"

    timeframes = {
        "now": "hin ti",
        "second": "mt giy",
        "seconds": "{0} giy",
        "minute": "mt pht",
        "minutes": "{0} pht",
        "hour": "mt gi",
        "hours": "{0} gi",
        "day": "mt ngy",
        "days": "{0} ngy",
        "week": "mt tun",
        "weeks": "{0} tun",
        "month": "mt thng",
        "months": "{0} thng",
        "year": "mt nm",
        "years": "{0} nm",
    }

    month_names = [
        "",
        "Thng Mt",
        "Thng Hai",
        "Thng Ba",
        "Thng T",
        "Thng Nm",
        "Thng Su",
        "Thng By",
        "Thng Tm",
        "Thng Chn",
        "Thng Mi",
        "Thng Mi Mt",
        "Thng Mi Hai",
    ]
    month_abbreviations = [
        "",
        "Thng 1",
        "Thng 2",
        "Thng 3",
        "Thng 4",
        "Thng 5",
        "Thng 6",
        "Thng 7",
        "Thng 8",
        "Thng 9",
        "Thng 10",
        "Thng 11",
        "Thng 12",
    ]

    day_names = [
        "",
        "Th Hai",
        "Th Ba",
        "Th T",
        "Th Nm",
        "Th Su",
        "Th By",
        "Ch Nht",
    ]
    day_abbreviations = ["", "Th 2", "Th 3", "Th 4", "Th 5", "Th 6", "Th 7", "CN"]


class TurkishLocale(Locale):

    names = ["tr", "tr_tr"]

    past = "{0} nce"
    future = "{0} sonra"

    timeframes = {
        "now": "imdi",
        "second": "bir saniye",
        "seconds": "{0} saniye",
        "minute": "bir dakika",
        "minutes": "{0} dakika",
        "hour": "bir saat",
        "hours": "{0} saat",
        "day": "bir gn",
        "days": "{0} gn",
        "month": "bir ay",
        "months": "{0} ay",
        "year": "yl",
        "years": "{0} yl",
    }

    month_names = [
        "",
        "Ocak",
        "ubat",
        "Mart",
        "Nisan",
        "Mays",
        "Haziran",
        "Temmuz",
        "Austos",
        "Eyll",
        "Ekim",
        "Kasm",
        "Aralk",
    ]
    month_abbreviations = [
        "",
        "Oca",
        "ub",
        "Mar",
        "Nis",
        "May",
        "Haz",
        "Tem",
        "Au",
        "Eyl",
        "Eki",
        "Kas",
        "Ara",
    ]

    day_names = [
        "",
        "Pazartesi",
        "Sal",
        "aramba",
        "Perembe",
        "Cuma",
        "Cumartesi",
        "Pazar",
    ]
    day_abbreviations = ["", "Pzt", "Sal", "ar", "Per", "Cum", "Cmt", "Paz"]


class AzerbaijaniLocale(Locale):

    names = ["az", "az_az"]

    past = "{0} vvl"
    future = "{0} sonra"

    timeframes = {
        "now": "indi",
        "second": "saniy",
        "seconds": "{0} saniy",
        "minute": "bir dqiq",
        "minutes": "{0} dqiq",
        "hour": "bir saat",
        "hours": "{0} saat",
        "day": "bir gn",
        "days": "{0} gn",
        "month": "bir ay",
        "months": "{0} ay",
        "year": "il",
        "years": "{0} il",
    }

    month_names = [
        "",
        "Yanvar",
        "Fevral",
        "Mart",
        "Aprel",
        "May",
        "yun",
        "yul",
        "Avqust",
        "Sentyabr",
        "Oktyabr",
        "Noyabr",
        "Dekabr",
    ]
    month_abbreviations = [
        "",
        "Yan",
        "Fev",
        "Mar",
        "Apr",
        "May",
        "yn",
        "yl",
        "Avq",
        "Sen",
        "Okt",
        "Noy",
        "Dek",
    ]

    day_names = [
        "",
        "Bazar ertsi",
        "rnb axam",
        "rnb",
        "Cm axam",
        "Cm",
        "nb",
        "Bazar",
    ]
    day_abbreviations = ["", "Ber", "ax", "r", "Cax", "Cm", "nb", "Bzr"]


class ArabicLocale(Locale):
    names = [
        "ar",
        "ar_ae",
        "ar_bh",
        "ar_dj",
        "ar_eg",
        "ar_eh",
        "ar_er",
        "ar_km",
        "ar_kw",
        "ar_ly",
        "ar_om",
        "ar_qa",
        "ar_sa",
        "ar_sd",
        "ar_so",
        "ar_ss",
        "ar_td",
        "ar_ye",
    ]

    past = " {0}"
    future = " {0}"

    timeframes = {
        "now": "",
        "second": "",
        "seconds": {"double": "", "ten": "{0} ", "higher": "{0} "},
        "minute": "",
        "minutes": {"double": "", "ten": "{0} ", "higher": "{0} "},
        "hour": "",
        "hours": {"double": "", "ten": "{0} ", "higher": "{0} "},
        "day": "",
        "days": {"double": "", "ten": "{0} ", "higher": "{0} "},
        "month": "",
        "months": {"double": "", "ten": "{0} ", "higher": "{0} "},
        "year": "",
        "years": {"double": "", "ten": "{0} ", "higher": "{0} "},
    }

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = ["", "", "", "", "", "", "", ""]

    def _format_timeframe(self, timeframe, delta):
        form = self.timeframes[timeframe]
        delta = abs(delta)
        if isinstance(form, dict):
            if delta == 2:
                form = form["double"]
            elif delta > 2 and delta <= 10:
                form = form["ten"]
            else:
                form = form["higher"]

        return form.format(delta)


class LevantArabicLocale(ArabicLocale):
    names = ["ar_iq", "ar_jo", "ar_lb", "ar_ps", "ar_sy"]
    month_names = [
        "",
        " ",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        " ",
        " ",
        " ",
    ]
    month_abbreviations = [
        "",
        " ",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        " ",
        " ",
        " ",
    ]


class AlgeriaTunisiaArabicLocale(ArabicLocale):
    names = ["ar_tn", "ar_dz"]
    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]


class MauritaniaArabicLocale(ArabicLocale):
    names = ["ar_mr"]
    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]


class MoroccoArabicLocale(ArabicLocale):
    names = ["ar_ma"]
    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]


class IcelandicLocale(Locale):
    def _format_timeframe(self, timeframe, delta):

        timeframe = self.timeframes[timeframe]
        if delta < 0:
            timeframe = timeframe[0]
        elif delta > 0:
            timeframe = timeframe[1]

        return timeframe.format(abs(delta))

    names = ["is", "is_is"]

    past = "fyrir {0} san"
    future = "eftir {0}"

    timeframes = {
        "now": "rtt  essu",
        "second": ("sekndu", "sekndu"),
        "seconds": ("{0} nokkrum sekndum", "nokkrar sekndur"),
        "minute": ("einni mntu", "eina mntu"),
        "minutes": ("{0} mntum", "{0} mntur"),
        "hour": ("einum tma", "einn tma"),
        "hours": ("{0} tmum", "{0} tma"),
        "day": ("einum degi", "einn dag"),
        "days": ("{0} dgum", "{0} daga"),
        "month": ("einum mnui", "einn mnu"),
        "months": ("{0} mnuum", "{0} mnui"),
        "year": ("einu ri", "eitt r"),
        "years": ("{0} rum", "{0} r"),
    }

    meridians = {"am": "f.h.", "pm": "e.h.", "AM": "f.h.", "PM": "e.h."}

    month_names = [
        "",
        "janar",
        "febrar",
        "mars",
        "aprl",
        "ma",
        "jn",
        "jl",
        "gst",
        "september",
        "oktber",
        "nvember",
        "desember",
    ]
    month_abbreviations = [
        "",
        "jan",
        "feb",
        "mar",
        "apr",
        "ma",
        "jn",
        "jl",
        "g",
        "sep",
        "okt",
        "nv",
        "des",
    ]

    day_names = [
        "",
        "mnudagur",
        "rijudagur",
        "mivikudagur",
        "fimmtudagur",
        "fstudagur",
        "laugardagur",
        "sunnudagur",
    ]
    day_abbreviations = ["", "mn", "ri", "mi", "fim", "fs", "lau", "sun"]


class DanishLocale(Locale):

    names = ["da", "da_dk"]

    past = "for {0} siden"
    future = "efter {0}"
    and_word = "og"

    timeframes = {
        "now": "lige nu",
        "second": "et sekund",
        "seconds": "{0} et par sekunder",
        "minute": "et minut",
        "minutes": "{0} minutter",
        "hour": "en time",
        "hours": "{0} timer",
        "day": "en dag",
        "days": "{0} dage",
        "month": "en mned",
        "months": "{0} mneder",
        "year": "et r",
        "years": "{0} r",
    }

    month_names = [
        "",
        "januar",
        "februar",
        "marts",
        "april",
        "maj",
        "juni",
        "juli",
        "august",
        "september",
        "oktober",
        "november",
        "december",
    ]
    month_abbreviations = [
        "",
        "jan",
        "feb",
        "mar",
        "apr",
        "maj",
        "jun",
        "jul",
        "aug",
        "sep",
        "okt",
        "nov",
        "dec",
    ]

    day_names = [
        "",
        "mandag",
        "tirsdag",
        "onsdag",
        "torsdag",
        "fredag",
        "lrdag",
        "sndag",
    ]
    day_abbreviations = ["", "man", "tir", "ons", "tor", "fre", "lr", "sn"]


class MalayalamLocale(Locale):

    names = ["ml"]

    past = "{0} "
    future = "{0} "

    timeframes = {
        "now": "",
        "second": " ",
        "seconds": "{0} ",
        "minute": " ",
        "minutes": "{0} ",
        "hour": " ",
        "hours": "{0} ",
        "day": "  ",
        "days": "{0}  ",
        "month": "  ",
        "months": "{0}  ",
        "year": "  ",
        "years": "{0}  ",
    }

    meridians = {
        "am": "",
        "pm": " ",
        "AM": "",
        "PM": " ",
    }

    month_names = [
        "",
        "",
        "",
        "",
        " ",
        " ",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        " ",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = ["", "", "", "", "", "", "", ""]
    day_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]


class HindiLocale(Locale):

    names = ["hi"]

    past = "{0} "
    future = "{0} "

    timeframes = {
        "now": "",
        "second": " ",
        "seconds": "{0} ",
        "minute": "  ",
        "minutes": "{0}  ",
        "hour": " ",
        "hours": "{0} ",
        "day": " ",
        "days": "{0} ",
        "month": "  ",
        "months": "{0}  ",
        "year": "  ",
        "years": "{0}  ",
    }

    meridians = {"am": "", "pm": "", "AM": "", "PM": ""}

    month_names = [
        "",
        "",
        "",
        "",
        " ",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


class CzechLocale(Locale):
    names = ["cs", "cs_cz"]

    timeframes = {
        "now": "Te",
        "second": {"past": "vteina", "future": "vteina", "zero": "vteina"},
        "seconds": {"past": "{0} sekundami", "future": ["{0} sekundy", "{0} sekund"]},
        "minute": {"past": "minutou", "future": "minutu", "zero": "{0} minut"},
        "minutes": {"past": "{0} minutami", "future": ["{0} minuty", "{0} minut"]},
        "hour": {"past": "hodinou", "future": "hodinu", "zero": "{0} hodin"},
        "hours": {"past": "{0} hodinami", "future": ["{0} hodiny", "{0} hodin"]},
        "day": {"past": "dnem", "future": "den", "zero": "{0} dn"},
        "days": {"past": "{0} dny", "future": ["{0} dny", "{0} dn"]},
        "month": {"past": "mscem", "future": "msc", "zero": "{0} msc"},
        "months": {"past": "{0} msci", "future": ["{0} msce", "{0} msc"]},
        "year": {"past": "rokem", "future": "rok", "zero": "{0} let"},
        "years": {"past": "{0} lety", "future": ["{0} roky", "{0} let"]},
    }

    past = "Ped {0}"
    future = "Za {0}"

    month_names = [
        "",
        "leden",
        "nor",
        "bezen",
        "duben",
        "kvten",
        "erven",
        "ervenec",
        "srpen",
        "z",
        "jen",
        "listopad",
        "prosinec",
    ]
    month_abbreviations = [
        "",
        "led",
        "no",
        "be",
        "dub",
        "kv",
        "vn",
        "vc",
        "srp",
        "z",
        "j",
        "lis",
        "pro",
    ]

    day_names = [
        "",
        "pondl",
        "ter",
        "steda",
        "tvrtek",
        "ptek",
        "sobota",
        "nedle",
    ]
    day_abbreviations = ["", "po", "t", "st", "t", "p", "so", "ne"]

    def _format_timeframe(self, timeframe, delta):
        """Czech aware time frame format function, takes into account
        the differences between past and future forms."""
        form = self.timeframes[timeframe]
        if isinstance(form, dict):
            if delta == 0:
                form = form["zero"]  # And *never* use 0 in the singular!
            elif delta > 0:
                form = form["future"]
            else:
                form = form["past"]
        delta = abs(delta)

        if isinstance(form, list):
            if 2 <= delta % 10 <= 4 and (delta % 100 < 10 or delta % 100 >= 20):
                form = form[0]
            else:
                form = form[1]

        return form.format(delta)


class SlovakLocale(Locale):
    names = ["sk", "sk_sk"]

    timeframes = {
        "now": "Teraz",
        "second": {"past": "sekundou", "future": "sekundu", "zero": "{0} seknd"},
        "seconds": {"past": "{0} sekundami", "future": ["{0} sekundy", "{0} seknd"]},
        "minute": {"past": "mintou", "future": "mintu", "zero": "{0} mint"},
        "minutes": {"past": "{0} mintami", "future": ["{0} minty", "{0} mint"]},
        "hour": {"past": "hodinou", "future": "hodinu", "zero": "{0} hodn"},
        "hours": {"past": "{0} hodinami", "future": ["{0} hodiny", "{0} hodn"]},
        "day": {"past": "dom", "future": "de", "zero": "{0} dn"},
        "days": {"past": "{0} dami", "future": ["{0} dni", "{0} dn"]},
        "week": {"past": "tdom", "future": "tde", "zero": "{0} tdov"},
        "weeks": {"past": "{0} tdami", "future": ["{0} tdne", "{0} tdov"]},
        "month": {"past": "mesiacom", "future": "mesiac", "zero": "{0} mesiacov"},
        "months": {"past": "{0} mesiacmi", "future": ["{0} mesiace", "{0} mesiacov"]},
        "year": {"past": "rokom", "future": "rok", "zero": "{0} rokov"},
        "years": {"past": "{0} rokmi", "future": ["{0} roky", "{0} rokov"]},
    }

    past = "Pred {0}"
    future = "O {0}"
    and_word = "a"

    month_names = [
        "",
        "janur",
        "februr",
        "marec",
        "aprl",
        "mj",
        "jn",
        "jl",
        "august",
        "september",
        "oktber",
        "november",
        "december",
    ]
    month_abbreviations = [
        "",
        "jan",
        "feb",
        "mar",
        "apr",
        "mj",
        "jn",
        "jl",
        "aug",
        "sep",
        "okt",
        "nov",
        "dec",
    ]

    day_names = [
        "",
        "pondelok",
        "utorok",
        "streda",
        "tvrtok",
        "piatok",
        "sobota",
        "nedea",
    ]
    day_abbreviations = ["", "po", "ut", "st", "t", "pi", "so", "ne"]

    def _format_timeframe(self, timeframe, delta):
        """Slovak aware time frame format function, takes into account
        the differences between past and future forms."""
        form = self.timeframes[timeframe]
        if isinstance(form, dict):
            if delta == 0:
                form = form["zero"]  # And *never* use 0 in the singular!
            elif delta > 0:
                form = form["future"]
            else:
                form = form["past"]
        delta = abs(delta)

        if isinstance(form, list):
            if 2 <= delta % 10 <= 4 and (delta % 100 < 10 or delta % 100 >= 20):
                form = form[0]
            else:
                form = form[1]

        return form.format(delta)


class FarsiLocale(Locale):

    names = ["fa", "fa_ir"]

    past = "{0} "
    future = " {0}"

    timeframes = {
        "now": "",
        "second": " ",
        "seconds": "{0} ",
        "minute": " ",
        "minutes": "{0} ",
        "hour": " ",
        "hours": "{0} ",
        "day": " ",
        "days": "{0} ",
        "month": " ",
        "months": "{0} ",
        "year": " ",
        "years": "{0} ",
    }

    meridians = {
        "am": "  ",
        "pm": "  ",
        "AM": "  ",
        "PM": "  ",
    }

    month_names = [
        "",
        "January",
        "February",
        "March",
        "April",
        "May",
        "June",
        "July",
        "August",
        "September",
        "October",
        "November",
        "December",
    ]
    month_abbreviations = [
        "",
        "Jan",
        "Feb",
        "Mar",
        "Apr",
        "May",
        "Jun",
        "Jul",
        "Aug",
        "Sep",
        "Oct",
        "Nov",
        "Dec",
    ]

    day_names = [
        "",
        " ",
        " ",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = ["", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"]


class HebrewLocale(Locale):

    names = ["he", "he_IL"]

    past = " {0}"
    future = " {0}"
    and_word = ""

    timeframes = {
        "now": "",
        "second": "",
        "seconds": "{0} ",
        "minute": "",
        "minutes": "{0} ",
        "hour": "",
        "hours": "{0} ",
        "2-hours": "",
        "day": "",
        "days": "{0} ",
        "2-days": "",
        "week": "",
        "weeks": "{0} ",
        "2-weeks": "",
        "month": "",
        "months": "{0} ",
        "2-months": "",
        "year": "",
        "years": "{0} ",
        "2-years": "",
    }

    meridians = {
        "am": '"',
        "pm": '"',
        "AM": " ",
        "PM": " ",
    }

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = ["", "", "", "", "", "", "", ""]
    day_abbreviations = ["", "", "", "", "", "", "", ""]

    def _format_timeframe(self, timeframe, delta):
        """Hebrew couple of <timeframe> aware"""
        couple = "2-{}".format(timeframe)
        single = timeframe.rstrip("s")
        if abs(delta) == 2 and couple in self.timeframes:
            key = couple
        elif abs(delta) == 1 and single in self.timeframes:
            key = single
        else:
            key = timeframe

        return self.timeframes[key].format(trunc(abs(delta)))

    def describe_multi(self, timeframes, only_distance=False):
        """ Describes a delta within multiple timeframes in plain language.
        In Hebrew, the and word behaves a bit differently.

        :param timeframes: a list of string, quantity pairs each representing a timeframe and delta.
        :param only_distance: return only distance eg: "2 hours and 11 seconds" without "in" or "ago" keywords
        """

        humanized = ""
        for index, (timeframe, delta) in enumerate(timeframes):
            last_humanized = self._format_timeframe(timeframe, delta)
            if index == 0:
                humanized = last_humanized
            elif index == len(timeframes) - 1:  # Must have at least 2 items
                humanized += " " + self.and_word
                if last_humanized[0].isdecimal():
                    humanized += ""
                humanized += last_humanized
            else:  # Don't add for the last one
                humanized += ", " + last_humanized

        if not only_distance:
            humanized = self._format_relative(humanized, timeframe, delta)

        return humanized


class MarathiLocale(Locale):

    names = ["mr"]

    past = "{0} "
    future = "{0} "

    timeframes = {
        "now": "",
        "second": " ",
        "seconds": "{0} ",
        "minute": "  ",
        "minutes": "{0}  ",
        "hour": " ",
        "hours": "{0} ",
        "day": " ",
        "days": "{0} ",
        "month": "  ",
        "months": "{0}  ",
        "year": "  ",
        "years": "{0}  ",
    }

    meridians = {"am": "", "pm": "", "AM": "", "PM": ""}

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = ["", "", "", "", "", "", "", ""]


def _map_locales():

    locales = {}

    for _, cls in inspect.getmembers(sys.modules[__name__], inspect.isclass):
        if issubclass(cls, Locale):  # pragma: no branch
            for name in cls.names:
                locales[name.lower()] = cls

    return locales


class CatalanLocale(Locale):
    names = ["ca", "ca_es", "ca_ad", "ca_fr", "ca_it"]
    past = "Fa {0}"
    future = "En {0}"
    and_word = "i"

    timeframes = {
        "now": "Ara mateix",
        "second": "un segon",
        "seconds": "{0} segons",
        "minute": "1 minut",
        "minutes": "{0} minuts",
        "hour": "una hora",
        "hours": "{0} hores",
        "day": "un dia",
        "days": "{0} dies",
        "month": "un mes",
        "months": "{0} mesos",
        "year": "un any",
        "years": "{0} anys",
    }

    month_names = [
        "",
        "Gener",
        "Febrer",
        "Mar",
        "Abril",
        "Maig",
        "Juny",
        "Juliol",
        "Agost",
        "Setembre",
        "Octubre",
        "Novembre",
        "Desembre",
    ]
    month_abbreviations = [
        "",
        "Gener",
        "Febrer",
        "Mar",
        "Abril",
        "Maig",
        "Juny",
        "Juliol",
        "Agost",
        "Setembre",
        "Octubre",
        "Novembre",
        "Desembre",
    ]
    day_names = [
        "",
        "Dilluns",
        "Dimarts",
        "Dimecres",
        "Dijous",
        "Divendres",
        "Dissabte",
        "Diumenge",
    ]
    day_abbreviations = [
        "",
        "Dilluns",
        "Dimarts",
        "Dimecres",
        "Dijous",
        "Divendres",
        "Dissabte",
        "Diumenge",
    ]


class BasqueLocale(Locale):
    names = ["eu", "eu_eu"]
    past = "duela {0}"
    future = "{0}"  # I don't know what's the right phrase in Basque for the future.

    timeframes = {
        "now": "Orain",
        "second": "segundo bat",
        "seconds": "{0} segundu",
        "minute": "minutu bat",
        "minutes": "{0} minutu",
        "hour": "ordu bat",
        "hours": "{0} ordu",
        "day": "egun bat",
        "days": "{0} egun",
        "month": "hilabete bat",
        "months": "{0} hilabet",
        "year": "urte bat",
        "years": "{0} urte",
    }

    month_names = [
        "",
        "urtarrilak",
        "otsailak",
        "martxoak",
        "apirilak",
        "maiatzak",
        "ekainak",
        "uztailak",
        "abuztuak",
        "irailak",
        "urriak",
        "azaroak",
        "abenduak",
    ]
    month_abbreviations = [
        "",
        "urt",
        "ots",
        "mar",
        "api",
        "mai",
        "eka",
        "uzt",
        "abu",
        "ira",
        "urr",
        "aza",
        "abe",
    ]
    day_names = [
        "",
        "astelehena",
        "asteartea",
        "asteazkena",
        "osteguna",
        "ostirala",
        "larunbata",
        "igandea",
    ]
    day_abbreviations = ["", "al", "ar", "az", "og", "ol", "lr", "ig"]


class HungarianLocale(Locale):

    names = ["hu", "hu_hu"]

    past = "{0} ezeltt"
    future = "{0} mlva"

    timeframes = {
        "now": "ppen most",
        "second": {"past": "egy msodik", "future": "egy msodik"},
        "seconds": {"past": "{0} msodpercekkel", "future": "{0} pr msodperc"},
        "minute": {"past": "egy perccel", "future": "egy perc"},
        "minutes": {"past": "{0} perccel", "future": "{0} perc"},
        "hour": {"past": "egy rval", "future": "egy ra"},
        "hours": {"past": "{0} rval", "future": "{0} ra"},
        "day": {"past": "egy nappal", "future": "egy nap"},
        "days": {"past": "{0} nappal", "future": "{0} nap"},
        "month": {"past": "egy hnappal", "future": "egy hnap"},
        "months": {"past": "{0} hnappal", "future": "{0} hnap"},
        "year": {"past": "egy vvel", "future": "egy v"},
        "years": {"past": "{0} vvel", "future": "{0} v"},
    }

    month_names = [
        "",
        "janur",
        "februr",
        "mrcius",
        "prilis",
        "mjus",
        "jnius",
        "jlius",
        "augusztus",
        "szeptember",
        "oktber",
        "november",
        "december",
    ]
    month_abbreviations = [
        "",
        "jan",
        "febr",
        "mrc",
        "pr",
        "mj",
        "jn",
        "jl",
        "aug",
        "szept",
        "okt",
        "nov",
        "dec",
    ]

    day_names = [
        "",
        "htf",
        "kedd",
        "szerda",
        "cstrtk",
        "pntek",
        "szombat",
        "vasrnap",
    ]
    day_abbreviations = ["", "ht", "kedd", "szer", "cst", "pnt", "szom", "vas"]

    meridians = {"am": "de", "pm": "du", "AM": "DE", "PM": "DU"}

    def _format_timeframe(self, timeframe, delta):
        form = self.timeframes[timeframe]

        if isinstance(form, dict):
            if delta > 0:
                form = form["future"]
            else:
                form = form["past"]

        return form.format(abs(delta))


class EsperantoLocale(Locale):
    names = ["eo", "eo_xx"]
    past = "anta {0}"
    future = "post {0}"

    timeframes = {
        "now": "nun",
        "second": "sekundo",
        "seconds": "{0} kelkaj sekundoj",
        "minute": "unu minuto",
        "minutes": "{0} minutoj",
        "hour": "un horo",
        "hours": "{0} horoj",
        "day": "unu tago",
        "days": "{0} tagoj",
        "month": "unu monato",
        "months": "{0} monatoj",
        "year": "unu jaro",
        "years": "{0} jaroj",
    }

    month_names = [
        "",
        "januaro",
        "februaro",
        "marto",
        "aprilo",
        "majo",
        "junio",
        "julio",
        "agusto",
        "septembro",
        "oktobro",
        "novembro",
        "decembro",
    ]
    month_abbreviations = [
        "",
        "jan",
        "feb",
        "mar",
        "apr",
        "maj",
        "jun",
        "jul",
        "ag",
        "sep",
        "okt",
        "nov",
        "dec",
    ]

    day_names = [
        "",
        "lundo",
        "mardo",
        "merkredo",
        "ado",
        "vendredo",
        "sabato",
        "dimano",
    ]
    day_abbreviations = ["", "lun", "mar", "mer", "a", "ven", "sab", "dim"]

    meridians = {"am": "atm", "pm": "ptm", "AM": "ATM", "PM": "PTM"}

    ordinal_day_re = r"((?P<value>[1-3]?[0-9](?=a))a)"

    def _ordinal_number(self, n):
        return "{}a".format(n)


class ThaiLocale(Locale):

    names = ["th", "th_th"]

    past = "{0}{1}"
    future = "{1}{0}"

    timeframes = {
        "now": "",
        "second": "",
        "seconds": "{0} ",
        "minute": "1 ",
        "minutes": "{0} ",
        "hour": "1 ",
        "hours": "{0} ",
        "day": "1 ",
        "days": "{0} ",
        "month": "1 ",
        "months": "{0} ",
        "year": "1 ",
        "years": "{0} ",
    }

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "..",
        "..",
        "..",
        "..",
        "..",
        "..",
        "..",
        "..",
        "..",
        "..",
        "..",
        "..",
    ]

    day_names = ["", "", "", "", "", "", "", ""]
    day_abbreviations = ["", "", "", "", "", "", "", ""]

    meridians = {"am": "am", "pm": "pm", "AM": "AM", "PM": "PM"}

    BE_OFFSET = 543

    def year_full(self, year):
        """Thai always use Buddhist Era (BE) which is CE + 543"""
        year += self.BE_OFFSET
        return "{:04d}".format(year)

    def year_abbreviation(self, year):
        """Thai always use Buddhist Era (BE) which is CE + 543"""
        year += self.BE_OFFSET
        return "{:04d}".format(year)[2:]

    def _format_relative(self, humanized, timeframe, delta):
        """Thai normally doesn't have any space between words"""
        if timeframe == "now":
            return humanized
        space = "" if timeframe == "seconds" else " "
        direction = self.past if delta < 0 else self.future

        return direction.format(humanized, space)


class BengaliLocale(Locale):

    names = ["bn", "bn_bd", "bn_in"]

    past = "{0} "
    future = "{0} "

    timeframes = {
        "now": "",
        "second": " ",
        "seconds": "{0} ",
        "minute": " ",
        "minutes": "{0} ",
        "hour": " ",
        "hours": "{0} ",
        "day": " ",
        "days": "{0} ",
        "month": " ",
        "months": "{0}  ",
        "year": " ",
        "years": "{0} ",
    }

    meridians = {"am": "", "pm": "", "AM": "", "PM": ""}

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    day_abbreviations = ["", "", "", "", "", "", "", ""]

    def _ordinal_number(self, n):
        if n > 10 or n == 0:
            return "{}".format(n)
        if n in [1, 5, 7, 8, 9, 10]:
            return "{}".format(n)
        if n in [2, 3]:
            return "{}".format(n)
        if n == 4:
            return "{}".format(n)
        if n == 6:
            return "{}".format(n)


class RomanshLocale(Locale):

    names = ["rm", "rm_ch"]

    past = "avant {0}"
    future = "en {0}"

    timeframes = {
        "now": "en quest mument",
        "second": "in secunda",
        "seconds": "{0} secundas",
        "minute": "ina minuta",
        "minutes": "{0} minutas",
        "hour": "in'ura",
        "hours": "{0} ura",
        "day": "in di",
        "days": "{0} dis",
        "month": "in mais",
        "months": "{0} mais",
        "year": "in onn",
        "years": "{0} onns",
    }

    month_names = [
        "",
        "schaner",
        "favrer",
        "mars",
        "avrigl",
        "matg",
        "zercladur",
        "fanadur",
        "avust",
        "settember",
        "october",
        "november",
        "december",
    ]

    month_abbreviations = [
        "",
        "schan",
        "fav",
        "mars",
        "avr",
        "matg",
        "zer",
        "fan",
        "avu",
        "set",
        "oct",
        "nov",
        "dec",
    ]

    day_names = [
        "",
        "glindesdi",
        "mardi",
        "mesemna",
        "gievgia",
        "venderdi",
        "sonda",
        "dumengia",
    ]

    day_abbreviations = ["", "gli", "ma", "me", "gie", "ve", "so", "du"]


class RomanianLocale(Locale):
    names = ["ro", "ro_ro"]

    past = "{0} n urm"
    future = "peste {0}"
    and_word = "i"

    timeframes = {
        "now": "acum",
        "second": "o secunda",
        "seconds": "{0} cteva secunde",
        "minute": "un minut",
        "minutes": "{0} minute",
        "hour": "o or",
        "hours": "{0} ore",
        "day": "o zi",
        "days": "{0} zile",
        "month": "o lun",
        "months": "{0} luni",
        "year": "un an",
        "years": "{0} ani",
    }

    month_names = [
        "",
        "ianuarie",
        "februarie",
        "martie",
        "aprilie",
        "mai",
        "iunie",
        "iulie",
        "august",
        "septembrie",
        "octombrie",
        "noiembrie",
        "decembrie",
    ]
    month_abbreviations = [
        "",
        "ian",
        "febr",
        "mart",
        "apr",
        "mai",
        "iun",
        "iul",
        "aug",
        "sept",
        "oct",
        "nov",
        "dec",
    ]

    day_names = [
        "",
        "luni",
        "mari",
        "miercuri",
        "joi",
        "vineri",
        "smbt",
        "duminic",
    ]
    day_abbreviations = ["", "Lun", "Mar", "Mie", "Joi", "Vin", "Sm", "Dum"]


class SlovenianLocale(Locale):
    names = ["sl", "sl_si"]

    past = "pred {0}"
    future = "ez {0}"
    and_word = "in"

    timeframes = {
        "now": "zdaj",
        "second": "sekundo",
        "seconds": "{0} sekund",
        "minute": "minuta",
        "minutes": "{0} minutami",
        "hour": "uro",
        "hours": "{0} ur",
        "day": "dan",
        "days": "{0} dni",
        "month": "mesec",
        "months": "{0} mesecev",
        "year": "leto",
        "years": "{0} let",
    }

    meridians = {"am": "", "pm": "", "AM": "", "PM": ""}

    month_names = [
        "",
        "Januar",
        "Februar",
        "Marec",
        "April",
        "Maj",
        "Junij",
        "Julij",
        "Avgust",
        "September",
        "Oktober",
        "November",
        "December",
    ]

    month_abbreviations = [
        "",
        "Jan",
        "Feb",
        "Mar",
        "Apr",
        "Maj",
        "Jun",
        "Jul",
        "Avg",
        "Sep",
        "Okt",
        "Nov",
        "Dec",
    ]

    day_names = [
        "",
        "Ponedeljek",
        "Torek",
        "Sreda",
        "etrtek",
        "Petek",
        "Sobota",
        "Nedelja",
    ]

    day_abbreviations = ["", "Pon", "Tor", "Sre", "et", "Pet", "Sob", "Ned"]


class IndonesianLocale(Locale):

    names = ["id", "id_id"]

    past = "{0} yang lalu"
    future = "dalam {0}"
    and_word = "dan"

    timeframes = {
        "now": "baru saja",
        "second": "1 sebentar",
        "seconds": "{0} detik",
        "minute": "1 menit",
        "minutes": "{0} menit",
        "hour": "1 jam",
        "hours": "{0} jam",
        "day": "1 hari",
        "days": "{0} hari",
        "month": "1 bulan",
        "months": "{0} bulan",
        "year": "1 tahun",
        "years": "{0} tahun",
    }

    meridians = {"am": "", "pm": "", "AM": "", "PM": ""}

    month_names = [
        "",
        "Januari",
        "Februari",
        "Maret",
        "April",
        "Mei",
        "Juni",
        "Juli",
        "Agustus",
        "September",
        "Oktober",
        "November",
        "Desember",
    ]

    month_abbreviations = [
        "",
        "Jan",
        "Feb",
        "Mar",
        "Apr",
        "Mei",
        "Jun",
        "Jul",
        "Ags",
        "Sept",
        "Okt",
        "Nov",
        "Des",
    ]

    day_names = ["", "Senin", "Selasa", "Rabu", "Kamis", "Jumat", "Sabtu", "Minggu"]

    day_abbreviations = [
        "",
        "Senin",
        "Selasa",
        "Rabu",
        "Kamis",
        "Jumat",
        "Sabtu",
        "Minggu",
    ]


class NepaliLocale(Locale):
    names = ["ne", "ne_np"]

    past = "{0} "
    future = "{0} "

    timeframes = {
        "now": "",
        "second": " ",
        "seconds": "{0} ",
        "minute": "",
        "minutes": "{0} ",
        "hour": " ",
        "hours": "{0} ",
        "day": " ",
        "days": "{0} ",
        "month": " ",
        "months": "{0} ",
        "year": " ",
        "years": "",
    }

    meridians = {"am": "", "pm": "", "AM": "", "PM": ""}

    month_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]
    month_abbreviations = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_names = [
        "",
        "",
        "",
        "",
        "",
        "",
        "",
        "",
    ]

    day_abbreviations = ["", "", "", "", "", "", "", ""]


class EstonianLocale(Locale):
    names = ["ee", "et"]

    past = "{0} tagasi"
    future = "{0} prast"
    and_word = "ja"

    timeframes = {
        "now": {"past": "just nd", "future": "just nd"},
        "second": {"past": "ks sekund", "future": "he sekundi"},
        "seconds": {"past": "{0} sekundit", "future": "{0} sekundi"},
        "minute": {"past": "ks minut", "future": "he minuti"},
        "minutes": {"past": "{0} minutit", "future": "{0} minuti"},
        "hour": {"past": "tund aega", "future": "tunni aja"},
        "hours": {"past": "{0} tundi", "future": "{0} tunni"},
        "day": {"past": "ks pev", "future": "he peva"},
        "days": {"past": "{0} peva", "future": "{0} peva"},
        "month": {"past": "ks kuu", "future": "he kuu"},
        "months": {"past": "{0} kuud", "future": "{0} kuu"},
        "year": {"past": "ks aasta", "future": "he aasta"},
        "years": {"past": "{0} aastat", "future": "{0} aasta"},
    }

    month_names = [
        "",
        "Jaanuar",
        "Veebruar",
        "Mrts",
        "Aprill",
        "Mai",
        "Juuni",
        "Juuli",
        "August",
        "September",
        "Oktoober",
        "November",
        "Detsember",
    ]
    month_abbreviations = [
        "",
        "Jan",
        "Veb",
        "Mr",
        "Apr",
        "Mai",
        "Jun",
        "Jul",
        "Aug",
        "Sep",
        "Okt",
        "Nov",
        "Dets",
    ]

    day_names = [
        "",
        "Esmaspev",
        "Teisipev",
        "Kolmapev",
        "Neljapev",
        "Reede",
        "Laupev",
        "Phapev",
    ]
    day_abbreviations = ["", "Esm", "Teis", "Kolm", "Nelj", "Re", "Lau", "Ph"]

    def _format_timeframe(self, timeframe, delta):
        form = self.timeframes[timeframe]
        if delta > 0:
            form = form["future"]
        else:
            form = form["past"]
        return form.format(abs(delta))


class SwahiliLocale(Locale):

    names = [
        "sw",
        "sw_ke",
        "sw_tz",
    ]

    past = "{0} iliyopita"
    future = "muda wa {0}"
    and_word = "na"

    timeframes = {
        "now": "sasa hivi",
        "second": "sekunde",
        "seconds": "sekunde {0}",
        "minute": "dakika moja",
        "minutes": "dakika {0}",
        "hour": "saa moja",
        "hours": "saa {0}",
        "day": "siku moja",
        "days": "siku {0}",
        "week": "wiki moja",
        "weeks": "wiki {0}",
        "month": "mwezi moja",
        "months": "miezi {0}",
        "year": "mwaka moja",
        "years": "miaka {0}",
    }

    meridians = {"am": "asu", "pm": "mch", "AM": "ASU", "PM": "MCH"}

    month_names = [
        "",
        "Januari",
        "Februari",
        "Machi",
        "Aprili",
        "Mei",
        "Juni",
        "Julai",
        "Agosti",
        "Septemba",
        "Oktoba",
        "Novemba",
        "Desemba",
    ]
    month_abbreviations = [
        "",
        "Jan",
        "Feb",
        "Mac",
        "Apr",
        "Mei",
        "Jun",
        "Jul",
        "Ago",
        "Sep",
        "Okt",
        "Nov",
        "Des",
    ]

    day_names = [
        "",
        "Jumatatu",
        "Jumanne",
        "Jumatano",
        "Alhamisi",
        "Ijumaa",
        "Jumamosi",
        "Jumapili",
    ]
    day_abbreviations = [
        "",
        "Jumatatu",
        "Jumanne",
        "Jumatano",
        "Alhamisi",
        "Ijumaa",
        "Jumamosi",
        "Jumapili",
    ]


_locales = _map_locales()




############################################################
### File: mbcharsetprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#   Proofpoint, Inc.
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetprober import CharSetProber
from .enums import ProbingState, MachineState


class MultiByteCharSetProber(CharSetProber):
    """
    MultiByteCharSetProber
    """

    def __init__(self, lang_filter=None):
        super(MultiByteCharSetProber, self).__init__(lang_filter=lang_filter)
        self.distribution_analyzer = None
        self.coding_sm = None
        self._last_char = [0, 0]

    def reset(self):
        super(MultiByteCharSetProber, self).reset()
        if self.coding_sm:
            self.coding_sm.reset()
        if self.distribution_analyzer:
            self.distribution_analyzer.reset()
        self._last_char = [0, 0]

    @property
    def charset_name(self):
        raise NotImplementedError

    @property
    def language(self):
        raise NotImplementedError

    def feed(self, byte_str):
        for i in range(len(byte_str)):
            coding_state = self.coding_sm.next_state(byte_str[i])
            if coding_state == MachineState.ERROR:
                self.logger.debug('%s %s prober hit error at byte %s',
                                  self.charset_name, self.language, i)
                self._state = ProbingState.NOT_ME
                break
            elif coding_state == MachineState.ITS_ME:
                self._state = ProbingState.FOUND_IT
                break
            elif coding_state == MachineState.START:
                char_len = self.coding_sm.get_current_charlen()
                if i == 0:
                    self._last_char[1] = byte_str[0]
                    self.distribution_analyzer.feed(self._last_char, char_len)
                else:
                    self.distribution_analyzer.feed(byte_str[i - 1:i + 1],
                                                    char_len)

        self._last_char[0] = byte_str[-1]

        if self.state == ProbingState.DETECTING:
            if (self.distribution_analyzer.got_enough_data() and
                    (self.get_confidence() > self.SHORTCUT_THRESHOLD)):
                self._state = ProbingState.FOUND_IT

        return self.state

    def get_confidence(self):
        return self.distribution_analyzer.get_confidence()




############################################################
### File: mbcsgroupprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#   Proofpoint, Inc.
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetgroupprober import CharSetGroupProber
from .utf8prober import UTF8Prober
from .sjisprober import SJISProber
from .eucjpprober import EUCJPProber
from .gb2312prober import GB2312Prober
from .euckrprober import EUCKRProber
from .cp949prober import CP949Prober
from .big5prober import Big5Prober
from .euctwprober import EUCTWProber


class MBCSGroupProber(CharSetGroupProber):
    def __init__(self, lang_filter=None):
        super(MBCSGroupProber, self).__init__(lang_filter=lang_filter)
        self.probers = [
            UTF8Prober(),
            SJISProber(),
            EUCJPProber(),
            GB2312Prober(),
            EUCKRProber(),
            CP949Prober(),
            Big5Prober(),
            EUCTWProber()
        ]
        self.reset()




############################################################
### File: mbcssm.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .enums import MachineState

# BIG5

BIG5_CLS = (
    1,1,1,1,1,1,1,1,  # 00 - 07    #allow 0x00 as legal value
    1,1,1,1,1,1,0,0,  # 08 - 0f
    1,1,1,1,1,1,1,1,  # 10 - 17
    1,1,1,0,1,1,1,1,  # 18 - 1f
    1,1,1,1,1,1,1,1,  # 20 - 27
    1,1,1,1,1,1,1,1,  # 28 - 2f
    1,1,1,1,1,1,1,1,  # 30 - 37
    1,1,1,1,1,1,1,1,  # 38 - 3f
    2,2,2,2,2,2,2,2,  # 40 - 47
    2,2,2,2,2,2,2,2,  # 48 - 4f
    2,2,2,2,2,2,2,2,  # 50 - 57
    2,2,2,2,2,2,2,2,  # 58 - 5f
    2,2,2,2,2,2,2,2,  # 60 - 67
    2,2,2,2,2,2,2,2,  # 68 - 6f
    2,2,2,2,2,2,2,2,  # 70 - 77
    2,2,2,2,2,2,2,1,  # 78 - 7f
    4,4,4,4,4,4,4,4,  # 80 - 87
    4,4,4,4,4,4,4,4,  # 88 - 8f
    4,4,4,4,4,4,4,4,  # 90 - 97
    4,4,4,4,4,4,4,4,  # 98 - 9f
    4,3,3,3,3,3,3,3,  # a0 - a7
    3,3,3,3,3,3,3,3,  # a8 - af
    3,3,3,3,3,3,3,3,  # b0 - b7
    3,3,3,3,3,3,3,3,  # b8 - bf
    3,3,3,3,3,3,3,3,  # c0 - c7
    3,3,3,3,3,3,3,3,  # c8 - cf
    3,3,3,3,3,3,3,3,  # d0 - d7
    3,3,3,3,3,3,3,3,  # d8 - df
    3,3,3,3,3,3,3,3,  # e0 - e7
    3,3,3,3,3,3,3,3,  # e8 - ef
    3,3,3,3,3,3,3,3,  # f0 - f7
    3,3,3,3,3,3,3,0  # f8 - ff
)

BIG5_ST = (
    MachineState.ERROR,MachineState.START,MachineState.START,     3,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#00-07
    MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ERROR,#08-0f
    MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START#10-17
)

BIG5_CHAR_LEN_TABLE = (0, 1, 1, 2, 0)

BIG5_SM_MODEL = {'class_table': BIG5_CLS,
                 'class_factor': 5,
                 'state_table': BIG5_ST,
                 'char_len_table': BIG5_CHAR_LEN_TABLE,
                 'name': 'Big5'}

# CP949

CP949_CLS  = (
    1,1,1,1,1,1,1,1, 1,1,1,1,1,1,0,0,  # 00 - 0f
    1,1,1,1,1,1,1,1, 1,1,1,0,1,1,1,1,  # 10 - 1f
    1,1,1,1,1,1,1,1, 1,1,1,1,1,1,1,1,  # 20 - 2f
    1,1,1,1,1,1,1,1, 1,1,1,1,1,1,1,1,  # 30 - 3f
    1,4,4,4,4,4,4,4, 4,4,4,4,4,4,4,4,  # 40 - 4f
    4,4,5,5,5,5,5,5, 5,5,5,1,1,1,1,1,  # 50 - 5f
    1,5,5,5,5,5,5,5, 5,5,5,5,5,5,5,5,  # 60 - 6f
    5,5,5,5,5,5,5,5, 5,5,5,1,1,1,1,1,  # 70 - 7f
    0,6,6,6,6,6,6,6, 6,6,6,6,6,6,6,6,  # 80 - 8f
    6,6,6,6,6,6,6,6, 6,6,6,6,6,6,6,6,  # 90 - 9f
    6,7,7,7,7,7,7,7, 7,7,7,7,7,8,8,8,  # a0 - af
    7,7,7,7,7,7,7,7, 7,7,7,7,7,7,7,7,  # b0 - bf
    7,7,7,7,7,7,9,2, 2,3,2,2,2,2,2,2,  # c0 - cf
    2,2,2,2,2,2,2,2, 2,2,2,2,2,2,2,2,  # d0 - df
    2,2,2,2,2,2,2,2, 2,2,2,2,2,2,2,2,  # e0 - ef
    2,2,2,2,2,2,2,2, 2,2,2,2,2,2,2,0,  # f0 - ff
)

CP949_ST = (
#cls=    0      1      2      3      4      5      6      7      8      9  # previous state =
    MachineState.ERROR,MachineState.START,     3,MachineState.ERROR,MachineState.START,MachineState.START,     4,     5,MachineState.ERROR,     6, # MachineState.START
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR, # MachineState.ERROR
    MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME, # MachineState.ITS_ME
    MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START, # 3
    MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START, # 4
    MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START, # 5
    MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START, # 6
)

CP949_CHAR_LEN_TABLE = (0, 1, 2, 0, 1, 1, 2, 2, 0, 2)

CP949_SM_MODEL = {'class_table': CP949_CLS,
                  'class_factor': 10,
                  'state_table': CP949_ST,
                  'char_len_table': CP949_CHAR_LEN_TABLE,
                  'name': 'CP949'}

# EUC-JP

EUCJP_CLS = (
    4,4,4,4,4,4,4,4,  # 00 - 07
    4,4,4,4,4,4,5,5,  # 08 - 0f
    4,4,4,4,4,4,4,4,  # 10 - 17
    4,4,4,5,4,4,4,4,  # 18 - 1f
    4,4,4,4,4,4,4,4,  # 20 - 27
    4,4,4,4,4,4,4,4,  # 28 - 2f
    4,4,4,4,4,4,4,4,  # 30 - 37
    4,4,4,4,4,4,4,4,  # 38 - 3f
    4,4,4,4,4,4,4,4,  # 40 - 47
    4,4,4,4,4,4,4,4,  # 48 - 4f
    4,4,4,4,4,4,4,4,  # 50 - 57
    4,4,4,4,4,4,4,4,  # 58 - 5f
    4,4,4,4,4,4,4,4,  # 60 - 67
    4,4,4,4,4,4,4,4,  # 68 - 6f
    4,4,4,4,4,4,4,4,  # 70 - 77
    4,4,4,4,4,4,4,4,  # 78 - 7f
    5,5,5,5,5,5,5,5,  # 80 - 87
    5,5,5,5,5,5,1,3,  # 88 - 8f
    5,5,5,5,5,5,5,5,  # 90 - 97
    5,5,5,5,5,5,5,5,  # 98 - 9f
    5,2,2,2,2,2,2,2,  # a0 - a7
    2,2,2,2,2,2,2,2,  # a8 - af
    2,2,2,2,2,2,2,2,  # b0 - b7
    2,2,2,2,2,2,2,2,  # b8 - bf
    2,2,2,2,2,2,2,2,  # c0 - c7
    2,2,2,2,2,2,2,2,  # c8 - cf
    2,2,2,2,2,2,2,2,  # d0 - d7
    2,2,2,2,2,2,2,2,  # d8 - df
    0,0,0,0,0,0,0,0,  # e0 - e7
    0,0,0,0,0,0,0,0,  # e8 - ef
    0,0,0,0,0,0,0,0,  # f0 - f7
    0,0,0,0,0,0,0,5  # f8 - ff
)

EUCJP_ST = (
          3,     4,     3,     5,MachineState.START,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#00-07
     MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,#08-0f
     MachineState.ITS_ME,MachineState.ITS_ME,MachineState.START,MachineState.ERROR,MachineState.START,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#10-17
     MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     3,MachineState.ERROR,#18-1f
          3,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START#20-27
)

EUCJP_CHAR_LEN_TABLE = (2, 2, 2, 3, 1, 0)

EUCJP_SM_MODEL = {'class_table': EUCJP_CLS,
                  'class_factor': 6,
                  'state_table': EUCJP_ST,
                  'char_len_table': EUCJP_CHAR_LEN_TABLE,
                  'name': 'EUC-JP'}

# EUC-KR

EUCKR_CLS  = (
    1,1,1,1,1,1,1,1,  # 00 - 07
    1,1,1,1,1,1,0,0,  # 08 - 0f
    1,1,1,1,1,1,1,1,  # 10 - 17
    1,1,1,0,1,1,1,1,  # 18 - 1f
    1,1,1,1,1,1,1,1,  # 20 - 27
    1,1,1,1,1,1,1,1,  # 28 - 2f
    1,1,1,1,1,1,1,1,  # 30 - 37
    1,1,1,1,1,1,1,1,  # 38 - 3f
    1,1,1,1,1,1,1,1,  # 40 - 47
    1,1,1,1,1,1,1,1,  # 48 - 4f
    1,1,1,1,1,1,1,1,  # 50 - 57
    1,1,1,1,1,1,1,1,  # 58 - 5f
    1,1,1,1,1,1,1,1,  # 60 - 67
    1,1,1,1,1,1,1,1,  # 68 - 6f
    1,1,1,1,1,1,1,1,  # 70 - 77
    1,1,1,1,1,1,1,1,  # 78 - 7f
    0,0,0,0,0,0,0,0,  # 80 - 87
    0,0,0,0,0,0,0,0,  # 88 - 8f
    0,0,0,0,0,0,0,0,  # 90 - 97
    0,0,0,0,0,0,0,0,  # 98 - 9f
    0,2,2,2,2,2,2,2,  # a0 - a7
    2,2,2,2,2,3,3,3,  # a8 - af
    2,2,2,2,2,2,2,2,  # b0 - b7
    2,2,2,2,2,2,2,2,  # b8 - bf
    2,2,2,2,2,2,2,2,  # c0 - c7
    2,3,2,2,2,2,2,2,  # c8 - cf
    2,2,2,2,2,2,2,2,  # d0 - d7
    2,2,2,2,2,2,2,2,  # d8 - df
    2,2,2,2,2,2,2,2,  # e0 - e7
    2,2,2,2,2,2,2,2,  # e8 - ef
    2,2,2,2,2,2,2,2,  # f0 - f7
    2,2,2,2,2,2,2,0   # f8 - ff
)

EUCKR_ST = (
    MachineState.ERROR,MachineState.START,     3,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#00-07
    MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START #08-0f
)

EUCKR_CHAR_LEN_TABLE = (0, 1, 2, 0)

EUCKR_SM_MODEL = {'class_table': EUCKR_CLS,
                'class_factor': 4,
                'state_table': EUCKR_ST,
                'char_len_table': EUCKR_CHAR_LEN_TABLE,
                'name': 'EUC-KR'}

# EUC-TW

EUCTW_CLS = (
    2,2,2,2,2,2,2,2,  # 00 - 07
    2,2,2,2,2,2,0,0,  # 08 - 0f
    2,2,2,2,2,2,2,2,  # 10 - 17
    2,2,2,0,2,2,2,2,  # 18 - 1f
    2,2,2,2,2,2,2,2,  # 20 - 27
    2,2,2,2,2,2,2,2,  # 28 - 2f
    2,2,2,2,2,2,2,2,  # 30 - 37
    2,2,2,2,2,2,2,2,  # 38 - 3f
    2,2,2,2,2,2,2,2,  # 40 - 47
    2,2,2,2,2,2,2,2,  # 48 - 4f
    2,2,2,2,2,2,2,2,  # 50 - 57
    2,2,2,2,2,2,2,2,  # 58 - 5f
    2,2,2,2,2,2,2,2,  # 60 - 67
    2,2,2,2,2,2,2,2,  # 68 - 6f
    2,2,2,2,2,2,2,2,  # 70 - 77
    2,2,2,2,2,2,2,2,  # 78 - 7f
    0,0,0,0,0,0,0,0,  # 80 - 87
    0,0,0,0,0,0,6,0,  # 88 - 8f
    0,0,0,0,0,0,0,0,  # 90 - 97
    0,0,0,0,0,0,0,0,  # 98 - 9f
    0,3,4,4,4,4,4,4,  # a0 - a7
    5,5,1,1,1,1,1,1,  # a8 - af
    1,1,1,1,1,1,1,1,  # b0 - b7
    1,1,1,1,1,1,1,1,  # b8 - bf
    1,1,3,1,3,3,3,3,  # c0 - c7
    3,3,3,3,3,3,3,3,  # c8 - cf
    3,3,3,3,3,3,3,3,  # d0 - d7
    3,3,3,3,3,3,3,3,  # d8 - df
    3,3,3,3,3,3,3,3,  # e0 - e7
    3,3,3,3,3,3,3,3,  # e8 - ef
    3,3,3,3,3,3,3,3,  # f0 - f7
    3,3,3,3,3,3,3,0   # f8 - ff
)

EUCTW_ST = (
    MachineState.ERROR,MachineState.ERROR,MachineState.START,     3,     3,     3,     4,MachineState.ERROR,#00-07
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,#08-0f
    MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ERROR,MachineState.START,MachineState.ERROR,#10-17
    MachineState.START,MachineState.START,MachineState.START,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#18-1f
         5,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.ERROR,MachineState.START,MachineState.START,#20-27
    MachineState.START,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START #28-2f
)

EUCTW_CHAR_LEN_TABLE = (0, 0, 1, 2, 2, 2, 3)

EUCTW_SM_MODEL = {'class_table': EUCTW_CLS,
                'class_factor': 7,
                'state_table': EUCTW_ST,
                'char_len_table': EUCTW_CHAR_LEN_TABLE,
                'name': 'x-euc-tw'}

# GB2312

GB2312_CLS = (
    1,1,1,1,1,1,1,1,  # 00 - 07
    1,1,1,1,1,1,0,0,  # 08 - 0f
    1,1,1,1,1,1,1,1,  # 10 - 17
    1,1,1,0,1,1,1,1,  # 18 - 1f
    1,1,1,1,1,1,1,1,  # 20 - 27
    1,1,1,1,1,1,1,1,  # 28 - 2f
    3,3,3,3,3,3,3,3,  # 30 - 37
    3,3,1,1,1,1,1,1,  # 38 - 3f
    2,2,2,2,2,2,2,2,  # 40 - 47
    2,2,2,2,2,2,2,2,  # 48 - 4f
    2,2,2,2,2,2,2,2,  # 50 - 57
    2,2,2,2,2,2,2,2,  # 58 - 5f
    2,2,2,2,2,2,2,2,  # 60 - 67
    2,2,2,2,2,2,2,2,  # 68 - 6f
    2,2,2,2,2,2,2,2,  # 70 - 77
    2,2,2,2,2,2,2,4,  # 78 - 7f
    5,6,6,6,6,6,6,6,  # 80 - 87
    6,6,6,6,6,6,6,6,  # 88 - 8f
    6,6,6,6,6,6,6,6,  # 90 - 97
    6,6,6,6,6,6,6,6,  # 98 - 9f
    6,6,6,6,6,6,6,6,  # a0 - a7
    6,6,6,6,6,6,6,6,  # a8 - af
    6,6,6,6,6,6,6,6,  # b0 - b7
    6,6,6,6,6,6,6,6,  # b8 - bf
    6,6,6,6,6,6,6,6,  # c0 - c7
    6,6,6,6,6,6,6,6,  # c8 - cf
    6,6,6,6,6,6,6,6,  # d0 - d7
    6,6,6,6,6,6,6,6,  # d8 - df
    6,6,6,6,6,6,6,6,  # e0 - e7
    6,6,6,6,6,6,6,6,  # e8 - ef
    6,6,6,6,6,6,6,6,  # f0 - f7
    6,6,6,6,6,6,6,0   # f8 - ff
)

GB2312_ST = (
    MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,     3,MachineState.ERROR,#00-07
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,#08-0f
    MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ERROR,MachineState.ERROR,MachineState.START,#10-17
         4,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#18-1f
    MachineState.ERROR,MachineState.ERROR,     5,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ERROR,#20-27
    MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.START #28-2f
)

# To be accurate, the length of class 6 can be either 2 or 4.
# But it is not necessary to discriminate between the two since
# it is used for frequency analysis only, and we are validating
# each code range there as well. So it is safe to set it to be
# 2 here.
GB2312_CHAR_LEN_TABLE = (0, 1, 1, 1, 1, 1, 2)

GB2312_SM_MODEL = {'class_table': GB2312_CLS,
                   'class_factor': 7,
                   'state_table': GB2312_ST,
                   'char_len_table': GB2312_CHAR_LEN_TABLE,
                   'name': 'GB2312'}

# Shift_JIS

SJIS_CLS = (
    1,1,1,1,1,1,1,1,  # 00 - 07
    1,1,1,1,1,1,0,0,  # 08 - 0f
    1,1,1,1,1,1,1,1,  # 10 - 17
    1,1,1,0,1,1,1,1,  # 18 - 1f
    1,1,1,1,1,1,1,1,  # 20 - 27
    1,1,1,1,1,1,1,1,  # 28 - 2f
    1,1,1,1,1,1,1,1,  # 30 - 37
    1,1,1,1,1,1,1,1,  # 38 - 3f
    2,2,2,2,2,2,2,2,  # 40 - 47
    2,2,2,2,2,2,2,2,  # 48 - 4f
    2,2,2,2,2,2,2,2,  # 50 - 57
    2,2,2,2,2,2,2,2,  # 58 - 5f
    2,2,2,2,2,2,2,2,  # 60 - 67
    2,2,2,2,2,2,2,2,  # 68 - 6f
    2,2,2,2,2,2,2,2,  # 70 - 77
    2,2,2,2,2,2,2,1,  # 78 - 7f
    3,3,3,3,3,2,2,3,  # 80 - 87
    3,3,3,3,3,3,3,3,  # 88 - 8f
    3,3,3,3,3,3,3,3,  # 90 - 97
    3,3,3,3,3,3,3,3,  # 98 - 9f
    #0xa0 is illegal in sjis encoding, but some pages does
    #contain such byte. We need to be more error forgiven.
    2,2,2,2,2,2,2,2,  # a0 - a7
    2,2,2,2,2,2,2,2,  # a8 - af
    2,2,2,2,2,2,2,2,  # b0 - b7
    2,2,2,2,2,2,2,2,  # b8 - bf
    2,2,2,2,2,2,2,2,  # c0 - c7
    2,2,2,2,2,2,2,2,  # c8 - cf
    2,2,2,2,2,2,2,2,  # d0 - d7
    2,2,2,2,2,2,2,2,  # d8 - df
    3,3,3,3,3,3,3,3,  # e0 - e7
    3,3,3,3,3,4,4,4,  # e8 - ef
    3,3,3,3,3,3,3,3,  # f0 - f7
    3,3,3,3,3,0,0,0)  # f8 - ff


SJIS_ST = (
    MachineState.ERROR,MachineState.START,MachineState.START,     3,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#00-07
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,#08-0f
    MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START #10-17
)

SJIS_CHAR_LEN_TABLE = (0, 1, 1, 2, 0, 0)

SJIS_SM_MODEL = {'class_table': SJIS_CLS,
               'class_factor': 6,
               'state_table': SJIS_ST,
               'char_len_table': SJIS_CHAR_LEN_TABLE,
               'name': 'Shift_JIS'}

# UCS2-BE

UCS2BE_CLS = (
    0,0,0,0,0,0,0,0,  # 00 - 07
    0,0,1,0,0,2,0,0,  # 08 - 0f
    0,0,0,0,0,0,0,0,  # 10 - 17
    0,0,0,3,0,0,0,0,  # 18 - 1f
    0,0,0,0,0,0,0,0,  # 20 - 27
    0,3,3,3,3,3,0,0,  # 28 - 2f
    0,0,0,0,0,0,0,0,  # 30 - 37
    0,0,0,0,0,0,0,0,  # 38 - 3f
    0,0,0,0,0,0,0,0,  # 40 - 47
    0,0,0,0,0,0,0,0,  # 48 - 4f
    0,0,0,0,0,0,0,0,  # 50 - 57
    0,0,0,0,0,0,0,0,  # 58 - 5f
    0,0,0,0,0,0,0,0,  # 60 - 67
    0,0,0,0,0,0,0,0,  # 68 - 6f
    0,0,0,0,0,0,0,0,  # 70 - 77
    0,0,0,0,0,0,0,0,  # 78 - 7f
    0,0,0,0,0,0,0,0,  # 80 - 87
    0,0,0,0,0,0,0,0,  # 88 - 8f
    0,0,0,0,0,0,0,0,  # 90 - 97
    0,0,0,0,0,0,0,0,  # 98 - 9f
    0,0,0,0,0,0,0,0,  # a0 - a7
    0,0,0,0,0,0,0,0,  # a8 - af
    0,0,0,0,0,0,0,0,  # b0 - b7
    0,0,0,0,0,0,0,0,  # b8 - bf
    0,0,0,0,0,0,0,0,  # c0 - c7
    0,0,0,0,0,0,0,0,  # c8 - cf
    0,0,0,0,0,0,0,0,  # d0 - d7
    0,0,0,0,0,0,0,0,  # d8 - df
    0,0,0,0,0,0,0,0,  # e0 - e7
    0,0,0,0,0,0,0,0,  # e8 - ef
    0,0,0,0,0,0,0,0,  # f0 - f7
    0,0,0,0,0,0,4,5   # f8 - ff
)

UCS2BE_ST  = (
          5,     7,     7,MachineState.ERROR,     4,     3,MachineState.ERROR,MachineState.ERROR,#00-07
     MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,#08-0f
     MachineState.ITS_ME,MachineState.ITS_ME,     6,     6,     6,     6,MachineState.ERROR,MachineState.ERROR,#10-17
          6,     6,     6,     6,     6,MachineState.ITS_ME,     6,     6,#18-1f
          6,     6,     6,     6,     5,     7,     7,MachineState.ERROR,#20-27
          5,     8,     6,     6,MachineState.ERROR,     6,     6,     6,#28-2f
          6,     6,     6,     6,MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START #30-37
)

UCS2BE_CHAR_LEN_TABLE = (2, 2, 2, 0, 2, 2)

UCS2BE_SM_MODEL = {'class_table': UCS2BE_CLS,
                   'class_factor': 6,
                   'state_table': UCS2BE_ST,
                   'char_len_table': UCS2BE_CHAR_LEN_TABLE,
                   'name': 'UTF-16BE'}

# UCS2-LE

UCS2LE_CLS = (
    0,0,0,0,0,0,0,0,  # 00 - 07
    0,0,1,0,0,2,0,0,  # 08 - 0f
    0,0,0,0,0,0,0,0,  # 10 - 17
    0,0,0,3,0,0,0,0,  # 18 - 1f
    0,0,0,0,0,0,0,0,  # 20 - 27
    0,3,3,3,3,3,0,0,  # 28 - 2f
    0,0,0,0,0,0,0,0,  # 30 - 37
    0,0,0,0,0,0,0,0,  # 38 - 3f
    0,0,0,0,0,0,0,0,  # 40 - 47
    0,0,0,0,0,0,0,0,  # 48 - 4f
    0,0,0,0,0,0,0,0,  # 50 - 57
    0,0,0,0,0,0,0,0,  # 58 - 5f
    0,0,0,0,0,0,0,0,  # 60 - 67
    0,0,0,0,0,0,0,0,  # 68 - 6f
    0,0,0,0,0,0,0,0,  # 70 - 77
    0,0,0,0,0,0,0,0,  # 78 - 7f
    0,0,0,0,0,0,0,0,  # 80 - 87
    0,0,0,0,0,0,0,0,  # 88 - 8f
    0,0,0,0,0,0,0,0,  # 90 - 97
    0,0,0,0,0,0,0,0,  # 98 - 9f
    0,0,0,0,0,0,0,0,  # a0 - a7
    0,0,0,0,0,0,0,0,  # a8 - af
    0,0,0,0,0,0,0,0,  # b0 - b7
    0,0,0,0,0,0,0,0,  # b8 - bf
    0,0,0,0,0,0,0,0,  # c0 - c7
    0,0,0,0,0,0,0,0,  # c8 - cf
    0,0,0,0,0,0,0,0,  # d0 - d7
    0,0,0,0,0,0,0,0,  # d8 - df
    0,0,0,0,0,0,0,0,  # e0 - e7
    0,0,0,0,0,0,0,0,  # e8 - ef
    0,0,0,0,0,0,0,0,  # f0 - f7
    0,0,0,0,0,0,4,5   # f8 - ff
)

UCS2LE_ST = (
          6,     6,     7,     6,     4,     3,MachineState.ERROR,MachineState.ERROR,#00-07
     MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,#08-0f
     MachineState.ITS_ME,MachineState.ITS_ME,     5,     5,     5,MachineState.ERROR,MachineState.ITS_ME,MachineState.ERROR,#10-17
          5,     5,     5,MachineState.ERROR,     5,MachineState.ERROR,     6,     6,#18-1f
          7,     6,     8,     8,     5,     5,     5,MachineState.ERROR,#20-27
          5,     5,     5,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     5,     5,#28-2f
          5,     5,     5,MachineState.ERROR,     5,MachineState.ERROR,MachineState.START,MachineState.START #30-37
)

UCS2LE_CHAR_LEN_TABLE = (2, 2, 2, 2, 2, 2)

UCS2LE_SM_MODEL = {'class_table': UCS2LE_CLS,
                 'class_factor': 6,
                 'state_table': UCS2LE_ST,
                 'char_len_table': UCS2LE_CHAR_LEN_TABLE,
                 'name': 'UTF-16LE'}

# UTF-8

UTF8_CLS = (
    1,1,1,1,1,1,1,1,  # 00 - 07  #allow 0x00 as a legal value
    1,1,1,1,1,1,0,0,  # 08 - 0f
    1,1,1,1,1,1,1,1,  # 10 - 17
    1,1,1,0,1,1,1,1,  # 18 - 1f
    1,1,1,1,1,1,1,1,  # 20 - 27
    1,1,1,1,1,1,1,1,  # 28 - 2f
    1,1,1,1,1,1,1,1,  # 30 - 37
    1,1,1,1,1,1,1,1,  # 38 - 3f
    1,1,1,1,1,1,1,1,  # 40 - 47
    1,1,1,1,1,1,1,1,  # 48 - 4f
    1,1,1,1,1,1,1,1,  # 50 - 57
    1,1,1,1,1,1,1,1,  # 58 - 5f
    1,1,1,1,1,1,1,1,  # 60 - 67
    1,1,1,1,1,1,1,1,  # 68 - 6f
    1,1,1,1,1,1,1,1,  # 70 - 77
    1,1,1,1,1,1,1,1,  # 78 - 7f
    2,2,2,2,3,3,3,3,  # 80 - 87
    4,4,4,4,4,4,4,4,  # 88 - 8f
    4,4,4,4,4,4,4,4,  # 90 - 97
    4,4,4,4,4,4,4,4,  # 98 - 9f
    5,5,5,5,5,5,5,5,  # a0 - a7
    5,5,5,5,5,5,5,5,  # a8 - af
    5,5,5,5,5,5,5,5,  # b0 - b7
    5,5,5,5,5,5,5,5,  # b8 - bf
    0,0,6,6,6,6,6,6,  # c0 - c7
    6,6,6,6,6,6,6,6,  # c8 - cf
    6,6,6,6,6,6,6,6,  # d0 - d7
    6,6,6,6,6,6,6,6,  # d8 - df
    7,8,8,8,8,8,8,8,  # e0 - e7
    8,8,8,8,8,9,8,8,  # e8 - ef
    10,11,11,11,11,11,11,11,  # f0 - f7
    12,13,13,13,14,15,0,0    # f8 - ff
)

UTF8_ST = (
    MachineState.ERROR,MachineState.START,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     12,   10,#00-07
         9,     11,     8,     7,     6,     5,     4,    3,#08-0f
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#10-17
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#18-1f
    MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,#20-27
    MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,MachineState.ITS_ME,#28-2f
    MachineState.ERROR,MachineState.ERROR,     5,     5,     5,     5,MachineState.ERROR,MachineState.ERROR,#30-37
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#38-3f
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     5,     5,     5,MachineState.ERROR,MachineState.ERROR,#40-47
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#48-4f
    MachineState.ERROR,MachineState.ERROR,     7,     7,     7,     7,MachineState.ERROR,MachineState.ERROR,#50-57
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#58-5f
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     7,     7,MachineState.ERROR,MachineState.ERROR,#60-67
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#68-6f
    MachineState.ERROR,MachineState.ERROR,     9,     9,     9,     9,MachineState.ERROR,MachineState.ERROR,#70-77
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#78-7f
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,     9,MachineState.ERROR,MachineState.ERROR,#80-87
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#88-8f
    MachineState.ERROR,MachineState.ERROR,    12,    12,    12,    12,MachineState.ERROR,MachineState.ERROR,#90-97
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#98-9f
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,    12,MachineState.ERROR,MachineState.ERROR,#a0-a7
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#a8-af
    MachineState.ERROR,MachineState.ERROR,    12,    12,    12,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#b0-b7
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,#b8-bf
    MachineState.ERROR,MachineState.ERROR,MachineState.START,MachineState.START,MachineState.START,MachineState.START,MachineState.ERROR,MachineState.ERROR,#c0-c7
    MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR,MachineState.ERROR #c8-cf
)

UTF8_CHAR_LEN_TABLE = (0, 1, 0, 0, 0, 0, 2, 3, 3, 3, 4, 4, 5, 5, 6, 6)

UTF8_SM_MODEL = {'class_table': UTF8_CLS,
                 'class_factor': 16,
                 'state_table': UTF8_ST,
                 'char_len_table': UTF8_CHAR_LEN_TABLE,
                 'name': 'UTF-8'}




############################################################
### File: message.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Messages"""

from __future__ import absolute_import

from io import StringIO
import struct
import time

import dns.edns
import dns.exception
import dns.flags
import dns.name
import dns.opcode
import dns.entropy
import dns.rcode
import dns.rdata
import dns.rdataclass
import dns.rdatatype
import dns.rrset
import dns.renderer
import dns.tsig
import dns.wiredata

from ._compat import long, xrange, string_types


class ShortHeader(dns.exception.FormError):
    """The DNS packet passed to from_wire() is too short."""


class TrailingJunk(dns.exception.FormError):
    """The DNS packet passed to from_wire() has extra junk at the end of it."""


class UnknownHeaderField(dns.exception.DNSException):
    """The header field name was not recognized when converting from text
    into a message."""


class BadEDNS(dns.exception.FormError):
    """An OPT record occurred somewhere other than the start of
    the additional data section."""


class BadTSIG(dns.exception.FormError):
    """A TSIG record occurred somewhere other than the end of
    the additional data section."""


class UnknownTSIGKey(dns.exception.DNSException):
    """A TSIG with an unknown key was received."""


#: The question section number
QUESTION = 0

#: The answer section number
ANSWER = 1

#: The authority section number
AUTHORITY = 2

#: The additional section number
ADDITIONAL = 3

class Message(object):
    """A DNS message."""

    def __init__(self, id=None):
        if id is None:
            self.id = dns.entropy.random_16()
        else:
            self.id = id
        self.flags = 0
        self.question = []
        self.answer = []
        self.authority = []
        self.additional = []
        self.edns = -1
        self.ednsflags = 0
        self.payload = 0
        self.options = []
        self.request_payload = 0
        self.keyring = None
        self.keyname = None
        self.keyalgorithm = dns.tsig.default_algorithm
        self.request_mac = b''
        self.other_data = b''
        self.tsig_error = 0
        self.fudge = 300
        self.original_id = self.id
        self.mac = b''
        self.xfr = False
        self.origin = None
        self.tsig_ctx = None
        self.had_tsig = False
        self.multi = False
        self.first = True
        self.index = {}

    def __repr__(self):
        return '<DNS message, ID ' + repr(self.id) + '>'

    def __str__(self):
        return self.to_text()

    def to_text(self, origin=None, relativize=True, **kw):
        """Convert the message to text.

        The *origin*, *relativize*, and any other keyword
        arguments are passed to the RRset ``to_wire()`` method.

        Returns a ``text``.
        """

        s = StringIO()
        s.write(u'id %d\n' % self.id)
        s.write(u'opcode %s\n' %
                dns.opcode.to_text(dns.opcode.from_flags(self.flags)))
        rc = dns.rcode.from_flags(self.flags, self.ednsflags)
        s.write(u'rcode %s\n' % dns.rcode.to_text(rc))
        s.write(u'flags %s\n' % dns.flags.to_text(self.flags))
        if self.edns >= 0:
            s.write(u'edns %s\n' % self.edns)
            if self.ednsflags != 0:
                s.write(u'eflags %s\n' %
                        dns.flags.edns_to_text(self.ednsflags))
            s.write(u'payload %d\n' % self.payload)
        for opt in self.options:
            s.write(u'option %s\n' % opt.to_text())
        is_update = dns.opcode.is_update(self.flags)
        if is_update:
            s.write(u';ZONE\n')
        else:
            s.write(u';QUESTION\n')
        for rrset in self.question:
            s.write(rrset.to_text(origin, relativize, **kw))
            s.write(u'\n')
        if is_update:
            s.write(u';PREREQ\n')
        else:
            s.write(u';ANSWER\n')
        for rrset in self.answer:
            s.write(rrset.to_text(origin, relativize, **kw))
            s.write(u'\n')
        if is_update:
            s.write(u';UPDATE\n')
        else:
            s.write(u';AUTHORITY\n')
        for rrset in self.authority:
            s.write(rrset.to_text(origin, relativize, **kw))
            s.write(u'\n')
        s.write(u';ADDITIONAL\n')
        for rrset in self.additional:
            s.write(rrset.to_text(origin, relativize, **kw))
            s.write(u'\n')
        #
        # We strip off the final \n so the caller can print the result without
        # doing weird things to get around eccentricities in Python print
        # formatting
        #
        return s.getvalue()[:-1]

    def __eq__(self, other):
        """Two messages are equal if they have the same content in the
        header, question, answer, and authority sections.

        Returns a ``bool``.
        """

        if not isinstance(other, Message):
            return False
        if self.id != other.id:
            return False
        if self.flags != other.flags:
            return False
        for n in self.question:
            if n not in other.question:
                return False
        for n in other.question:
            if n not in self.question:
                return False
        for n in self.answer:
            if n not in other.answer:
                return False
        for n in other.answer:
            if n not in self.answer:
                return False
        for n in self.authority:
            if n not in other.authority:
                return False
        for n in other.authority:
            if n not in self.authority:
                return False
        return True

    def __ne__(self, other):
        return not self.__eq__(other)

    def is_response(self, other):
        """Is this message a response to *other*?

        Returns a ``bool``.
        """

        if other.flags & dns.flags.QR == 0 or \
           self.id != other.id or \
           dns.opcode.from_flags(self.flags) != \
           dns.opcode.from_flags(other.flags):
            return False
        if dns.rcode.from_flags(other.flags, other.ednsflags) != \
                dns.rcode.NOERROR:
            return True
        if dns.opcode.is_update(self.flags):
            return True
        for n in self.question:
            if n not in other.question:
                return False
        for n in other.question:
            if n not in self.question:
                return False
        return True

    def section_number(self, section):
        """Return the "section number" of the specified section for use
        in indexing.  The question section is 0, the answer section is 1,
        the authority section is 2, and the additional section is 3.

        *section* is one of the section attributes of this message.

        Raises ``ValueError`` if the section isn't known.

        Returns an ``int``.
        """

        if section is self.question:
            return QUESTION
        elif section is self.answer:
            return ANSWER
        elif section is self.authority:
            return AUTHORITY
        elif section is self.additional:
            return ADDITIONAL
        else:
            raise ValueError('unknown section')

    def section_from_number(self, number):
        """Return the "section number" of the specified section for use
        in indexing.  The question section is 0, the answer section is 1,
        the authority section is 2, and the additional section is 3.

        *section* is one of the section attributes of this message.

        Raises ``ValueError`` if the section isn't known.

        Returns an ``int``.
        """

        if number == QUESTION:
            return self.question
        elif number == ANSWER:
            return self.answer
        elif number == AUTHORITY:
            return self.authority
        elif number == ADDITIONAL:
            return self.additional
        else:
            raise ValueError('unknown section')

    def find_rrset(self, section, name, rdclass, rdtype,
                   covers=dns.rdatatype.NONE, deleting=None, create=False,
                   force_unique=False):
        """Find the RRset with the given attributes in the specified section.

        *section*, an ``int`` section number, or one of the section
        attributes of this message.  This specifies the
        the section of the message to search.  For example::

            my_message.find_rrset(my_message.answer, name, rdclass, rdtype)
            my_message.find_rrset(dns.message.ANSWER, name, rdclass, rdtype)

        *name*, a ``dns.name.Name``, the name of the RRset.

        *rdclass*, an ``int``, the class of the RRset.

        *rdtype*, an ``int``, the type of the RRset.

        *covers*, an ``int`` or ``None``, the covers value of the RRset.
        The default is ``None``.

        *deleting*, an ``int`` or ``None``, the deleting value of the RRset.
        The default is ``None``.

        *create*, a ``bool``.  If ``True``, create the RRset if it is not found.
        The created RRset is appended to *section*.

        *force_unique*, a ``bool``.  If ``True`` and *create* is also ``True``,
        create a new RRset regardless of whether a matching RRset exists
        already.  The default is ``False``.  This is useful when creating
        DDNS Update messages, as order matters for them.

        Raises ``KeyError`` if the RRset was not found and create was
        ``False``.

        Returns a ``dns.rrset.RRset object``.
        """

        if isinstance(section, int):
            section_number = section
            section = self.section_from_number(section_number)
        else:
            section_number = self.section_number(section)
        key = (section_number, name, rdclass, rdtype, covers, deleting)
        if not force_unique:
            if self.index is not None:
                rrset = self.index.get(key)
                if rrset is not None:
                    return rrset
            else:
                for rrset in section:
                    if rrset.match(name, rdclass, rdtype, covers, deleting):
                        return rrset
        if not create:
            raise KeyError
        rrset = dns.rrset.RRset(name, rdclass, rdtype, covers, deleting)
        section.append(rrset)
        if self.index is not None:
            self.index[key] = rrset
        return rrset

    def get_rrset(self, section, name, rdclass, rdtype,
                  covers=dns.rdatatype.NONE, deleting=None, create=False,
                  force_unique=False):
        """Get the RRset with the given attributes in the specified section.

        If the RRset is not found, None is returned.

        *section*, an ``int`` section number, or one of the section
        attributes of this message.  This specifies the
        the section of the message to search.  For example::

            my_message.get_rrset(my_message.answer, name, rdclass, rdtype)
            my_message.get_rrset(dns.message.ANSWER, name, rdclass, rdtype)

        *name*, a ``dns.name.Name``, the name of the RRset.

        *rdclass*, an ``int``, the class of the RRset.

        *rdtype*, an ``int``, the type of the RRset.

        *covers*, an ``int`` or ``None``, the covers value of the RRset.
        The default is ``None``.

        *deleting*, an ``int`` or ``None``, the deleting value of the RRset.
        The default is ``None``.

        *create*, a ``bool``.  If ``True``, create the RRset if it is not found.
        The created RRset is appended to *section*.

        *force_unique*, a ``bool``.  If ``True`` and *create* is also ``True``,
        create a new RRset regardless of whether a matching RRset exists
        already.  The default is ``False``.  This is useful when creating
        DDNS Update messages, as order matters for them.

        Returns a ``dns.rrset.RRset object`` or ``None``.
        """

        try:
            rrset = self.find_rrset(section, name, rdclass, rdtype, covers,
                                    deleting, create, force_unique)
        except KeyError:
            rrset = None
        return rrset

    def to_wire(self, origin=None, max_size=0, **kw):
        """Return a string containing the message in DNS compressed wire
        format.

        Additional keyword arguments are passed to the RRset ``to_wire()``
        method.

        *origin*, a ``dns.name.Name`` or ``None``, the origin to be appended
        to any relative names.

        *max_size*, an ``int``, the maximum size of the wire format
        output; default is 0, which means "the message's request
        payload, if nonzero, or 65535".

        Raises ``dns.exception.TooBig`` if *max_size* was exceeded.

        Returns a ``binary``.
        """

        if max_size == 0:
            if self.request_payload != 0:
                max_size = self.request_payload
            else:
                max_size = 65535
        if max_size < 512:
            max_size = 512
        elif max_size > 65535:
            max_size = 65535
        r = dns.renderer.Renderer(self.id, self.flags, max_size, origin)
        for rrset in self.question:
            r.add_question(rrset.name, rrset.rdtype, rrset.rdclass)
        for rrset in self.answer:
            r.add_rrset(dns.renderer.ANSWER, rrset, **kw)
        for rrset in self.authority:
            r.add_rrset(dns.renderer.AUTHORITY, rrset, **kw)
        if self.edns >= 0:
            r.add_edns(self.edns, self.ednsflags, self.payload, self.options)
        for rrset in self.additional:
            r.add_rrset(dns.renderer.ADDITIONAL, rrset, **kw)
        r.write_header()
        if self.keyname is not None:
            r.add_tsig(self.keyname, self.keyring[self.keyname],
                       self.fudge, self.original_id, self.tsig_error,
                       self.other_data, self.request_mac,
                       self.keyalgorithm)
            self.mac = r.mac
        return r.get_wire()

    def use_tsig(self, keyring, keyname=None, fudge=300,
                 original_id=None, tsig_error=0, other_data=b'',
                 algorithm=dns.tsig.default_algorithm):
        """When sending, a TSIG signature using the specified keyring
        and keyname should be added.

        See the documentation of the Message class for a complete
        description of the keyring dictionary.

        *keyring*, a ``dict``, the TSIG keyring to use.  If a
        *keyring* is specified but a *keyname* is not, then the key
        used will be the first key in the *keyring*.  Note that the
        order of keys in a dictionary is not defined, so applications
        should supply a keyname when a keyring is used, unless they
        know the keyring contains only one key.

        *keyname*, a ``dns.name.Name`` or ``None``, the name of the TSIG key
        to use; defaults to ``None``. The key must be defined in the keyring.

        *fudge*, an ``int``, the TSIG time fudge.

        *original_id*, an ``int``, the TSIG original id.  If ``None``,
        the message's id is used.

        *tsig_error*, an ``int``, the TSIG error code.

        *other_data*, a ``binary``, the TSIG other data.

        *algorithm*, a ``dns.name.Name``, the TSIG algorithm to use.
        """

        self.keyring = keyring
        if keyname is None:
            self.keyname = list(self.keyring.keys())[0]
        else:
            if isinstance(keyname, string_types):
                keyname = dns.name.from_text(keyname)
            self.keyname = keyname
        self.keyalgorithm = algorithm
        self.fudge = fudge
        if original_id is None:
            self.original_id = self.id
        else:
            self.original_id = original_id
        self.tsig_error = tsig_error
        self.other_data = other_data

    def use_edns(self, edns=0, ednsflags=0, payload=1280, request_payload=None,
                 options=None):
        """Configure EDNS behavior.

        *edns*, an ``int``, is the EDNS level to use.  Specifying
        ``None``, ``False``, or ``-1`` means "do not use EDNS", and in this case
        the other parameters are ignored.  Specifying ``True`` is
        equivalent to specifying 0, i.e. "use EDNS0".

        *ednsflags*, an ``int``, the EDNS flag values.

        *payload*, an ``int``, is the EDNS sender's payload field, which is the
        maximum size of UDP datagram the sender can handle.  I.e. how big
        a response to this message can be.

        *request_payload*, an ``int``, is the EDNS payload size to use when
        sending this message.  If not specified, defaults to the value of
        *payload*.

        *options*, a list of ``dns.edns.Option`` objects or ``None``, the EDNS
        options.
        """

        if edns is None or edns is False:
            edns = -1
        if edns is True:
            edns = 0
        if request_payload is None:
            request_payload = payload
        if edns < 0:
            ednsflags = 0
            payload = 0
            request_payload = 0
            options = []
        else:
            # make sure the EDNS version in ednsflags agrees with edns
            ednsflags &= long(0xFF00FFFF)
            ednsflags |= (edns << 16)
            if options is None:
                options = []
        self.edns = edns
        self.ednsflags = ednsflags
        self.payload = payload
        self.options = options
        self.request_payload = request_payload

    def want_dnssec(self, wanted=True):
        """Enable or disable 'DNSSEC desired' flag in requests.

        *wanted*, a ``bool``.  If ``True``, then DNSSEC data is
        desired in the response, EDNS is enabled if required, and then
        the DO bit is set.  If ``False``, the DO bit is cleared if
        EDNS is enabled.
        """

        if wanted:
            if self.edns < 0:
                self.use_edns()
            self.ednsflags |= dns.flags.DO
        elif self.edns >= 0:
            self.ednsflags &= ~dns.flags.DO

    def rcode(self):
        """Return the rcode.

        Returns an ``int``.
        """
        return dns.rcode.from_flags(self.flags, self.ednsflags)

    def set_rcode(self, rcode):
        """Set the rcode.

        *rcode*, an ``int``, is the rcode to set.
        """
        (value, evalue) = dns.rcode.to_flags(rcode)
        self.flags &= 0xFFF0
        self.flags |= value
        self.ednsflags &= long(0x00FFFFFF)
        self.ednsflags |= evalue
        if self.ednsflags != 0 and self.edns < 0:
            self.edns = 0

    def opcode(self):
        """Return the opcode.

        Returns an ``int``.
        """
        return dns.opcode.from_flags(self.flags)

    def set_opcode(self, opcode):
        """Set the opcode.

        *opcode*, an ``int``, is the opcode to set.
        """
        self.flags &= 0x87FF
        self.flags |= dns.opcode.to_flags(opcode)


class _WireReader(object):

    """Wire format reader.

    wire: a binary, is the wire-format message.
    message: The message object being built
    current: When building a message object from wire format, this
    variable contains the offset from the beginning of wire of the next octet
    to be read.
    updating: Is the message a dynamic update?
    one_rr_per_rrset: Put each RR into its own RRset?
    ignore_trailing: Ignore trailing junk at end of request?
    zone_rdclass: The class of the zone in messages which are
    DNS dynamic updates.
    """

    def __init__(self, wire, message, question_only=False,
                 one_rr_per_rrset=False, ignore_trailing=False):
        self.wire = dns.wiredata.maybe_wrap(wire)
        self.message = message
        self.current = 0
        self.updating = False
        self.zone_rdclass = dns.rdataclass.IN
        self.question_only = question_only
        self.one_rr_per_rrset = one_rr_per_rrset
        self.ignore_trailing = ignore_trailing

    def _get_question(self, qcount):
        """Read the next *qcount* records from the wire data and add them to
        the question section.
        """

        if self.updating and qcount > 1:
            raise dns.exception.FormError

        for i in xrange(0, qcount):
            (qname, used) = dns.name.from_wire(self.wire, self.current)
            if self.message.origin is not None:
                qname = qname.relativize(self.message.origin)
            self.current = self.current + used
            (rdtype, rdclass) = \
                struct.unpack('!HH',
                              self.wire[self.current:self.current + 4])
            self.current = self.current + 4
            self.message.find_rrset(self.message.question, qname,
                                    rdclass, rdtype, create=True,
                                    force_unique=True)
            if self.updating:
                self.zone_rdclass = rdclass

    def _get_section(self, section, count):
        """Read the next I{count} records from the wire data and add them to
        the specified section.

        section: the section of the message to which to add records
        count: the number of records to read
        """

        if self.updating or self.one_rr_per_rrset:
            force_unique = True
        else:
            force_unique = False
        seen_opt = False
        for i in xrange(0, count):
            rr_start = self.current
            (name, used) = dns.name.from_wire(self.wire, self.current)
            absolute_name = name
            if self.message.origin is not None:
                name = name.relativize(self.message.origin)
            self.current = self.current + used
            (rdtype, rdclass, ttl, rdlen) = \
                struct.unpack('!HHIH',
                              self.wire[self.current:self.current + 10])
            self.current = self.current + 10
            if rdtype == dns.rdatatype.OPT:
                if section is not self.message.additional or seen_opt:
                    raise BadEDNS
                self.message.payload = rdclass
                self.message.ednsflags = ttl
                self.message.edns = (ttl & 0xff0000) >> 16
                self.message.options = []
                current = self.current
                optslen = rdlen
                while optslen > 0:
                    (otype, olen) = \
                        struct.unpack('!HH',
                                      self.wire[current:current + 4])
                    current = current + 4
                    opt = dns.edns.option_from_wire(
                        otype, self.wire, current, olen)
                    self.message.options.append(opt)
                    current = current + olen
                    optslen = optslen - 4 - olen
                seen_opt = True
            elif rdtype == dns.rdatatype.TSIG:
                if not (section is self.message.additional and
                        i == (count - 1)):
                    raise BadTSIG
                if self.message.keyring is None:
                    raise UnknownTSIGKey('got signed message without keyring')
                secret = self.message.keyring.get(absolute_name)
                if secret is None:
                    raise UnknownTSIGKey("key '%s' unknown" % name)
                self.message.keyname = absolute_name
                (self.message.keyalgorithm, self.message.mac) = \
                    dns.tsig.get_algorithm_and_mac(self.wire, self.current,
                                                   rdlen)
                self.message.tsig_ctx = \
                    dns.tsig.validate(self.wire,
                                      absolute_name,
                                      secret,
                                      int(time.time()),
                                      self.message.request_mac,
                                      rr_start,
                                      self.current,
                                      rdlen,
                                      self.message.tsig_ctx,
                                      self.message.multi,
                                      self.message.first)
                self.message.had_tsig = True
            else:
                if ttl < 0:
                    ttl = 0
                if self.updating and \
                   (rdclass == dns.rdataclass.ANY or
                        rdclass == dns.rdataclass.NONE):
                    deleting = rdclass
                    rdclass = self.zone_rdclass
                else:
                    deleting = None
                if deleting == dns.rdataclass.ANY or \
                   (deleting == dns.rdataclass.NONE and
                        section is self.message.answer):
                    covers = dns.rdatatype.NONE
                    rd = None
                else:
                    rd = dns.rdata.from_wire(rdclass, rdtype, self.wire,
                                             self.current, rdlen,
                                             self.message.origin)
                    covers = rd.covers()
                if self.message.xfr and rdtype == dns.rdatatype.SOA:
                    force_unique = True
                rrset = self.message.find_rrset(section, name,
                                                rdclass, rdtype, covers,
                                                deleting, True, force_unique)
                if rd is not None:
                    rrset.add(rd, ttl)
            self.current = self.current + rdlen

    def read(self):
        """Read a wire format DNS message and build a dns.message.Message
        object."""

        l = len(self.wire)
        if l < 12:
            raise ShortHeader
        (self.message.id, self.message.flags, qcount, ancount,
         aucount, adcount) = struct.unpack('!HHHHHH', self.wire[:12])
        self.current = 12
        if dns.opcode.is_update(self.message.flags):
            self.updating = True
        self._get_question(qcount)
        if self.question_only:
            return
        self._get_section(self.message.answer, ancount)
        self._get_section(self.message.authority, aucount)
        self._get_section(self.message.additional, adcount)
        if not self.ignore_trailing and self.current != l:
            raise TrailingJunk
        if self.message.multi and self.message.tsig_ctx and \
                not self.message.had_tsig:
            self.message.tsig_ctx.update(self.wire)


def from_wire(wire, keyring=None, request_mac=b'', xfr=False, origin=None,
              tsig_ctx=None, multi=False, first=True,
              question_only=False, one_rr_per_rrset=False,
              ignore_trailing=False):
    """Convert a DNS wire format message into a message
    object.

    *keyring*, a ``dict``, the keyring to use if the message is signed.

    *request_mac*, a ``binary``.  If the message is a response to a
    TSIG-signed request, *request_mac* should be set to the MAC of
    that request.

    *xfr*, a ``bool``, should be set to ``True`` if this message is part of
    a zone transfer.

    *origin*, a ``dns.name.Name`` or ``None``.  If the message is part
    of a zone transfer, *origin* should be the origin name of the
    zone.

    *tsig_ctx*, a ``hmac.HMAC`` objext, the ongoing TSIG context, used
    when validating zone transfers.

    *multi*, a ``bool``, should be set to ``True`` if this message
    part of a multiple message sequence.

    *first*, a ``bool``, should be set to ``True`` if this message is
    stand-alone, or the first message in a multi-message sequence.

    *question_only*, a ``bool``.  If ``True``, read only up to
    the end of the question section.

    *one_rr_per_rrset*, a ``bool``.  If ``True``, put each RR into its
    own RRset.

    *ignore_trailing*, a ``bool``.  If ``True``, ignore trailing
    junk at end of the message.

    Raises ``dns.message.ShortHeader`` if the message is less than 12 octets
    long.

    Raises ``dns.messaage.TrailingJunk`` if there were octets in the message
    past the end of the proper DNS message, and *ignore_trailing* is ``False``.

    Raises ``dns.message.BadEDNS`` if an OPT record was in the
    wrong section, or occurred more than once.

    Raises ``dns.message.BadTSIG`` if a TSIG record was not the last
    record of the additional data section.

    Returns a ``dns.message.Message``.
    """

    m = Message(id=0)
    m.keyring = keyring
    m.request_mac = request_mac
    m.xfr = xfr
    m.origin = origin
    m.tsig_ctx = tsig_ctx
    m.multi = multi
    m.first = first

    reader = _WireReader(wire, m, question_only, one_rr_per_rrset,
                         ignore_trailing)
    reader.read()

    return m


class _TextReader(object):

    """Text format reader.

    tok: the tokenizer.
    message: The message object being built.
    updating: Is the message a dynamic update?
    zone_rdclass: The class of the zone in messages which are
    DNS dynamic updates.
    last_name: The most recently read name when building a message object.
    """

    def __init__(self, text, message):
        self.message = message
        self.tok = dns.tokenizer.Tokenizer(text)
        self.last_name = None
        self.zone_rdclass = dns.rdataclass.IN
        self.updating = False

    def _header_line(self, section):
        """Process one line from the text format header section."""

        token = self.tok.get()
        what = token.value
        if what == 'id':
            self.message.id = self.tok.get_int()
        elif what == 'flags':
            while True:
                token = self.tok.get()
                if not token.is_identifier():
                    self.tok.unget(token)
                    break
                self.message.flags = self.message.flags | \
                    dns.flags.from_text(token.value)
            if dns.opcode.is_update(self.message.flags):
                self.updating = True
        elif what == 'edns':
            self.message.edns = self.tok.get_int()
            self.message.ednsflags = self.message.ednsflags | \
                (self.message.edns << 16)
        elif what == 'eflags':
            if self.message.edns < 0:
                self.message.edns = 0
            while True:
                token = self.tok.get()
                if not token.is_identifier():
                    self.tok.unget(token)
                    break
                self.message.ednsflags = self.message.ednsflags | \
                    dns.flags.edns_from_text(token.value)
        elif what == 'payload':
            self.message.payload = self.tok.get_int()
            if self.message.edns < 0:
                self.message.edns = 0
        elif what == 'opcode':
            text = self.tok.get_string()
            self.message.flags = self.message.flags | \
                dns.opcode.to_flags(dns.opcode.from_text(text))
        elif what == 'rcode':
            text = self.tok.get_string()
            self.message.set_rcode(dns.rcode.from_text(text))
        else:
            raise UnknownHeaderField
        self.tok.get_eol()

    def _question_line(self, section):
        """Process one line from the text format question section."""

        token = self.tok.get(want_leading=True)
        if not token.is_whitespace():
            self.last_name = dns.name.from_text(token.value, None)
        name = self.last_name
        token = self.tok.get()
        if not token.is_identifier():
            raise dns.exception.SyntaxError
        # Class
        try:
            rdclass = dns.rdataclass.from_text(token.value)
            token = self.tok.get()
            if not token.is_identifier():
                raise dns.exception.SyntaxError
        except dns.exception.SyntaxError:
            raise dns.exception.SyntaxError
        except Exception:
            rdclass = dns.rdataclass.IN
        # Type
        rdtype = dns.rdatatype.from_text(token.value)
        self.message.find_rrset(self.message.question, name,
                                rdclass, rdtype, create=True,
                                force_unique=True)
        if self.updating:
            self.zone_rdclass = rdclass
        self.tok.get_eol()

    def _rr_line(self, section):
        """Process one line from the text format answer, authority, or
        additional data sections.
        """

        deleting = None
        # Name
        token = self.tok.get(want_leading=True)
        if not token.is_whitespace():
            self.last_name = dns.name.from_text(token.value, None)
        name = self.last_name
        token = self.tok.get()
        if not token.is_identifier():
            raise dns.exception.SyntaxError
        # TTL
        try:
            ttl = int(token.value, 0)
            token = self.tok.get()
            if not token.is_identifier():
                raise dns.exception.SyntaxError
        except dns.exception.SyntaxError:
            raise dns.exception.SyntaxError
        except Exception:
            ttl = 0
        # Class
        try:
            rdclass = dns.rdataclass.from_text(token.value)
            token = self.tok.get()
            if not token.is_identifier():
                raise dns.exception.SyntaxError
            if rdclass == dns.rdataclass.ANY or rdclass == dns.rdataclass.NONE:
                deleting = rdclass
                rdclass = self.zone_rdclass
        except dns.exception.SyntaxError:
            raise dns.exception.SyntaxError
        except Exception:
            rdclass = dns.rdataclass.IN
        # Type
        rdtype = dns.rdatatype.from_text(token.value)
        token = self.tok.get()
        if not token.is_eol_or_eof():
            self.tok.unget(token)
            rd = dns.rdata.from_text(rdclass, rdtype, self.tok, None)
            covers = rd.covers()
        else:
            rd = None
            covers = dns.rdatatype.NONE
        rrset = self.message.find_rrset(section, name,
                                        rdclass, rdtype, covers,
                                        deleting, True, self.updating)
        if rd is not None:
            rrset.add(rd, ttl)

    def read(self):
        """Read a text format DNS message and build a dns.message.Message
        object."""

        line_method = self._header_line
        section = None
        while 1:
            token = self.tok.get(True, True)
            if token.is_eol_or_eof():
                break
            if token.is_comment():
                u = token.value.upper()
                if u == 'HEADER':
                    line_method = self._header_line
                elif u == 'QUESTION' or u == 'ZONE':
                    line_method = self._question_line
                    section = self.message.question
                elif u == 'ANSWER' or u == 'PREREQ':
                    line_method = self._rr_line
                    section = self.message.answer
                elif u == 'AUTHORITY' or u == 'UPDATE':
                    line_method = self._rr_line
                    section = self.message.authority
                elif u == 'ADDITIONAL':
                    line_method = self._rr_line
                    section = self.message.additional
                self.tok.get_eol()
                continue
            self.tok.unget(token)
            line_method(section)


def from_text(text):
    """Convert the text format message into a message object.

    *text*, a ``text``, the text format message.

    Raises ``dns.message.UnknownHeaderField`` if a header is unknown.

    Raises ``dns.exception.SyntaxError`` if the text is badly formed.

    Returns a ``dns.message.Message object``
    """

    # 'text' can also be a file, but we don't publish that fact
    # since it's an implementation detail.  The official file
    # interface is from_file().

    m = Message()

    reader = _TextReader(text, m)
    reader.read()

    return m


def from_file(f):
    """Read the next text format message from the specified file.

    *f*, a ``file`` or ``text``.  If *f* is text, it is treated as the
    pathname of a file to open.

    Raises ``dns.message.UnknownHeaderField`` if a header is unknown.

    Raises ``dns.exception.SyntaxError`` if the text is badly formed.

    Returns a ``dns.message.Message object``
    """

    str_type = string_types
    opts = 'rU'

    if isinstance(f, str_type):
        f = open(f, opts)
        want_close = True
    else:
        want_close = False

    try:
        m = from_text(f)
    finally:
        if want_close:
            f.close()
    return m


def make_query(qname, rdtype, rdclass=dns.rdataclass.IN, use_edns=None,
               want_dnssec=False, ednsflags=None, payload=None,
               request_payload=None, options=None):
    """Make a query message.

    The query name, type, and class may all be specified either
    as objects of the appropriate type, or as strings.

    The query will have a randomly chosen query id, and its DNS flags
    will be set to dns.flags.RD.

    qname, a ``dns.name.Name`` or ``text``, the query name.

    *rdtype*, an ``int`` or ``text``, the desired rdata type.

    *rdclass*, an ``int`` or ``text``,  the desired rdata class; the default
    is class IN.

    *use_edns*, an ``int``, ``bool`` or ``None``.  The EDNS level to use; the
    default is None (no EDNS).
    See the description of dns.message.Message.use_edns() for the possible
    values for use_edns and their meanings.

    *want_dnssec*, a ``bool``.  If ``True``, DNSSEC data is desired.

    *ednsflags*, an ``int``, the EDNS flag values.

    *payload*, an ``int``, is the EDNS sender's payload field, which is the
    maximum size of UDP datagram the sender can handle.  I.e. how big
    a response to this message can be.

    *request_payload*, an ``int``, is the EDNS payload size to use when
    sending this message.  If not specified, defaults to the value of
    *payload*.

    *options*, a list of ``dns.edns.Option`` objects or ``None``, the EDNS
    options.

    Returns a ``dns.message.Message``
    """

    if isinstance(qname, string_types):
        qname = dns.name.from_text(qname)
    if isinstance(rdtype, string_types):
        rdtype = dns.rdatatype.from_text(rdtype)
    if isinstance(rdclass, string_types):
        rdclass = dns.rdataclass.from_text(rdclass)
    m = Message()
    m.flags |= dns.flags.RD
    m.find_rrset(m.question, qname, rdclass, rdtype, create=True,
                 force_unique=True)
    # only pass keywords on to use_edns if they have been set to a
    # non-None value.  Setting a field will turn EDNS on if it hasn't
    # been configured.
    kwargs = {}
    if ednsflags is not None:
        kwargs['ednsflags'] = ednsflags
        if use_edns is None:
            use_edns = 0
    if payload is not None:
        kwargs['payload'] = payload
        if use_edns is None:
            use_edns = 0
    if request_payload is not None:
        kwargs['request_payload'] = request_payload
        if use_edns is None:
            use_edns = 0
    if options is not None:
        kwargs['options'] = options
        if use_edns is None:
            use_edns = 0
    kwargs['edns'] = use_edns
    m.use_edns(**kwargs)
    m.want_dnssec(want_dnssec)
    return m


def make_response(query, recursion_available=False, our_payload=8192,
                  fudge=300):
    """Make a message which is a response for the specified query.
    The message returned is really a response skeleton; it has all
    of the infrastructure required of a response, but none of the
    content.

    The response's question section is a shallow copy of the query's
    question section, so the query's question RRsets should not be
    changed.

    *query*, a ``dns.message.Message``, the query to respond to.

    *recursion_available*, a ``bool``, should RA be set in the response?

    *our_payload*, an ``int``, the payload size to advertise in EDNS
    responses.

    *fudge*, an ``int``, the TSIG time fudge.

    Returns a ``dns.message.Message`` object.
    """

    if query.flags & dns.flags.QR:
        raise dns.exception.FormError('specified query message is not a query')
    response = dns.message.Message(query.id)
    response.flags = dns.flags.QR | (query.flags & dns.flags.RD)
    if recursion_available:
        response.flags |= dns.flags.RA
    response.set_opcode(query.opcode())
    response.question = list(query.question)
    if query.edns >= 0:
        response.use_edns(0, 0, our_payload, query.payload)
    if query.had_tsig:
        response.use_tsig(query.keyring, query.keyname, fudge, None, 0, b'',
                          query.keyalgorithm)
        response.request_mac = query.mac
    return response




############################################################
### File: models.py
############################################################
# -*- coding: utf-8 -*-

"""
requests.models
~~~~~~~~~~~~~~~

This module contains the primary objects that power Requests.
"""

import datetime
import sys

# Import encoding now, to avoid implicit import later.
# Implicit import within threads may cause LookupError when standard library is in a ZIP,
# such as in Embedded Python. See https://github.com/psf/requests/issues/3578.
import encodings.idna

from urllib3.fields import RequestField
from urllib3.filepost import encode_multipart_formdata
from urllib3.util import parse_url
from urllib3.exceptions import (
    DecodeError, ReadTimeoutError, ProtocolError, LocationParseError)

from io import UnsupportedOperation
from .hooks import default_hooks
from .structures import CaseInsensitiveDict

from .auth import HTTPBasicAuth
from .cookies import cookiejar_from_dict, get_cookie_header, _copy_cookie_jar
from .exceptions import (
    HTTPError, MissingSchema, InvalidURL, ChunkedEncodingError,
    ContentDecodingError, ConnectionError, StreamConsumedError,
    InvalidJSONError)
from .exceptions import JSONDecodeError as RequestsJSONDecodeError
from ._internal_utils import to_native_string, unicode_is_ascii
from .utils import (
    guess_filename, get_auth_from_url, requote_uri,
    stream_decode_response_unicode, to_key_val_list, parse_header_links,
    iter_slices, guess_json_utf, super_len, check_header_validity)
from .compat import (
    Callable, Mapping,
    cookielib, urlunparse, urlsplit, urlencode, str, bytes,
    is_py2, chardet, builtin_str, basestring, JSONDecodeError)
from .compat import json as complexjson
from .status_codes import codes

#: The set of HTTP status codes that indicate an automatically
#: processable redirect.
REDIRECT_STATI = (
    codes.moved,               # 301
    codes.found,               # 302
    codes.other,               # 303
    codes.temporary_redirect,  # 307
    codes.permanent_redirect,  # 308
)

DEFAULT_REDIRECT_LIMIT = 30
CONTENT_CHUNK_SIZE = 10 * 1024
ITER_CHUNK_SIZE = 512


class RequestEncodingMixin(object):
    @property
    def path_url(self):
        """Build the path URL to use."""

        url = []

        p = urlsplit(self.url)

        path = p.path
        if not path:
            path = '/'

        url.append(path)

        query = p.query
        if query:
            url.append('?')
            url.append(query)

        return ''.join(url)

    @staticmethod
    def _encode_params(data):
        """Encode parameters in a piece of data.

        Will successfully encode parameters when passed as a dict or a list of
        2-tuples. Order is retained if data is a list of 2-tuples but arbitrary
        if parameters are supplied as a dict.
        """

        if isinstance(data, (str, bytes)):
            return data
        elif hasattr(data, 'read'):
            return data
        elif hasattr(data, '__iter__'):
            result = []
            for k, vs in to_key_val_list(data):
                if isinstance(vs, basestring) or not hasattr(vs, '__iter__'):
                    vs = [vs]
                for v in vs:
                    if v is not None:
                        result.append(
                            (k.encode('utf-8') if isinstance(k, str) else k,
                             v.encode('utf-8') if isinstance(v, str) else v))
            return urlencode(result, doseq=True)
        else:
            return data

    @staticmethod
    def _encode_files(files, data):
        """Build the body for a multipart/form-data request.

        Will successfully encode files when passed as a dict or a list of
        tuples. Order is retained if data is a list of tuples but arbitrary
        if parameters are supplied as a dict.
        The tuples may be 2-tuples (filename, fileobj), 3-tuples (filename, fileobj, contentype)
        or 4-tuples (filename, fileobj, contentype, custom_headers).
        """
        if (not files):
            raise ValueError("Files must be provided.")
        elif isinstance(data, basestring):
            raise ValueError("Data must not be a string.")

        new_fields = []
        fields = to_key_val_list(data or {})
        files = to_key_val_list(files or {})

        for field, val in fields:
            if isinstance(val, basestring) or not hasattr(val, '__iter__'):
                val = [val]
            for v in val:
                if v is not None:
                    # Don't call str() on bytestrings: in Py3 it all goes wrong.
                    if not isinstance(v, bytes):
                        v = str(v)

                    new_fields.append(
                        (field.decode('utf-8') if isinstance(field, bytes) else field,
                         v.encode('utf-8') if isinstance(v, str) else v))

        for (k, v) in files:
            # support for explicit filename
            ft = None
            fh = None
            if isinstance(v, (tuple, list)):
                if len(v) == 2:
                    fn, fp = v
                elif len(v) == 3:
                    fn, fp, ft = v
                else:
                    fn, fp, ft, fh = v
            else:
                fn = guess_filename(v) or k
                fp = v

            if isinstance(fp, (str, bytes, bytearray)):
                fdata = fp
            elif hasattr(fp, 'read'):
                fdata = fp.read()
            elif fp is None:
                continue
            else:
                fdata = fp

            rf = RequestField(name=k, data=fdata, filename=fn, headers=fh)
            rf.make_multipart(content_type=ft)
            new_fields.append(rf)

        body, content_type = encode_multipart_formdata(new_fields)

        return body, content_type


class RequestHooksMixin(object):
    def register_hook(self, event, hook):
        """Properly register a hook."""

        if event not in self.hooks:
            raise ValueError('Unsupported event specified, with event name "%s"' % (event))

        if isinstance(hook, Callable):
            self.hooks[event].append(hook)
        elif hasattr(hook, '__iter__'):
            self.hooks[event].extend(h for h in hook if isinstance(h, Callable))

    def deregister_hook(self, event, hook):
        """Deregister a previously registered hook.
        Returns True if the hook existed, False if not.
        """

        try:
            self.hooks[event].remove(hook)
            return True
        except ValueError:
            return False


class Request(RequestHooksMixin):
    """A user-created :class:`Request <Request>` object.

    Used to prepare a :class:`PreparedRequest <PreparedRequest>`, which is sent to the server.

    :param method: HTTP method to use.
    :param url: URL to send.
    :param headers: dictionary of headers to send.
    :param files: dictionary of {filename: fileobject} files to multipart upload.
    :param data: the body to attach to the request. If a dictionary or
        list of tuples ``[(key, value)]`` is provided, form-encoding will
        take place.
    :param json: json for the body to attach to the request (if files or data is not specified).
    :param params: URL parameters to append to the URL. If a dictionary or
        list of tuples ``[(key, value)]`` is provided, form-encoding will
        take place.
    :param auth: Auth handler or (user, pass) tuple.
    :param cookies: dictionary or CookieJar of cookies to attach to this request.
    :param hooks: dictionary of callback hooks, for internal usage.

    Usage::

      >>> import requests
      >>> req = requests.Request('GET', 'https://httpbin.org/get')
      >>> req.prepare()
      <PreparedRequest [GET]>
    """

    def __init__(self,
            method=None, url=None, headers=None, files=None, data=None,
            params=None, auth=None, cookies=None, hooks=None, json=None):

        # Default empty dicts for dict params.
        data = [] if data is None else data
        files = [] if files is None else files
        headers = {} if headers is None else headers
        params = {} if params is None else params
        hooks = {} if hooks is None else hooks

        self.hooks = default_hooks()
        for (k, v) in list(hooks.items()):
            self.register_hook(event=k, hook=v)

        self.method = method
        self.url = url
        self.headers = headers
        self.files = files
        self.data = data
        self.json = json
        self.params = params
        self.auth = auth
        self.cookies = cookies

    def __repr__(self):
        return '<Request [%s]>' % (self.method)

    def prepare(self):
        """Constructs a :class:`PreparedRequest <PreparedRequest>` for transmission and returns it."""
        p = PreparedRequest()
        p.prepare(
            method=self.method,
            url=self.url,
            headers=self.headers,
            files=self.files,
            data=self.data,
            json=self.json,
            params=self.params,
            auth=self.auth,
            cookies=self.cookies,
            hooks=self.hooks,
        )
        return p


class PreparedRequest(RequestEncodingMixin, RequestHooksMixin):
    """The fully mutable :class:`PreparedRequest <PreparedRequest>` object,
    containing the exact bytes that will be sent to the server.

    Instances are generated from a :class:`Request <Request>` object, and
    should not be instantiated manually; doing so may produce undesirable
    effects.

    Usage::

      >>> import requests
      >>> req = requests.Request('GET', 'https://httpbin.org/get')
      >>> r = req.prepare()
      >>> r
      <PreparedRequest [GET]>

      >>> s = requests.Session()
      >>> s.send(r)
      <Response [200]>
    """

    def __init__(self):
        #: HTTP verb to send to the server.
        self.method = None
        #: HTTP URL to send the request to.
        self.url = None
        #: dictionary of HTTP headers.
        self.headers = None
        # The `CookieJar` used to create the Cookie header will be stored here
        # after prepare_cookies is called
        self._cookies = None
        #: request body to send to the server.
        self.body = None
        #: dictionary of callback hooks, for internal usage.
        self.hooks = default_hooks()
        #: integer denoting starting position of a readable file-like body.
        self._body_position = None

    def prepare(self,
            method=None, url=None, headers=None, files=None, data=None,
            params=None, auth=None, cookies=None, hooks=None, json=None):
        """Prepares the entire request with the given parameters."""

        self.prepare_method(method)
        self.prepare_url(url, params)
        self.prepare_headers(headers)
        self.prepare_cookies(cookies)
        self.prepare_body(data, files, json)
        self.prepare_auth(auth, url)

        # Note that prepare_auth must be last to enable authentication schemes
        # such as OAuth to work on a fully prepared request.

        # This MUST go after prepare_auth. Authenticators could add a hook
        self.prepare_hooks(hooks)

    def __repr__(self):
        return '<PreparedRequest [%s]>' % (self.method)

    def copy(self):
        p = PreparedRequest()
        p.method = self.method
        p.url = self.url
        p.headers = self.headers.copy() if self.headers is not None else None
        p._cookies = _copy_cookie_jar(self._cookies)
        p.body = self.body
        p.hooks = self.hooks
        p._body_position = self._body_position
        return p

    def prepare_method(self, method):
        """Prepares the given HTTP method."""
        self.method = method
        if self.method is not None:
            self.method = to_native_string(self.method.upper())

    @staticmethod
    def _get_idna_encoded_host(host):
        import idna

        try:
            host = idna.encode(host, uts46=True).decode('utf-8')
        except idna.IDNAError:
            raise UnicodeError
        return host

    def prepare_url(self, url, params):
        """Prepares the given HTTP URL."""
        #: Accept objects that have string representations.
        #: We're unable to blindly call unicode/str functions
        #: as this will include the bytestring indicator (b'')
        #: on python 3.x.
        #: https://github.com/psf/requests/pull/2238
        if isinstance(url, bytes):
            url = url.decode('utf8')
        else:
            url = unicode(url) if is_py2 else str(url)

        # Remove leading whitespaces from url
        url = url.lstrip()

        # Don't do any URL preparation for non-HTTP schemes like `mailto`,
        # `data` etc to work around exceptions from `url_parse`, which
        # handles RFC 3986 only.
        if ':' in url and not url.lower().startswith('http'):
            self.url = url
            return

        # Support for unicode domain names and paths.
        try:
            scheme, auth, host, port, path, query, fragment = parse_url(url)
        except LocationParseError as e:
            raise InvalidURL(*e.args)

        if not scheme:
            error = ("Invalid URL {0!r}: No scheme supplied. Perhaps you meant http://{0}?")
            error = error.format(to_native_string(url, 'utf8'))

            raise MissingSchema(error)

        if not host:
            raise InvalidURL("Invalid URL %r: No host supplied" % url)

        # In general, we want to try IDNA encoding the hostname if the string contains
        # non-ASCII characters. This allows users to automatically get the correct IDNA
        # behaviour. For strings containing only ASCII characters, we need to also verify
        # it doesn't start with a wildcard (*), before allowing the unencoded hostname.
        if not unicode_is_ascii(host):
            try:
                host = self._get_idna_encoded_host(host)
            except UnicodeError:
                raise InvalidURL('URL has an invalid label.')
        elif host.startswith((u'*', u'.')):
            raise InvalidURL('URL has an invalid label.')

        # Carefully reconstruct the network location
        netloc = auth or ''
        if netloc:
            netloc += '@'
        netloc += host
        if port:
            netloc += ':' + str(port)

        # Bare domains aren't valid URLs.
        if not path:
            path = '/'

        if is_py2:
            if isinstance(scheme, str):
                scheme = scheme.encode('utf-8')
            if isinstance(netloc, str):
                netloc = netloc.encode('utf-8')
            if isinstance(path, str):
                path = path.encode('utf-8')
            if isinstance(query, str):
                query = query.encode('utf-8')
            if isinstance(fragment, str):
                fragment = fragment.encode('utf-8')

        if isinstance(params, (str, bytes)):
            params = to_native_string(params)

        enc_params = self._encode_params(params)
        if enc_params:
            if query:
                query = '%s&%s' % (query, enc_params)
            else:
                query = enc_params

        url = requote_uri(urlunparse([scheme, netloc, path, None, query, fragment]))
        self.url = url

    def prepare_headers(self, headers):
        """Prepares the given HTTP headers."""

        self.headers = CaseInsensitiveDict()
        if headers:
            for header in headers.items():
                # Raise exception on invalid header value.
                check_header_validity(header)
                name, value = header
                self.headers[to_native_string(name)] = value

    def prepare_body(self, data, files, json=None):
        """Prepares the given HTTP body data."""

        # Check if file, fo, generator, iterator.
        # If not, run through normal process.

        # Nottin' on you.
        body = None
        content_type = None

        if not data and json is not None:
            # urllib3 requires a bytes-like body. Python 2's json.dumps
            # provides this natively, but Python 3 gives a Unicode string.
            content_type = 'application/json'

            try:
                body = complexjson.dumps(json, allow_nan=False)
            except ValueError as ve:
                raise InvalidJSONError(ve, request=self)

            if not isinstance(body, bytes):
                body = body.encode('utf-8')

        is_stream = all([
            hasattr(data, '__iter__'),
            not isinstance(data, (basestring, list, tuple, Mapping))
        ])

        if is_stream:
            try:
                length = super_len(data)
            except (TypeError, AttributeError, UnsupportedOperation):
                length = None

            body = data

            if getattr(body, 'tell', None) is not None:
                # Record the current file position before reading.
                # This will allow us to rewind a file in the event
                # of a redirect.
                try:
                    self._body_position = body.tell()
                except (IOError, OSError):
                    # This differentiates from None, allowing us to catch
                    # a failed `tell()` later when trying to rewind the body
                    self._body_position = object()

            if files:
                raise NotImplementedError('Streamed bodies and files are mutually exclusive.')

            if length:
                self.headers['Content-Length'] = builtin_str(length)
            else:
                self.headers['Transfer-Encoding'] = 'chunked'
        else:
            # Multi-part file uploads.
            if files:
                (body, content_type) = self._encode_files(files, data)
            else:
                if data:
                    body = self._encode_params(data)
                    if isinstance(data, basestring) or hasattr(data, 'read'):
                        content_type = None
                    else:
                        content_type = 'application/x-www-form-urlencoded'

            self.prepare_content_length(body)

            # Add content-type if it wasn't explicitly provided.
            if content_type and ('content-type' not in self.headers):
                self.headers['Content-Type'] = content_type

        self.body = body

    def prepare_content_length(self, body):
        """Prepare Content-Length header based on request method and body"""
        if body is not None:
            length = super_len(body)
            if length:
                # If length exists, set it. Otherwise, we fallback
                # to Transfer-Encoding: chunked.
                self.headers['Content-Length'] = builtin_str(length)
        elif self.method not in ('GET', 'HEAD') and self.headers.get('Content-Length') is None:
            # Set Content-Length to 0 for methods that can have a body
            # but don't provide one. (i.e. not GET or HEAD)
            self.headers['Content-Length'] = '0'

    def prepare_auth(self, auth, url=''):
        """Prepares the given HTTP auth data."""

        # If no Auth is explicitly provided, extract it from the URL first.
        if auth is None:
            url_auth = get_auth_from_url(self.url)
            auth = url_auth if any(url_auth) else None

        if auth:
            if isinstance(auth, tuple) and len(auth) == 2:
                # special-case basic HTTP auth
                auth = HTTPBasicAuth(*auth)

            # Allow auth to make its changes.
            r = auth(self)

            # Update self to reflect the auth changes.
            self.__dict__.update(r.__dict__)

            # Recompute Content-Length
            self.prepare_content_length(self.body)

    def prepare_cookies(self, cookies):
        """Prepares the given HTTP cookie data.

        This function eventually generates a ``Cookie`` header from the
        given cookies using cookielib. Due to cookielib's design, the header
        will not be regenerated if it already exists, meaning this function
        can only be called once for the life of the
        :class:`PreparedRequest <PreparedRequest>` object. Any subsequent calls
        to ``prepare_cookies`` will have no actual effect, unless the "Cookie"
        header is removed beforehand.
        """
        if isinstance(cookies, cookielib.CookieJar):
            self._cookies = cookies
        else:
            self._cookies = cookiejar_from_dict(cookies)

        cookie_header = get_cookie_header(self._cookies, self)
        if cookie_header is not None:
            self.headers['Cookie'] = cookie_header

    def prepare_hooks(self, hooks):
        """Prepares the given hooks."""
        # hooks can be passed as None to the prepare method and to this
        # method. To prevent iterating over None, simply use an empty list
        # if hooks is False-y
        hooks = hooks or []
        for event in hooks:
            self.register_hook(event, hooks[event])


class Response(object):
    """The :class:`Response <Response>` object, which contains a
    server's response to an HTTP request.
    """

    __attrs__ = [
        '_content', 'status_code', 'headers', 'url', 'history',
        'encoding', 'reason', 'cookies', 'elapsed', 'request'
    ]

    def __init__(self):
        self._content = False
        self._content_consumed = False
        self._next = None

        #: Integer Code of responded HTTP Status, e.g. 404 or 200.
        self.status_code = None

        #: Case-insensitive Dictionary of Response Headers.
        #: For example, ``headers['content-encoding']`` will return the
        #: value of a ``'Content-Encoding'`` response header.
        self.headers = CaseInsensitiveDict()

        #: File-like object representation of response (for advanced usage).
        #: Use of ``raw`` requires that ``stream=True`` be set on the request.
        #: This requirement does not apply for use internally to Requests.
        self.raw = None

        #: Final URL location of Response.
        self.url = None

        #: Encoding to decode with when accessing r.text.
        self.encoding = None

        #: A list of :class:`Response <Response>` objects from
        #: the history of the Request. Any redirect responses will end
        #: up here. The list is sorted from the oldest to the most recent request.
        self.history = []

        #: Textual reason of responded HTTP Status, e.g. "Not Found" or "OK".
        self.reason = None

        #: A CookieJar of Cookies the server sent back.
        self.cookies = cookiejar_from_dict({})

        #: The amount of time elapsed between sending the request
        #: and the arrival of the response (as a timedelta).
        #: This property specifically measures the time taken between sending
        #: the first byte of the request and finishing parsing the headers. It
        #: is therefore unaffected by consuming the response content or the
        #: value of the ``stream`` keyword argument.
        self.elapsed = datetime.timedelta(0)

        #: The :class:`PreparedRequest <PreparedRequest>` object to which this
        #: is a response.
        self.request = None

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.close()

    def __getstate__(self):
        # Consume everything; accessing the content attribute makes
        # sure the content has been fully read.
        if not self._content_consumed:
            self.content

        return {attr: getattr(self, attr, None) for attr in self.__attrs__}

    def __setstate__(self, state):
        for name, value in state.items():
            setattr(self, name, value)

        # pickled objects do not have .raw
        setattr(self, '_content_consumed', True)
        setattr(self, 'raw', None)

    def __repr__(self):
        return '<Response [%s]>' % (self.status_code)

    def __bool__(self):
        """Returns True if :attr:`status_code` is less than 400.

        This attribute checks if the status code of the response is between
        400 and 600 to see if there was a client error or a server error. If
        the status code, is between 200 and 400, this will return True. This
        is **not** a check to see if the response code is ``200 OK``.
        """
        return self.ok

    def __nonzero__(self):
        """Returns True if :attr:`status_code` is less than 400.

        This attribute checks if the status code of the response is between
        400 and 600 to see if there was a client error or a server error. If
        the status code, is between 200 and 400, this will return True. This
        is **not** a check to see if the response code is ``200 OK``.
        """
        return self.ok

    def __iter__(self):
        """Allows you to use a response as an iterator."""
        return self.iter_content(128)

    @property
    def ok(self):
        """Returns True if :attr:`status_code` is less than 400, False if not.

        This attribute checks if the status code of the response is between
        400 and 600 to see if there was a client error or a server error. If
        the status code is between 200 and 400, this will return True. This
        is **not** a check to see if the response code is ``200 OK``.
        """
        try:
            self.raise_for_status()
        except HTTPError:
            return False
        return True

    @property
    def is_redirect(self):
        """True if this Response is a well-formed HTTP redirect that could have
        been processed automatically (by :meth:`Session.resolve_redirects`).
        """
        return ('location' in self.headers and self.status_code in REDIRECT_STATI)

    @property
    def is_permanent_redirect(self):
        """True if this Response one of the permanent versions of redirect."""
        return ('location' in self.headers and self.status_code in (codes.moved_permanently, codes.permanent_redirect))

    @property
    def next(self):
        """Returns a PreparedRequest for the next request in a redirect chain, if there is one."""
        return self._next

    @property
    def apparent_encoding(self):
        """The apparent encoding, provided by the charset_normalizer or chardet libraries."""
        return chardet.detect(self.content)['encoding']

    def iter_content(self, chunk_size=1, decode_unicode=False):
        """Iterates over the response data.  When stream=True is set on the
        request, this avoids reading the content at once into memory for
        large responses.  The chunk size is the number of bytes it should
        read into memory.  This is not necessarily the length of each item
        returned as decoding can take place.

        chunk_size must be of type int or None. A value of None will
        function differently depending on the value of `stream`.
        stream=True will read data as it arrives in whatever size the
        chunks are received. If stream=False, data is returned as
        a single chunk.

        If decode_unicode is True, content will be decoded using the best
        available encoding based on the response.
        """

        def generate():
            # Special case for urllib3.
            if hasattr(self.raw, 'stream'):
                try:
                    for chunk in self.raw.stream(chunk_size, decode_content=True):
                        yield chunk
                except ProtocolError as e:
                    raise ChunkedEncodingError(e)
                except DecodeError as e:
                    raise ContentDecodingError(e)
                except ReadTimeoutError as e:
                    raise ConnectionError(e)
            else:
                # Standard file-like object.
                while True:
                    chunk = self.raw.read(chunk_size)
                    if not chunk:
                        break
                    yield chunk

            self._content_consumed = True

        if self._content_consumed and isinstance(self._content, bool):
            raise StreamConsumedError()
        elif chunk_size is not None and not isinstance(chunk_size, int):
            raise TypeError("chunk_size must be an int, it is instead a %s." % type(chunk_size))
        # simulate reading small chunks of the content
        reused_chunks = iter_slices(self._content, chunk_size)

        stream_chunks = generate()

        chunks = reused_chunks if self._content_consumed else stream_chunks

        if decode_unicode:
            chunks = stream_decode_response_unicode(chunks, self)

        return chunks

    def iter_lines(self, chunk_size=ITER_CHUNK_SIZE, decode_unicode=False, delimiter=None):
        """Iterates over the response data, one line at a time.  When
        stream=True is set on the request, this avoids reading the
        content at once into memory for large responses.

        .. note:: This method is not reentrant safe.
        """

        pending = None

        for chunk in self.iter_content(chunk_size=chunk_size, decode_unicode=decode_unicode):

            if pending is not None:
                chunk = pending + chunk

            if delimiter:
                lines = chunk.split(delimiter)
            else:
                lines = chunk.splitlines()

            if lines and lines[-1] and chunk and lines[-1][-1] == chunk[-1]:
                pending = lines.pop()
            else:
                pending = None

            for line in lines:
                yield line

        if pending is not None:
            yield pending

    @property
    def content(self):
        """Content of the response, in bytes."""

        if self._content is False:
            # Read the contents.
            if self._content_consumed:
                raise RuntimeError(
                    'The content for this response was already consumed')

            if self.status_code == 0 or self.raw is None:
                self._content = None
            else:
                self._content = b''.join(self.iter_content(CONTENT_CHUNK_SIZE)) or b''

        self._content_consumed = True
        # don't need to release the connection; that's been handled by urllib3
        # since we exhausted the data.
        return self._content

    @property
    def text(self):
        """Content of the response, in unicode.

        If Response.encoding is None, encoding will be guessed using
        ``charset_normalizer`` or ``chardet``.

        The encoding of the response content is determined based solely on HTTP
        headers, following RFC 2616 to the letter. If you can take advantage of
        non-HTTP knowledge to make a better guess at the encoding, you should
        set ``r.encoding`` appropriately before accessing this property.
        """

        # Try charset from content-type
        content = None
        encoding = self.encoding

        if not self.content:
            return str('')

        # Fallback to auto-detected encoding.
        if self.encoding is None:
            encoding = self.apparent_encoding

        # Decode unicode from given encoding.
        try:
            content = str(self.content, encoding, errors='replace')
        except (LookupError, TypeError):
            # A LookupError is raised if the encoding was not found which could
            # indicate a misspelling or similar mistake.
            #
            # A TypeError can be raised if encoding is None
            #
            # So we try blindly encoding.
            content = str(self.content, errors='replace')

        return content

    def json(self, **kwargs):
        r"""Returns the json-encoded content of a response, if any.

        :param \*\*kwargs: Optional arguments that ``json.loads`` takes.
        :raises requests.exceptions.JSONDecodeError: If the response body does not
            contain valid json.
        """

        if not self.encoding and self.content and len(self.content) > 3:
            # No encoding set. JSON RFC 4627 section 3 states we should expect
            # UTF-8, -16 or -32. Detect which one to use; If the detection or
            # decoding fails, fall back to `self.text` (using charset_normalizer to make
            # a best guess).
            encoding = guess_json_utf(self.content)
            if encoding is not None:
                try:
                    return complexjson.loads(
                        self.content.decode(encoding), **kwargs
                    )
                except UnicodeDecodeError:
                    # Wrong UTF codec detected; usually because it's not UTF-8
                    # but some other 8-bit codec.  This is an RFC violation,
                    # and the server didn't bother to tell us what codec *was*
                    # used.
                    pass

        try:
            return complexjson.loads(self.text, **kwargs)
        except JSONDecodeError as e:
            # Catch JSON-related errors and raise as requests.JSONDecodeError
            # This aliases json.JSONDecodeError and simplejson.JSONDecodeError
            if is_py2: # e is a ValueError
                raise RequestsJSONDecodeError(e.message)
            else:
                raise RequestsJSONDecodeError(e.msg, e.doc, e.pos)

    @property
    def links(self):
        """Returns the parsed header links of the response, if any."""

        header = self.headers.get('link')

        # l = MultiDict()
        l = {}

        if header:
            links = parse_header_links(header)

            for link in links:
                key = link.get('rel') or link.get('url')
                l[key] = link

        return l

    def raise_for_status(self):
        """Raises :class:`HTTPError`, if one occurred."""

        http_error_msg = ''
        if isinstance(self.reason, bytes):
            # We attempt to decode utf-8 first because some servers
            # choose to localize their reason strings. If the string
            # isn't utf-8, we fall back to iso-8859-1 for all other
            # encodings. (See PR #3538)
            try:
                reason = self.reason.decode('utf-8')
            except UnicodeDecodeError:
                reason = self.reason.decode('iso-8859-1')
        else:
            reason = self.reason

        if 400 <= self.status_code < 500:
            http_error_msg = u'%s Client Error: %s for url: %s' % (self.status_code, reason, self.url)

        elif 500 <= self.status_code < 600:
            http_error_msg = u'%s Server Error: %s for url: %s' % (self.status_code, reason, self.url)

        if http_error_msg:
            raise HTTPError(http_error_msg, response=self)

    def close(self):
        """Releases the connection back to the pool. Once this method has been
        called the underlying ``raw`` object must not be accessed again.

        *Note: Should not normally need to be called explicitly.*
        """
        if not self._content_consumed:
            self.raw.close()

        release_conn = getattr(self.raw, 'release_conn', None)
        if release_conn is not None:
            release_conn()




############################################################
### File: name.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Names.
"""

from io import BytesIO
import struct
import sys
import copy
import encodings.idna
try:
    import idna
    have_idna_2008 = True
except ImportError:
    have_idna_2008 = False

import dns.exception
import dns.wiredata

from ._compat import long, binary_type, text_type, unichr, maybe_decode

try:
    maxint = sys.maxint  # pylint: disable=sys-max-int
except AttributeError:
    maxint = (1 << (8 * struct.calcsize("P"))) // 2 - 1


# fullcompare() result values

#: The compared names have no relationship to each other.
NAMERELN_NONE = 0
#: the first name is a superdomain of the second.
NAMERELN_SUPERDOMAIN = 1
#: The first name is a subdomain of the second.
NAMERELN_SUBDOMAIN = 2
#: The compared names are equal.
NAMERELN_EQUAL = 3
#: The compared names have a common ancestor.
NAMERELN_COMMONANCESTOR = 4


class EmptyLabel(dns.exception.SyntaxError):
    """A DNS label is empty."""


class BadEscape(dns.exception.SyntaxError):
    """An escaped code in a text format of DNS name is invalid."""


class BadPointer(dns.exception.FormError):
    """A DNS compression pointer points forward instead of backward."""


class BadLabelType(dns.exception.FormError):
    """The label type in DNS name wire format is unknown."""


class NeedAbsoluteNameOrOrigin(dns.exception.DNSException):
    """An attempt was made to convert a non-absolute name to
    wire when there was also a non-absolute (or missing) origin."""


class NameTooLong(dns.exception.FormError):
    """A DNS name is > 255 octets long."""


class LabelTooLong(dns.exception.SyntaxError):
    """A DNS label is > 63 octets long."""


class AbsoluteConcatenation(dns.exception.DNSException):
    """An attempt was made to append anything other than the
    empty name to an absolute DNS name."""


class NoParent(dns.exception.DNSException):
    """An attempt was made to get the parent of the root name
    or the empty name."""

class NoIDNA2008(dns.exception.DNSException):
    """IDNA 2008 processing was requested but the idna module is not
    available."""


class IDNAException(dns.exception.DNSException):
    """IDNA processing raised an exception."""

    supp_kwargs = {'idna_exception'}
    fmt = "IDNA processing exception: {idna_exception}"


class IDNACodec(object):
    """Abstract base class for IDNA encoder/decoders."""

    def __init__(self):
        pass

    def encode(self, label):
        raise NotImplementedError

    def decode(self, label):
        # We do not apply any IDNA policy on decode; we just
        downcased = label.lower()
        if downcased.startswith(b'xn--'):
            try:
                label = downcased[4:].decode('punycode')
            except Exception as e:
                raise IDNAException(idna_exception=e)
        else:
            label = maybe_decode(label)
        return _escapify(label, True)


class IDNA2003Codec(IDNACodec):
    """IDNA 2003 encoder/decoder."""

    def __init__(self, strict_decode=False):
        """Initialize the IDNA 2003 encoder/decoder.

        *strict_decode* is a ``bool``. If `True`, then IDNA2003 checking
        is done when decoding.  This can cause failures if the name
        was encoded with IDNA2008.  The default is `False`.
        """

        super(IDNA2003Codec, self).__init__()
        self.strict_decode = strict_decode

    def encode(self, label):
        """Encode *label*."""

        if label == '':
            return b''
        try:
            return encodings.idna.ToASCII(label)
        except UnicodeError:
            raise LabelTooLong

    def decode(self, label):
        """Decode *label*."""
        if not self.strict_decode:
            return super(IDNA2003Codec, self).decode(label)
        if label == b'':
            return u''
        try:
            return _escapify(encodings.idna.ToUnicode(label), True)
        except Exception as e:
            raise IDNAException(idna_exception=e)


class IDNA2008Codec(IDNACodec):
    """IDNA 2008 encoder/decoder.

        *uts_46* is a ``bool``.  If True, apply Unicode IDNA
        compatibility processing as described in Unicode Technical
        Standard #46 (http://unicode.org/reports/tr46/).
        If False, do not apply the mapping.  The default is False.

        *transitional* is a ``bool``: If True, use the
        "transitional" mode described in Unicode Technical Standard
        #46.  The default is False.

        *allow_pure_ascii* is a ``bool``.  If True, then a label which
        consists of only ASCII characters is allowed.  This is less
        strict than regular IDNA 2008, but is also necessary for mixed
        names, e.g. a name with starting with "_sip._tcp." and ending
        in an IDN suffix which would otherwise be disallowed.  The
        default is False.

        *strict_decode* is a ``bool``: If True, then IDNA2008 checking
        is done when decoding.  This can cause failures if the name
        was encoded with IDNA2003.  The default is False.
        """

    def __init__(self, uts_46=False, transitional=False,
                 allow_pure_ascii=False, strict_decode=False):
        """Initialize the IDNA 2008 encoder/decoder."""
        super(IDNA2008Codec, self).__init__()
        self.uts_46 = uts_46
        self.transitional = transitional
        self.allow_pure_ascii = allow_pure_ascii
        self.strict_decode = strict_decode

    def is_all_ascii(self, label):
        for c in label:
            if ord(c) > 0x7f:
                return False
        return True

    def encode(self, label):
        if label == '':
            return b''
        if self.allow_pure_ascii and self.is_all_ascii(label):
            return label.encode('ascii')
        if not have_idna_2008:
            raise NoIDNA2008
        try:
            if self.uts_46:
                label = idna.uts46_remap(label, False, self.transitional)
            return idna.alabel(label)
        except idna.IDNAError as e:
            raise IDNAException(idna_exception=e)

    def decode(self, label):
        if not self.strict_decode:
            return super(IDNA2008Codec, self).decode(label)
        if label == b'':
            return u''
        if not have_idna_2008:
            raise NoIDNA2008
        try:
            if self.uts_46:
                label = idna.uts46_remap(label, False, False)
            return _escapify(idna.ulabel(label), True)
        except idna.IDNAError as e:
            raise IDNAException(idna_exception=e)

_escaped = bytearray(b'"().;\\@$')

IDNA_2003_Practical = IDNA2003Codec(False)
IDNA_2003_Strict = IDNA2003Codec(True)
IDNA_2003 = IDNA_2003_Practical
IDNA_2008_Practical = IDNA2008Codec(True, False, True, False)
IDNA_2008_UTS_46 = IDNA2008Codec(True, False, False, False)
IDNA_2008_Strict = IDNA2008Codec(False, False, False, True)
IDNA_2008_Transitional = IDNA2008Codec(True, True, False, False)
IDNA_2008 = IDNA_2008_Practical

def _escapify(label, unicode_mode=False):
    """Escape the characters in label which need it.
    @param unicode_mode: escapify only special and whitespace (<= 0x20)
    characters
    @returns: the escaped string
    @rtype: string"""
    if not unicode_mode:
        text = ''
        if isinstance(label, text_type):
            label = label.encode()
        for c in bytearray(label):
            if c in _escaped:
                text += '\\' + chr(c)
            elif c > 0x20 and c < 0x7F:
                text += chr(c)
            else:
                text += '\\%03d' % c
        return text.encode()

    text = u''
    if isinstance(label, binary_type):
        label = label.decode()
    for c in label:
        if c > u'\x20' and c < u'\x7f':
            text += c
        else:
            if c >= u'\x7f':
                text += c
            else:
                text += u'\\%03d' % ord(c)
    return text

def _validate_labels(labels):
    """Check for empty labels in the middle of a label sequence,
    labels that are too long, and for too many labels.

    Raises ``dns.name.NameTooLong`` if the name as a whole is too long.

    Raises ``dns.name.EmptyLabel`` if a label is empty (i.e. the root
    label) and appears in a position other than the end of the label
    sequence

    """

    l = len(labels)
    total = 0
    i = -1
    j = 0
    for label in labels:
        ll = len(label)
        total += ll + 1
        if ll > 63:
            raise LabelTooLong
        if i < 0 and label == b'':
            i = j
        j += 1
    if total > 255:
        raise NameTooLong
    if i >= 0 and i != l - 1:
        raise EmptyLabel


def _maybe_convert_to_binary(label):
    """If label is ``text``, convert it to ``binary``.  If it is already
    ``binary`` just return it.

    """

    if isinstance(label, binary_type):
        return label
    if isinstance(label, text_type):
        return label.encode()
    raise ValueError


class Name(object):

    """A DNS name.

    The dns.name.Name class represents a DNS name as a tuple of
    labels.  Each label is a `binary` in DNS wire format.  Instances
    of the class are immutable.
    """

    __slots__ = ['labels']

    def __init__(self, labels):
        """*labels* is any iterable whose values are ``text`` or ``binary``.
        """

        labels = [_maybe_convert_to_binary(x) for x in labels]
        super(Name, self).__setattr__('labels', tuple(labels))
        _validate_labels(self.labels)

    def __setattr__(self, name, value):
        # Names are immutable
        raise TypeError("object doesn't support attribute assignment")

    def __copy__(self):
        return Name(self.labels)

    def __deepcopy__(self, memo):
        return Name(copy.deepcopy(self.labels, memo))

    def __getstate__(self):
        # Names can be pickled
        return {'labels': self.labels}

    def __setstate__(self, state):
        super(Name, self).__setattr__('labels', state['labels'])
        _validate_labels(self.labels)

    def is_absolute(self):
        """Is the most significant label of this name the root label?

        Returns a ``bool``.
        """

        return len(self.labels) > 0 and self.labels[-1] == b''

    def is_wild(self):
        """Is this name wild?  (I.e. Is the least significant label '*'?)

        Returns a ``bool``.
        """

        return len(self.labels) > 0 and self.labels[0] == b'*'

    def __hash__(self):
        """Return a case-insensitive hash of the name.

        Returns an ``int``.
        """

        h = long(0)
        for label in self.labels:
            for c in bytearray(label.lower()):
                h += (h << 3) + c
        return int(h % maxint)

    def fullcompare(self, other):
        """Compare two names, returning a 3-tuple
        ``(relation, order, nlabels)``.

        *relation* describes the relation ship between the names,
        and is one of: ``dns.name.NAMERELN_NONE``,
        ``dns.name.NAMERELN_SUPERDOMAIN``, ``dns.name.NAMERELN_SUBDOMAIN``,
        ``dns.name.NAMERELN_EQUAL``, or ``dns.name.NAMERELN_COMMONANCESTOR``.

        *order* is < 0 if *self* < *other*, > 0 if *self* > *other*, and ==
        0 if *self* == *other*.  A relative name is always less than an
        absolute name.  If both names have the same relativity, then
        the DNSSEC order relation is used to order them.

        *nlabels* is the number of significant labels that the two names
        have in common.

        Here are some examples.  Names ending in "." are absolute names,
        those not ending in "." are relative names.

        =============  =============  ===========  =====  =======
        self           other          relation     order  nlabels
        =============  =============  ===========  =====  =======
        www.example.   www.example.   equal        0      3
        www.example.   example.       subdomain    > 0    2
        example.       www.example.   superdomain  < 0    2
        example1.com.  example2.com.  common anc.  < 0    2
        example1       example2.      none         < 0    0
        example1.      example2       none         > 0    0
        =============  =============  ===========  =====  =======
        """

        sabs = self.is_absolute()
        oabs = other.is_absolute()
        if sabs != oabs:
            if sabs:
                return (NAMERELN_NONE, 1, 0)
            else:
                return (NAMERELN_NONE, -1, 0)
        l1 = len(self.labels)
        l2 = len(other.labels)
        ldiff = l1 - l2
        if ldiff < 0:
            l = l1
        else:
            l = l2

        order = 0
        nlabels = 0
        namereln = NAMERELN_NONE
        while l > 0:
            l -= 1
            l1 -= 1
            l2 -= 1
            label1 = self.labels[l1].lower()
            label2 = other.labels[l2].lower()
            if label1 < label2:
                order = -1
                if nlabels > 0:
                    namereln = NAMERELN_COMMONANCESTOR
                return (namereln, order, nlabels)
            elif label1 > label2:
                order = 1
                if nlabels > 0:
                    namereln = NAMERELN_COMMONANCESTOR
                return (namereln, order, nlabels)
            nlabels += 1
        order = ldiff
        if ldiff < 0:
            namereln = NAMERELN_SUPERDOMAIN
        elif ldiff > 0:
            namereln = NAMERELN_SUBDOMAIN
        else:
            namereln = NAMERELN_EQUAL
        return (namereln, order, nlabels)

    def is_subdomain(self, other):
        """Is self a subdomain of other?

        Note that the notion of subdomain includes equality, e.g.
        "dnpython.org" is a subdomain of itself.

        Returns a ``bool``.
        """

        (nr, o, nl) = self.fullcompare(other)
        if nr == NAMERELN_SUBDOMAIN or nr == NAMERELN_EQUAL:
            return True
        return False

    def is_superdomain(self, other):
        """Is self a superdomain of other?

        Note that the notion of superdomain includes equality, e.g.
        "dnpython.org" is a superdomain of itself.

        Returns a ``bool``.
        """

        (nr, o, nl) = self.fullcompare(other)
        if nr == NAMERELN_SUPERDOMAIN or nr == NAMERELN_EQUAL:
            return True
        return False

    def canonicalize(self):
        """Return a name which is equal to the current name, but is in
        DNSSEC canonical form.
        """

        return Name([x.lower() for x in self.labels])

    def __eq__(self, other):
        if isinstance(other, Name):
            return self.fullcompare(other)[1] == 0
        else:
            return False

    def __ne__(self, other):
        if isinstance(other, Name):
            return self.fullcompare(other)[1] != 0
        else:
            return True

    def __lt__(self, other):
        if isinstance(other, Name):
            return self.fullcompare(other)[1] < 0
        else:
            return NotImplemented

    def __le__(self, other):
        if isinstance(other, Name):
            return self.fullcompare(other)[1] <= 0
        else:
            return NotImplemented

    def __ge__(self, other):
        if isinstance(other, Name):
            return self.fullcompare(other)[1] >= 0
        else:
            return NotImplemented

    def __gt__(self, other):
        if isinstance(other, Name):
            return self.fullcompare(other)[1] > 0
        else:
            return NotImplemented

    def __repr__(self):
        return '<DNS name ' + self.__str__() + '>'

    def __str__(self):
        return self.to_text(False)

    def to_text(self, omit_final_dot=False):
        """Convert name to DNS text format.

        *omit_final_dot* is a ``bool``.  If True, don't emit the final
        dot (denoting the root label) for absolute names.  The default
        is False.

        Returns a ``text``.
        """

        if len(self.labels) == 0:
            return maybe_decode(b'@')
        if len(self.labels) == 1 and self.labels[0] == b'':
            return maybe_decode(b'.')
        if omit_final_dot and self.is_absolute():
            l = self.labels[:-1]
        else:
            l = self.labels
        s = b'.'.join(map(_escapify, l))
        return maybe_decode(s)

    def to_unicode(self, omit_final_dot=False, idna_codec=None):
        """Convert name to Unicode text format.

        IDN ACE labels are converted to Unicode.

        *omit_final_dot* is a ``bool``.  If True, don't emit the final
        dot (denoting the root label) for absolute names.  The default
        is False.
        *idna_codec* specifies the IDNA encoder/decoder.  If None, the
        dns.name.IDNA_2003_Practical encoder/decoder is used.
        The IDNA_2003_Practical decoder does
        not impose any policy, it just decodes punycode, so if you
        don't want checking for compliance, you can use this decoder
        for IDNA2008 as well.

        Returns a ``text``.
        """

        if len(self.labels) == 0:
            return u'@'
        if len(self.labels) == 1 and self.labels[0] == b'':
            return u'.'
        if omit_final_dot and self.is_absolute():
            l = self.labels[:-1]
        else:
            l = self.labels
        if idna_codec is None:
            idna_codec = IDNA_2003_Practical
        return u'.'.join([idna_codec.decode(x) for x in l])

    def to_digestable(self, origin=None):
        """Convert name to a format suitable for digesting in hashes.

        The name is canonicalized and converted to uncompressed wire
        format.  All names in wire format are absolute.  If the name
        is a relative name, then an origin must be supplied.

        *origin* is a ``dns.name.Name`` or ``None``.  If the name is
        relative and origin is not ``None``, then origin will be appended
        to the name.

        Raises ``dns.name.NeedAbsoluteNameOrOrigin`` if the name is
        relative and no origin was provided.

        Returns a ``binary``.
        """

        if not self.is_absolute():
            if origin is None or not origin.is_absolute():
                raise NeedAbsoluteNameOrOrigin
            labels = list(self.labels)
            labels.extend(list(origin.labels))
        else:
            labels = self.labels
        dlabels = [struct.pack('!B%ds' % len(x), len(x), x.lower())
                   for x in labels]
        return b''.join(dlabels)

    def to_wire(self, file=None, compress=None, origin=None):
        """Convert name to wire format, possibly compressing it.

        *file* is the file where the name is emitted (typically a
        BytesIO file).  If ``None`` (the default), a ``binary``
        containing the wire name will be returned.

        *compress*, a ``dict``, is the compression table to use.  If
        ``None`` (the default), names will not be compressed.

        *origin* is a ``dns.name.Name`` or ``None``.  If the name is
        relative and origin is not ``None``, then *origin* will be appended
        to it.

        Raises ``dns.name.NeedAbsoluteNameOrOrigin`` if the name is
        relative and no origin was provided.

        Returns a ``binary`` or ``None``.
        """

        if file is None:
            file = BytesIO()
            want_return = True
        else:
            want_return = False

        if not self.is_absolute():
            if origin is None or not origin.is_absolute():
                raise NeedAbsoluteNameOrOrigin
            labels = list(self.labels)
            labels.extend(list(origin.labels))
        else:
            labels = self.labels
        i = 0
        for label in labels:
            n = Name(labels[i:])
            i += 1
            if compress is not None:
                pos = compress.get(n)
            else:
                pos = None
            if pos is not None:
                value = 0xc000 + pos
                s = struct.pack('!H', value)
                file.write(s)
                break
            else:
                if compress is not None and len(n) > 1:
                    pos = file.tell()
                    if pos <= 0x3fff:
                        compress[n] = pos
                l = len(label)
                file.write(struct.pack('!B', l))
                if l > 0:
                    file.write(label)
        if want_return:
            return file.getvalue()

    def __len__(self):
        """The length of the name (in labels).

        Returns an ``int``.
        """

        return len(self.labels)

    def __getitem__(self, index):
        return self.labels[index]

    def __add__(self, other):
        return self.concatenate(other)

    def __sub__(self, other):
        return self.relativize(other)

    def split(self, depth):
        """Split a name into a prefix and suffix names at the specified depth.

        *depth* is an ``int`` specifying the number of labels in the suffix

        Raises ``ValueError`` if *depth* was not >= 0 and <= the length of the
        name.

        Returns the tuple ``(prefix, suffix)``.
        """

        l = len(self.labels)
        if depth == 0:
            return (self, dns.name.empty)
        elif depth == l:
            return (dns.name.empty, self)
        elif depth < 0 or depth > l:
            raise ValueError(
                'depth must be >= 0 and <= the length of the name')
        return (Name(self[: -depth]), Name(self[-depth:]))

    def concatenate(self, other):
        """Return a new name which is the concatenation of self and other.

        Raises ``dns.name.AbsoluteConcatenation`` if the name is
        absolute and *other* is not the empty name.

        Returns a ``dns.name.Name``.
        """

        if self.is_absolute() and len(other) > 0:
            raise AbsoluteConcatenation
        labels = list(self.labels)
        labels.extend(list(other.labels))
        return Name(labels)

    def relativize(self, origin):
        """If the name is a subdomain of *origin*, return a new name which is
        the name relative to origin.  Otherwise return the name.

        For example, relativizing ``www.dnspython.org.`` to origin
        ``dnspython.org.`` returns the name ``www``.  Relativizing ``example.``
        to origin ``dnspython.org.`` returns ``example.``.

        Returns a ``dns.name.Name``.
        """

        if origin is not None and self.is_subdomain(origin):
            return Name(self[: -len(origin)])
        else:
            return self

    def derelativize(self, origin):
        """If the name is a relative name, return a new name which is the
        concatenation of the name and origin.  Otherwise return the name.

        For example, derelativizing ``www`` to origin ``dnspython.org.``
        returns the name ``www.dnspython.org.``.  Derelativizing ``example.``
        to origin ``dnspython.org.`` returns ``example.``.

        Returns a ``dns.name.Name``.
        """

        if not self.is_absolute():
            return self.concatenate(origin)
        else:
            return self

    def choose_relativity(self, origin=None, relativize=True):
        """Return a name with the relativity desired by the caller.

        If *origin* is ``None``, then the name is returned.
        Otherwise, if *relativize* is ``True`` the name is
        relativized, and if *relativize* is ``False`` the name is
        derelativized.

        Returns a ``dns.name.Name``.
        """

        if origin:
            if relativize:
                return self.relativize(origin)
            else:
                return self.derelativize(origin)
        else:
            return self

    def parent(self):
        """Return the parent of the name.

        For example, the parent of ``www.dnspython.org.`` is ``dnspython.org``.

        Raises ``dns.name.NoParent`` if the name is either the root name or the
        empty name, and thus has no parent.

        Returns a ``dns.name.Name``.
        """

        if self == root or self == empty:
            raise NoParent
        return Name(self.labels[1:])

#: The root name, '.'
root = Name([b''])

#: The empty name.
empty = Name([])

def from_unicode(text, origin=root, idna_codec=None):
    """Convert unicode text into a Name object.

    Labels are encoded in IDN ACE form according to rules specified by
    the IDNA codec.

    *text*, a ``text``, is the text to convert into a name.

    *origin*, a ``dns.name.Name``, specifies the origin to
    append to non-absolute names.  The default is the root name.

    *idna_codec*, a ``dns.name.IDNACodec``, specifies the IDNA
    encoder/decoder.  If ``None``, the default IDNA 2003 encoder/decoder
    is used.

    Returns a ``dns.name.Name``.
    """

    if not isinstance(text, text_type):
        raise ValueError("input to from_unicode() must be a unicode string")
    if not (origin is None or isinstance(origin, Name)):
        raise ValueError("origin must be a Name or None")
    labels = []
    label = u''
    escaping = False
    edigits = 0
    total = 0
    if idna_codec is None:
        idna_codec = IDNA_2003
    if text == u'@':
        text = u''
    if text:
        if text == u'.':
            return Name([b''])        # no Unicode "u" on this constant!
        for c in text:
            if escaping:
                if edigits == 0:
                    if c.isdigit():
                        total = int(c)
                        edigits += 1
                    else:
                        label += c
                        escaping = False
                else:
                    if not c.isdigit():
                        raise BadEscape
                    total *= 10
                    total += int(c)
                    edigits += 1
                    if edigits == 3:
                        escaping = False
                        label += unichr(total)
            elif c in [u'.', u'\u3002', u'\uff0e', u'\uff61']:
                if len(label) == 0:
                    raise EmptyLabel
                labels.append(idna_codec.encode(label))
                label = u''
            elif c == u'\\':
                escaping = True
                edigits = 0
                total = 0
            else:
                label += c
        if escaping:
            raise BadEscape
        if len(label) > 0:
            labels.append(idna_codec.encode(label))
        else:
            labels.append(b'')

    if (len(labels) == 0 or labels[-1] != b'') and origin is not None:
        labels.extend(list(origin.labels))
    return Name(labels)


def from_text(text, origin=root, idna_codec=None):
    """Convert text into a Name object.

    *text*, a ``text``, is the text to convert into a name.

    *origin*, a ``dns.name.Name``, specifies the origin to
    append to non-absolute names.  The default is the root name.

    *idna_codec*, a ``dns.name.IDNACodec``, specifies the IDNA
    encoder/decoder.  If ``None``, the default IDNA 2003 encoder/decoder
    is used.

    Returns a ``dns.name.Name``.
    """

    if isinstance(text, text_type):
        return from_unicode(text, origin, idna_codec)
    if not isinstance(text, binary_type):
        raise ValueError("input to from_text() must be a string")
    if not (origin is None or isinstance(origin, Name)):
        raise ValueError("origin must be a Name or None")
    labels = []
    label = b''
    escaping = False
    edigits = 0
    total = 0
    if text == b'@':
        text = b''
    if text:
        if text == b'.':
            return Name([b''])
        for c in bytearray(text):
            byte_ = struct.pack('!B', c)
            if escaping:
                if edigits == 0:
                    if byte_.isdigit():
                        total = int(byte_)
                        edigits += 1
                    else:
                        label += byte_
                        escaping = False
                else:
                    if not byte_.isdigit():
                        raise BadEscape
                    total *= 10
                    total += int(byte_)
                    edigits += 1
                    if edigits == 3:
                        escaping = False
                        label += struct.pack('!B', total)
            elif byte_ == b'.':
                if len(label) == 0:
                    raise EmptyLabel
                labels.append(label)
                label = b''
            elif byte_ == b'\\':
                escaping = True
                edigits = 0
                total = 0
            else:
                label += byte_
        if escaping:
            raise BadEscape
        if len(label) > 0:
            labels.append(label)
        else:
            labels.append(b'')
    if (len(labels) == 0 or labels[-1] != b'') and origin is not None:
        labels.extend(list(origin.labels))
    return Name(labels)


def from_wire(message, current):
    """Convert possibly compressed wire format into a Name.

    *message* is a ``binary`` containing an entire DNS message in DNS
    wire form.

    *current*, an ``int``, is the offset of the beginning of the name
    from the start of the message

    Raises ``dns.name.BadPointer`` if a compression pointer did not
    point backwards in the message.

    Raises ``dns.name.BadLabelType`` if an invalid label type was encountered.

    Returns a ``(dns.name.Name, int)`` tuple consisting of the name
    that was read and the number of bytes of the wire format message
    which were consumed reading it.
    """

    if not isinstance(message, binary_type):
        raise ValueError("input to from_wire() must be a byte string")
    message = dns.wiredata.maybe_wrap(message)
    labels = []
    biggest_pointer = current
    hops = 0
    count = message[current]
    current += 1
    cused = 1
    while count != 0:
        if count < 64:
            labels.append(message[current: current + count].unwrap())
            current += count
            if hops == 0:
                cused += count
        elif count >= 192:
            current = (count & 0x3f) * 256 + message[current]
            if hops == 0:
                cused += 1
            if current >= biggest_pointer:
                raise BadPointer
            biggest_pointer = current
            hops += 1
        else:
            raise BadLabelType
        count = message[current]
        current += 1
        if hops == 0:
            cused += 1
    labels.append('')
    return (Name(labels), cused)




############################################################
### File: namedict.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
# Copyright (C) 2016 Coresec Systems AB
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND CORESEC SYSTEMS AB DISCLAIMS ALL
# WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED
# WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL CORESEC
# SYSTEMS AB BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR
# CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS
# OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,
# NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION
# WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS name dictionary"""

import collections
import dns.name
from ._compat import xrange


class NameDict(collections.MutableMapping):
    """A dictionary whose keys are dns.name.Name objects.

    In addition to being like a regular Python dictionary, this
    dictionary can also get the deepest match for a given key.
    """

    __slots__ = ["max_depth", "max_depth_items", "__store"]

    def __init__(self, *args, **kwargs):
        super(NameDict, self).__init__()
        self.__store = dict()
        #: the maximum depth of the keys that have ever been added
        self.max_depth = 0
        #: the number of items of maximum depth
        self.max_depth_items = 0
        self.update(dict(*args, **kwargs))

    def __update_max_depth(self, key):
        if len(key) == self.max_depth:
            self.max_depth_items = self.max_depth_items + 1
        elif len(key) > self.max_depth:
            self.max_depth = len(key)
            self.max_depth_items = 1

    def __getitem__(self, key):
        return self.__store[key]

    def __setitem__(self, key, value):
        if not isinstance(key, dns.name.Name):
            raise ValueError('NameDict key must be a name')
        self.__store[key] = value
        self.__update_max_depth(key)

    def __delitem__(self, key):
        value = self.__store.pop(key)
        if len(value) == self.max_depth:
            self.max_depth_items = self.max_depth_items - 1
        if self.max_depth_items == 0:
            self.max_depth = 0
            for k in self.__store:
                self.__update_max_depth(k)

    def __iter__(self):
        return iter(self.__store)

    def __len__(self):
        return len(self.__store)

    def has_key(self, key):
        return key in self.__store

    def get_deepest_match(self, name):
        """Find the deepest match to *fname* in the dictionary.

        The deepest match is the longest name in the dictionary which is
        a superdomain of *name*.  Note that *superdomain* includes matching
        *name* itself.

        *name*, a ``dns.name.Name``, the name to find.

        Returns a ``(key, value)`` where *key* is the deepest
        ``dns.name.Name``, and *value* is the value associated with *key*.
        """

        depth = len(name)
        if depth > self.max_depth:
            depth = self.max_depth
        for i in xrange(-depth, 0):
            n = dns.name.Name(name[i:])
            if n in self:
                return (n, self[n])
        v = self[dns.name.empty]
        return (dns.name.empty, v)




############################################################
### File: node_import.py
############################################################
__all__ = ['require']

import subprocess, os, codecs, glob
from .evaljs import translate_js, DEFAULT_HEADER
from .translators.friendly_nodes import is_valid_py_name
import six
import tempfile
import hashlib
import random

DID_INIT = False
DIRNAME = tempfile.mkdtemp()
PY_NODE_MODULES_PATH = os.path.join(os.path.dirname(os.path.abspath(__file__)), 'py_node_modules')


def _init():
    global DID_INIT
    if DID_INIT:
        return
    assert subprocess.call(
        'node -v', shell=True, cwd=DIRNAME
    ) == 0, 'You must have node installed! run: brew install node'
    assert subprocess.call(
        'cd %s;npm install babel-core babel-cli babel-preset-es2015 babel-polyfill babelify browserify browserify-shim'
        % repr(DIRNAME),
        shell=True,
        cwd=DIRNAME) == 0, 'Could not link required node_modules'
    DID_INIT = True


ADD_TO_GLOBALS_FUNC = '''
;function addToGlobals(name, obj) {
    if (!Object.prototype.hasOwnProperty('_fake_exports')) {
        Object.prototype._fake_exports = {};
    }
    Object.prototype._fake_exports[name] = obj;
};

'''
# subprocess.call("""node -e 'require("browserify")'""", shell=True)
GET_FROM_GLOBALS_FUNC = '''
;function getFromGlobals(name) {
    if (!Object.prototype.hasOwnProperty('_fake_exports')) {
        throw Error("Could not find any value named "+name);
    }
    if (Object.prototype._fake_exports.hasOwnProperty(name)) {
        return Object.prototype._fake_exports[name];
    } else {
        throw Error("Could not find any value named "+name);
    }
};

'''


def _get_module_py_name(module_name):
    return module_name.replace('-', '_')


def _get_module_var_name(module_name):
    cand =  _get_module_py_name(module_name).rpartition('/')[-1]
    if not is_valid_py_name(cand):
        raise ValueError(
            "Invalid Python module name %s (generated from %s). Unsupported/invalid npm module specification?" % (
                repr(cand), repr(module_name)))
    return cand


def _get_and_translate_npm_module(module_name, include_polyfill=False, update=False, maybe_version_str=""):
    assert isinstance(module_name, str), 'module_name must be a string!'

    py_name = _get_module_py_name(module_name)
    module_filename = '%s.py' % py_name
    var_name = _get_module_var_name(module_name)
    if not os.path.exists(os.path.join(PY_NODE_MODULES_PATH,
                                       module_filename)) or update:
        _init()
        module_hash = hashlib.sha1(module_name.encode("utf-8")).hexdigest()[:15]
        version = random.randrange(10000000000000)
        in_file_name = 'in_%s_%d.js' % (module_hash, version)
        out_file_name = 'out_%s_%d.js' % (module_hash, version)
        code = ADD_TO_GLOBALS_FUNC
        if include_polyfill:
            code += "\n;require('babel-polyfill');\n"
        code += """
        var module_temp_love_python = require(%s);
        addToGlobals(%s, module_temp_love_python);
        """ % (repr(module_name), repr(module_name))
        with open(os.path.join(DIRNAME, in_file_name), 'wb') as f:
            f.write(code.encode('utf-8') if six.PY3 else code)

        pkg_name = module_name.partition('/')[0]
        if maybe_version_str:
            pkg_name += '@' + maybe_version_str
        # make sure the module is installed
        assert subprocess.call(
            'cd %s;npm install %s' % (repr(DIRNAME), pkg_name),
            shell=True,
            cwd=DIRNAME
        ) == 0, 'Could not install the required module: ' + pkg_name

        # convert the module
        assert subprocess.call(
            '''node -e "(require('browserify')('./%s').bundle(function (err,data) {if (err) {console.log(err);throw new Error(err);};fs.writeFile('%s', require('babel-core').transform(data, {'presets': require('babel-preset-es2015')}).code, ()=>{});}))"'''
            % (in_file_name, out_file_name),
            shell=True,
            cwd=DIRNAME,
        ) == 0, 'Error when converting module to the js bundle'

        os.remove(os.path.join(DIRNAME, in_file_name))
        with codecs.open(os.path.join(DIRNAME, out_file_name), "r",
                         "utf-8") as f:
            js_code = f.read()
        print("Bundled JS library dumped at: %s" % os.path.join(DIRNAME, out_file_name))
        if len(js_code) < 50:
            raise RuntimeError("Candidate JS bundle too short - likely browserify issue.")
        js_code += GET_FROM_GLOBALS_FUNC
        js_code += ';var %s = getFromGlobals(%s);%s' % (
            var_name, repr(module_name), var_name)
        print('Please wait, translating...')
        py_code = translate_js(js_code)

        dirname = os.path.dirname(
            os.path.join(PY_NODE_MODULES_PATH, module_filename))
        if not os.path.isdir(dirname):
            os.makedirs(dirname)
        with open(os.path.join(PY_NODE_MODULES_PATH, module_filename),
                  'wb') as f:
            f.write(py_code.encode('utf-8') if six.PY3 else py_code)
    else:
        with codecs.open(
                os.path.join(PY_NODE_MODULES_PATH, module_filename), "r",
                "utf-8") as f:
            py_code = f.read()
    return py_code


def require(module_name, include_polyfill=True, update=False, context=None):
    """
    Installs the provided npm module, exports a js bundle via browserify, converts to ECMA 5.1 via babel and
    finally translates the generated JS bundle to Python via Js2Py.
    Returns a pure python object that behaves like the installed module. Nice!

    :param module_name: Name of the npm module to require. For example 'esprima'. Supports specific versions via @
        specification. Eg: 'crypto-js@3.3'.
    :param include_polyfill: Whether the babel-polyfill should be included as part of the translation. May be needed
    for some modules that use unsupported features of JS6 such as Map or typed arrays.
    :param update: Whether to force update the translation. Otherwise uses a cached version if exists.
    :param context: Optional context in which the translated module should be executed in. If provided, the
        header (js2py imports) will be skipped as it is assumed that the context already has all the necessary imports.
    :return: The JsObjectWrapper containing the translated module object. Can be used like a standard python object.
    """
    module_name, maybe_version = (module_name+"@@@").split('@')[:2]

    py_code = _get_and_translate_npm_module(module_name, include_polyfill=include_polyfill, update=update,
                                            maybe_version_str=maybe_version)
    # this is a bit hacky but we need to strip the default header from the generated code...
    if context is not None:
        if not py_code.startswith(DEFAULT_HEADER):
            # new header version? retranslate...
            assert not update, "Unexpected header."
            py_code = _get_and_translate_npm_module(module_name, include_polyfill=include_polyfill, update=True)
            assert py_code.startswith(DEFAULT_HEADER), "Unexpected header."
        py_code = py_code[len(DEFAULT_HEADER):]
    context = {} if context is None else context
    exec(py_code, context)
    return context['var'][_get_module_var_name(module_name)].to_py()




############################################################
### File: node.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS nodes.  A node is a set of rdatasets."""

from io import StringIO

import dns.rdataset
import dns.rdatatype
import dns.renderer


class Node(object):

    """A Node is a set of rdatasets."""

    __slots__ = ['rdatasets']

    def __init__(self):
        #: the set of rdatsets, represented as a list.
        self.rdatasets = []

    def to_text(self, name, **kw):
        """Convert a node to text format.

        Each rdataset at the node is printed.  Any keyword arguments
        to this method are passed on to the rdataset's to_text() method.

        *name*, a ``dns.name.Name`` or ``text``, the owner name of the rdatasets.

        Returns a ``text``.
        """

        s = StringIO()
        for rds in self.rdatasets:
            if len(rds) > 0:
                s.write(rds.to_text(name, **kw))
                s.write(u'\n')
        return s.getvalue()[:-1]

    def __repr__(self):
        return '<DNS node ' + str(id(self)) + '>'

    def __eq__(self, other):
        #
        # This is inefficient.  Good thing we don't need to do it much.
        #
        for rd in self.rdatasets:
            if rd not in other.rdatasets:
                return False
        for rd in other.rdatasets:
            if rd not in self.rdatasets:
                return False
        return True

    def __ne__(self, other):
        return not self.__eq__(other)

    def __len__(self):
        return len(self.rdatasets)

    def __iter__(self):
        return iter(self.rdatasets)

    def find_rdataset(self, rdclass, rdtype, covers=dns.rdatatype.NONE,
                      create=False):
        """Find an rdataset matching the specified properties in the
        current node.

        *rdclass*, an ``int``, the class of the rdataset.

        *rdtype*, an ``int``, the type of the rdataset.

        *covers*, an ``int``, the covered type.  Usually this value is
        dns.rdatatype.NONE, but if the rdtype is dns.rdatatype.SIG or
        dns.rdatatype.RRSIG, then the covers value will be the rdata
        type the SIG/RRSIG covers.  The library treats the SIG and RRSIG
        types as if they were a family of
        types, e.g. RRSIG(A), RRSIG(NS), RRSIG(SOA).  This makes RRSIGs much
        easier to work with than if RRSIGs covering different rdata
        types were aggregated into a single RRSIG rdataset.

        *create*, a ``bool``.  If True, create the rdataset if it is not found.

        Raises ``KeyError`` if an rdataset of the desired type and class does
        not exist and *create* is not ``True``.

        Returns a ``dns.rdataset.Rdataset``.
        """

        for rds in self.rdatasets:
            if rds.match(rdclass, rdtype, covers):
                return rds
        if not create:
            raise KeyError
        rds = dns.rdataset.Rdataset(rdclass, rdtype)
        self.rdatasets.append(rds)
        return rds

    def get_rdataset(self, rdclass, rdtype, covers=dns.rdatatype.NONE,
                     create=False):
        """Get an rdataset matching the specified properties in the
        current node.

        None is returned if an rdataset of the specified type and
        class does not exist and *create* is not ``True``.

        *rdclass*, an ``int``, the class of the rdataset.

        *rdtype*, an ``int``, the type of the rdataset.

        *covers*, an ``int``, the covered type.  Usually this value is
        dns.rdatatype.NONE, but if the rdtype is dns.rdatatype.SIG or
        dns.rdatatype.RRSIG, then the covers value will be the rdata
        type the SIG/RRSIG covers.  The library treats the SIG and RRSIG
        types as if they were a family of
        types, e.g. RRSIG(A), RRSIG(NS), RRSIG(SOA).  This makes RRSIGs much
        easier to work with than if RRSIGs covering different rdata
        types were aggregated into a single RRSIG rdataset.

        *create*, a ``bool``.  If True, create the rdataset if it is not found.

        Returns a ``dns.rdataset.Rdataset`` or ``None``.
        """

        try:
            rds = self.find_rdataset(rdclass, rdtype, covers, create)
        except KeyError:
            rds = None
        return rds

    def delete_rdataset(self, rdclass, rdtype, covers=dns.rdatatype.NONE):
        """Delete the rdataset matching the specified properties in the
        current node.

        If a matching rdataset does not exist, it is not an error.

        *rdclass*, an ``int``, the class of the rdataset.

        *rdtype*, an ``int``, the type of the rdataset.

        *covers*, an ``int``, the covered type.
        """

        rds = self.get_rdataset(rdclass, rdtype, covers)
        if rds is not None:
            self.rdatasets.remove(rds)

    def replace_rdataset(self, replacement):
        """Replace an rdataset.

        It is not an error if there is no rdataset matching *replacement*.

        Ownership of the *replacement* object is transferred to the node;
        in other words, this method does not store a copy of *replacement*
        at the node, it stores *replacement* itself.

        *replacement*, a ``dns.rdataset.Rdataset``.

        Raises ``ValueError`` if *replacement* is not a
        ``dns.rdataset.Rdataset``.
        """

        if not isinstance(replacement, dns.rdataset.Rdataset):
            raise ValueError('replacement is not an rdataset')
        self.delete_rdataset(replacement.rdclass, replacement.rdtype,
                             replacement.covers)
        self.rdatasets.append(replacement)




############################################################
### File: opcode.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Opcodes."""

import dns.exception

#: Query
QUERY = 0
#: Inverse Query (historical)
IQUERY = 1
#: Server Status (unspecified and unimplemented anywhere)
STATUS = 2
#: Notify
NOTIFY = 4
#: Dynamic Update
UPDATE = 5

_by_text = {
    'QUERY': QUERY,
    'IQUERY': IQUERY,
    'STATUS': STATUS,
    'NOTIFY': NOTIFY,
    'UPDATE': UPDATE
}

# We construct the inverse mapping programmatically to ensure that we
# cannot make any mistakes (e.g. omissions, cut-and-paste errors) that
# would cause the mapping not to be true inverse.

_by_value = {y: x for x, y in _by_text.items()}


class UnknownOpcode(dns.exception.DNSException):
    """An DNS opcode is unknown."""


def from_text(text):
    """Convert text into an opcode.

    *text*, a ``text``, the textual opcode

    Raises ``dns.opcode.UnknownOpcode`` if the opcode is unknown.

    Returns an ``int``.
    """

    if text.isdigit():
        value = int(text)
        if value >= 0 and value <= 15:
            return value
    value = _by_text.get(text.upper())
    if value is None:
        raise UnknownOpcode
    return value


def from_flags(flags):
    """Extract an opcode from DNS message flags.

    *flags*, an ``int``, the DNS flags.

    Returns an ``int``.
    """

    return (flags & 0x7800) >> 11


def to_flags(value):
    """Convert an opcode to a value suitable for ORing into DNS message
    flags.

    *value*, an ``int``, the DNS opcode value.

    Returns an ``int``.
    """

    return (value << 11) & 0x7800


def to_text(value):
    """Convert an opcode to text.

    *value*, an ``int`` the opcode value,

    Raises ``dns.opcode.UnknownOpcode`` if the opcode is unknown.

    Returns a ``text``.
    """

    text = _by_value.get(value)
    if text is None:
        text = str(value)
    return text


def is_update(flags):
    """Is the opcode in flags UPDATE?

    *flags*, an ``int``, the DNS message flags.

    Returns a ``bool``.
    """

    return from_flags(flags) == UPDATE




############################################################
### File: package_data.py
############################################################
__version__ = '2.10'





############################################################
### File: packages.py
############################################################
import sys

try:
    import chardet
except ImportError:
    import charset_normalizer as chardet
    import warnings

    warnings.filterwarnings('ignore', 'Trying to detect', module='charset_normalizer')

# This code exists for backwards compatibility reasons.
# I don't like it either. Just look the other way. :)

for package in ('urllib3', 'idna'):
    locals()[package] = __import__(package)
    # This traversal is apparently necessary such that the identities are
    # preserved (requests.packages.urllib3.* is urllib3.*)
    for mod in list(sys.modules):
        if mod == package or mod.startswith(package + '.'):
            sys.modules['requests.packages.' + mod] = sys.modules[mod]

target = chardet.__name__
for mod in list(sys.modules):
    if mod == target or mod.startswith(target + '.'):
        sys.modules['requests.packages.' + target.replace(target, 'chardet')] = sys.modules[mod]
# Kinda cool, though, right?




############################################################
### File: parser.py
############################################################
# The MIT License
#
# Copyright 2014, 2015 Piotr Dabkowski
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the 'Software'),
# to deal in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
# the Software, and to permit persons to whom the Software is furnished to do so, subject
# to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all copies or
# substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT
# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
#  OR THE USE OR OTHER DEALINGS IN THE SOFTWARE
from __future__ import unicode_literals
from .pyjsparserdata import *
from .std_nodes import *
from pprint import pprint
import sys

__all__ = [
    'PyJsParser', 'parse', 'ENABLE_JS2PY_ERRORS', 'ENABLE_PYIMPORT',
    'JsSyntaxError'
]
REGEXP_SPECIAL_SINGLE = ('\\', '^', '$', '*', '+', '?', '.', '[', ']', '(',
                         ')', '{', '{', '|', '-')
ENABLE_PYIMPORT = False
ENABLE_JS2PY_ERRORS = False

PY3 = sys.version_info >= (3, 0)

if PY3:
    basestring = str
    long = int
    xrange = range
    unicode = str

ESPRIMA_VERSION = '2.2.0'
DEBUG = False
# Small naming convention changes
# len -> leng
# id -> d
# type -> typ
# str -> st
true = True
false = False
null = None


class PyJsParser:
    """ Usage:
        parser = PyJsParser()
        parser.parse('var JavaScriptCode = 5.1')
    """

    def __init__(self):
        self.clean()

    def test(self, code):
        pprint(self.parse(code))

    def clean(self):
        self.strict = None
        self.sourceType = None
        self.index = 0
        self.lineNumber = 1
        self.lineStart = 0
        self.hasLineTerminator = None
        self.lastIndex = None
        self.lastLineNumber = None
        self.lastLineStart = None
        self.startIndex = None
        self.startLineNumber = None
        self.startLineStart = None
        self.scanning = None
        self.lookahead = None
        self.state = None
        self.extra = None
        self.isBindingElement = None
        self.isAssignmentTarget = None
        self.firstCoverInitializedNameError = None

    # 7.4 Comments

    def skipSingleLineComment(self, offset):
        start = self.index - offset
        while self.index < self.length:
            ch = self.source[self.index]
            self.index += 1
            if isLineTerminator(ch):
                if (ord(ch) == 13 and ord(self.source[self.index]) == 10):
                    self.index += 1
                self.lineNumber += 1
                self.hasLineTerminator = True
                self.lineStart = self.index
                return

    def skipMultiLineComment(self):
        while self.index < self.length:
            ch = ord(self.source[self.index])
            if isLineTerminator(ch):
                if (ch == 0x0D and ord(self.source[self.index + 1]) == 0x0A):
                    self.index += 1
                self.lineNumber += 1
                self.index += 1
                self.hasLineTerminator = True
                self.lineStart = self.index
            elif ch == 0x2A:
                # Block comment ends with '*/'.
                if ord(self.source[self.index + 1]) == 0x2F:
                    self.index += 2
                    return
                self.index += 1
            else:
                self.index += 1
        self.tolerateUnexpectedToken()

    def skipComment(self):
        self.hasLineTerminator = False
        start = (self.index == 0)
        while self.index < self.length:
            ch = ord(self.source[self.index])
            if isWhiteSpace(ch):
                self.index += 1
            elif isLineTerminator(ch):
                self.hasLineTerminator = True
                self.index += 1
                if (ch == 0x0D and ord(self.source[self.index]) == 0x0A):
                    self.index += 1
                self.lineNumber += 1
                self.lineStart = self.index
                start = True
            elif (ch == 0x2F):  # U+002F is '/'
                ch = ord(self.source[self.index + 1])
                if (ch == 0x2F):
                    self.index += 2
                    self.skipSingleLineComment(2)
                    start = True
                elif (ch == 0x2A):  # U+002A is '*'
                    self.index += 2
                    self.skipMultiLineComment()
                else:
                    break
            elif (start and ch == 0x2D):  # U+002D is '-'
                # U+003E is '>'
                if (ord(self.source[self.index + 1]) == 0x2D) and (ord(
                        self.source[self.index + 2]) == 0x3E):
                    # '-->' is a single-line comment
                    self.index += 3
                    self.skipSingleLineComment(3)
                else:
                    break
            elif (ch == 0x3C):  # U+003C is '<'
                if self.source[self.index + 1:self.index + 4] == '!--':
                    # <!--
                    self.index += 4
                    self.skipSingleLineComment(4)
                else:
                    break
            else:
                break

    def scanHexEscape(self, prefix):
        code = 0
        leng = 4 if (prefix == 'u') else 2
        for i in xrange(leng):
            if self.index < self.length and isHexDigit(
                    self.source[self.index]):
                ch = self.source[self.index]
                self.index += 1
                code = code * 16 + HEX_CONV[ch]
            else:
                return ''
        return unichr(code)

    def scanUnicodeCodePointEscape(self):
        ch = self.source[self.index]
        code = 0
        # At least, one hex digit is required.
        if ch == '}':
            self.throwUnexpectedToken()
        while (self.index < self.length):
            ch = self.source[self.index]
            self.index += 1
            if not isHexDigit(ch):
                break
            code = code * 16 + HEX_CONV[ch]
        if code > 0x10FFFF or ch != '}':
            self.throwUnexpectedToken()
        # UTF-16 Encoding
        if (code <= 0xFFFF):
            return unichr(code)
        cu1 = ((code - 0x10000) >> 10) + 0xD800
        cu2 = ((code - 0x10000) & 1023) + 0xDC00
        return unichr(cu1) + unichr(cu2)

    def ccode(self, offset=0):
        return ord(self.source[self.index + offset])

    def log_err_case(self):
        if not DEBUG:
            return
        print('INDEX', self.index)
        print(self.source[self.index - 10:self.index + 10])
        print('')

    def at(self, loc):
        return None if loc >= self.length else self.source[loc]

    def substr(self, le, offset=0):
        return self.source[self.index + offset:self.index + offset + le]

    def getEscapedIdentifier(self):
        d = self.source[self.index]
        ch = ord(d)
        self.index += 1
        # '\u' (U+005C, U+0075) denotes an escaped character.
        if (ch == 0x5C):
            if (ord(self.source[self.index]) != 0x75):
                self.throwUnexpectedToken()
            self.index += 1
            ch = self.scanHexEscape('u')
            if not ch or ch == '\\' or not isIdentifierStart(ch[0]):
                self.throwUnexpectedToken()
            d = ch
        while (self.index < self.length):
            ch = self.ccode()
            if not isIdentifierPart(ch):
                break
            self.index += 1
            d += unichr(ch)

            # '\u' (U+005C, U+0075) denotes an escaped character.
            if (ch == 0x5C):
                d = d[0:len(d) - 1]
                if (self.ccode() != 0x75):
                    self.throwUnexpectedToken()
                self.index += 1
                ch = self.scanHexEscape('u')
                if (not ch or ch == '\\' or not isIdentifierPart(ch[0])):
                    self.throwUnexpectedToken()
                d += ch
        return d

    def getIdentifier(self):
        start = self.index
        self.index += 1
        while (self.index < self.length):
            ch = self.ccode()
            if (ch == 0x5C):
                # Blackslash (U+005C) marks Unicode escape sequence.
                self.index = start
                return self.getEscapedIdentifier()
            if (isIdentifierPart(ch)):
                self.index += 1
            else:
                break
        return self.source[start:self.index]

    def scanIdentifier(self):
        start = self.index

        # Backslash (U+005C) starts an escaped character.
        d = self.getEscapedIdentifier() if (
            self.ccode() == 0x5C) else self.getIdentifier()

        # There is no keyword or literal with only one character.
        # Thus, it must be an identifier.
        if (len(d) == 1):
            type = Token.Identifier
        elif (isKeyword(d)):
            type = Token.Keyword
        elif (d == 'null'):
            type = Token.NullLiteral
        elif (d == 'true' or d == 'false'):
            type = Token.BooleanLiteral
        else:
            type = Token.Identifier
        return {
            'type': type,
            'value': d,
            'raw': self.source[start:self.index],
            'lineNumber': self.lineNumber,
            'lineStart': self.lineStart,
            'start': start,
            'end': self.index
        }

    # 7.7 Punctuators

    def scanPunctuator(self):
        token = {
            'type': Token.Punctuator,
            'value': '',
            'lineNumber': self.lineNumber,
            'lineStart': self.lineStart,
            'start': self.index,
            'end': self.index
        }
        # Check for most common single-character punctuators.
        st = self.source[self.index]
        if st == '{':
            self.state['curlyStack'].append('{')
            self.index += 1
        elif st == '}':
            self.index += 1
            self.state['curlyStack'].pop()
        elif st in ('.', '(', ')', ';', ',', '[', ']', ':', '?', '~'):
            self.index += 1
        else:
            # 4-character punctuator.
            st = self.substr(4)
            if (st == '>>>='):
                self.index += 4
            else:
                # 3-character punctuators.
                st = st[0:3]
                if st in ('===', '!==', '>>>', '<<=', '>>='):
                    self.index += 3
                else:
                    # 2-character punctuators.
                    st = st[0:2]
                    if st in ('&&', '||', '==', '!=', '+=', '-=', '*=', '/=',
                              '++', '--', '<<', '>>', '&=', '|=', '^=', '%=',
                              '<=', '>=', '=>'):
                        self.index += 2
                    else:
                        # 1-character punctuators.
                        st = self.source[self.index]
                        if st in ('<', '>', '=', '!', '+', '-', '*', '%', '&',
                                  '|', '^', '/'):
                            self.index += 1
        if self.index == token['start']:
            self.throwUnexpectedToken()
        token['end'] = self.index
        token['value'] = st
        return token

    # 7.8.3 Numeric Literals

    def scanHexLiteral(self, start):
        number = ''
        while (self.index < self.length):
            if (not isHexDigit(self.source[self.index])):
                break
            number += self.source[self.index]
            self.index += 1
        if not number:
            self.throwUnexpectedToken()
        if isIdentifierStart(self.ccode()):
            self.throwUnexpectedToken()
        return {
            'type': Token.NumericLiteral,
            'value': int(number, 16),
            'raw': self.source[start:self.index],
            'lineNumber': self.lineNumber,
            'lineStart': self.lineStart,
            'start': start,
            'end': self.index
        }

    def scanBinaryLiteral(self, start):
        number = ''
        while (self.index < self.length):
            ch = self.source[self.index]
            if (ch != '0' and ch != '1'):
                break
            number += self.source[self.index]
            self.index += 1

        if not number:
            # only 0b or 0B
            self.throwUnexpectedToken()
        if (self.index < self.length):
            ch = self.source[self.index]
            # istanbul ignore else
            if (isIdentifierStart(ch) or isDecimalDigit(ch)):
                self.throwUnexpectedToken()
        return {
            'type': Token.NumericLiteral,
            'value': int(number, 2),
            'raw': self.source[start:self.index],
            'lineNumber': self.lineNumber,
            'lineStart': self.lineStart,
            'start': start,
            'end': self.index
        }

    def scanOctalLiteral(self, prefix, start):
        if isOctalDigit(prefix):
            octal = True
            number = '0' + self.source[self.index]
            self.index += 1
        else:
            octal = False
            self.index += 1
            number = ''
        while (self.index < self.length):
            if (not isOctalDigit(self.source[self.index])):
                break
            number += self.source[self.index]
            self.index += 1
        if (not octal and not number):
            # only 0o or 0O
            self.throwUnexpectedToken()
        if (isIdentifierStart(self.ccode()) or isDecimalDigit(self.ccode())):
            self.throwUnexpectedToken()
        return {
            'type': Token.NumericLiteral,
            'value': int(number, 8),
            'raw': self.source[start:self.index],
            'lineNumber': self.lineNumber,
            'lineStart': self.lineStart,
            'start': start,
            'end': self.index
        }

    def octalToDecimal(self, ch):
        # \0 is not octal escape sequence
        octal = (ch != '0')
        code = int(ch, 8)

        if (self.index < self.length
                and isOctalDigit(self.source[self.index])):
            octal = True
            code = code * 8 + int(self.source[self.index], 8)
            self.index += 1

            # 3 digits are only allowed when string starts
            # with 0, 1, 2, 3
            if (ch in '0123' and self.index < self.length
                    and isOctalDigit(self.source[self.index])):
                code = code * 8 + int((self.source[self.index]), 8)
                self.index += 1
        return {'code': code, 'octal': octal}

    def isImplicitOctalLiteral(self):
        # Implicit octal, unless there is a non-octal digit.
        # (Annex B.1.1 on Numeric Literals)
        for i in xrange(self.index + 1, self.length):
            ch = self.source[i]
            if (ch == '8' or ch == '9'):
                return False
            if (not isOctalDigit(ch)):
                return True
        return True

    def scanNumericLiteral(self):
        ch = self.source[self.index]
        assert isDecimalDigit(ch) or (
            ch == '.'
        ), 'Numeric literal must start with a decimal digit or a decimal point'
        start = self.index
        number = ''
        if ch != '.':
            number = self.source[self.index]
            self.index += 1
            ch = self.source[self.index]
            # Hex number starts with '0x'.
            # Octal number starts with '0'.
            # Octal number in ES6 starts with '0o'.
            # Binary number in ES6 starts with '0b'.
            if (number == '0'):
                if (ch == 'x' or ch == 'X'):
                    self.index += 1
                    return self.scanHexLiteral(start)
                if (ch == 'b' or ch == 'B'):
                    self.index += 1
                    return self.scanBinaryLiteral(start)
                if (ch == 'o' or ch == 'O'):
                    return self.scanOctalLiteral(ch, start)
                if (isOctalDigit(ch)):
                    if (self.isImplicitOctalLiteral()):
                        return self.scanOctalLiteral(ch, start)
            while (isDecimalDigit(self.ccode())):
                number += self.source[self.index]
                self.index += 1
            ch = self.source[self.index]
        if (ch == '.'):
            number += self.source[self.index]
            self.index += 1
            while (isDecimalDigit(self.source[self.index])):
                number += self.source[self.index]
                self.index += 1
            ch = self.source[self.index]
        if (ch == 'e' or ch == 'E'):
            number += self.source[self.index]
            self.index += 1
            ch = self.source[self.index]
            if (ch == '+' or ch == '-'):
                number += self.source[self.index]
                self.index += 1
            if (isDecimalDigit(self.source[self.index])):
                while (isDecimalDigit(self.source[self.index])):
                    number += self.source[self.index]
                    self.index += 1
            else:
                self.throwUnexpectedToken()
        if (isIdentifierStart(self.source[self.index])):
            self.throwUnexpectedToken()
        return {
            'type': Token.NumericLiteral,
            'value': float(number),
            'raw': self.source[start:self.index],
            'lineNumber': self.lineNumber,
            'lineStart': self.lineStart,
            'start': start,
            'end': self.index
        }

    # 7.8.4 String Literals

    def _interpret_regexp(self, string, flags):
        '''Perform sctring escape - for regexp literals'''
        self.index = 0
        self.length = len(string)
        self.source = string
        self.lineNumber = 0
        self.lineStart = 0
        octal = False
        st = ''
        inside_square = 0
        while (self.index < self.length):
            template = '[%s]' if not inside_square else '%s'
            ch = self.source[self.index]
            self.index += 1
            if ch == '\\':
                ch = self.source[self.index]
                self.index += 1
                if (not isLineTerminator(ch)):
                    if ch == 'u':
                        digs = self.source[self.index:self.index + 4]
                        if len(digs) == 4 and all(isHexDigit(d) for d in digs):
                            st += template % unichr(int(digs, 16))
                            self.index += 4
                        else:
                            st += 'u'
                    elif ch == 'x':
                        digs = self.source[self.index:self.index + 2]
                        if len(digs) == 2 and all(isHexDigit(d) for d in digs):
                            st += template % unichr(int(digs, 16))
                            self.index += 2
                        else:
                            st += 'x'
                    # special meaning - single char.
                    elif ch == '0':
                        st += '\\0'
                    elif ch == 'n':
                        st += '\\n'
                    elif ch == 'r':
                        st += '\\r'
                    elif ch == 't':
                        st += '\\t'
                    elif ch == 'f':
                        st += '\\f'
                    elif ch == 'v':
                        st += '\\v'

                    # unescape special single characters like . so that they are interpreted literally
                    elif ch in REGEXP_SPECIAL_SINGLE:
                        st += '\\' + ch

                    # character groups
                    elif ch == 'b':
                        st += '\\b'
                    elif ch == 'B':
                        st += '\\B'
                    elif ch == 'w':
                        st += '\\w'
                    elif ch == 'W':
                        st += '\\W'
                    elif ch == 'd':
                        st += '\\d'
                    elif ch == 'D':
                        st += '\\D'
                    elif ch == 's':
                        st += template % u' \f\n\r\t\v\u00a0\u1680\u180e\u2000-\u200a\u2028\u2029\u202f\u205f\u3000\ufeff'
                    elif ch == 'S':
                        st += template % u'\u0000-\u0008\u000e-\u001f\u0021-\u009f\u00a1-\u167f\u1681-\u180d\u180f-\u1fff\u200b-\u2027\u202a-\u202e\u2030-\u205e\u2060-\u2fff\u3001-\ufefe\uff00-\uffff'
                    else:
                        if isDecimalDigit(ch):
                            num = ch
                            while self.index < self.length and isDecimalDigit(
                                    self.source[self.index]):
                                num += self.source[self.index]
                                self.index += 1
                            st += '\\' + num

                        else:
                            st += ch  # DONT ESCAPE!!!
                else:
                    self.lineNumber += 1
                    if (ch == '\r' and self.source[self.index] == '\n'):
                        self.index += 1
                    self.lineStart = self.index
            else:
                if ch == '[':
                    inside_square = True
                elif ch == ']':
                    inside_square = False
                st += ch
        # print string, 'was transformed to', st
        return st

    def scanStringLiteral(self):
        st = ''
        octal = False

        quote = self.source[self.index]
        assert quote == '\'' or quote == '"', 'String literal must starts with a quote'
        start = self.index
        self.index += 1

        while (self.index < self.length):
            ch = self.source[self.index]
            self.index += 1
            if (ch == quote):
                quote = ''
                break
            elif (ch == '\\'):
                ch = self.source[self.index]
                self.index += 1
                if (not isLineTerminator(ch)):
                    if ch in 'ux':
                        if (self.source[self.index] == '{'):
                            self.index += 1
                            st += self.scanUnicodeCodePointEscape()
                        else:
                            unescaped = self.scanHexEscape(ch)
                            if (not unescaped):
                                self.throwUnexpectedToken(
                                )  # with throw I don't know whats the difference
                            st += unescaped
                    elif ch == 'n':
                        st += '\n'
                    elif ch == 'r':
                        st += '\r'
                    elif ch == 't':
                        st += '\t'
                    elif ch == 'b':
                        st += '\b'
                    elif ch == 'f':
                        st += '\f'
                    elif ch == 'v':
                        st += '\x0B'
                    # elif ch in '89':
                    #    self.throwUnexpectedToken() # again with throw....
                    else:
                        if isOctalDigit(ch):
                            octToDec = self.octalToDecimal(ch)
                            octal = octToDec.get('octal') or octal
                            st += unichr(octToDec['code'])
                        else:
                            st += ch
                else:
                    self.lineNumber += 1
                    if (ch == '\r' and self.source[self.index] == '\n'):
                        self.index += 1
                    self.lineStart = self.index
            elif isLineTerminator(ch):
                break
            else:
                st += ch
        if (quote != ''):
            self.throwUnexpectedToken()
        return {
            'type': Token.StringLiteral,
            'value': st,
            'raw': self.source[start:self.index],
            'octal': octal,
            'lineNumber': self.lineNumber,
            'lineStart': self.startLineStart,
            'start': start,
            'end': self.index
        }

    def scanTemplate(self):
        cooked = ''
        terminated = False
        tail = False
        start = self.index
        head = (self.source[self.index] == '`')
        rawOffset = 2

        self.index += 1

        while (self.index < self.length):
            ch = self.source[self.index]
            self.index += 1
            if (ch == '`'):
                rawOffset = 1
                tail = True
                terminated = True
                break
            elif (ch == '$'):
                if (self.source[self.index] == '{'):
                    self.state['curlyStack'].append('${')
                    self.index += 1
                    terminated = True
                    break
                cooked += ch
            elif (ch == '\\'):
                ch = self.source[self.index]
                self.index += 1
                if (not isLineTerminator(ch)):
                    if ch == 'n':
                        cooked += '\n'
                    elif ch == 'r':
                        cooked += '\r'
                    elif ch == 't':
                        cooked += '\t'
                    elif ch in 'ux':
                        if (self.source[self.index] == '{'):
                            self.index += 1
                            cooked += self.scanUnicodeCodePointEscape()
                        else:
                            restore = self.index
                            unescaped = self.scanHexEscape(ch)
                            if (unescaped):
                                cooked += unescaped
                            else:
                                self.index = restore
                                cooked += ch
                    elif ch == 'b':
                        cooked += '\b'
                    elif ch == 'f':
                        cooked += '\f'
                    elif ch == 'v':
                        cooked += '\v'
                    else:
                        if (ch == '0'):
                            if isDecimalDigit(self.ccode()):
                                # Illegal: \01 \02 and so on
                                self.throwError(Messages.TemplateOctalLiteral)
                            cooked += '\0'
                        elif (isOctalDigit(ch)):
                            # Illegal: \1 \2
                            self.throwError(Messages.TemplateOctalLiteral)
                        else:
                            cooked += ch
                else:
                    self.lineNumber += 1
                    if (ch == '\r' and self.source[self.index] == '\n'):
                        self.index += 1
                    self.lineStart = self.index
            elif (isLineTerminator(ch)):
                self.lineNumber += 1
                if (ch == '\r' and self.source[self.index] == '\n'):
                    self.index += 1
                self.lineStart = self.index
                cooked += '\n'
            else:
                cooked += ch
        if (not terminated):
            self.throwUnexpectedToken()

        if (not head):
            self.state['curlyStack'].pop()

        return {
            'type': Token.Template,
            'value': {
                'cooked': cooked,
                'raw': self.source[start + 1:self.index - rawOffset]
            },
            'head': head,
            'tail': tail,
            'lineNumber': self.lineNumber,
            'lineStart': self.lineStart,
            'start': start,
            'end': self.index
        }

    def testRegExp(self, pattern, flags):
        # todo: you should return python regexp object
        return (pattern, flags)

    def scanRegExpBody(self):
        ch = self.source[self.index]
        assert ch == '/', 'Regular expression literal must start with a slash'
        st = ch
        self.index += 1

        classMarker = False
        terminated = False
        while (self.index < self.length):
            ch = self.source[self.index]
            self.index += 1
            st += ch
            if (ch == '\\'):
                ch = self.source[self.index]
                self.index += 1
                # ECMA-262 7.8.5
                if (isLineTerminator(ch)):
                    self.throwUnexpectedToken(None,
                                              Messages.UnterminatedRegExp)
                st += ch
            elif (isLineTerminator(ch)):
                self.throwUnexpectedToken(None, Messages.UnterminatedRegExp)
            elif (classMarker):
                if (ch == ']'):
                    classMarker = False
            else:
                if (ch == '/'):
                    terminated = True
                    break
                elif (ch == '['):
                    classMarker = True
        if (not terminated):
            self.throwUnexpectedToken(None, Messages.UnterminatedRegExp)

        # Exclude leading and trailing slash.
        body = st[1:-1]
        return {'value': body, 'literal': st}

    def scanRegExpFlags(self):
        st = ''
        flags = ''
        while (self.index < self.length):
            ch = self.source[self.index]
            if (not isIdentifierPart(ch)):
                break
            self.index += 1
            if (ch == '\\' and self.index < self.length):
                ch = self.source[self.index]
                if (ch == 'u'):
                    self.index += 1
                    restore = self.index
                    ch = self.scanHexEscape('u')
                    if (ch):
                        flags += ch
                        st += '\\u'
                        while restore < self.index:
                            st += self.source[restore]
                            restore += 1
                    else:
                        self.index = restore
                        flags += 'u'
                        st += '\\u'
                    self.tolerateUnexpectedToken()
                else:
                    st += '\\'
                    self.tolerateUnexpectedToken()
            else:
                flags += ch
                st += ch
        return {'value': flags, 'literal': st}

    def scanRegExp(self):
        self.scanning = True
        self.lookahead = None
        self.skipComment()
        start = self.index

        body = self.scanRegExpBody()
        flags = self.scanRegExpFlags()
        value = self.testRegExp(body['value'], flags['value'])
        scanning = False
        return {
            'literal': body['literal'] + flags['literal'],
            'value': value,
            'raw': self.source[start:self.index],
            'regex': {
                'pattern': body['value'],
                'flags': flags['value']
            },
            'start': start,
            'end': self.index
        }

    def collectRegex(self):
        self.skipComment()
        return self.scanRegExp()

    def isIdentifierName(self, token):
        return token['type'] in (1, 3, 4, 5)

    # def advanceSlash(self): ???

    def advance(self):
        if (self.index >= self.length):
            return {
                'type': Token.EOF,
                'lineNumber': self.lineNumber,
                'lineStart': self.lineStart,
                'start': self.index,
                'end': self.index
            }
        ch = self.ccode()

        if isIdentifierStart(ch):
            token = self.scanIdentifier()
            if (self.strict and isStrictModeReservedWord(token['value'])):
                token['type'] = Token.Keyword
            return token
        # Very common: ( and ) and ;
        if (ch == 0x28 or ch == 0x29 or ch == 0x3B):
            return self.scanPunctuator()

        # String literal starts with single quote (U+0027) or double quote (U+0022).
        if (ch == 0x27 or ch == 0x22):
            return self.scanStringLiteral()

        # Dot (.) U+002E can also start a floating-point number, hence the need
        # to check the next character.
        if (ch == 0x2E):
            if (isDecimalDigit(self.ccode(1))):
                return self.scanNumericLiteral()
            return self.scanPunctuator()

        if (isDecimalDigit(ch)):
            return self.scanNumericLiteral()

        # Slash (/) U+002F can also start a regex.
        # if (extra.tokenize && ch == 0x2F):
        #    return advanceSlash();

        # Template literals start with ` (U+0060) for template head
        # or } (U+007D) for template middle or template tail.
        if (ch == 0x60
                or (ch == 0x7D
                    and self.state['curlyStack'][len(self.state['curlyStack'])
                                                 - 1] == '${')):
            return self.scanTemplate()
        return self.scanPunctuator()

    # def collectToken(self):
    #    loc = {
    #        'start': {
    #            'line': self.lineNumber,
    #            'column': self.index - self.lineStart}}
    #
    #    token = self.advance()
    #
    #    loc['end'] = {
    #        'line': self.lineNumber,
    #        'column': self.index - self.lineStart}
    #    if (token['type'] != Token.EOF):
    #        value = self.source[token['start']: token['end']]
    #        entry = {
    #            'type': TokenName[token['type']],
    #            'value': value,
    #            'range': [token['start'], token['end']],
    #            'loc': loc}
    #        if (token.get('regex')):
    #            entry['regex'] = {
    #                'pattern': token['regex']['pattern'],
    #                'flags': token['regex']['flags']}
    #        self.extra['tokens'].append(entry)
    #    return token;

    def lex(self):
        self.scanning = True

        self.lastIndex = self.index
        self.lastLineNumber = self.lineNumber
        self.lastLineStart = self.lineStart

        self.skipComment()

        token = self.lookahead

        self.startIndex = self.index
        self.startLineNumber = self.lineNumber
        self.startLineStart = self.lineStart

        self.lookahead = self.advance()
        self.scanning = False
        return token

    def peek(self):
        self.scanning = True

        self.skipComment()

        self.lastIndex = self.index
        self.lastLineNumber = self.lineNumber
        self.lastLineStart = self.lineStart

        self.startIndex = self.index
        self.startLineNumber = self.lineNumber
        self.startLineStart = self.lineStart

        self.lookahead = self.advance()
        self.scanning = False

    def createError(self, line, pos, description):
        global ENABLE_PYIMPORT
        msg = 'Line ' + unicode(line) + ': ' + unicode(description)
        if ENABLE_JS2PY_ERRORS:
            return ENABLE_JS2PY_ERRORS(msg)
        else:
            return JsSyntaxError(msg)

    # Throw an exception

    def throwError(self, messageFormat, *args):
        msg = messageFormat % tuple(unicode(e) for e in args)
        raise self.createError(self.lastLineNumber, self.lastIndex, msg)

    def tolerateError(self, messageFormat, *args):
        return self.throwError(messageFormat, *args)

    # Throw an exception because of the token.

    def unexpectedTokenError(self, token={}, message=''):
        msg = message or Messages.UnexpectedToken
        if (token):
            typ = token['type']
            if (not message):
                if typ == Token.EOF:
                    msg = Messages.UnexpectedEOS
                elif (typ == Token.Identifier):
                    msg = Messages.UnexpectedIdentifier
                elif (typ == Token.NumericLiteral):
                    msg = Messages.UnexpectedNumber
                elif (typ == Token.StringLiteral):
                    msg = Messages.UnexpectedString
                elif (typ == Token.Template):
                    msg = Messages.UnexpectedTemplate
                else:
                    msg = Messages.UnexpectedToken
                if (typ == Token.Keyword):
                    if (isFutureReservedWord(token['value'])):
                        msg = Messages.UnexpectedReserved
                    elif (self.strict
                          and isStrictModeReservedWord(token['value'])):
                        msg = Messages.StrictReservedWord
            value = token['value']['raw'] if (
                typ == Token.Template) else token.get('value')
        else:
            value = 'ILLEGAL'
        msg = msg.replace('%s', unicode(value))

        return (self.createError(token['lineNumber'], token['start'], msg) if
                (token and token.get('lineNumber')) else self.createError(
                    self.lineNumber if self.scanning else self.lastLineNumber,
                    self.index if self.scanning else self.lastIndex, msg))

    def throwUnexpectedToken(self, token={}, message=''):
        raise self.unexpectedTokenError(token, message)

    def tolerateUnexpectedToken(self, token={}, message=''):
        self.throwUnexpectedToken(token, message)

    # Expect the next token to match the specified punctuator.
    # If not, an exception will be thrown.

    def expect(self, value):
        token = self.lex()
        if (token['type'] != Token.Punctuator or token['value'] != value):
            self.throwUnexpectedToken(token)

    # /**
    # * @name expectCommaSeparator
    # * @description Quietly expect a comma when in tolerant mode, otherwise delegates
    # * to <code>expect(value)</code>
    # * @since 2.0
    # */
    def expectCommaSeparator(self):
        self.expect(',')

    # Expect the next token to match the specified keyword.
    # If not, an exception will be thrown.

    def expectKeyword(self, keyword):
        token = self.lex()
        if (token['type'] != Token.Keyword or token['value'] != keyword):
            self.throwUnexpectedToken(token)

    # Return true if the next token matches the specified punctuator.

    def match(self, value):
        return self.lookahead['type'] == Token.Punctuator and self.lookahead[
            'value'] == value

    # Return true if the next token matches the specified keyword

    def matchKeyword(self, keyword):
        return self.lookahead['type'] == Token.Keyword and self.lookahead[
            'value'] == keyword

    # Return true if the next token matches the specified contextual keyword
    # (where an identifier is sometimes a keyword depending on the context)

    def matchContextualKeyword(self, keyword):
        return self.lookahead['type'] == Token.Identifier and self.lookahead[
            'value'] == keyword

    # Return true if the next token is an assignment operator

    def matchAssign(self):
        if (self.lookahead['type'] != Token.Punctuator):
            return False
        op = self.lookahead['value']
        return op in ('=', '*=', '/=', '%=', '+=', '-=', '<<=', '>>=', '>>>=',
                      '&=', '^=', '|=')

    def consumeSemicolon(self):
        # Catch the very common case first: immediately a semicolon (U+003B).

        if (self.at(self.startIndex) == ';' or self.match(';')):
            self.lex()
            return

        if (self.hasLineTerminator):
            return

        # TODO: FIXME(ikarienator): this is seemingly an issue in the previous location info convention.
        self.lastIndex = self.startIndex
        self.lastLineNumber = self.startLineNumber
        self.lastLineStart = self.startLineStart

        if (self.lookahead['type'] != Token.EOF and not self.match('}')):
            self.throwUnexpectedToken(self.lookahead)

    # // Cover grammar support.
    # //
    # // When an assignment expression position starts with an left parenthesis, the determination of the type
    # // of the syntax is to be deferred arbitrarily long until the end of the parentheses pair (plus a lookahead)
    # // or the first comma. This situation also defers the determination of all the expressions nested in the pair.
    # //
    # // There are three productions that can be parsed in a parentheses pair that needs to be determined
    # // after the outermost pair is closed. They are:
    # //
    # //   1. AssignmentExpression
    # //   2. BindingElements
    # //   3. AssignmentTargets
    # //
    # // In order to avoid exponential backtracking, we use two flags to denote if the production can be
    # // binding element or assignment target.
    # //
    # // The three productions have the relationship:
    # //
    # //   BindingElements <= AssignmentTargets <= AssignmentExpression
    # //
    # // with a single exception that CoverInitializedName when used directly in an Expression, generates
    # // an early error. Therefore, we need the third state, firstCoverInitializedNameError, to track the
    # // first usage of CoverInitializedName and report it when we reached the end of the parentheses pair.
    # //
    # // isolateCoverGrammar function runs the given parser function with a new cover grammar context, and it does not
    # // effect the current flags. This means the production the parser parses is only used as an expression. Therefore
    # // the CoverInitializedName check is conducted.
    # //
    # // inheritCoverGrammar function runs the given parse function with a new cover grammar context, and it propagates
    # // the flags outside of the parser. This means the production the parser parses is used as a part of a potential
    # // pattern. The CoverInitializedName check is deferred.

    def isolateCoverGrammar(self, parser):
        oldIsBindingElement = self.isBindingElement
        oldIsAssignmentTarget = self.isAssignmentTarget
        oldFirstCoverInitializedNameError = self.firstCoverInitializedNameError
        self.isBindingElement = true
        self.isAssignmentTarget = true
        self.firstCoverInitializedNameError = null
        result = parser()
        if (self.firstCoverInitializedNameError != null):
            self.throwUnexpectedToken(self.firstCoverInitializedNameError)
        self.isBindingElement = oldIsBindingElement
        self.isAssignmentTarget = oldIsAssignmentTarget
        self.firstCoverInitializedNameError = oldFirstCoverInitializedNameError
        return result

    def inheritCoverGrammar(self, parser):
        oldIsBindingElement = self.isBindingElement
        oldIsAssignmentTarget = self.isAssignmentTarget
        oldFirstCoverInitializedNameError = self.firstCoverInitializedNameError
        self.isBindingElement = true
        self.isAssignmentTarget = true
        self.firstCoverInitializedNameError = null
        result = parser()
        self.isBindingElement = self.isBindingElement and oldIsBindingElement
        self.isAssignmentTarget = self.isAssignmentTarget and oldIsAssignmentTarget
        self.firstCoverInitializedNameError = oldFirstCoverInitializedNameError or self.firstCoverInitializedNameError
        return result

    def parseArrayPattern(self):
        raise Ecma51NotSupported('ArrayPattern')

        node = Node()
        elements = []
        self.expect('[')
        while (not self.match(']')):
            if (self.match(',')):
                self.lex()
                elements.append(null)
            else:
                if (self.match('...')):
                    restNode = Node()
                    self.lex()
                    rest = self.parseVariableIdentifier()
                    elements.append(restNode.finishRestElement(rest))
                    break
                else:
                    elements.append(self.parsePatternWithDefault())
                if (not self.match(']')):
                    self.expect(',')
        self.expect(']')
        return node.finishArrayPattern(elements)

    def parsePropertyPattern(self):
        node = Node()
        computed = self.match('[')
        if (self.lookahead['type'] == Token.Identifier):
            key = self.parseVariableIdentifier()
            if (self.match('=')):
                self.lex()
                init = self.parseAssignmentExpression()
                return node.finishProperty(
                    'init', key, false,
                    WrappingNode(key).finishAssignmentPattern(key, init),
                    false, false)
            elif (not self.match(':')):
                return node.finishProperty('init', key, false, key, false,
                                           true)
        else:
            key = self.parseObjectPropertyKey()
        self.expect(':')
        init = self.parsePatternWithDefault()
        return node.finishProperty('init', key, computed, init, false, false)

    def parseObjectPattern(self):
        raise Ecma51NotSupported('ObjectPattern')
        node = Node()
        properties = []
        self.expect('{')
        while (not self.match('}')):
            properties.append(self.parsePropertyPattern())
            if (not self.match('}')):
                self.expect(',')
        self.lex()
        return node.finishObjectPattern(properties)

    def parsePattern(self):
        if (self.lookahead['type'] == Token.Identifier):
            return self.parseVariableIdentifier()
        elif (self.match('[')):
            return self.parseArrayPattern()
        elif (self.match('{')):
            return self.parseObjectPattern()
        self.throwUnexpectedToken(self.lookahead)

    def parsePatternWithDefault(self):
        startToken = self.lookahead

        pattern = self.parsePattern()
        if (self.match('=')):
            self.lex()
            right = self.isolateCoverGrammar(self.parseAssignmentExpression)
            pattern = WrappingNode(startToken).finishAssignmentPattern(
                pattern, right)
        return pattern

    # 11.1.4 Array Initialiser

    def parseArrayInitialiser(self):
        elements = []
        node = Node()

        self.expect('[')

        while (not self.match(']')):
            if (self.match(',')):
                self.lex()
                elements.append(null)
            elif (self.match('...')):
                restSpread = Node()
                self.lex()
                restSpread.finishSpreadElement(
                    self.inheritCoverGrammar(self.parseAssignmentExpression))
                if (not self.match(']')):
                    self.isAssignmentTarget = self.isBindingElement = false
                    self.expect(',')
                elements.append(restSpread)
            else:
                elements.append(
                    self.inheritCoverGrammar(self.parseAssignmentExpression))
                if (not self.match(']')):
                    self.expect(',')
        self.lex()

        return node.finishArrayExpression(elements)

    # 11.1.5 Object Initialiser

    def parsePropertyFunction(self, node, paramInfo):

        self.isAssignmentTarget = self.isBindingElement = false

        previousStrict = self.strict
        body = self.isolateCoverGrammar(self.parseFunctionSourceElements)

        if (self.strict and paramInfo['firstRestricted']):
            self.tolerateUnexpectedToken(paramInfo['firstRestricted'],
                                         paramInfo.get('message'))
        if (self.strict and paramInfo.get('stricted')):
            self.tolerateUnexpectedToken(
                paramInfo.get('stricted'), paramInfo.get('message'))

        self.strict = previousStrict
        return node.finishFunctionExpression(null, paramInfo.get('params'),
                                             paramInfo.get('defaults'), body)

    def parsePropertyMethodFunction(self):
        node = Node()

        params = self.parseParams(null)
        method = self.parsePropertyFunction(node, params)
        return method

    def parseObjectPropertyKey(self):
        node = Node()

        token = self.lex()

        # // Note: This function is called only from parseObjectProperty(), where
        # // EOF and Punctuator tokens are already filtered out.

        typ = token['type']

        if typ in [Token.StringLiteral, Token.NumericLiteral]:
            if self.strict and token.get('octal'):
                self.tolerateUnexpectedToken(token,
                                             Messages.StrictOctalLiteral)
            return node.finishLiteral(token)
        elif typ in (Token.Identifier, Token.BooleanLiteral, Token.NullLiteral,
                     Token.Keyword):
            return node.finishIdentifier(token['value'])
        elif typ == Token.Punctuator:
            if (token['value'] == '['):
                expr = self.isolateCoverGrammar(self.parseAssignmentExpression)
                self.expect(']')
                return expr
        self.throwUnexpectedToken(token)

    def lookaheadPropertyName(self):
        typ = self.lookahead['type']
        if typ in (Token.Identifier, Token.StringLiteral, Token.BooleanLiteral,
                   Token.NullLiteral, Token.NumericLiteral, Token.Keyword):
            return true
        if typ == Token.Punctuator:
            return self.lookahead['value'] == '['
        return false

    # // This function is to try to parse a MethodDefinition as defined in 14.3. But in the case of object literals,
    # // it might be called at a position where there is in fact a short hand identifier pattern or a data property.
    # // This can only be determined after we consumed up to the left parentheses.
    # //
    # // In order to avoid back tracking, it returns `null` if the position is not a MethodDefinition and the caller
    # // is responsible to visit other options.
    def tryParseMethodDefinition(self, token, key, computed, node):
        if (token['type'] == Token.Identifier):
            # check for `get` and `set`;

            if (token['value'] == 'get' and self.lookaheadPropertyName()):
                computed = self.match('[')
                key = self.parseObjectPropertyKey()
                methodNode = Node()
                self.expect('(')
                self.expect(')')
                value = self.parsePropertyFunction(
                    methodNode, {
                        'params': [],
                        'defaults': [],
                        'stricted': null,
                        'firstRestricted': null,
                        'message': null
                    })
                return node.finishProperty('get', key, computed, value, false,
                                           false)
            elif (token['value'] == 'set' and self.lookaheadPropertyName()):
                computed = self.match('[')
                key = self.parseObjectPropertyKey()
                methodNode = Node()
                self.expect('(')

                options = {
                    'params': [],
                    'defaultCount': 0,
                    'defaults': [],
                    'firstRestricted': null,
                    'paramSet': {}
                }
                if (self.match(')')):
                    self.tolerateUnexpectedToken(self.lookahead)
                else:
                    self.parseParam(options)
                    if (options['defaultCount'] == 0):
                        options['defaults'] = []
                self.expect(')')

                value = self.parsePropertyFunction(methodNode, options)
                return node.finishProperty('set', key, computed, value, false,
                                           false)
        if (self.match('(')):
            value = self.parsePropertyMethodFunction()
            return node.finishProperty('init', key, computed, value, true,
                                       false)
        return null

    def checkProto(self, key, computed, hasProto):
        return
        if (computed == false and
            (key['type'] == Syntax.Identifier and key['name'] == '__proto__' or
             key['type'] == Syntax.Literal and key['value'] == '__proto__')):
            if (hasProto['value']):
                self.tolerateError(Messages.DuplicateProtoProperty)
            else:
                hasProto['value'] = true

    def parseObjectProperty(self, hasProto):
        token = self.lookahead
        node = Node()

        computed = self.match('[')
        key = self.parseObjectPropertyKey()
        maybeMethod = self.tryParseMethodDefinition(token, key, computed, node)

        if (maybeMethod):
            self.checkProto(maybeMethod['key'], maybeMethod['computed'],
                            hasProto)
            return maybeMethod

        # // init property or short hand property.
        self.checkProto(key, computed, hasProto)

        if (self.match(':')):
            self.lex()
            value = self.inheritCoverGrammar(self.parseAssignmentExpression)
            return node.finishProperty('init', key, computed, value, false,
                                       false)

        if (token['type'] == Token.Identifier):
            if (self.match('=')):
                self.firstCoverInitializedNameError = self.lookahead
                self.lex()
                value = self.isolateCoverGrammar(
                    self.parseAssignmentExpression)
                return node.finishProperty(
                    'init', key, computed,
                    WrappingNode(token).finishAssignmentPattern(key, value),
                    false, true)
            return node.finishProperty('init', key, computed, key, false, true)
        self.throwUnexpectedToken(self.lookahead)

    def parseObjectInitialiser(self):
        properties = []
        hasProto = {'value': false}
        node = Node()

        self.expect('{')

        while (not self.match('}')):
            properties.append(self.parseObjectProperty(hasProto))

            if (not self.match('}')):
                self.expectCommaSeparator()
        self.expect('}')
        return node.finishObjectExpression(properties)

    def reinterpretExpressionAsPattern(self, expr):
        typ = (expr['type'])
        if typ in (Syntax.Identifier, Syntax.MemberExpression,
                   Syntax.RestElement, Syntax.AssignmentPattern):
            pass
        elif typ == Syntax.SpreadElement:
            expr['type'] = Syntax.RestElement
            self.reinterpretExpressionAsPattern(expr.argument)
        elif typ == Syntax.ArrayExpression:
            expr['type'] = Syntax.ArrayPattern
            for i in xrange(len(expr['elements'])):
                if (expr['elements'][i] != null):
                    self.reinterpretExpressionAsPattern(expr['elements'][i])
        elif typ == Syntax.ObjectExpression:
            expr['type'] = Syntax.ObjectPattern
            for i in xrange(len(expr['properties'])):
                self.reinterpretExpressionAsPattern(
                    expr['properties'][i]['value'])
        elif Syntax.AssignmentExpression:
            raise Ecma51NotSupported('AssignmentPattern')
            expr['type'] = Syntax.AssignmentPattern
            self.reinterpretExpressionAsPattern(expr['left'])
        else:
            # // Allow other node type for tolerant parsing.
            return

    def parseTemplateElement(self, option):

        if (self.lookahead['type'] != Token.Template
                or (option['head'] and not self.lookahead['head'])):
            self.throwUnexpectedToken()

        node = Node()
        token = self.lex()

        return node.finishTemplateElement({
            'raw': token['value']['raw'],
            'cooked': token['value']['cooked']
        }, token['tail'])

    def parseTemplateLiteral(self):
        node = Node()

        quasi = self.parseTemplateElement({'head': true})
        quasis = [quasi]
        expressions = []

        while (not quasi['tail']):
            expressions.append(self.parseExpression())
            quasi = self.parseTemplateElement({
                'head': false
            })
            quasis.append(quasi)
        return node.finishTemplateLiteral(quasis, expressions)

    # 11.1.6 The Grouping Operator

    def parseGroupExpression(self):
        self.expect('(')

        if (self.match(')')):
            raise Ecma51NotSupported('ArrowFunction')
            self.lex()
            if (not self.match('=>')):
                self.expect('=>')
            return {
                'type': PlaceHolders.ArrowParameterPlaceHolder,
                'params': []
            }

        startToken = self.lookahead
        if (self.match('...')):
            expr = self.parseRestElement()
            self.expect(')')
            if (not self.match('=>')):
                self.expect('=>')
            return {
                'type': PlaceHolders.ArrowParameterPlaceHolder,
                'params': [expr]
            }

        self.isBindingElement = true
        expr = self.inheritCoverGrammar(self.parseAssignmentExpression)

        if (self.match(',')):
            self.isAssignmentTarget = false
            expressions = [expr]

            while (self.startIndex < self.length):
                if (not self.match(',')):
                    break
                self.lex()

                if (self.match('...')):
                    raise Ecma51NotSupported('ArrowFunction')
                    if (not self.isBindingElement):
                        self.throwUnexpectedToken(self.lookahead)
                    expressions.append(self.parseRestElement())
                    self.expect(')')
                    if (not self.match('=>')):
                        self.expect('=>')
                    self.isBindingElement = false
                    for i in xrange(len(expressions)):
                        self.reinterpretExpressionAsPattern(expressions[i])
                    return {
                        'type': PlaceHolders.ArrowParameterPlaceHolder,
                        'params': expressions
                    }
                expressions.append(
                    self.inheritCoverGrammar(self.parseAssignmentExpression))
            expr = WrappingNode(startToken).finishSequenceExpression(
                expressions)
        self.expect(')')

        if (self.match('=>')):
            raise Ecma51NotSupported('ArrowFunction')
            if (not self.isBindingElement):
                self.throwUnexpectedToken(self.lookahead)
            if (expr['type'] == Syntax.SequenceExpression):
                for i in xrange(len(expr.expressions)):
                    self.reinterpretExpressionAsPattern(expr['expressions'][i])
            else:
                self.reinterpretExpressionAsPattern(expr)
            expr = {
                'type':
                PlaceHolders.ArrowParameterPlaceHolder,
                'params':
                expr['expressions']
                if expr['type'] == Syntax.SequenceExpression else [expr]
            }
        self.isBindingElement = false
        return expr

    # 11.1 Primary Expressions

    def parsePrimaryExpression(self):
        if (self.match('(')):
            self.isBindingElement = false
            return self.inheritCoverGrammar(self.parseGroupExpression)
        if (self.match('[')):
            return self.inheritCoverGrammar(self.parseArrayInitialiser)

        if (self.match('{')):
            return self.inheritCoverGrammar(self.parseObjectInitialiser)

        typ = self.lookahead['type']
        node = Node()

        if (typ == Token.Identifier):
            expr = node.finishIdentifier(self.lex()['value'])
        elif (typ == Token.StringLiteral or typ == Token.NumericLiteral):
            self.isAssignmentTarget = self.isBindingElement = false
            if (self.strict and self.lookahead.get('octal')):
                self.tolerateUnexpectedToken(self.lookahead,
                                             Messages.StrictOctalLiteral)
            expr = node.finishLiteral(self.lex())
        elif (typ == Token.Keyword):
            self.isAssignmentTarget = self.isBindingElement = false
            if (self.matchKeyword('function')):
                return self.parseFunctionExpression()
            if (self.matchKeyword('this')):
                self.lex()
                return node.finishThisExpression()
            if (self.matchKeyword('class')):
                return self.parseClassExpression()
            self.throwUnexpectedToken(self.lex())
        elif (typ == Token.BooleanLiteral):
            isAssignmentTarget = self.isBindingElement = false
            token = self.lex()
            token['value'] = (token['value'] == 'true')
            expr = node.finishLiteral(token)
        elif (typ == Token.NullLiteral):
            self.isAssignmentTarget = self.isBindingElement = false
            token = self.lex()
            token['value'] = null
            expr = node.finishLiteral(token)
        elif (self.match('/') or self.match('/=')):
            self.isAssignmentTarget = self.isBindingElement = false
            self.index = self.startIndex
            token = self.scanRegExp()
            # hehe, here you are!
            self.lex()
            expr = node.finishLiteral(token)
        elif (typ == Token.Template):
            expr = self.parseTemplateLiteral()
        else:
            self.throwUnexpectedToken(self.lex())
        return expr

    # 11.2 Left-Hand-Side Expressions

    def parseArguments(self):
        args = []

        self.expect('(')
        if (not self.match(')')):
            while (self.startIndex < self.length):
                args.append(
                    self.isolateCoverGrammar(self.parseAssignmentExpression))
                if (self.match(')')):
                    break
                self.expectCommaSeparator()
        self.expect(')')
        return args

    def parseNonComputedProperty(self):
        node = Node()

        token = self.lex()

        if (not self.isIdentifierName(token)):
            self.throwUnexpectedToken(token)
        return node.finishIdentifier(token['value'])

    def parseNonComputedMember(self):
        self.expect('.')
        return self.parseNonComputedProperty()

    def parseComputedMember(self):
        self.expect('[')

        expr = self.isolateCoverGrammar(self.parseExpression)
        self.expect(']')

        return expr

    def parseNewExpression(self):
        node = Node()
        self.expectKeyword('new')
        callee = self.isolateCoverGrammar(self.parseLeftHandSideExpression)
        args = self.parseArguments() if self.match('(') else []

        self.isAssignmentTarget = self.isBindingElement = false

        return node.finishNewExpression(callee, args)

    def parseLeftHandSideExpressionAllowCall(self):
        previousAllowIn = self.state['allowIn']

        startToken = self.lookahead
        self.state['allowIn'] = true

        if (self.matchKeyword('super') and self.state['inFunctionBody']):
            expr = Node()
            self.lex()
            expr = expr.finishSuper()
            if (not self.match('(') and not self.match('.')
                    and not self.match('[')):
                self.throwUnexpectedToken(self.lookahead)
        else:
            expr = self.inheritCoverGrammar(
                self.parseNewExpression if self.matchKeyword('new') else self.
                parsePrimaryExpression)
        while True:
            if (self.match('.')):
                self.isBindingElement = false
                self.isAssignmentTarget = true
                property = self.parseNonComputedMember()
                expr = WrappingNode(startToken).finishMemberExpression(
                    '.', expr, property)
            elif (self.match('(')):
                self.isBindingElement = false
                self.isAssignmentTarget = false
                args = self.parseArguments()
                expr = WrappingNode(startToken).finishCallExpression(
                    expr, args)
            elif (self.match('[')):
                self.isBindingElement = false
                self.isAssignmentTarget = true
                property = self.parseComputedMember()
                expr = WrappingNode(startToken).finishMemberExpression(
                    '[', expr, property)
            elif (self.lookahead['type'] == Token.Template
                  and self.lookahead['head']):
                quasi = self.parseTemplateLiteral()
                expr = WrappingNode(startToken).finishTaggedTemplateExpression(
                    expr, quasi)
            else:
                break
        self.state['allowIn'] = previousAllowIn

        return expr

    def parseLeftHandSideExpression(self):
        assert self.state[
            'allowIn'], 'callee of new expression always allow in keyword.'

        startToken = self.lookahead

        if (self.matchKeyword('super') and self.state['inFunctionBody']):
            expr = Node()
            self.lex()
            expr = expr.finishSuper()
            if (not self.match('[') and not self.match('.')):
                self.throwUnexpectedToken(self.lookahead)
        else:
            expr = self.inheritCoverGrammar(
                self.parseNewExpression if self.matchKeyword('new') else self.
                parsePrimaryExpression)

        while True:
            if (self.match('[')):
                self.isBindingElement = false
                self.isAssignmentTarget = true
                property = self.parseComputedMember()
                expr = WrappingNode(startToken).finishMemberExpression(
                    '[', expr, property)
            elif (self.match('.')):
                self.isBindingElement = false
                self.isAssignmentTarget = true
                property = self.parseNonComputedMember()
                expr = WrappingNode(startToken).finishMemberExpression(
                    '.', expr, property)
            elif (self.lookahead['type'] == Token.Template
                  and self.lookahead['head']):
                quasi = self.parseTemplateLiteral()
                expr = WrappingNode(startToken).finishTaggedTemplateExpression(
                    expr, quasi)
            else:
                break
        return expr

    # 11.3 Postfix Expressions

    def parsePostfixExpression(self):
        startToken = self.lookahead

        expr = self.inheritCoverGrammar(
            self.parseLeftHandSideExpressionAllowCall)

        if (not self.hasLineTerminator
                and self.lookahead['type'] == Token.Punctuator):
            if (self.match('++') or self.match('--')):
                # 11.3.1, 11.3.2
                if (self.strict and expr.type == Syntax.Identifier
                        and isRestrictedWord(expr.name)):
                    self.tolerateError(Messages.StrictLHSPostfix)
                if (not self.isAssignmentTarget):
                    self.tolerateError(Messages.InvalidLHSInAssignment)
                self.isAssignmentTarget = self.isBindingElement = false

                token = self.lex()
                expr = WrappingNode(startToken).finishPostfixExpression(
                    token['value'], expr)
        return expr

    # 11.4 Unary Operators

    def parseUnaryExpression(self):

        if (self.lookahead['type'] != Token.Punctuator
                and self.lookahead['type'] != Token.Keyword):
            expr = self.parsePostfixExpression()
        elif (self.match('++') or self.match('--')):
            startToken = self.lookahead
            token = self.lex()
            expr = self.inheritCoverGrammar(self.parseUnaryExpression)
            # 11.4.4, 11.4.5
            if (self.strict and expr.type == Syntax.Identifier
                    and isRestrictedWord(expr.name)):
                self.tolerateError(Messages.StrictLHSPrefix)
            if (not self.isAssignmentTarget):
                self.tolerateError(Messages.InvalidLHSInAssignment)
            expr = WrappingNode(startToken).finishUnaryExpression(
                token['value'], expr)
            self.isAssignmentTarget = self.isBindingElement = false
        elif (self.match('+') or self.match('-') or self.match('~')
              or self.match('!')):
            startToken = self.lookahead
            token = self.lex()
            expr = self.inheritCoverGrammar(self.parseUnaryExpression)
            expr = WrappingNode(startToken).finishUnaryExpression(
                token['value'], expr)
            self.isAssignmentTarget = self.isBindingElement = false
        elif (self.matchKeyword('delete') or self.matchKeyword('void')
              or self.matchKeyword('typeof')):
            startToken = self.lookahead
            token = self.lex()
            expr = self.inheritCoverGrammar(self.parseUnaryExpression)
            expr = WrappingNode(startToken).finishUnaryExpression(
                token['value'], expr)
            if (self.strict and expr.operator == 'delete'
                    and expr.argument.type == Syntax.Identifier):
                self.tolerateError(Messages.StrictDelete)
            self.isAssignmentTarget = self.isBindingElement = false
        else:
            expr = self.parsePostfixExpression()
        return expr

    def binaryPrecedence(self, token, allowIn):
        prec = 0
        typ = token['type']
        if (typ != Token.Punctuator and typ != Token.Keyword):
            return 0
        val = token['value']
        if val == 'in' and not allowIn:
            return 0
        return PRECEDENCE.get(val, 0)

    # 11.5 Multiplicative Operators
    # 11.6 Additive Operators
    # 11.7 Bitwise Shift Operators
    # 11.8 Relational Operators
    # 11.9 Equality Operators
    # 11.10 Binary Bitwise Operators
    # 11.11 Binary Logical Operators

    def parseBinaryExpression(self):

        marker = self.lookahead
        left = self.inheritCoverGrammar(self.parseUnaryExpression)

        token = self.lookahead
        prec = self.binaryPrecedence(token, self.state['allowIn'])
        if (prec == 0):
            return left
        self.isAssignmentTarget = self.isBindingElement = false
        token['prec'] = prec
        self.lex()

        markers = [marker, self.lookahead]
        right = self.isolateCoverGrammar(self.parseUnaryExpression)

        stack = [left, token, right]

        while True:
            prec = self.binaryPrecedence(self.lookahead, self.state['allowIn'])
            if not prec > 0:
                break
            # Reduce: make a binary expression from the three topmost entries.
            while ((len(stack) > 2)
                   and (prec <= stack[len(stack) - 2]['prec'])):
                right = stack.pop()
                operator = stack.pop()['value']
                left = stack.pop()
                markers.pop()
                expr = WrappingNode(
                    markers[len(markers) - 1]).finishBinaryExpression(
                        operator, left, right)
                stack.append(expr)

            # Shift
            token = self.lex()
            token['prec'] = prec
            stack.append(token)
            markers.append(self.lookahead)
            expr = self.isolateCoverGrammar(self.parseUnaryExpression)
            stack.append(expr)

        # Final reduce to clean-up the stack.
        i = len(stack) - 1
        expr = stack[i]
        markers.pop()
        while (i > 1):
            expr = WrappingNode(markers.pop()).finishBinaryExpression(
                stack[i - 1]['value'], stack[i - 2], expr)
            i -= 2
        return expr

    # 11.12 Conditional Operator

    def parseConditionalExpression(self):

        startToken = self.lookahead

        expr = self.inheritCoverGrammar(self.parseBinaryExpression)
        if (self.match('?')):
            self.lex()
            previousAllowIn = self.state['allowIn']
            self.state['allowIn'] = true
            consequent = self.isolateCoverGrammar(
                self.parseAssignmentExpression)
            self.state['allowIn'] = previousAllowIn
            self.expect(':')
            alternate = self.isolateCoverGrammar(
                self.parseAssignmentExpression)

            expr = WrappingNode(startToken).finishConditionalExpression(
                expr, consequent, alternate)
            self.isAssignmentTarget = self.isBindingElement = false
        return expr

    # [ES6] 14.2 Arrow Function

    def parseConciseBody(self):
        if (self.match('{')):
            return self.parseFunctionSourceElements()
        return self.isolateCoverGrammar(self.parseAssignmentExpression)

    def checkPatternParam(self, options, param):
        typ = param.type
        if typ == Syntax.Identifier:
            self.validateParam(options, param, param.name)
        elif typ == Syntax.RestElement:
            self.checkPatternParam(options, param.argument)
        elif typ == Syntax.AssignmentPattern:
            self.checkPatternParam(options, param.left)
        elif typ == Syntax.ArrayPattern:
            for i in xrange(len(param.elements)):
                if (param.elements[i] != null):
                    self.checkPatternParam(options, param.elements[i])
        else:
            assert typ == Syntax.ObjectPattern, 'Invalid type'
            for i in xrange(len(param.properties)):
                self.checkPatternParam(options, param.properties[i]['value'])

    def reinterpretAsCoverFormalsList(self, expr):
        defaults = []
        defaultCount = 0
        params = [expr]
        typ = expr.type
        if typ == Syntax.Identifier:
            pass
        elif typ == PlaceHolders.ArrowParameterPlaceHolder:
            params = expr.params
        else:
            return null
        options = {'paramSet': {}}
        le = len(params)
        for i in xrange(le):
            param = params[i]
            if param.type == Syntax.AssignmentPattern:
                params[i] = param.left
                defaults.append(param.right)
                defaultCount += 1
                self.checkPatternParam(options, param.left)
            else:
                self.checkPatternParam(options, param)
                params[i] = param
                defaults.append(null)
        if (options.get('message') == Messages.StrictParamDupe):
            token = options.get(
                'stricted') if self.strict else options['firstRestricted']
            self.throwUnexpectedToken(token, options.get('message'))
        if (defaultCount == 0):
            defaults = []
        return {
            'params': params,
            'defaults': defaults,
            'stricted': options['stricted'],
            'firstRestricted': options['firstRestricted'],
            'message': options.get('message')
        }

    def parseArrowFunctionExpression(self, options, node):
        raise Ecma51NotSupported('ArrowFunctionExpression')
        if (self.hasLineTerminator):
            self.tolerateUnexpectedToken(self.lookahead)
        self.expect('=>')
        previousStrict = self.strict

        body = self.parseConciseBody()

        if (self.strict and options['firstRestricted']):
            self.throwUnexpectedToken(options['firstRestricted'],
                                      options.get('message'))
        if (self.strict and options['stricted']):
            self.tolerateUnexpectedToken(options['stricted'],
                                         options['message'])

        self.strict = previousStrict

        return node.finishArrowFunctionExpression(
            options['params'], options['defaults'], body,
            body.type != Syntax.BlockStatement)

    # 11.13 Assignment Operators

    def parseAssignmentExpression(self):
        startToken = self.lookahead
        token = self.lookahead

        expr = self.parseConditionalExpression()

        if (expr.type == PlaceHolders.ArrowParameterPlaceHolder
                or self.match('=>')):
            raise Ecma51NotSupported('ArrowFunctionExpression')
            self.isAssignmentTarget = self.isBindingElement = false
            lis = self.reinterpretAsCoverFormalsList(expr)

            if (lis):
                self.firstCoverInitializedNameError = null
                return self.parseArrowFunctionExpression(
                    lis, WrappingNode(startToken))
            return expr

        if (self.matchAssign()):
            if (not self.isAssignmentTarget):
                self.tolerateError(Messages.InvalidLHSInAssignment)
            # 11.13.1

            if (self.strict and expr.type == Syntax.Identifier
                    and isRestrictedWord(expr.name)):
                self.tolerateUnexpectedToken(token,
                                             Messages.StrictLHSAssignment)
            if (not self.match('=')):
                self.isAssignmentTarget = self.isBindingElement = false
            else:
                self.reinterpretExpressionAsPattern(expr)
            token = self.lex()
            right = self.isolateCoverGrammar(self.parseAssignmentExpression)
            expr = WrappingNode(startToken).finishAssignmentExpression(
                token['value'], expr, right)
            self.firstCoverInitializedNameError = null
        return expr

    # 11.14 Comma Operator

    def parseExpression(self):
        startToken = self.lookahead
        expr = self.isolateCoverGrammar(self.parseAssignmentExpression)

        if (self.match(',')):
            expressions = [expr]

            while (self.startIndex < self.length):
                if (not self.match(',')):
                    break
                self.lex()
                expressions.append(
                    self.isolateCoverGrammar(self.parseAssignmentExpression))
            expr = WrappingNode(startToken).finishSequenceExpression(
                expressions)
        return expr

    # 12.1 Block

    def parseStatementListItem(self):
        if (self.lookahead['type'] == Token.Keyword):
            val = (self.lookahead['value'])
            if val == 'export':
                raise Ecma51NotSupported('ExportDeclaration')
            elif val == 'import':
                raise Ecma51NotSupported('ImportDeclaration')
            elif val == 'const' or val == 'let':
                return self.parseLexicalDeclaration({
                    'inFor': false
                })
            elif val == 'function':
                return self.parseFunctionDeclaration(Node())
            elif val == 'class':
                raise Ecma51NotSupported('ClassDeclaration')
            elif ENABLE_PYIMPORT and val == 'pyimport':  # <<<<< MODIFIED HERE
                return self.parsePyimportStatement()
        return self.parseStatement()

    def parsePyimportStatement(self):
        if not ENABLE_PYIMPORT:
            raise Ecma51NotSupported('PyimportStatement')
        n = Node()
        self.lex()
        n.finishPyimport(self.parseVariableIdentifier())
        self.consumeSemicolon()
        return n

    def parseStatementList(self):
        list = []
        while (self.startIndex < self.length):
            if (self.match('}')):
                break
            list.append(self.parseStatementListItem())
        return list

    def parseBlock(self):
        node = Node()

        self.expect('{')

        block = self.parseStatementList()

        self.expect('}')

        return node.finishBlockStatement(block)

    # 12.2 Variable Statement

    def parseVariableIdentifier(self):
        node = Node()

        token = self.lex()

        if (token['type'] != Token.Identifier):
            if (self.strict and token['type'] == Token.Keyword
                    and isStrictModeReservedWord(token['value'])):
                self.tolerateUnexpectedToken(token,
                                             Messages.StrictReservedWord)
            else:
                self.throwUnexpectedToken(token)
        return node.finishIdentifier(token['value'])

    def parseVariableDeclaration(self):
        init = null
        node = Node()

        d = self.parsePattern()

        # 12.2.1
        if (self.strict and isRestrictedWord(d.name)):
            self.tolerateError(Messages.StrictVarName)

        if (self.match('=')):
            self.lex()
            init = self.isolateCoverGrammar(self.parseAssignmentExpression)
        elif (d.type != Syntax.Identifier):
            self.expect('=')
        return node.finishVariableDeclarator(d, init)

    def parseVariableDeclarationList(self):
        lis = []

        while True:
            lis.append(self.parseVariableDeclaration())
            if (not self.match(',')):
                break
            self.lex()
            if not (self.startIndex < self.length):
                break

        return lis

    def parseVariableStatement(self, node):
        self.expectKeyword('var')

        declarations = self.parseVariableDeclarationList()

        self.consumeSemicolon()

        return node.finishVariableDeclaration(declarations)

    def parseLexicalBinding(self, kind, options):
        init = null
        node = Node()

        d = self.parsePattern()

        # 12.2.1
        if (self.strict and d.type == Syntax.Identifier
                and isRestrictedWord(d.name)):
            self.tolerateError(Messages.StrictVarName)

        if (kind == 'const'):
            if (not self.matchKeyword('in')):
                self.expect('=')
                init = self.isolateCoverGrammar(self.parseAssignmentExpression)
        elif ((not options['inFor'] and d.type != Syntax.Identifier)
              or self.match('=')):
            self.expect('=')
            init = self.isolateCoverGrammar(self.parseAssignmentExpression)
        return node.finishVariableDeclarator(d, init)

    def parseBindingList(self, kind, options):
        list = []

        while True:
            list.append(self.parseLexicalBinding(kind, options))
            if (not self.match(',')):
                break
            self.lex()
            if not (self.startIndex < self.length):
                break
        return list

    def parseLexicalDeclaration(self, options):
        node = Node()

        kind = self.lex()['value']
        assert kind == 'let' or kind == 'const', 'Lexical declaration must be either let or const'
        declarations = self.parseBindingList(kind, options)
        self.consumeSemicolon()
        return node.finishLexicalDeclaration(declarations, kind)

    def parseRestElement(self):
        raise Ecma51NotSupported('RestElement')
        node = Node()

        self.lex()

        if (self.match('{')):
            self.throwError(Messages.ObjectPatternAsRestParameter)
        param = self.parseVariableIdentifier()
        if (self.match('=')):
            self.throwError(Messages.DefaultRestParameter)

        if (not self.match(')')):
            self.throwError(Messages.ParameterAfterRestParameter)
        return node.finishRestElement(param)

    # 12.3 Empty Statement

    def parseEmptyStatement(self, node):
        self.expect(';')
        return node.finishEmptyStatement()

    # 12.4 Expression Statement

    def parseExpressionStatement(self, node):
        expr = self.parseExpression()
        self.consumeSemicolon()
        return node.finishExpressionStatement(expr)

    # 12.5 If statement

    def parseIfStatement(self, node):
        self.expectKeyword('if')

        self.expect('(')

        test = self.parseExpression()

        self.expect(')')

        consequent = self.parseStatement()

        if (self.matchKeyword('else')):
            self.lex()
            alternate = self.parseStatement()
        else:
            alternate = null
        return node.finishIfStatement(test, consequent, alternate)

    # 12.6 Iteration Statements

    def parseDoWhileStatement(self, node):

        self.expectKeyword('do')

        oldInIteration = self.state['inIteration']
        self.state['inIteration'] = true

        body = self.parseStatement()

        self.state['inIteration'] = oldInIteration

        self.expectKeyword('while')

        self.expect('(')

        test = self.parseExpression()

        self.expect(')')

        if (self.match(';')):
            self.lex()
        return node.finishDoWhileStatement(body, test)

    def parseWhileStatement(self, node):

        self.expectKeyword('while')

        self.expect('(')

        test = self.parseExpression()

        self.expect(')')

        oldInIteration = self.state['inIteration']
        self.state['inIteration'] = true

        body = self.parseStatement()

        self.state['inIteration'] = oldInIteration

        return node.finishWhileStatement(test, body)

    def parseForStatement(self, node):
        previousAllowIn = self.state['allowIn']

        init = test = update = null

        self.expectKeyword('for')

        self.expect('(')

        if (self.match(';')):
            self.lex()
        else:
            if (self.matchKeyword('var')):
                init = Node()
                self.lex()

                self.state['allowIn'] = false
                init = init.finishVariableDeclaration(
                    self.parseVariableDeclarationList())
                self.state['allowIn'] = previousAllowIn

                if (len(init.declarations) == 1 and self.matchKeyword('in')):
                    self.lex()
                    left = init
                    right = self.parseExpression()
                    init = null
                else:
                    self.expect(';')
            elif (self.matchKeyword('const') or self.matchKeyword('let')):
                init = Node()
                kind = self.lex()['value']

                self.state['allowIn'] = false
                declarations = self.parseBindingList(kind, {'inFor': true})
                self.state['allowIn'] = previousAllowIn

                if (len(declarations) == 1 and declarations[0].init == null
                        and self.matchKeyword('in')):
                    init = init.finishLexicalDeclaration(declarations, kind)
                    self.lex()
                    left = init
                    right = self.parseExpression()
                    init = null
                else:
                    self.consumeSemicolon()
                    init = init.finishLexicalDeclaration(declarations, kind)
            else:
                initStartToken = self.lookahead
                self.state['allowIn'] = false
                init = self.inheritCoverGrammar(self.parseAssignmentExpression)
                self.state['allowIn'] = previousAllowIn

                if (self.matchKeyword('in')):
                    if (not self.isAssignmentTarget):
                        self.tolerateError(Messages.InvalidLHSInForIn)
                    self.lex()
                    self.reinterpretExpressionAsPattern(init)
                    left = init
                    right = self.parseExpression()
                    init = null
                else:
                    if (self.match(',')):
                        initSeq = [init]
                        while (self.match(',')):
                            self.lex()
                            initSeq.append(
                                self.isolateCoverGrammar(
                                    self.parseAssignmentExpression))
                        init = WrappingNode(
                            initStartToken).finishSequenceExpression(initSeq)
                    self.expect(';')

        if ('left' not in locals()):
            if (not self.match(';')):
                test = self.parseExpression()

            self.expect(';')

            if (not self.match(')')):
                update = self.parseExpression()

        self.expect(')')

        oldInIteration = self.state['inIteration']
        self.state['inIteration'] = true

        body = self.isolateCoverGrammar(self.parseStatement)

        self.state['inIteration'] = oldInIteration

        return node.finishForStatement(init, test, update, body) if (
            'left' not in locals()) else node.finishForInStatement(
                left, right, body)

    # 12.7 The continue statement

    def parseContinueStatement(self, node):
        label = null

        self.expectKeyword('continue')

        # Optimize the most common form: 'continue;'.
        if ord(self.source[self.startIndex]) == 0x3B:
            self.lex()
            if (not self.state['inIteration']):
                self.throwError(Messages.IllegalContinue)
            return node.finishContinueStatement(null)
        if (self.hasLineTerminator):
            if (not self.state['inIteration']):
                self.throwError(Messages.IllegalContinue)
            return node.finishContinueStatement(null)

        if (self.lookahead['type'] == Token.Identifier):
            label = self.parseVariableIdentifier()

            key = '$' + label.name
            if not key in self.state['labelSet']:  # todo make sure its correct!
                self.throwError(Messages.UnknownLabel, label.name)
        self.consumeSemicolon()

        if (label == null and not self.state['inIteration']):
            self.throwError(Messages.IllegalContinue)
        return node.finishContinueStatement(label)

    # 12.8 The break statement

    def parseBreakStatement(self, node):
        label = null

        self.expectKeyword('break')

        # Catch the very common case first: immediately a semicolon (U+003B).
        if (ord(self.source[self.lastIndex]) == 0x3B):
            self.lex()

            if (not (self.state['inIteration'] or self.state['inSwitch'])):
                self.throwError(Messages.IllegalBreak)
            return node.finishBreakStatement(null)
        if (self.hasLineTerminator):
            if (not (self.state['inIteration'] or self.state['inSwitch'])):
                self.throwError(Messages.IllegalBreak)
            return node.finishBreakStatement(null)
        if (self.lookahead['type'] == Token.Identifier):
            label = self.parseVariableIdentifier()

            key = '$' + label.name
            if not (key in self.state['labelSet']):
                self.throwError(Messages.UnknownLabel, label.name)
        self.consumeSemicolon()

        if (label == null
                and not (self.state['inIteration'] or self.state['inSwitch'])):
            self.throwError(Messages.IllegalBreak)
        return node.finishBreakStatement(label)

    # 12.9 The return statement

    def parseReturnStatement(self, node):
        argument = null

        self.expectKeyword('return')

        if (not self.state['inFunctionBody']):
            self.tolerateError(Messages.IllegalReturn)

        # 'return' followed by a space and an identifier is very common.
        if (ord(self.source[self.lastIndex]) == 0x20):
            if (isIdentifierStart(self.source[self.lastIndex + 1])):
                argument = self.parseExpression()
                self.consumeSemicolon()
                return node.finishReturnStatement(argument)
        if (self.hasLineTerminator):
            # HACK
            return node.finishReturnStatement(null)

        if (not self.match(';')):
            if (not self.match('}') and self.lookahead['type'] != Token.EOF):
                argument = self.parseExpression()
        self.consumeSemicolon()

        return node.finishReturnStatement(argument)

    # 12.10 The with statement

    def parseWithStatement(self, node):
        if (self.strict):
            self.tolerateError(Messages.StrictModeWith)

        self.expectKeyword('with')

        self.expect('(')

        obj = self.parseExpression()

        self.expect(')')

        body = self.parseStatement()

        return node.finishWithStatement(obj, body)

    # 12.10 The swith statement

    def parseSwitchCase(self):
        consequent = []
        node = Node()

        if (self.matchKeyword('default')):
            self.lex()
            test = null
        else:
            self.expectKeyword('case')
            test = self.parseExpression()

        self.expect(':')

        while (self.startIndex < self.length):
            if (self.match('}') or self.matchKeyword('default')
                    or self.matchKeyword('case')):
                break
            statement = self.parseStatementListItem()
            consequent.append(statement)
        return node.finishSwitchCase(test, consequent)

    def parseSwitchStatement(self, node):

        self.expectKeyword('switch')

        self.expect('(')

        discriminant = self.parseExpression()

        self.expect(')')

        self.expect('{')

        cases = []

        if (self.match('}')):
            self.lex()
            return node.finishSwitchStatement(discriminant, cases)

        oldInSwitch = self.state['inSwitch']
        self.state['inSwitch'] = true
        defaultFound = false

        while (self.startIndex < self.length):
            if (self.match('}')):
                break
            clause = self.parseSwitchCase()
            if (clause.test == null):
                if (defaultFound):
                    self.throwError(Messages.MultipleDefaultsInSwitch)
                defaultFound = true
            cases.append(clause)

        self.state['inSwitch'] = oldInSwitch

        self.expect('}')

        return node.finishSwitchStatement(discriminant, cases)

    # 12.13 The throw statement

    def parseThrowStatement(self, node):

        self.expectKeyword('throw')

        if (self.hasLineTerminator):
            self.throwError(Messages.NewlineAfterThrow)

        argument = self.parseExpression()

        self.consumeSemicolon()

        return node.finishThrowStatement(argument)

    # 12.14 The try statement

    def parseCatchClause(self):
        node = Node()

        self.expectKeyword('catch')

        self.expect('(')
        if (self.match(')')):
            self.throwUnexpectedToken(self.lookahead)
        param = self.parsePattern()

        # 12.14.1
        if (self.strict and isRestrictedWord(param.name)):
            self.tolerateError(Messages.StrictCatchVariable)

        self.expect(')')
        body = self.parseBlock()
        return node.finishCatchClause(param, body)

    def parseTryStatement(self, node):
        handler = null
        finalizer = null

        self.expectKeyword('try')

        block = self.parseBlock()

        if (self.matchKeyword('catch')):
            handler = self.parseCatchClause()

        if (self.matchKeyword('finally')):
            self.lex()
            finalizer = self.parseBlock()

        if (not handler and not finalizer):
            self.throwError(Messages.NoCatchOrFinally)

        return node.finishTryStatement(block, handler, finalizer)

    # 12.15 The debugger statement

    def parseDebuggerStatement(self, node):
        self.expectKeyword('debugger')

        self.consumeSemicolon()

        return node.finishDebuggerStatement()

    # 12 Statements

    def parseStatement(self):
        typ = self.lookahead['type']

        if (typ == Token.EOF):
            self.throwUnexpectedToken(self.lookahead)

        if (typ == Token.Punctuator and self.lookahead['value'] == '{'):
            return self.parseBlock()

        self.isAssignmentTarget = self.isBindingElement = true
        node = Node()
        val = self.lookahead['value']

        if (typ == Token.Punctuator):
            if val == ';':
                return self.parseEmptyStatement(node)
            elif val == '(':
                return self.parseExpressionStatement(node)
        elif (typ == Token.Keyword):
            if val == 'break':
                return self.parseBreakStatement(node)
            elif val == 'continue':
                return self.parseContinueStatement(node)
            elif val == 'debugger':
                return self.parseDebuggerStatement(node)
            elif val == 'do':
                return self.parseDoWhileStatement(node)
            elif val == 'for':
                return self.parseForStatement(node)
            elif val == 'function':
                return self.parseFunctionDeclaration(node)
            elif val == 'if':
                return self.parseIfStatement(node)
            elif val == 'return':
                return self.parseReturnStatement(node)
            elif val == 'switch':
                return self.parseSwitchStatement(node)
            elif val == 'throw':
                return self.parseThrowStatement(node)
            elif val == 'try':
                return self.parseTryStatement(node)
            elif val == 'var':
                return self.parseVariableStatement(node)
            elif val == 'while':
                return self.parseWhileStatement(node)
            elif val == 'with':
                return self.parseWithStatement(node)

        expr = self.parseExpression()

        # 12.12 Labelled Statements
        if ((expr.type == Syntax.Identifier) and self.match(':')):
            self.lex()

            key = '$' + expr.name
            if key in self.state['labelSet']:
                self.throwError(Messages.Redeclaration, 'Label', expr.name)
            self.state['labelSet'][key] = true
            labeledBody = self.parseStatement()
            del self.state['labelSet'][key]
            return node.finishLabeledStatement(expr, labeledBody)
        self.consumeSemicolon()
        return node.finishExpressionStatement(expr)

    # 13 Function Definition

    def parseFunctionSourceElements(self):
        body = []
        node = Node()
        firstRestricted = None

        self.expect('{')

        while (self.startIndex < self.length):
            if (self.lookahead['type'] != Token.StringLiteral):
                break
            token = self.lookahead

            statement = self.parseStatementListItem()
            body.append(statement)
            if (statement.expression.type != Syntax.Literal):
                # this is not directive
                break
            directive = self.source[token['start'] + 1:token['end'] - 1]
            if (directive == 'use strict'):
                self.strict = true
                if (firstRestricted):
                    self.tolerateUnexpectedToken(firstRestricted,
                                                 Messages.StrictOctalLiteral)
            else:
                if (not firstRestricted and token.get('octal')):
                    firstRestricted = token

        oldLabelSet = self.state['labelSet']
        oldInIteration = self.state['inIteration']
        oldInSwitch = self.state['inSwitch']
        oldInFunctionBody = self.state['inFunctionBody']
        oldParenthesisCount = self.state['parenthesizedCount']

        self.state['labelSet'] = {}
        self.state['inIteration'] = false
        self.state['inSwitch'] = false
        self.state['inFunctionBody'] = true
        self.state['parenthesizedCount'] = 0

        while (self.startIndex < self.length):
            if (self.match('}')):
                break
            body.append(self.parseStatementListItem())
        self.expect('}')

        self.state['labelSet'] = oldLabelSet
        self.state['inIteration'] = oldInIteration
        self.state['inSwitch'] = oldInSwitch
        self.state['inFunctionBody'] = oldInFunctionBody
        self.state['parenthesizedCount'] = oldParenthesisCount

        return node.finishBlockStatement(body)

    def validateParam(self, options, param, name):
        key = '$' + name
        if (self.strict):
            if (isRestrictedWord(name)):
                options['stricted'] = param
                options['message'] = Messages.StrictParamName
            if key in options['paramSet']:
                options['stricted'] = param
                options['message'] = Messages.StrictParamDupe
        elif (not options['firstRestricted']):
            if (isRestrictedWord(name)):
                options['firstRestricted'] = param
                options['message'] = Messages.StrictParamName
            elif (isStrictModeReservedWord(name)):
                options['firstRestricted'] = param
                options['message'] = Messages.StrictReservedWord
            elif key in options['paramSet']:
                options['firstRestricted'] = param
                options['message'] = Messages.StrictParamDupe
        options['paramSet'][key] = true

    def parseParam(self, options):
        token = self.lookahead
        de = None
        if (token['value'] == '...'):
            param = self.parseRestElement()
            self.validateParam(options, param.argument, param.argument.name)
            options['params'].append(param)
            options['defaults'].append(null)
            return false
        param = self.parsePatternWithDefault()
        self.validateParam(options, token, token['value'])

        if (param.type == Syntax.AssignmentPattern):
            de = param.right
            param = param.left
            options['defaultCount'] += 1
        options['params'].append(param)
        options['defaults'].append(de)
        return not self.match(')')

    def parseParams(self, firstRestricted):
        options = {
            'params': [],
            'defaultCount': 0,
            'defaults': [],
            'firstRestricted': firstRestricted
        }

        self.expect('(')

        if (not self.match(')')):
            options['paramSet'] = {}
            while (self.startIndex < self.length):
                if (not self.parseParam(options)):
                    break
                self.expect(',')
        self.expect(')')

        if (options['defaultCount'] == 0):
            options['defaults'] = []

        return {
            'params': options['params'],
            'defaults': options['defaults'],
            'stricted': options.get('stricted'),
            'firstRestricted': options.get('firstRestricted'),
            'message': options.get('message')
        }

    def parseFunctionDeclaration(self, node, identifierIsOptional=None):
        d = null
        params = []
        defaults = []
        message = None
        firstRestricted = None

        self.expectKeyword('function')
        if (identifierIsOptional or not self.match('(')):
            token = self.lookahead
            d = self.parseVariableIdentifier()
            if (self.strict):
                if (isRestrictedWord(token['value'])):
                    self.tolerateUnexpectedToken(token,
                                                 Messages.StrictFunctionName)
            else:
                if (isRestrictedWord(token['value'])):
                    firstRestricted = token
                    message = Messages.StrictFunctionName
                elif (isStrictModeReservedWord(token['value'])):
                    firstRestricted = token
                    message = Messages.StrictReservedWord

        tmp = self.parseParams(firstRestricted)
        params = tmp['params']
        defaults = tmp['defaults']
        stricted = tmp.get('stricted')
        firstRestricted = tmp['firstRestricted']
        if (tmp.get('message')):
            message = tmp['message']

        previousStrict = self.strict
        body = self.parseFunctionSourceElements()
        if (self.strict and firstRestricted):
            self.throwUnexpectedToken(firstRestricted, message)

        if (self.strict and stricted):
            self.tolerateUnexpectedToken(stricted, message)
        self.strict = previousStrict

        return node.finishFunctionDeclaration(d, params, defaults, body)

    def parseFunctionExpression(self):
        id = null
        params = []
        defaults = []
        node = Node()
        firstRestricted = None
        message = None

        self.expectKeyword('function')

        if (not self.match('(')):
            token = self.lookahead
            id = self.parseVariableIdentifier()
            if (self.strict):
                if (isRestrictedWord(token['value'])):
                    self.tolerateUnexpectedToken(token,
                                                 Messages.StrictFunctionName)
            else:
                if (isRestrictedWord(token['value'])):
                    firstRestricted = token
                    message = Messages.StrictFunctionName
                elif (isStrictModeReservedWord(token['value'])):
                    firstRestricted = token
                    message = Messages.StrictReservedWord
        tmp = self.parseParams(firstRestricted)
        params = tmp['params']
        defaults = tmp['defaults']
        stricted = tmp.get('stricted')
        firstRestricted = tmp['firstRestricted']
        if (tmp.get('message')):
            message = tmp['message']

        previousStrict = self.strict
        body = self.parseFunctionSourceElements()
        if (self.strict and firstRestricted):
            self.throwUnexpectedToken(firstRestricted, message)
        if (self.strict and stricted):
            self.tolerateUnexpectedToken(stricted, message)
        self.strict = previousStrict

        return node.finishFunctionExpression(id, params, defaults, body)

    # todo Translate parse class functions!

    def parseClassExpression(self):
        raise Ecma51NotSupported('ClassExpression')

    def parseClassDeclaration(self):
        raise Ecma51NotSupported('ClassDeclaration')

    # 14 Program

    def parseScriptBody(self):
        body = []
        firstRestricted = None

        while (self.startIndex < self.length):
            token = self.lookahead
            if (token['type'] != Token.StringLiteral):
                break
            statement = self.parseStatementListItem()
            body.append(statement)
            if (statement.expression.type != Syntax.Literal):
                # this is not directive
                break
            directive = self.source[token['start'] + 1:token['end'] - 1]
            if (directive == 'use strict'):
                self.strict = true
                if (firstRestricted):
                    self.tolerateUnexpectedToken(firstRestricted,
                                                 Messages.StrictOctalLiteral)
            else:
                if (not firstRestricted and token.get('octal')):
                    firstRestricted = token
        while (self.startIndex < self.length):
            statement = self.parseStatementListItem()
            # istanbul ignore if
            if (statement is None):
                break
            body.append(statement)
        return body

    def parseProgram(self):
        self.peek()
        node = Node()

        body = self.parseScriptBody()
        return node.finishProgram(body)

    # DONE!!!
    def parse(self, code, options={}):
        if options:
            raise NotImplementedError(
                'Options not implemented! You can only use default settings.')

        self.clean()
        self.source = unicode(
            code
        ) + ' \n ; //END'  # I have to add it in order not to check for EOF every time
        self.index = 0
        self.lineNumber = 1 if len(self.source) > 0 else 0
        self.lineStart = 0
        self.startIndex = self.index
        self.startLineNumber = self.lineNumber
        self.startLineStart = self.lineStart
        self.length = len(self.source)
        self.lookahead = null
        self.state = {
            'allowIn': true,
            'labelSet': {},
            'inFunctionBody': false,
            'inIteration': false,
            'inSwitch': false,
            'lastCommentStart': -1,
            'curlyStack': [],
            'parenthesizedCount': None
        }
        self.sourceType = 'script'
        self.strict = false
        try:
            program = self.parseProgram()
        except Ecma51NotSupported as e:
            raise self.createError(self.lineNumber, self.lastIndex, unicode(e))
        return node_to_dict(program)


def parse(javascript_code):
    """Returns syntax tree of javascript_code.
       Same as PyJsParser().parse  For your convenience :) """
    p = PyJsParser()
    return p.parse(javascript_code)


if __name__ == '__main__':
    import time

    test_path = None
    if test_path:
        f = open(test_path, 'rb')
        x = f.read()
        f.close()
    else:
        x = 'var $ = "Hello!"'
    p = PyJsParser()
    t = time.time()
    res = p.parse(x)
    dt = time.time() - t + 0.000000001
    if test_path:
        print(len(res))
    else:
        pprint(res)
    print()
    print('Parsed everyting in', round(dt, 5), 'seconds.')
    print('Thats %d characters per second' % int(len(x) / dt))




############################################################
### File: peewee.py
############################################################
from bisect import bisect_left
from bisect import bisect_right
from contextlib import contextmanager
from copy import deepcopy
from functools import wraps
from inspect import isclass
import calendar
import collections
import datetime
import decimal
import hashlib
import itertools
import logging
import operator
import re
import socket
import struct
import sys
import threading
import time
import uuid
import warnings
try:
    from collections.abc import Mapping
except ImportError:
    from collections import Mapping

try:
    from pysqlite3 import dbapi2 as pysq3
except ImportError:
    try:
        from pysqlite2 import dbapi2 as pysq3
    except ImportError:
        pysq3 = None
try:
    import sqlite3
except ImportError:
    sqlite3 = pysq3
else:
    if pysq3 and pysq3.sqlite_version_info >= sqlite3.sqlite_version_info:
        sqlite3 = pysq3
try:
    from psycopg2cffi import compat
    compat.register()
except ImportError:
    pass
try:
    import psycopg2
    from psycopg2 import extensions as pg_extensions
    try:
        from psycopg2 import errors as pg_errors
    except ImportError:
        pg_errors = None
except ImportError:
    psycopg2 = pg_errors = None
try:
    from psycopg2.extras import register_uuid as pg_register_uuid
    pg_register_uuid()
except Exception:
    pass
try:
    from psycopg import errors as pg3_errors
except ImportError:
    pg3_errors = None

mysql_passwd = False
try:
    import pymysql as mysql
except ImportError:
    try:
        import MySQLdb as mysql
        mysql_passwd = True
    except ImportError:
        mysql = None


__version__ = '3.17.6'
__all__ = [
    'AnyField',
    'AsIs',
    'AutoField',
    'BareField',
    'BigAutoField',
    'BigBitField',
    'BigIntegerField',
    'BinaryUUIDField',
    'BitField',
    'BlobField',
    'BooleanField',
    'Case',
    'Cast',
    'CharField',
    'Check',
    'chunked',
    'Column',
    'CompositeKey',
    'Context',
    'Database',
    'DatabaseError',
    'DatabaseProxy',
    'DataError',
    'DateField',
    'DateTimeField',
    'DecimalField',
    'DeferredForeignKey',
    'DeferredThroughModel',
    'DJANGO_MAP',
    'DoesNotExist',
    'DoubleField',
    'DQ',
    'EXCLUDED',
    'Field',
    'FixedCharField',
    'FloatField',
    'fn',
    'ForeignKeyField',
    'IdentityField',
    'ImproperlyConfigured',
    'Index',
    'IntegerField',
    'IntegrityError',
    'InterfaceError',
    'InternalError',
    'IPField',
    'JOIN',
    'ManyToManyField',
    'Model',
    'ModelIndex',
    'MySQLDatabase',
    'NotSupportedError',
    'OP',
    'OperationalError',
    'PostgresqlDatabase',
    'PrimaryKeyField',  # XXX: Deprecated, change to AutoField.
    'prefetch',
    'PREFETCH_TYPE',
    'ProgrammingError',
    'Proxy',
    'QualifiedNames',
    'SchemaManager',
    'SmallIntegerField',
    'Select',
    'SQL',
    'SqliteDatabase',
    'Table',
    'TextField',
    'TimeField',
    'TimestampField',
    'Tuple',
    'UUIDField',
    'Value',
    'ValuesList',
    'Window',
]

try:  # Python 2.7+
    from logging import NullHandler
except ImportError:
    class NullHandler(logging.Handler):
        def emit(self, record):
            pass

logger = logging.getLogger('peewee')
logger.addHandler(NullHandler())


if sys.version_info[0] == 2:
    text_type = unicode
    bytes_type = str
    buffer_type = buffer
    izip_longest = itertools.izip_longest
    callable_ = callable
    multi_types = (list, tuple, frozenset, set)
    exec('def reraise(tp, value, tb=None): raise tp, value, tb')
    def print_(s):
        sys.stdout.write(s)
        sys.stdout.write('\n')
else:
    import builtins
    try:
        from collections.abc import Callable
    except ImportError:
        from collections import Callable
    from functools import reduce
    callable_ = lambda c: isinstance(c, Callable)
    text_type = str
    bytes_type = bytes
    buffer_type = memoryview
    basestring = str
    long = int
    multi_types = (list, tuple, frozenset, set, range)
    print_ = getattr(builtins, 'print')
    izip_longest = itertools.zip_longest
    def reraise(tp, value, tb=None):
        if value.__traceback__ is not tb:
            raise value.with_traceback(tb)
        raise value

# Other compat issues.
if sys.version_info < (3, 12):
    utcfromtimestamp = datetime.datetime.utcfromtimestamp
    utcnow = datetime.datetime.utcnow
else:
    def utcfromtimestamp(ts):
        return (datetime.datetime
                .fromtimestamp(ts, tz=datetime.timezone.utc)
                .replace(tzinfo=None))
    def utcnow():
        return (datetime.datetime
                .now(datetime.timezone.utc)
                .replace(tzinfo=None))


if sqlite3:
    sqlite3.register_adapter(decimal.Decimal, str)
    sqlite3.register_adapter(datetime.date, str)
    sqlite3.register_adapter(datetime.time, str)
    if sys.version_info >= (3, 12):
        # We need to register datetime adapters as these are deprecated.
        def datetime_adapter(d): return d.isoformat(' ')
        def convert_date(d): return datetime.date(*map(int, d.split(b'-')))
        def convert_timestamp(t):
            date, time = t.split(b' ')
            y, m, d = map(int, date.split(b'-'))
            t_full = time.split(b'.')
            hour, minute, second = map(int, t_full[0].split(b':'))
            if len(t_full) == 2:
                usec = int('{:0<6.6}'.format(t_full[1].decode()))
            else:
                usec = 0
            return datetime.datetime(y, m, d, hour, minute, second, usec)
        sqlite3.register_adapter(datetime.datetime, datetime_adapter)
        sqlite3.register_converter('date', convert_date)
        sqlite3.register_converter('timestamp', convert_timestamp)

    __sqlite_version__ = sqlite3.sqlite_version_info
else:
    __sqlite_version__ = (0, 0, 0)


__date_parts__ = set(('year', 'month', 'day', 'hour', 'minute', 'second'))

# Sqlite does not support the `date_part` SQL function, so we will define an
# implementation in python.
__sqlite_datetime_formats__ = (
    '%Y-%m-%d %H:%M:%S',
    '%Y-%m-%d %H:%M:%S.%f',
    '%Y-%m-%d',
    '%H:%M:%S',
    '%H:%M:%S.%f',
    '%H:%M')

__sqlite_date_trunc__ = {
    'year': '%Y-01-01 00:00:00',
    'month': '%Y-%m-01 00:00:00',
    'day': '%Y-%m-%d 00:00:00',
    'hour': '%Y-%m-%d %H:00:00',
    'minute': '%Y-%m-%d %H:%M:00',
    'second': '%Y-%m-%d %H:%M:%S'}

__mysql_date_trunc__ = __sqlite_date_trunc__.copy()
__mysql_date_trunc__['minute'] = '%Y-%m-%d %H:%i:00'
__mysql_date_trunc__['second'] = '%Y-%m-%d %H:%i:%S'

def _sqlite_date_part(lookup_type, datetime_string):
    assert lookup_type in __date_parts__
    if not datetime_string:
        return
    dt = format_date_time(datetime_string, __sqlite_datetime_formats__)
    return getattr(dt, lookup_type)

def _sqlite_date_trunc(lookup_type, datetime_string):
    assert lookup_type in __sqlite_date_trunc__
    if not datetime_string:
        return
    dt = format_date_time(datetime_string, __sqlite_datetime_formats__)
    return dt.strftime(__sqlite_date_trunc__[lookup_type])


def __deprecated__(s):
    warnings.warn(s, DeprecationWarning)


class attrdict(dict):
    def __getattr__(self, attr):
        try:
            return self[attr]
        except KeyError:
            raise AttributeError(attr)
    def __setattr__(self, attr, value): self[attr] = value
    def __iadd__(self, rhs): self.update(rhs); return self
    def __add__(self, rhs): d = attrdict(self); d.update(rhs); return d

SENTINEL = object()

#: Operations for use in SQL expressions.
OP = attrdict(
    AND='AND',
    OR='OR',
    ADD='+',
    SUB='-',
    MUL='*',
    DIV='/',
    BIN_AND='&',
    BIN_OR='|',
    XOR='#',
    MOD='%',
    EQ='=',
    LT='<',
    LTE='<=',
    GT='>',
    GTE='>=',
    NE='!=',
    IN='IN',
    NOT_IN='NOT IN',
    IS='IS',
    IS_NOT='IS NOT',
    LIKE='LIKE',
    ILIKE='ILIKE',
    BETWEEN='BETWEEN',
    REGEXP='REGEXP',
    IREGEXP='IREGEXP',
    CONCAT='||',
    BITWISE_NEGATION='~')

# To support "django-style" double-underscore filters, create a mapping between
# operation name and operation code, e.g. "__eq" == OP.EQ.
DJANGO_MAP = attrdict({
    'eq': operator.eq,
    'lt': operator.lt,
    'lte': operator.le,
    'gt': operator.gt,
    'gte': operator.ge,
    'ne': operator.ne,
    'in': operator.lshift,
    'is': lambda l, r: Expression(l, OP.IS, r),
    'like': lambda l, r: Expression(l, OP.LIKE, r),
    'ilike': lambda l, r: Expression(l, OP.ILIKE, r),
    'regexp': lambda l, r: Expression(l, OP.REGEXP, r),
})

#: Mapping of field type to the data-type supported by the database. Databases
#: may override or add to this list.
FIELD = attrdict(
    AUTO='INTEGER',
    BIGAUTO='BIGINT',
    BIGINT='BIGINT',
    BLOB='BLOB',
    BOOL='SMALLINT',
    CHAR='CHAR',
    DATE='DATE',
    DATETIME='DATETIME',
    DECIMAL='DECIMAL',
    DEFAULT='',
    DOUBLE='REAL',
    FLOAT='REAL',
    INT='INTEGER',
    SMALLINT='SMALLINT',
    TEXT='TEXT',
    TIME='TIME',
    UUID='TEXT',
    UUIDB='BLOB',
    VARCHAR='VARCHAR')

#: Join helpers (for convenience) -- all join types are supported, this object
#: is just to help avoid introducing errors by using strings everywhere.
JOIN = attrdict(
    INNER='INNER JOIN',
    LEFT_OUTER='LEFT OUTER JOIN',
    RIGHT_OUTER='RIGHT OUTER JOIN',
    FULL='FULL JOIN',
    FULL_OUTER='FULL OUTER JOIN',
    CROSS='CROSS JOIN',
    NATURAL='NATURAL JOIN',
    LATERAL='LATERAL',
    LEFT_LATERAL='LEFT JOIN LATERAL')

# Row representations.
ROW = attrdict(
    TUPLE=1,
    DICT=2,
    NAMED_TUPLE=3,
    CONSTRUCTOR=4,
    MODEL=5)

# Query type to use with prefetch
PREFETCH_TYPE = attrdict(
    WHERE=1,
    JOIN=2)

SCOPE_NORMAL = 1
SCOPE_SOURCE = 2
SCOPE_VALUES = 4
SCOPE_CTE = 8
SCOPE_COLUMN = 16

# Rules for parentheses around subqueries in compound select.
CSQ_PARENTHESES_NEVER = 0
CSQ_PARENTHESES_ALWAYS = 1
CSQ_PARENTHESES_UNNESTED = 2

# Regular expressions used to convert class names to snake-case table names.
# First regex handles acronym followed by word or initial lower-word followed
# by a capitalized word. e.g. APIResponse -> API_Response / fooBar -> foo_Bar.
# Second regex handles the normal case of two title-cased words.
SNAKE_CASE_STEP1 = re.compile('(.)_*([A-Z][a-z]+)')
SNAKE_CASE_STEP2 = re.compile('([a-z0-9])_*([A-Z])')

# Helper functions that are used in various parts of the codebase.
MODEL_BASE = '_metaclass_helper_'

def with_metaclass(meta, base=object):
    return meta(MODEL_BASE, (base,), {})

def merge_dict(source, overrides):
    merged = source.copy()
    if overrides:
        merged.update(overrides)
    return merged

def quote(path, quote_chars):
    if len(path) == 1:
        return path[0].join(quote_chars)
    return '.'.join([part.join(quote_chars) for part in path])

is_model = lambda o: isclass(o) and issubclass(o, Model)

def ensure_tuple(value):
    if value is not None:
        return value if isinstance(value, (list, tuple)) else (value,)

def ensure_entity(value):
    if value is not None:
        return value if isinstance(value, Node) else Entity(value)

def make_snake_case(s):
    first = SNAKE_CASE_STEP1.sub(r'\1_\2', s)
    return SNAKE_CASE_STEP2.sub(r'\1_\2', first).lower()

def chunked(it, n):
    marker = object()
    for group in (list(g) for g in izip_longest(*[iter(it)] * n,
                                                fillvalue=marker)):
        if group[-1] is marker:
            del group[group.index(marker):]
        yield group


class _callable_context_manager(object):
    def __call__(self, fn):
        @wraps(fn)
        def inner(*args, **kwargs):
            with self:
                return fn(*args, **kwargs)
        return inner


class Proxy(object):
    """
    Create a proxy or placeholder for another object.
    """
    __slots__ = ('obj', '_callbacks')

    def __init__(self):
        self._callbacks = []
        self.initialize(None)

    def initialize(self, obj):
        self.obj = obj
        for callback in self._callbacks:
            callback(obj)

    def attach_callback(self, callback):
        self._callbacks.append(callback)
        return callback

    def passthrough(method):
        def inner(self, *args, **kwargs):
            if self.obj is None:
                raise AttributeError('Cannot use uninitialized Proxy.')
            return getattr(self.obj, method)(*args, **kwargs)
        return inner

    # Allow proxy to be used as a context-manager.
    __enter__ = passthrough('__enter__')
    __exit__ = passthrough('__exit__')

    def __getattr__(self, attr):
        if self.obj is None:
            raise AttributeError('Cannot use uninitialized Proxy.')
        return getattr(self.obj, attr)

    def __setattr__(self, attr, value):
        if attr not in self.__slots__:
            raise AttributeError('Cannot set attribute on proxy.')
        return super(Proxy, self).__setattr__(attr, value)


class DatabaseProxy(Proxy):
    """
    Proxy implementation specifically for proxying `Database` objects.
    """
    __slots__ = ('obj', '_callbacks', '_Model')

    def connection_context(self):
        return ConnectionContext(self)
    def atomic(self, *args, **kwargs):
        return _atomic(self, *args, **kwargs)
    def manual_commit(self):
        return _manual(self)
    def transaction(self, *args, **kwargs):
        return _transaction(self, *args, **kwargs)
    def savepoint(self):
        return _savepoint(self)
    @property
    def Model(self):
        if not hasattr(self, '_Model'):
            class Meta: database = self
            self._Model = type('BaseModel', (Model,), {'Meta': Meta})
        return self._Model


class ModelDescriptor(object): pass


# SQL Generation.


class AliasManager(object):
    __slots__ = ('_counter', '_current_index', '_mapping')

    def __init__(self):
        # A list of dictionaries containing mappings at various depths.
        self._counter = 0
        self._current_index = 0
        self._mapping = []
        self.push()

    @property
    def mapping(self):
        return self._mapping[self._current_index - 1]

    def add(self, source):
        if source not in self.mapping:
            self._counter += 1
            self[source] = 't%d' % self._counter
        return self.mapping[source]

    def get(self, source, any_depth=False):
        if any_depth:
            for idx in reversed(range(self._current_index)):
                if source in self._mapping[idx]:
                    return self._mapping[idx][source]
        return self.add(source)

    def __getitem__(self, source):
        return self.get(source)

    def __setitem__(self, source, alias):
        self.mapping[source] = alias

    def push(self):
        self._current_index += 1
        if self._current_index > len(self._mapping):
            self._mapping.append({})

    def pop(self):
        if self._current_index == 1:
            raise ValueError('Cannot pop() from empty alias manager.')
        self._current_index -= 1


class State(collections.namedtuple('_State', ('scope', 'parentheses',
                                              'settings'))):
    def __new__(cls, scope=SCOPE_NORMAL, parentheses=False, **kwargs):
        return super(State, cls).__new__(cls, scope, parentheses, kwargs)

    def __call__(self, scope=None, parentheses=None, **kwargs):
        # Scope and settings are "inherited" (parentheses is not, however).
        scope = self.scope if scope is None else scope

        # Try to avoid unnecessary dict copying.
        if kwargs and self.settings:
            settings = self.settings.copy()  # Copy original settings dict.
            settings.update(kwargs)  # Update copy with overrides.
        elif kwargs:
            settings = kwargs
        else:
            settings = self.settings
        return State(scope, parentheses, **settings)

    def __getattr__(self, attr_name):
        return self.settings.get(attr_name)


def __scope_context__(scope):
    @contextmanager
    def inner(self, **kwargs):
        with self(scope=scope, **kwargs):
            yield self
    return inner


class Context(object):
    __slots__ = ('stack', '_sql', '_values', 'alias_manager', 'state')

    def __init__(self, **settings):
        self.stack = []
        self._sql = []
        self._values = []
        self.alias_manager = AliasManager()
        self.state = State(**settings)

    def as_new(self):
        return Context(**self.state.settings)

    def column_sort_key(self, item):
        return item[0].get_sort_key(self)

    @property
    def scope(self):
        return self.state.scope

    @property
    def parentheses(self):
        return self.state.parentheses

    @property
    def subquery(self):
        return self.state.subquery

    def __call__(self, **overrides):
        if overrides and overrides.get('scope') == self.scope:
            del overrides['scope']

        self.stack.append(self.state)
        self.state = self.state(**overrides)
        return self

    scope_normal = __scope_context__(SCOPE_NORMAL)
    scope_source = __scope_context__(SCOPE_SOURCE)
    scope_values = __scope_context__(SCOPE_VALUES)
    scope_cte = __scope_context__(SCOPE_CTE)
    scope_column = __scope_context__(SCOPE_COLUMN)

    def __enter__(self):
        if self.parentheses:
            self.literal('(')
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.parentheses:
            self.literal(')')
        self.state = self.stack.pop()

    @contextmanager
    def push_alias(self):
        self.alias_manager.push()
        yield
        self.alias_manager.pop()

    def sql(self, obj):
        if isinstance(obj, (Node, Context)):
            return obj.__sql__(self)
        elif is_model(obj):
            return obj._meta.table.__sql__(self)
        else:
            return self.sql(Value(obj))

    def literal(self, keyword):
        self._sql.append(keyword)
        return self

    def value(self, value, converter=None, add_param=True):
        if converter:
            value = converter(value)
        elif converter is None and self.state.converter:
            # Explicitly check for None so that "False" can be used to signify
            # that no conversion should be applied.
            value = self.state.converter(value)

        if isinstance(value, Node):
            with self(converter=None):
                return self.sql(value)
        elif is_model(value):
            # Under certain circumstances, we could end-up treating a model-
            # class itself as a value. This check ensures that we drop the
            # table alias into the query instead of trying to parameterize a
            # model (for instance, passing a model as a function argument).
            with self.scope_column():
                return self.sql(value)

        if self.state.value_literals:
            return self.literal(_query_val_transform(value))

        self._values.append(value)
        return self.literal(self.state.param or '?') if add_param else self

    def __sql__(self, ctx):
        ctx._sql.extend(self._sql)
        ctx._values.extend(self._values)
        return ctx

    def parse(self, node):
        return self.sql(node).query()

    def query(self):
        return ''.join(self._sql), self._values


def query_to_string(query):
    # NOTE: this function is not exported by default as it might be misused --
    # and this misuse could lead to sql injection vulnerabilities. This
    # function is intended for debugging or logging purposes ONLY.
    db = getattr(query, '_database', None)
    if db is not None:
        ctx = db.get_sql_context()
    else:
        ctx = Context()

    sql, params = ctx.sql(query).query()
    if not params:
        return sql

    param = ctx.state.param or '?'
    if param == '?':
        sql = sql.replace('?', '%s')

    return sql % tuple(map(_query_val_transform, params))

def _query_val_transform(v):
    # Interpolate parameters.
    if isinstance(v, (text_type, datetime.datetime, datetime.date,
                      datetime.time)):
        v = "'%s'" % v
    elif isinstance(v, bytes_type):
        try:
            v = v.decode('utf8')
        except UnicodeDecodeError:
            v = v.decode('raw_unicode_escape')
        v = "'%s'" % v
    elif isinstance(v, int):
        v = '%s' % int(v)  # Also handles booleans -> 1 or 0.
    elif v is None:
        v = 'NULL'
    else:
        v = str(v)
    return v


# AST.


class Node(object):
    _coerce = True
    __isabstractmethod__ = False  # Avoid issue w/abc and __getattr__, eg fn.X

    def clone(self):
        obj = self.__class__.__new__(self.__class__)
        obj.__dict__ = self.__dict__.copy()
        return obj

    def __sql__(self, ctx):
        raise NotImplementedError

    @staticmethod
    def copy(method):
        def inner(self, *args, **kwargs):
            clone = self.clone()
            method(clone, *args, **kwargs)
            return clone
        return inner

    def coerce(self, _coerce=True):
        if _coerce != self._coerce:
            clone = self.clone()
            clone._coerce = _coerce
            return clone
        return self

    def is_alias(self):
        return False

    def unwrap(self):
        return self


class ColumnFactory(object):
    __slots__ = ('node',)

    def __init__(self, node):
        self.node = node

    def __getattr__(self, attr):
        return Column(self.node, attr)
    __getitem__ = __getattr__


class _DynamicColumn(object):
    __slots__ = ()

    def __get__(self, instance, instance_type=None):
        if instance is not None:
            return ColumnFactory(instance)  # Implements __getattr__().
        return self


class _ExplicitColumn(object):
    __slots__ = ()

    def __get__(self, instance, instance_type=None):
        if instance is not None:
            raise AttributeError(
                '%s specifies columns explicitly, and does not support '
                'dynamic column lookups.' % instance)
        return self


class Star(Node):
    def __init__(self, source):
        self.source = source
    def __sql__(self, ctx):
        return ctx.sql(QualifiedNames(self.source)).literal('.*')


class Source(Node):
    c = _DynamicColumn()

    def __init__(self, alias=None):
        super(Source, self).__init__()
        self._alias = alias

    @Node.copy
    def alias(self, name):
        self._alias = name

    def select(self, *columns):
        if not columns:
            columns = (SQL('*'),)
        return Select((self,), columns)

    @property
    def __star__(self):
        return Star(self)

    def join(self, dest, join_type=JOIN.INNER, on=None):
        return Join(self, dest, join_type, on)

    def left_outer_join(self, dest, on=None):
        return Join(self, dest, JOIN.LEFT_OUTER, on)

    def cte(self, name, recursive=False, columns=None, materialized=None):
        return CTE(name, self, recursive=recursive, columns=columns,
                   materialized=materialized)

    def get_sort_key(self, ctx):
        if self._alias:
            return (self._alias,)
        return (ctx.alias_manager[self],)

    def apply_alias(self, ctx):
        # If we are defining the source, include the "AS alias" declaration. An
        # alias is created for the source if one is not already defined.
        if ctx.scope == SCOPE_SOURCE:
            if self._alias:
                ctx.alias_manager[self] = self._alias
            ctx.literal(' AS ').sql(Entity(ctx.alias_manager[self]))
        return ctx

    def apply_column(self, ctx):
        if self._alias:
            ctx.alias_manager[self] = self._alias
        return ctx.sql(Entity(ctx.alias_manager[self]))


class _HashableSource(object):
    def __init__(self, *args, **kwargs):
        super(_HashableSource, self).__init__(*args, **kwargs)
        self._update_hash()

    @Node.copy
    def alias(self, name):
        self._alias = name
        self._update_hash()

    def _update_hash(self):
        self._hash = self._get_hash()

    def _get_hash(self):
        return hash((self.__class__, self._path, self._alias))

    def __hash__(self):
        return self._hash

    def __eq__(self, other):
        if isinstance(other, _HashableSource):
            return self._hash == other._hash
        return Expression(self, OP.EQ, other)

    def __ne__(self, other):
        if isinstance(other, _HashableSource):
            return self._hash != other._hash
        return Expression(self, OP.NE, other)

    def _e(op):
        def inner(self, rhs):
            return Expression(self, op, rhs)
        return inner
    __lt__ = _e(OP.LT)
    __le__ = _e(OP.LTE)
    __gt__ = _e(OP.GT)
    __ge__ = _e(OP.GTE)


def __bind_database__(meth):
    @wraps(meth)
    def inner(self, *args, **kwargs):
        result = meth(self, *args, **kwargs)
        if self._database:
            return result.bind(self._database)
        return result
    return inner


def __join__(join_type=JOIN.INNER, inverted=False):
    def method(self, other):
        if inverted:
            self, other = other, self
        return Join(self, other, join_type=join_type)
    return method


class BaseTable(Source):
    __and__ = __join__(JOIN.INNER)
    __add__ = __join__(JOIN.LEFT_OUTER)
    __sub__ = __join__(JOIN.RIGHT_OUTER)
    __or__ = __join__(JOIN.FULL_OUTER)
    __mul__ = __join__(JOIN.CROSS)
    __rand__ = __join__(JOIN.INNER, inverted=True)
    __radd__ = __join__(JOIN.LEFT_OUTER, inverted=True)
    __rsub__ = __join__(JOIN.RIGHT_OUTER, inverted=True)
    __ror__ = __join__(JOIN.FULL_OUTER, inverted=True)
    __rmul__ = __join__(JOIN.CROSS, inverted=True)


class _BoundTableContext(object):
    def __init__(self, table, database):
        self.table = table
        self.database = database

    def __call__(self, fn):
        @wraps(fn)
        def inner(*args, **kwargs):
            with _BoundTableContext(self.table, self.database):
                return fn(*args, **kwargs)
        return inner

    def __enter__(self):
        self._orig_database = self.table._database
        self.table.bind(self.database)
        if self.table._model is not None:
            self.table._model.bind(self.database)
        return self.table

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.table.bind(self._orig_database)
        if self.table._model is not None:
            self.table._model.bind(self._orig_database)


class Table(_HashableSource, BaseTable):
    def __init__(self, name, columns=None, primary_key=None, schema=None,
                 alias=None, _model=None, _database=None):
        self.__name__ = name
        self._columns = columns
        self._primary_key = primary_key
        self._schema = schema
        self._path = (schema, name) if schema else (name,)
        self._model = _model
        self._database = _database
        super(Table, self).__init__(alias=alias)

        # Allow tables to restrict what columns are available.
        if columns is not None:
            self.c = _ExplicitColumn()
            for column in columns:
                setattr(self, column, Column(self, column))

        if primary_key:
            col_src = self if self._columns else self.c
            self.primary_key = getattr(col_src, primary_key)
        else:
            self.primary_key = None

    def clone(self):
        # Ensure a deep copy of the column instances.
        return Table(
            self.__name__,
            columns=self._columns,
            primary_key=self._primary_key,
            schema=self._schema,
            alias=self._alias,
            _model=self._model,
            _database=self._database)

    def bind(self, database=None):
        self._database = database
        return self

    def bind_ctx(self, database=None):
        return _BoundTableContext(self, database)

    def _get_hash(self):
        return hash((self.__class__, self._path, self._alias, self._model))

    @__bind_database__
    def select(self, *columns):
        if not columns and self._columns:
            columns = [Column(self, column) for column in self._columns]
        return Select((self,), columns)

    @__bind_database__
    def insert(self, insert=None, columns=None, **kwargs):
        if kwargs:
            insert = {} if insert is None else insert
            src = self if self._columns else self.c
            for key, value in kwargs.items():
                insert[getattr(src, key)] = value
        return Insert(self, insert=insert, columns=columns)

    @__bind_database__
    def replace(self, insert=None, columns=None, **kwargs):
        return (self
                .insert(insert=insert, columns=columns)
                .on_conflict('REPLACE'))

    @__bind_database__
    def update(self, update=None, **kwargs):
        if kwargs:
            update = {} if update is None else update
            for key, value in kwargs.items():
                src = self if self._columns else self.c
                update[getattr(src, key)] = value
        return Update(self, update=update)

    @__bind_database__
    def delete(self):
        return Delete(self)

    def __sql__(self, ctx):
        if ctx.scope == SCOPE_VALUES:
            # Return the quoted table name.
            return ctx.sql(Entity(*self._path))

        if self._alias:
            ctx.alias_manager[self] = self._alias

        if ctx.scope == SCOPE_SOURCE:
            # Define the table and its alias.
            return self.apply_alias(ctx.sql(Entity(*self._path)))
        else:
            # Refer to the table using the alias.
            return self.apply_column(ctx)


class Join(BaseTable):
    def __init__(self, lhs, rhs, join_type=JOIN.INNER, on=None, alias=None):
        super(Join, self).__init__(alias=alias)
        self.lhs = lhs
        self.rhs = rhs
        self.join_type = join_type
        self._on = on

    def on(self, predicate):
        self._on = predicate
        return self

    def __sql__(self, ctx):
        (ctx
         .sql(self.lhs)
         .literal(' %s ' % self.join_type)
         .sql(self.rhs))
        if self._on is not None:
            ctx.literal(' ON ').sql(self._on)
        return ctx


class ValuesList(_HashableSource, BaseTable):
    def __init__(self, values, columns=None, alias=None):
        self._values = values
        self._columns = columns
        super(ValuesList, self).__init__(alias=alias)

    def _get_hash(self):
        return hash((self.__class__, id(self._values), self._alias))

    @Node.copy
    def columns(self, *names):
        self._columns = names

    def __sql__(self, ctx):
        if self._alias:
            ctx.alias_manager[self] = self._alias

        if ctx.scope == SCOPE_SOURCE or ctx.scope == SCOPE_NORMAL:
            with ctx(parentheses=not ctx.parentheses):
                ctx = (ctx
                       .literal('VALUES ')
                       .sql(CommaNodeList([
                           EnclosedNodeList(row) for row in self._values])))

            if ctx.scope == SCOPE_SOURCE:
                ctx.literal(' AS ').sql(Entity(ctx.alias_manager[self]))
                if self._columns:
                    entities = [Entity(c) for c in self._columns]
                    ctx.sql(EnclosedNodeList(entities))
        else:
            ctx.sql(Entity(ctx.alias_manager[self]))

        return ctx


class CTE(_HashableSource, Source):
    def __init__(self, name, query, recursive=False, columns=None,
                 materialized=None):
        self._alias = name
        self._query = query
        self._recursive = recursive
        self._materialized = materialized
        if columns is not None:
            columns = [Entity(c) if isinstance(c, basestring) else c
                       for c in columns]
        self._columns = columns
        query._cte_list = ()
        super(CTE, self).__init__(alias=name)

    def select_from(self, *columns):
        if not columns:
            raise ValueError('select_from() must specify one or more columns '
                             'from the CTE to select.')

        query = (Select((self,), columns)
                 .with_cte(self)
                 .bind(self._query._database))
        try:
            query = query.objects(self._query.model)
        except AttributeError:
            pass
        return query

    def _get_hash(self):
        return hash((self.__class__, self._alias, id(self._query)))

    def union_all(self, rhs):
        clone = self._query.clone()
        return CTE(self._alias, clone + rhs, self._recursive, self._columns)
    __add__ = union_all

    def union(self, rhs):
        clone = self._query.clone()
        return CTE(self._alias, clone | rhs, self._recursive, self._columns)
    __or__ = union

    def __sql__(self, ctx):
        if ctx.scope != SCOPE_CTE:
            return ctx.sql(Entity(self._alias))

        with ctx.push_alias():
            ctx.alias_manager[self] = self._alias
            ctx.sql(Entity(self._alias))

            if self._columns:
                ctx.literal(' ').sql(EnclosedNodeList(self._columns))
            ctx.literal(' AS ')

            if self._materialized:
                ctx.literal('MATERIALIZED ')
            elif self._materialized is False:
                ctx.literal('NOT MATERIALIZED ')

            with ctx.scope_normal(parentheses=True):
                ctx.sql(self._query)
        return ctx


class ColumnBase(Node):
    _converter = None

    @Node.copy
    def converter(self, converter=None):
        self._converter = converter

    def alias(self, alias):
        if alias:
            return Alias(self, alias)
        return self

    def unalias(self):
        return self

    def bind_to(self, dest):
        return BindTo(self, dest)

    def cast(self, as_type):
        return Cast(self, as_type)

    def asc(self, collation=None, nulls=None):
        return Asc(self, collation=collation, nulls=nulls)
    __pos__ = asc

    def desc(self, collation=None, nulls=None):
        return Desc(self, collation=collation, nulls=nulls)
    __neg__ = desc

    def __invert__(self):
        return Negated(self)

    def _e(op, inv=False):
        """
        Lightweight factory which returns a method that builds an Expression
        consisting of the left-hand and right-hand operands, using `op`.
        """
        def inner(self, rhs):
            if inv:
                return Expression(rhs, op, self)
            return Expression(self, op, rhs)
        return inner
    __and__ = _e(OP.AND)
    __or__ = _e(OP.OR)

    __add__ = _e(OP.ADD)
    __sub__ = _e(OP.SUB)
    __mul__ = _e(OP.MUL)
    __div__ = __truediv__ = _e(OP.DIV)
    __xor__ = _e(OP.XOR)
    __radd__ = _e(OP.ADD, inv=True)
    __rsub__ = _e(OP.SUB, inv=True)
    __rmul__ = _e(OP.MUL, inv=True)
    __rdiv__ = __rtruediv__ = _e(OP.DIV, inv=True)
    __rand__ = _e(OP.AND, inv=True)
    __ror__ = _e(OP.OR, inv=True)
    __rxor__ = _e(OP.XOR, inv=True)

    def __eq__(self, rhs):
        op = OP.IS if rhs is None else OP.EQ
        return Expression(self, op, rhs)
    def __ne__(self, rhs):
        op = OP.IS_NOT if rhs is None else OP.NE
        return Expression(self, op, rhs)

    __lt__ = _e(OP.LT)
    __le__ = _e(OP.LTE)
    __gt__ = _e(OP.GT)
    __ge__ = _e(OP.GTE)
    __lshift__ = _e(OP.IN)
    __rshift__ = _e(OP.IS)
    __mod__ = _e(OP.LIKE)
    __pow__ = _e(OP.ILIKE)

    like = _e(OP.LIKE)
    ilike = _e(OP.ILIKE)

    bin_and = _e(OP.BIN_AND)
    bin_or = _e(OP.BIN_OR)
    in_ = _e(OP.IN)
    not_in = _e(OP.NOT_IN)
    regexp = _e(OP.REGEXP)
    iregexp = _e(OP.IREGEXP)

    # Special expressions.
    def is_null(self, is_null=True):
        op = OP.IS if is_null else OP.IS_NOT
        return Expression(self, op, None)

    def _escape_like_expr(self, s, template):
        if s.find('_') >= 0 or s.find('%') >= 0 or s.find('\\') >= 0:
            s = s.replace('\\', '\\\\').replace('_', '\\_').replace('%', '\\%')
            # Pass the expression and escape string as unconverted values, to
            # avoid (e.g.) a Json field converter turning the escaped LIKE
            # pattern into a Json-quoted string.
            return NodeList((
                Value(template % s, converter=False),
                SQL('ESCAPE'),
                Value('\\', converter=False)))
        return template % s
    def contains(self, rhs):
        if isinstance(rhs, Node):
            rhs = Expression('%', OP.CONCAT,
                             Expression(rhs, OP.CONCAT, '%'))
        else:
            rhs = self._escape_like_expr(rhs, '%%%s%%')
        return Expression(self, OP.ILIKE, rhs)
    def startswith(self, rhs):
        if isinstance(rhs, Node):
            rhs = Expression(rhs, OP.CONCAT, '%')
        else:
            rhs = self._escape_like_expr(rhs, '%s%%')
        return Expression(self, OP.ILIKE, rhs)
    def endswith(self, rhs):
        if isinstance(rhs, Node):
            rhs = Expression('%', OP.CONCAT, rhs)
        else:
            rhs = self._escape_like_expr(rhs, '%%%s')
        return Expression(self, OP.ILIKE, rhs)
    def between(self, lo, hi):
        return Expression(self, OP.BETWEEN, NodeList((lo, SQL('AND'), hi)))
    def concat(self, rhs):
        return StringExpression(self, OP.CONCAT, rhs)
    def __getitem__(self, item):
        if isinstance(item, slice):
            if item.start is None or item.stop is None:
                raise ValueError('BETWEEN range must have both a start- and '
                                 'end-point.')
            return self.between(item.start, item.stop)
        return self == item
    __iter__ = None  # Prevent infinite loop.

    def distinct(self):
        return NodeList((SQL('DISTINCT'), self))

    def collate(self, collation):
        return NodeList((self, SQL('COLLATE %s' % collation)))

    def get_sort_key(self, ctx):
        return ()


class Column(ColumnBase):
    def __init__(self, source, name):
        self.source = source
        self.name = name

    def get_sort_key(self, ctx):
        if ctx.scope == SCOPE_VALUES:
            return (self.name,)
        else:
            return self.source.get_sort_key(ctx) + (self.name,)

    def __hash__(self):
        return hash((self.source, self.name))

    def __sql__(self, ctx):
        if ctx.scope == SCOPE_VALUES:
            return ctx.sql(Entity(self.name))
        else:
            with ctx.scope_column():
                return ctx.sql(self.source).literal('.').sql(Entity(self.name))


class WrappedNode(ColumnBase):
    def __init__(self, node):
        self.node = node
        self._coerce = getattr(node, '_coerce', True)
        self._converter = getattr(node, '_converter', None)

    def is_alias(self):
        return self.node.is_alias()

    def unwrap(self):
        return self.node.unwrap()


class EntityFactory(object):
    __slots__ = ('node',)
    def __init__(self, node):
        self.node = node
    def __getattr__(self, attr):
        return Entity(self.node, attr)


class _DynamicEntity(object):
    __slots__ = ()
    def __get__(self, instance, instance_type=None):
        if instance is not None:
            return EntityFactory(instance._alias)  # Implements __getattr__().
        return self


class Alias(WrappedNode):
    c = _DynamicEntity()

    def __init__(self, node, alias):
        super(Alias, self).__init__(node)
        self._alias = alias

    def __hash__(self):
        return hash(self._alias)

    @property
    def name(self):
        return self._alias
    @name.setter
    def name(self, value):
        self._alias = value

    def alias(self, alias=None):
        if alias is None:
            return self.node
        else:
            return Alias(self.node, alias)

    def unalias(self):
        return self.node

    def is_alias(self):
        return True

    def __sql__(self, ctx):
        if ctx.scope == SCOPE_SOURCE:
            return (ctx
                    .sql(self.node)
                    .literal(' AS ')
                    .sql(Entity(self._alias)))
        else:
            return ctx.sql(Entity(self._alias))


class BindTo(WrappedNode):
    def __init__(self, node, dest):
        super(BindTo, self).__init__(node)
        self.dest = dest

    def __sql__(self, ctx):
        return ctx.sql(self.node)


class Negated(WrappedNode):
    def __invert__(self):
        return self.node

    def __sql__(self, ctx):
        return ctx.literal('NOT ').sql(self.node)


class BitwiseMixin(object):
    def __and__(self, other):
        return self.bin_and(other)

    def __or__(self, other):
        return self.bin_or(other)

    def __sub__(self, other):
        return self.bin_and(other.bin_negated())

    def __invert__(self):
        return BitwiseNegated(self)


class BitwiseNegated(BitwiseMixin, WrappedNode):
    def __invert__(self):
        return self.node

    def __sql__(self, ctx):
        if ctx.state.operations:
            op_sql = ctx.state.operations.get(self.op, self.op)
        else:
            op_sql = self.op
        return ctx.literal(op_sql).sql(self.node)


class Value(ColumnBase):
    def __init__(self, value, converter=None, unpack=True):
        self.value = value
        self.converter = converter
        self.multi = unpack and isinstance(self.value, multi_types)
        if self.multi:
            self.values = []
            for item in self.value:
                if isinstance(item, Node):
                    self.values.append(item)
                else:
                    self.values.append(Value(item, self.converter))

    def __sql__(self, ctx):
        if self.multi:
            # For multi-part values (e.g. lists of IDs).
            return ctx.sql(EnclosedNodeList(self.values))

        return ctx.value(self.value, self.converter)


class ValueLiterals(WrappedNode):
    def __sql__(self, ctx):
        with ctx(value_literals=True):
            return ctx.sql(self.node)


def AsIs(value):
    return Value(value, unpack=False)


class Cast(WrappedNode):
    def __init__(self, node, cast):
        super(Cast, self).__init__(node)
        self._cast = cast
        self._coerce = False

    def __sql__(self, ctx):
        return (ctx
                .literal('CAST(')
                .sql(self.node)
                .literal(' AS %s)' % self._cast))


class Ordering(WrappedNode):
    def __init__(self, node, direction, collation=None, nulls=None):
        super(Ordering, self).__init__(node)
        self.direction = direction
        self.collation = collation
        self.nulls = nulls
        if nulls and nulls.lower() not in ('first', 'last'):
            raise ValueError('Ordering nulls= parameter must be "first" or '
                             '"last", got: %s' % nulls)

    def collate(self, collation=None):
        return Ordering(self.node, self.direction, collation)

    def _null_ordering_case(self, nulls):
        if nulls.lower() == 'last':
            ifnull, notnull = 1, 0
        elif nulls.lower() == 'first':
            ifnull, notnull = 0, 1
        else:
            raise ValueError('unsupported value for nulls= ordering.')
        return Case(None, ((self.node.is_null(), ifnull),), notnull)

    def __sql__(self, ctx):
        if self.nulls and not ctx.state.nulls_ordering:
            ctx.sql(self._null_ordering_case(self.nulls)).literal(', ')

        ctx.sql(self.node).literal(' %s' % self.direction)
        if self.collation:
            ctx.literal(' COLLATE %s' % self.collation)
        if self.nulls and ctx.state.nulls_ordering:
            ctx.literal(' NULLS %s' % self.nulls)
        return ctx


def Asc(node, collation=None, nulls=None):
    return Ordering(node, 'ASC', collation, nulls)


def Desc(node, collation=None, nulls=None):
    return Ordering(node, 'DESC', collation, nulls)


class Expression(ColumnBase):
    def __init__(self, lhs, op, rhs, flat=False):
        self.lhs = lhs
        self.op = op
        self.rhs = rhs
        self.flat = flat

    def __sql__(self, ctx):
        overrides = {'parentheses': not self.flat, 'in_expr': True}

        # First attempt to unwrap the node on the left-hand-side, so that we
        # can get at the underlying Field if one is present.
        node = raw_node = self.lhs
        if isinstance(raw_node, WrappedNode):
            node = raw_node.unwrap()

        # Set up the appropriate converter if we have a field on the left side.
        if isinstance(node, Field) and raw_node._coerce:
            overrides['converter'] = node.db_value
            overrides['is_fk_expr'] = isinstance(node, ForeignKeyField)
        else:
            overrides['converter'] = None

        if ctx.state.operations:
            op_sql = ctx.state.operations.get(self.op, self.op)
        else:
            op_sql = self.op

        with ctx(**overrides):
            # Postgresql reports an error for IN/NOT IN (), so convert to
            # the equivalent boolean expression.
            op_in = self.op == OP.IN or self.op == OP.NOT_IN
            if op_in and ctx.as_new().parse(self.rhs)[0] == '()':
                return ctx.literal('0 = 1' if self.op == OP.IN else '1 = 1')
            rhs = self.rhs
            if rhs is None and (self.op == OP.IS or self.op == OP.IS_NOT):
                rhs = SQL('NULL')

            return (ctx
                    .sql(self.lhs)
                    .literal(' %s ' % op_sql)
                    .sql(rhs))


class StringExpression(Expression):
    def __add__(self, rhs):
        return self.concat(rhs)
    def __radd__(self, lhs):
        return StringExpression(lhs, OP.CONCAT, self)


class Entity(ColumnBase):
    def __init__(self, *path):
        self._path = [part.replace('"', '""') for part in path if part]

    def __getattr__(self, attr):
        return Entity(*self._path + [attr])

    def get_sort_key(self, ctx):
        return tuple(self._path)

    def __hash__(self):
        return hash((self.__class__.__name__, tuple(self._path)))

    def __sql__(self, ctx):
        return ctx.literal(quote(self._path, ctx.state.quote or '""'))


class SQL(ColumnBase):
    def __init__(self, sql, params=None):
        self.sql = sql
        self.params = params

    def __sql__(self, ctx):
        ctx.literal(self.sql)
        if self.params:
            for param in self.params:
                ctx.value(param, False, add_param=False)
        return ctx


def Check(constraint, name=None):
    check = SQL('CHECK (%s)' % constraint)
    if not name:
        return check
    return NodeList((SQL('CONSTRAINT'), Entity(name), check))


class Function(ColumnBase):
    no_coerce_functions = set(('sum', 'count', 'avg', 'cast', 'array_agg'))

    def __init__(self, name, arguments, coerce=True, python_value=None):
        self.name = name
        self.arguments = arguments
        self._filter = None
        self._order_by = None
        self._python_value = python_value
        if name and name.lower() in self.no_coerce_functions:
            self._coerce = False
        else:
            self._coerce = coerce

    def __getattr__(self, attr):
        def decorator(*args, **kwargs):
            return Function(attr, args, **kwargs)
        return decorator

    @Node.copy
    def filter(self, where=None):
        self._filter = where

    @Node.copy
    def order_by(self, *ordering):
        self._order_by = ordering

    @Node.copy
    def python_value(self, func=None):
        self._python_value = func

    def over(self, partition_by=None, order_by=None, start=None, end=None,
             frame_type=None, window=None, exclude=None):
        if isinstance(partition_by, Window) and window is None:
            window = partition_by

        if window is not None:
            node = WindowAlias(window)
        else:
            node = Window(partition_by=partition_by, order_by=order_by,
                          start=start, end=end, frame_type=frame_type,
                          exclude=exclude, _inline=True)
        return NodeList((self, SQL('OVER'), node))

    def __sql__(self, ctx):
        ctx.literal(self.name)
        if not len(self.arguments):
            ctx.literal('()')
        else:
            args = self.arguments

            # If this is an ordered aggregate, then we will modify the last
            # argument to append the ORDER BY ... clause. We do this to avoid
            # double-wrapping any expression args in parentheses, as NodeList
            # has a special check (hack) in place to work around this.
            if self._order_by:
                args = list(args)
                args[-1] = NodeList((args[-1], SQL('ORDER BY'),
                                     CommaNodeList(self._order_by)))

            with ctx(in_function=True, function_arg_count=len(self.arguments)):
                ctx.sql(EnclosedNodeList([
                    (arg if isinstance(arg, Node) else Value(arg, False))
                    for arg in args]))

        if self._filter:
            ctx.literal(' FILTER (WHERE ').sql(self._filter).literal(')')
        return ctx


fn = Function(None, None)


class Window(Node):
    # Frame start/end and frame exclusion.
    CURRENT_ROW = SQL('CURRENT ROW')
    GROUP = SQL('GROUP')
    TIES = SQL('TIES')
    NO_OTHERS = SQL('NO OTHERS')

    # Frame types.
    GROUPS = 'GROUPS'
    RANGE = 'RANGE'
    ROWS = 'ROWS'

    def __init__(self, partition_by=None, order_by=None, start=None, end=None,
                 frame_type=None, extends=None, exclude=None, alias=None,
                 _inline=False):
        super(Window, self).__init__()
        if start is not None and not isinstance(start, SQL):
            start = SQL(start)
        if end is not None and not isinstance(end, SQL):
            end = SQL(end)

        self.partition_by = ensure_tuple(partition_by)
        self.order_by = ensure_tuple(order_by)
        self.start = start
        self.end = end
        if self.start is None and self.end is not None:
            raise ValueError('Cannot specify WINDOW end without start.')
        self._alias = alias or 'w'
        self._inline = _inline
        self.frame_type = frame_type
        self._extends = extends
        self._exclude = exclude

    def alias(self, alias=None):
        self._alias = alias or 'w'
        return self

    @Node.copy
    def as_range(self):
        self.frame_type = Window.RANGE

    @Node.copy
    def as_rows(self):
        self.frame_type = Window.ROWS

    @Node.copy
    def as_groups(self):
        self.frame_type = Window.GROUPS

    @Node.copy
    def extends(self, window=None):
        self._extends = window

    @Node.copy
    def exclude(self, frame_exclusion=None):
        if isinstance(frame_exclusion, basestring):
            frame_exclusion = SQL(frame_exclusion)
        self._exclude = frame_exclusion

    @staticmethod
    def following(value=None):
        if value is None:
            return SQL('UNBOUNDED FOLLOWING')
        return SQL('%d FOLLOWING' % value)

    @staticmethod
    def preceding(value=None):
        if value is None:
            return SQL('UNBOUNDED PRECEDING')
        return SQL('%d PRECEDING' % value)

    def __sql__(self, ctx):
        if ctx.scope != SCOPE_SOURCE and not self._inline:
            ctx.literal(self._alias)
            ctx.literal(' AS ')

        with ctx(parentheses=True):
            parts = []
            if self._extends is not None:
                ext = self._extends
                if isinstance(ext, Window):
                    ext = SQL(ext._alias)
                elif isinstance(ext, basestring):
                    ext = SQL(ext)
                parts.append(ext)
            if self.partition_by:
                parts.extend((
                    SQL('PARTITION BY'),
                    CommaNodeList(self.partition_by)))
            if self.order_by:
                parts.extend((
                    SQL('ORDER BY'),
                    CommaNodeList(self.order_by)))
            if self.start is not None and self.end is not None:
                frame = self.frame_type or 'ROWS'
                parts.extend((
                    SQL('%s BETWEEN' % frame),
                    self.start,
                    SQL('AND'),
                    self.end))
            elif self.start is not None:
                parts.extend((SQL(self.frame_type or 'ROWS'), self.start))
            elif self.frame_type is not None:
                parts.append(SQL('%s UNBOUNDED PRECEDING' % self.frame_type))
            if self._exclude is not None:
                parts.extend((SQL('EXCLUDE'), self._exclude))
            ctx.sql(NodeList(parts))
        return ctx


class WindowAlias(Node):
    def __init__(self, window):
        self.window = window

    def alias(self, window_alias):
        self.window._alias = window_alias
        return self

    def __sql__(self, ctx):
        return ctx.literal(self.window._alias or 'w')


class _InFunction(Node):
    def __init__(self, node, in_function=True):
        self.node = node
        self.in_function = in_function

    def __sql__(self, ctx):
        with ctx(in_function=self.in_function):
            return ctx.sql(self.node)


class Case(ColumnBase):
    def __init__(self, predicate, expression_tuples, default=None):
        self.predicate = predicate
        self.expression_tuples = expression_tuples
        self.default = default

    def __sql__(self, ctx):
        clauses = [SQL('CASE')]
        if self.predicate is not None:
            clauses.append(self.predicate)
        for expr, value in self.expression_tuples:
            clauses.extend((SQL('WHEN'), expr,
                            SQL('THEN'), _InFunction(value)))
        if self.default is not None:
            clauses.extend((SQL('ELSE'), _InFunction(self.default)))
        clauses.append(SQL('END'))
        with ctx(in_function=False):
            return ctx.sql(NodeList(clauses))


class ForUpdate(Node):
    def __init__(self, expr, of=None, nowait=None):
        expr = 'FOR UPDATE' if expr is True else expr
        if expr.lower().endswith('nowait'):
            expr = expr[:-7]  # Strip off the "nowait" bit.
            nowait = True

        self._expr = expr
        if of is not None and not isinstance(of, (list, set, tuple)):
            of = (of,)
        self._of = of
        self._nowait = nowait

    def __sql__(self, ctx):
        ctx.literal(self._expr)
        if self._of is not None:
            ctx.literal(' OF ').sql(CommaNodeList(self._of))
        if self._nowait:
            ctx.literal(' NOWAIT')
        return ctx


class NodeList(ColumnBase):
    def __init__(self, nodes, glue=' ', parens=False):
        self.nodes = nodes
        self.glue = glue
        self.parens = parens
        if parens and len(self.nodes) == 1 and \
           isinstance(self.nodes[0], Expression) and \
           not self.nodes[0].flat:
            # Hack to avoid double-parentheses.
            self.nodes = (self.nodes[0].clone(),)
            self.nodes[0].flat = True

    def __sql__(self, ctx):
        n_nodes = len(self.nodes)
        if n_nodes == 0:
            return ctx.literal('()') if self.parens else ctx
        with ctx(parentheses=self.parens):
            for i in range(n_nodes - 1):
                ctx.sql(self.nodes[i])
                ctx.literal(self.glue)
            ctx.sql(self.nodes[n_nodes - 1])
        return ctx


def CommaNodeList(nodes):
    return NodeList(nodes, ', ')


def EnclosedNodeList(nodes):
    return NodeList(nodes, ', ', True)


class _Namespace(Node):
    __slots__ = ('_name',)
    def __init__(self, name):
        self._name = name
    def __getattr__(self, attr):
        return NamespaceAttribute(self, attr)
    __getitem__ = __getattr__

class NamespaceAttribute(ColumnBase):
    def __init__(self, namespace, attribute):
        self._namespace = namespace
        self._attribute = attribute

    def __sql__(self, ctx):
        return (ctx
                .literal(self._namespace._name + '.')
                .sql(Entity(self._attribute)))

EXCLUDED = _Namespace('EXCLUDED')


class DQ(ColumnBase):
    def __init__(self, **query):
        super(DQ, self).__init__()
        self.query = query
        self._negated = False

    @Node.copy
    def __invert__(self):
        self._negated = not self._negated

    def clone(self):
        node = DQ(**self.query)
        node._negated = self._negated
        return node

#: Represent a row tuple.
Tuple = lambda *a: EnclosedNodeList(a)


class QualifiedNames(WrappedNode):
    def __sql__(self, ctx):
        with ctx.scope_column():
            return ctx.sql(self.node)


def qualify_names(node):
    # Search a node heirarchy to ensure that any column-like objects are
    # referenced using fully-qualified names.
    if isinstance(node, Expression):
        return node.__class__(qualify_names(node.lhs), node.op,
                              qualify_names(node.rhs), node.flat)
    elif isinstance(node, ColumnBase):
        return QualifiedNames(node)
    return node


class OnConflict(Node):
    def __init__(self, action=None, update=None, preserve=None, where=None,
                 conflict_target=None, conflict_where=None,
                 conflict_constraint=None):
        self._action = action
        self._update = update
        self._preserve = ensure_tuple(preserve)
        self._where = where
        if conflict_target is not None and conflict_constraint is not None:
            raise ValueError('only one of "conflict_target" and '
                             '"conflict_constraint" may be specified.')
        self._conflict_target = ensure_tuple(conflict_target)
        self._conflict_where = conflict_where
        self._conflict_constraint = conflict_constraint

    def get_conflict_statement(self, ctx, query):
        return ctx.state.conflict_statement(self, query)

    def get_conflict_update(self, ctx, query):
        return ctx.state.conflict_update(self, query)

    @Node.copy
    def preserve(self, *columns):
        self._preserve = columns

    @Node.copy
    def update(self, _data=None, **kwargs):
        if _data and kwargs and not isinstance(_data, dict):
            raise ValueError('Cannot mix data with keyword arguments in the '
                             'OnConflict update method.')
        _data = _data or {}
        if kwargs:
            _data.update(kwargs)
        self._update = _data

    @Node.copy
    def where(self, *expressions):
        if self._where is not None:
            expressions = (self._where,) + expressions
        self._where = reduce(operator.and_, expressions)

    @Node.copy
    def conflict_target(self, *constraints):
        self._conflict_constraint = None
        self._conflict_target = constraints

    @Node.copy
    def conflict_where(self, *expressions):
        if self._conflict_where is not None:
            expressions = (self._conflict_where,) + expressions
        self._conflict_where = reduce(operator.and_, expressions)

    @Node.copy
    def conflict_constraint(self, constraint):
        self._conflict_constraint = constraint
        self._conflict_target = None


def database_required(method):
    @wraps(method)
    def inner(self, database=None, *args, **kwargs):
        database = self._database if database is None else database
        if not database:
            raise InterfaceError('Query must be bound to a database in order '
                                 'to call "%s".' % method.__name__)
        return method(self, database, *args, **kwargs)
    return inner

# BASE QUERY INTERFACE.

class BaseQuery(Node):
    default_row_type = ROW.DICT

    def __init__(self, _database=None, **kwargs):
        self._database = _database
        self._cursor_wrapper = None
        self._row_type = None
        self._constructor = None
        super(BaseQuery, self).__init__(**kwargs)

    def bind(self, database=None):
        self._database = database
        return self

    def clone(self):
        query = super(BaseQuery, self).clone()
        query._cursor_wrapper = None
        return query

    @Node.copy
    def dicts(self, as_dict=True):
        self._row_type = ROW.DICT if as_dict else None
        return self

    @Node.copy
    def tuples(self, as_tuple=True):
        self._row_type = ROW.TUPLE if as_tuple else None
        return self

    @Node.copy
    def namedtuples(self, as_namedtuple=True):
        self._row_type = ROW.NAMED_TUPLE if as_namedtuple else None
        return self

    @Node.copy
    def objects(self, constructor=None):
        self._row_type = ROW.CONSTRUCTOR if constructor else None
        self._constructor = constructor
        return self

    def _get_cursor_wrapper(self, cursor):
        row_type = self._row_type or self.default_row_type

        if row_type == ROW.DICT:
            return DictCursorWrapper(cursor)
        elif row_type == ROW.TUPLE:
            return CursorWrapper(cursor)
        elif row_type == ROW.NAMED_TUPLE:
            return NamedTupleCursorWrapper(cursor)
        elif row_type == ROW.CONSTRUCTOR:
            return ObjectCursorWrapper(cursor, self._constructor)
        else:
            raise ValueError('Unrecognized row type: "%s".' % row_type)

    def __sql__(self, ctx):
        raise NotImplementedError

    def sql(self):
        if self._database:
            context = self._database.get_sql_context()
        else:
            context = Context()
        return context.parse(self)

    @database_required
    def execute(self, database):
        return self._execute(database)

    def _execute(self, database):
        raise NotImplementedError

    def iterator(self, database=None):
        return iter(self.execute(database).iterator())

    def _ensure_execution(self):
        if self._cursor_wrapper is None:
            if not self._database:
                raise ValueError('Query has not been executed.')
            self.execute()

    def __iter__(self):
        self._ensure_execution()
        return iter(self._cursor_wrapper)

    def __getitem__(self, value):
        self._ensure_execution()
        if isinstance(value, slice):
            index = value.stop
        else:
            index = value
        if index is not None:
            index = index + 1 if index >= 0 else 0
        self._cursor_wrapper.fill_cache(index)
        return self._cursor_wrapper.row_cache[value]

    def __len__(self):
        self._ensure_execution()
        return len(self._cursor_wrapper)

    def __str__(self):
        return query_to_string(self)


class RawQuery(BaseQuery):
    def __init__(self, sql=None, params=None, **kwargs):
        super(RawQuery, self).__init__(**kwargs)
        self._sql = sql
        self._params = params

    def __sql__(self, ctx):
        ctx.literal(self._sql)
        if self._params:
            for param in self._params:
                ctx.value(param, add_param=False)
        return ctx

    def _execute(self, database):
        if self._cursor_wrapper is None:
            cursor = database.execute(self)
            self._cursor_wrapper = self._get_cursor_wrapper(cursor)
        return self._cursor_wrapper


class Query(BaseQuery):
    def __init__(self, where=None, order_by=None, limit=None, offset=None,
                 **kwargs):
        super(Query, self).__init__(**kwargs)
        self._where = where
        self._order_by = order_by
        self._limit = limit
        self._offset = offset

        self._cte_list = None

    @Node.copy
    def with_cte(self, *cte_list):
        self._cte_list = cte_list

    @Node.copy
    def where(self, *expressions):
        if self._where is not None:
            expressions = (self._where,) + expressions
        self._where = reduce(operator.and_, expressions)

    @Node.copy
    def orwhere(self, *expressions):
        if self._where is not None:
            expressions = (self._where,) + expressions
        self._where = reduce(operator.or_, expressions)

    @Node.copy
    def order_by(self, *values):
        self._order_by = values

    @Node.copy
    def order_by_extend(self, *values):
        self._order_by = ((self._order_by or ()) + values) or None

    @Node.copy
    def limit(self, value=None):
        self._limit = value

    @Node.copy
    def offset(self, value=None):
        self._offset = value

    @Node.copy
    def paginate(self, page, paginate_by=20):
        if page > 0:
            page -= 1
        self._limit = paginate_by
        self._offset = page * paginate_by

    def _apply_ordering(self, ctx):
        if self._order_by:
            (ctx
             .literal(' ORDER BY ')
             .sql(CommaNodeList(self._order_by)))
        if self._limit is not None or (self._offset is not None and
                                       ctx.state.limit_max):
            limit = ctx.state.limit_max if self._limit is None else self._limit
            ctx.literal(' LIMIT ').sql(limit)
        if self._offset is not None:
            ctx.literal(' OFFSET ').sql(self._offset)
        return ctx

    def __sql__(self, ctx):
        if self._cte_list:
            # The CTE scope is only used at the very beginning of the query,
            # when we are describing the various CTEs we will be using.
            recursive = any(cte._recursive for cte in self._cte_list)

            # Explicitly disable the "subquery" flag here, so as to avoid
            # unnecessary parentheses around subsequent selects.
            with ctx.scope_cte(subquery=False):
                (ctx
                 .literal('WITH RECURSIVE ' if recursive else 'WITH ')
                 .sql(CommaNodeList(self._cte_list))
                 .literal(' '))
        return ctx


def __compound_select__(operation, inverted=False):
    @__bind_database__
    def method(self, other):
        if inverted:
            self, other = other, self
        return CompoundSelectQuery(self, operation, other)
    return method


class SelectQuery(Query):
    union_all = __add__ = __compound_select__('UNION ALL')
    union = __or__ = __compound_select__('UNION')
    intersect = __and__ = __compound_select__('INTERSECT')
    except_ = __sub__ = __compound_select__('EXCEPT')
    __radd__ = __compound_select__('UNION ALL', inverted=True)
    __ror__ = __compound_select__('UNION', inverted=True)
    __rand__ = __compound_select__('INTERSECT', inverted=True)
    __rsub__ = __compound_select__('EXCEPT', inverted=True)

    def select_from(self, *columns):
        if not columns:
            raise ValueError('select_from() must specify one or more columns.')

        query = (Select((self,), columns)
                 .bind(self._database))
        if getattr(self, 'model', None) is not None:
            # Bind to the sub-select's model type, if defined.
            query = query.objects(self.model)
        return query


class SelectBase(_HashableSource, Source, SelectQuery):
    def _get_hash(self):
        return hash((self.__class__, self._alias or id(self)))

    def _execute(self, database):
        if self._cursor_wrapper is None:
            cursor = database.execute(self)
            self._cursor_wrapper = self._get_cursor_wrapper(cursor)
        return self._cursor_wrapper

    @database_required
    def peek(self, database, n=1):
        rows = self.execute(database)[:n]
        if rows:
            return rows[0] if n == 1 else rows

    @database_required
    def first(self, database, n=1):
        if self._limit != n:
            self._limit = n
            self._cursor_wrapper = None
        return self.peek(database, n=n)

    @database_required
    def scalar(self, database, as_tuple=False, as_dict=False):
        if as_dict:
            return self.dicts().peek(database)
        row = self.tuples().peek(database)
        return row[0] if row and not as_tuple else row

    @database_required
    def scalars(self, database):
        for row in self.tuples().execute(database):
            yield row[0]

    @database_required
    def count(self, database, clear_limit=False):
        clone = self.order_by().alias('_wrapped')
        if clear_limit:
            clone._limit = clone._offset = None
        try:
            if clone._having is None and clone._group_by is None and \
               clone._windows is None and clone._distinct is None and \
               clone._simple_distinct is not True:
                clone = clone.select(SQL('1'))
        except AttributeError:
            pass
        return Select([clone], [fn.COUNT(SQL('1'))]).scalar(database)

    @database_required
    def exists(self, database):
        clone = self.columns(SQL('1'))
        clone._limit = 1
        clone._offset = None
        return bool(clone.scalar())

    @database_required
    def get(self, database):
        self._cursor_wrapper = None
        try:
            return self.execute(database)[0]
        except IndexError:
            pass


# QUERY IMPLEMENTATIONS.


class CompoundSelectQuery(SelectBase):
    def __init__(self, lhs, op, rhs):
        super(CompoundSelectQuery, self).__init__()
        self.lhs = lhs
        self.op = op
        self.rhs = rhs

    @property
    def _returning(self):
        return self.lhs._returning

    @database_required
    def exists(self, database):
        query = Select((self.limit(1),), (SQL('1'),)).bind(database)
        return bool(query.scalar())

    def _get_query_key(self):
        return (self.lhs.get_query_key(), self.rhs.get_query_key())

    def _wrap_parens(self, ctx, subq):
        csq_setting = ctx.state.compound_select_parentheses

        if not csq_setting or csq_setting == CSQ_PARENTHESES_NEVER:
            return False
        elif csq_setting == CSQ_PARENTHESES_ALWAYS:
            return True
        elif csq_setting == CSQ_PARENTHESES_UNNESTED:
            if ctx.state.in_expr or ctx.state.in_function:
                # If this compound select query is being used inside an
                # expression, e.g., an IN or EXISTS().
                return False

            # If the query on the left or right is itself a compound select
            # query, then we do not apply parentheses. However, if it is a
            # regular SELECT query, we will apply parentheses.
            return not isinstance(subq, CompoundSelectQuery)

    def __sql__(self, ctx):
        if ctx.scope == SCOPE_COLUMN:
            return self.apply_column(ctx)

        # Call parent method to handle any CTEs.
        super(CompoundSelectQuery, self).__sql__(ctx)

        outer_parens = ctx.subquery or (ctx.scope == SCOPE_SOURCE)
        with ctx(parentheses=outer_parens):
            # Should the left-hand query be wrapped in parentheses?
            lhs_parens = self._wrap_parens(ctx, self.lhs)
            with ctx.scope_normal(parentheses=lhs_parens, subquery=False):
                ctx.sql(self.lhs)
            ctx.literal(' %s ' % self.op)
            with ctx.push_alias():
                # Should the right-hand query be wrapped in parentheses?
                rhs_parens = self._wrap_parens(ctx, self.rhs)
                with ctx.scope_normal(parentheses=rhs_parens, subquery=False):
                    ctx.sql(self.rhs)

            # Apply ORDER BY, LIMIT, OFFSET. We use the "values" scope so that
            # entity names are not fully-qualified. This is a bit of a hack, as
            # we're relying on the logic in Column.__sql__() to not fully
            # qualify column names.
            with ctx.scope_values():
                self._apply_ordering(ctx)

        return self.apply_alias(ctx)


class Select(SelectBase):
    def __init__(self, from_list=None, columns=None, group_by=None,
                 having=None, distinct=None, windows=None, for_update=None,
                 for_update_of=None, nowait=None, lateral=None, **kwargs):
        super(Select, self).__init__(**kwargs)
        self._from_list = (list(from_list) if isinstance(from_list, tuple)
                           else from_list) or []
        self._returning = columns
        self._group_by = group_by
        self._having = having
        self._windows = None
        self._for_update = for_update  # XXX: consider reorganizing.
        self._for_update_of = for_update_of
        self._for_update_nowait = nowait
        self._lateral = lateral

        self._distinct = self._simple_distinct = None
        if distinct:
            if isinstance(distinct, bool):
                self._simple_distinct = distinct
            else:
                self._distinct = distinct

        self._cursor_wrapper = None

    def clone(self):
        clone = super(Select, self).clone()
        if clone._from_list:
            clone._from_list = list(clone._from_list)
        return clone

    @Node.copy
    def columns(self, *columns, **kwargs):
        self._returning = columns
    select = columns

    @Node.copy
    def select_extend(self, *columns):
        self._returning = tuple(self._returning) + columns

    @property
    def selected_columns(self):
        return self._returning
    @selected_columns.setter
    def selected_columns(self, value):
        self._returning = value

    @Node.copy
    def from_(self, *sources):
        self._from_list = list(sources)

    @Node.copy
    def join(self, dest, join_type=JOIN.INNER, on=None):
        if not self._from_list:
            raise ValueError('No sources to join on.')
        item = self._from_list.pop()
        self._from_list.append(Join(item, dest, join_type, on))

    def left_outer_join(self, dest, on=None):
        return self.join(dest, JOIN.LEFT_OUTER, on)

    @Node.copy
    def group_by(self, *columns):
        grouping = []
        for column in columns:
            if isinstance(column, Table):
                if not column._columns:
                    raise ValueError('Cannot pass a table to group_by() that '
                                     'does not have columns explicitly '
                                     'declared.')
                grouping.extend([getattr(column, col_name)
                                 for col_name in column._columns])
            else:
                grouping.append(column)
        self._group_by = grouping

    def group_by_extend(self, *values):
        """@Node.copy used from group_by() call"""
        group_by = tuple(self._group_by or ()) + values
        return self.group_by(*group_by)

    @Node.copy
    def having(self, *expressions):
        if self._having is not None:
            expressions = (self._having,) + expressions
        self._having = reduce(operator.and_, expressions)

    @Node.copy
    def distinct(self, *columns):
        if len(columns) == 1 and (columns[0] is True or columns[0] is False):
            self._simple_distinct = columns[0]
        else:
            self._simple_distinct = False
            self._distinct = columns

    @Node.copy
    def window(self, *windows):
        self._windows = windows if windows else None

    @Node.copy
    def for_update(self, for_update=True, of=None, nowait=None):
        if not for_update and (of is not None or nowait):
            for_update = True
        self._for_update = for_update
        self._for_update_of = of
        self._for_update_nowait = nowait

    @Node.copy
    def lateral(self, lateral=True):
        self._lateral = lateral

    def _get_query_key(self):
        return self._alias

    def __sql_selection__(self, ctx, is_subquery=False):
        return ctx.sql(CommaNodeList(self._returning))

    def __sql__(self, ctx):
        if ctx.scope == SCOPE_COLUMN:
            return self.apply_column(ctx)

        if self._lateral and ctx.scope == SCOPE_SOURCE:
            ctx.literal('LATERAL ')

        is_subquery = ctx.subquery
        state = {
            'converter': None,
            'in_function': False,
            'parentheses': is_subquery or (ctx.scope == SCOPE_SOURCE),
            'subquery': True,
        }
        if ctx.state.in_function and ctx.state.function_arg_count == 1:
            state['parentheses'] = False

        with ctx.scope_normal(**state):
            # Defer calling parent SQL until here. This ensures that any CTEs
            # for this query will be properly nested if this query is a
            # sub-select or is used in an expression. See GH#1809 for example.
            super(Select, self).__sql__(ctx)

            ctx.literal('SELECT ')
            if self._simple_distinct or self._distinct is not None:
                ctx.literal('DISTINCT ')
                if self._distinct:
                    (ctx
                     .literal('ON ')
                     .sql(EnclosedNodeList(self._distinct))
                     .literal(' '))

            with ctx.scope_source():
                ctx = self.__sql_selection__(ctx, is_subquery)

            if self._from_list:
                with ctx.scope_source(parentheses=False):
                    ctx.literal(' FROM ').sql(CommaNodeList(self._from_list))

            if self._where is not None:
                ctx.literal(' WHERE ').sql(self._where)

            if self._group_by:
                ctx.literal(' GROUP BY ').sql(CommaNodeList(self._group_by))

            if self._having is not None:
                ctx.literal(' HAVING ').sql(self._having)

            if self._windows is not None:
                ctx.literal(' WINDOW ')
                ctx.sql(CommaNodeList(self._windows))

            # Apply ORDER BY, LIMIT, OFFSET.
            self._apply_ordering(ctx)

            if self._for_update:
                if not ctx.state.for_update:
                    raise ValueError('FOR UPDATE specified but not supported '
                                     'by database.')
                ctx.literal(' ')
                ctx.sql(ForUpdate(self._for_update, self._for_update_of,
                                  self._for_update_nowait))

        # If the subquery is inside a function -or- we are evaluating a
        # subquery on either side of an expression w/o an explicit alias, do
        # not generate an alias + AS clause.
        if ctx.state.in_function or (ctx.state.in_expr and
                                     self._alias is None):
            return ctx

        return self.apply_alias(ctx)


class _WriteQuery(Query):
    def __init__(self, table, returning=None, **kwargs):
        self.table = table
        self._returning = returning
        self._return_cursor = True if returning else False
        super(_WriteQuery, self).__init__(**kwargs)

    def cte(self, name, recursive=False, columns=None, materialized=None):
        return CTE(name, self, recursive=recursive, columns=columns,
                   materialized=materialized)

    @Node.copy
    def returning(self, *returning):
        self._returning = returning
        self._return_cursor = True if returning else False

    def apply_returning(self, ctx):
        if self._returning:
            with ctx.scope_source():
                ctx.literal(' RETURNING ').sql(CommaNodeList(self._returning))
        return ctx

    def _execute(self, database):
        if self._returning:
            cursor = self.execute_returning(database)
        else:
            cursor = database.execute(self)
        return self.handle_result(database, cursor)

    def execute_returning(self, database):
        if self._cursor_wrapper is None:
            cursor = database.execute(self)
            self._cursor_wrapper = self._get_cursor_wrapper(cursor)
        return self._cursor_wrapper

    def handle_result(self, database, cursor):
        if self._return_cursor:
            return cursor
        return database.rows_affected(cursor)

    def _set_table_alias(self, ctx):
        ctx.alias_manager[self.table] = self.table.__name__

    def __sql__(self, ctx):
        super(_WriteQuery, self).__sql__(ctx)
        # We explicitly set the table alias to the table's name, which ensures
        # that if a sub-select references a column on the outer table, we won't
        # assign it a new alias (e.g. t2) but will refer to it as table.column.
        self._set_table_alias(ctx)
        return ctx


class Update(_WriteQuery):
    def __init__(self, table, update=None, **kwargs):
        super(Update, self).__init__(table, **kwargs)
        self._update = update
        self._from = None

    @Node.copy
    def from_(self, *sources):
        self._from = sources

    def __sql__(self, ctx):
        super(Update, self).__sql__(ctx)

        with ctx.scope_values(subquery=True):
            ctx.literal('UPDATE ')

            expressions = []
            for k, v in sorted(self._update.items(), key=ctx.column_sort_key):
                if not isinstance(v, Node):
                    if isinstance(k, Field):
                        v = k.to_value(v)
                    else:
                        v = Value(v, unpack=False)
                elif isinstance(v, Model) and isinstance(k, ForeignKeyField):
                    # NB: we want to ensure that when passed a model instance
                    # in the context of a foreign-key, we apply the fk-specific
                    # adaptation of the model.
                    v = k.to_value(v)

                if not isinstance(v, Value):
                    v = qualify_names(v)

                expressions.append(NodeList((k, SQL('='), v)))

            (ctx
             .sql(self.table)
             .literal(' SET ')
             .sql(CommaNodeList(expressions)))

            if self._from:
                with ctx.scope_source(parentheses=False):
                    ctx.literal(' FROM ').sql(CommaNodeList(self._from))

            if self._where:
                with ctx.scope_normal():
                    ctx.literal(' WHERE ').sql(self._where)
            self._apply_ordering(ctx)
            return self.apply_returning(ctx)


class Insert(_WriteQuery):
    SIMPLE = 0
    QUERY = 1
    MULTI = 2
    class DefaultValuesException(Exception): pass

    def __init__(self, table, insert=None, columns=None, on_conflict=None,
                 **kwargs):
        super(Insert, self).__init__(table, **kwargs)
        self._insert = insert
        self._columns = columns
        self._on_conflict = on_conflict
        self._query_type = None
        self._as_rowcount = False

    def where(self, *expressions):
        raise NotImplementedError('INSERT queries cannot have a WHERE clause.')

    @Node.copy
    def as_rowcount(self, _as_rowcount=True):
        self._as_rowcount = _as_rowcount

    @Node.copy
    def on_conflict_ignore(self, ignore=True):
        self._on_conflict = OnConflict('IGNORE') if ignore else None

    @Node.copy
    def on_conflict_replace(self, replace=True):
        self._on_conflict = OnConflict('REPLACE') if replace else None

    @Node.copy
    def on_conflict(self, *args, **kwargs):
        self._on_conflict = (OnConflict(*args, **kwargs) if (args or kwargs)
                             else None)

    def _simple_insert(self, ctx):
        if not self._insert:
            raise self.DefaultValuesException('Error: no data to insert.')
        return self._generate_insert((self._insert,), ctx)

    def get_default_data(self):
        return {}

    def get_default_columns(self):
        if self.table._columns:
            return [getattr(self.table, col) for col in self.table._columns
                    if col != self.table._primary_key]

    def _generate_insert(self, insert, ctx):
        rows_iter = iter(insert)
        columns = self._columns

        # Load and organize column defaults (if provided).
        defaults = self.get_default_data()

        # First figure out what columns are being inserted (if they weren't
        # specified explicitly). Resulting columns are normalized and ordered.
        if not columns:
            try:
                row = next(rows_iter)
            except StopIteration:
                raise self.DefaultValuesException('Error: no rows to insert.')

            if not isinstance(row, Mapping):
                columns = self.get_default_columns()
                if columns is None:
                    raise ValueError('Bulk insert must specify columns.')
            else:
                # Infer column names from the dict of data being inserted.
                accum = []
                for column in row:
                    if isinstance(column, basestring):
                        column = getattr(self.table, column)
                    accum.append(column)

                # Add any columns present in the default data that are not
                # accounted for by the dictionary of row data.
                column_set = set(accum)
                for col in (set(defaults) - column_set):
                    accum.append(col)

                columns = sorted(accum, key=lambda obj: obj.get_sort_key(ctx))
            rows_iter = itertools.chain(iter((row,)), rows_iter)
        else:
            clean_columns = []
            seen = set()
            for column in columns:
                if isinstance(column, basestring):
                    column_obj = getattr(self.table, column)
                else:
                    column_obj = column
                clean_columns.append(column_obj)
                seen.add(column_obj)

            columns = clean_columns
            for col in sorted(defaults, key=lambda obj: obj.get_sort_key(ctx)):
                if col not in seen:
                    columns.append(col)

        fk_fields = set()
        nullable_columns = set()
        value_lookups = {}
        for column in columns:
            lookups = [column, column.name]
            if isinstance(column, Field):
                if column.name != column.column_name:
                    lookups.append(column.column_name)
                if column.null:
                    nullable_columns.add(column)
                if isinstance(column, ForeignKeyField):
                    fk_fields.add(column)
            value_lookups[column] = lookups

        ctx.sql(EnclosedNodeList(columns)).literal(' VALUES ')
        columns_converters = [
            (column, column.db_value if isinstance(column, Field) else None)
            for column in columns]

        all_values = []
        for row in rows_iter:
            values = []
            is_dict = isinstance(row, Mapping)
            for i, (column, converter) in enumerate(columns_converters):
                try:
                    if is_dict:
                        # The logic is a bit convoluted, but in order to be
                        # flexible in what we accept (dict keyed by
                        # column/field, field name, or underlying column name),
                        # we try accessing the row data dict using each
                        # possible key. If no match is found, throw an error.
                        for lookup in value_lookups[column]:
                            try:
                                val = row[lookup]
                            except KeyError: pass
                            else: break
                        else:
                            raise KeyError
                    else:
                        val = row[i]
                except (KeyError, IndexError):
                    if column in defaults:
                        val = defaults[column]
                        if callable_(val):
                            val = val()
                    elif column in nullable_columns:
                        val = None
                    else:
                        raise ValueError('Missing value for %s.' % column.name)

                if not isinstance(val, Node) or (isinstance(val, Model) and
                                                 column in fk_fields):
                    val = Value(val, converter=converter, unpack=False)
                values.append(val)

            all_values.append(EnclosedNodeList(values))

        if not all_values:
            raise self.DefaultValuesException('Error: no data to insert.')

        with ctx.scope_values(subquery=True):
            return ctx.sql(CommaNodeList(all_values))

    def _query_insert(self, ctx):
        return (ctx
                .sql(EnclosedNodeList(self._columns))
                .literal(' ')
                .sql(self._insert))

    def _default_values(self, ctx):
        if not self._database:
            return ctx.literal('DEFAULT VALUES')
        return self._database.default_values_insert(ctx)

    def __sql__(self, ctx):
        super(Insert, self).__sql__(ctx)
        with ctx.scope_values():
            stmt = None
            if self._on_conflict is not None:
                stmt = self._on_conflict.get_conflict_statement(ctx, self)

            (ctx
             .sql(stmt or SQL('INSERT'))
             .literal(' INTO ')
             .sql(self.table)
             .literal(' '))

            if isinstance(self._insert, Mapping) and not self._columns:
                try:
                    self._simple_insert(ctx)
                except self.DefaultValuesException:
                    self._default_values(ctx)
                self._query_type = Insert.SIMPLE
            elif isinstance(self._insert, (SelectQuery, SQL)):
                self._query_insert(ctx)
                self._query_type = Insert.QUERY
            else:
                self._generate_insert(self._insert, ctx)
                self._query_type = Insert.MULTI

            if self._on_conflict is not None:
                update = self._on_conflict.get_conflict_update(ctx, self)
                if update is not None:
                    ctx.literal(' ').sql(update)

            return self.apply_returning(ctx)

    def _execute(self, database):
        if self._returning is None and database.returning_clause \
           and self.table._primary_key:
            self._returning = (self.table._primary_key,)
        try:
            return super(Insert, self)._execute(database)
        except self.DefaultValuesException:
            pass

    def handle_result(self, database, cursor):
        if self._return_cursor:
            return cursor
        if self._as_rowcount:
            return database.rows_affected(cursor)
        return database.last_insert_id(cursor, self._query_type)


class Delete(_WriteQuery):
    def __sql__(self, ctx):
        super(Delete, self).__sql__(ctx)

        with ctx.scope_values(subquery=True):
            ctx.literal('DELETE FROM ').sql(self.table)
            if self._where is not None:
                with ctx.scope_normal():
                    ctx.literal(' WHERE ').sql(self._where)

            self._apply_ordering(ctx)
            return self.apply_returning(ctx)


class Index(Node):
    def __init__(self, name, table, expressions, unique=False, safe=False,
                 where=None, using=None):
        self._name = name
        self._table = Entity(table) if not isinstance(table, Table) else table
        self._expressions = expressions
        self._where = where
        self._unique = unique
        self._safe = safe
        self._using = using

    @Node.copy
    def safe(self, _safe=True):
        self._safe = _safe

    @Node.copy
    def where(self, *expressions):
        if self._where is not None:
            expressions = (self._where,) + expressions
        self._where = reduce(operator.and_, expressions)

    @Node.copy
    def using(self, _using=None):
        self._using = _using

    def __sql__(self, ctx):
        statement = 'CREATE UNIQUE INDEX ' if self._unique else 'CREATE INDEX '
        with ctx.scope_values(subquery=True):
            ctx.literal(statement)
            if self._safe:
                ctx.literal('IF NOT EXISTS ')

            # Sqlite uses CREATE INDEX <schema>.<name> ON <table>, whereas most
            # others use: CREATE INDEX <name> ON <schema>.<table>.
            if ctx.state.index_schema_prefix and \
               isinstance(self._table, Table) and self._table._schema:
                index_name = Entity(self._table._schema, self._name)
                table_name = Entity(self._table.__name__)
            else:
                index_name = Entity(self._name)
                table_name = self._table

            ctx.sql(index_name)
            if self._using is not None and \
               ctx.state.index_using_precedes_table:
                ctx.literal(' USING %s' % self._using)  # MySQL style.

            (ctx
             .literal(' ON ')
             .sql(table_name)
             .literal(' '))

            if self._using is not None and not \
               ctx.state.index_using_precedes_table:
                ctx.literal('USING %s ' % self._using)  # Postgres/default.

            ctx.sql(EnclosedNodeList([
                SQL(expr) if isinstance(expr, basestring) else expr
                for expr in self._expressions]))
            if self._where is not None:
                ctx.literal(' WHERE ').sql(self._where)

        return ctx


class ModelIndex(Index):
    def __init__(self, model, fields, unique=False, safe=True, where=None,
                 using=None, name=None):
        self._model = model
        if name is None:
            name = self._generate_name_from_fields(model, fields)
        if using is None:
            for field in fields:
                if isinstance(field, Field) and hasattr(field, 'index_type'):
                    using = field.index_type
        super(ModelIndex, self).__init__(
            name=name,
            table=model._meta.table,
            expressions=fields,
            unique=unique,
            safe=safe,
            where=where,
            using=using)

    def _generate_name_from_fields(self, model, fields):
        accum = []
        for field in fields:
            if isinstance(field, basestring):
                accum.append(field.split()[0])
            else:
                if isinstance(field, Node) and not isinstance(field, Field):
                    field = field.unwrap()
                if isinstance(field, Field):
                    accum.append(field.column_name)

        if not accum:
            raise ValueError('Unable to generate a name for the index, please '
                             'explicitly specify a name.')

        clean_field_names = re.sub(r'[^\w]+', '', '_'.join(accum))
        meta = model._meta
        prefix = meta.name if meta.legacy_table_names else meta.table_name
        return _truncate_constraint_name('_'.join((prefix, clean_field_names)))


def _truncate_constraint_name(constraint, maxlen=64):
    if len(constraint) > maxlen:
        name_hash = hashlib.md5(constraint.encode('utf-8')).hexdigest()
        constraint = '%s_%s' % (constraint[:(maxlen - 8)], name_hash[:7])
    return constraint


# DB-API 2.0 EXCEPTIONS.


class PeeweeException(Exception):
    def __init__(self, *args):
        if args and isinstance(args[0], Exception):
            self.orig, args = args[0], args[1:]
        super(PeeweeException, self).__init__(*args)
class ImproperlyConfigured(PeeweeException): pass
class DatabaseError(PeeweeException): pass
class DataError(DatabaseError): pass
class IntegrityError(DatabaseError): pass
class InterfaceError(PeeweeException): pass
class InternalError(DatabaseError): pass
class NotSupportedError(DatabaseError): pass
class OperationalError(DatabaseError): pass
class ProgrammingError(DatabaseError): pass


class ExceptionWrapper(object):
    __slots__ = ('exceptions',)
    def __init__(self, exceptions):
        self.exceptions = exceptions
    def __enter__(self): pass
    def __exit__(self, exc_type, exc_value, traceback):
        if exc_type is None:
            return
        # psycopg shits out a million cute error types. Try to catch em all.
        if pg_errors is not None and exc_type.__name__ not in self.exceptions \
           and issubclass(exc_type, pg_errors.Error):
            exc_type = exc_type.__bases__[0]
        elif pg3_errors is not None and \
           exc_type.__name__ not in self.exceptions \
           and issubclass(exc_type, pg3_errors.Error):
            exc_type = exc_type.__bases__[0]
        if exc_type.__name__ in self.exceptions:
            new_type = self.exceptions[exc_type.__name__]
            exc_args = exc_value.args
            reraise(new_type, new_type(exc_value, *exc_args), traceback)


EXCEPTIONS = {
    'ConstraintError': IntegrityError,
    'DatabaseError': DatabaseError,
    'DataError': DataError,
    'IntegrityError': IntegrityError,
    'InterfaceError': InterfaceError,
    'InternalError': InternalError,
    'NotSupportedError': NotSupportedError,
    'OperationalError': OperationalError,
    'ProgrammingError': ProgrammingError,
    'TransactionRollbackError': OperationalError,
    'UndefinedFunction': ProgrammingError,
    'UniqueViolation': IntegrityError}

__exception_wrapper__ = ExceptionWrapper(EXCEPTIONS)


# DATABASE INTERFACE AND CONNECTION MANAGEMENT.


IndexMetadata = collections.namedtuple(
    'IndexMetadata',
    ('name', 'sql', 'columns', 'unique', 'table'))
ColumnMetadata = collections.namedtuple(
    'ColumnMetadata',
    ('name', 'data_type', 'null', 'primary_key', 'table', 'default'))
ForeignKeyMetadata = collections.namedtuple(
    'ForeignKeyMetadata',
    ('column', 'dest_table', 'dest_column', 'table'))
ViewMetadata = collections.namedtuple('ViewMetadata', ('name', 'sql'))


class _ConnectionState(object):
    def __init__(self, **kwargs):
        super(_ConnectionState, self).__init__(**kwargs)
        self.reset()

    def reset(self):
        self.closed = True
        self.conn = None
        self.ctx = []
        self.transactions = []

    def set_connection(self, conn):
        self.conn = conn
        self.closed = False
        self.ctx = []
        self.transactions = []


class _ConnectionLocal(_ConnectionState, threading.local): pass
class _NoopLock(object):
    __slots__ = ()
    def __enter__(self): return self
    def __exit__(self, exc_type, exc_val, exc_tb): pass


class ConnectionContext(object):
    __slots__ = ('db',)
    def __init__(self, db): self.db = db
    def __enter__(self):
        if self.db.is_closed():
            self.db.connect()
    def __exit__(self, exc_type, exc_val, exc_tb): self.db.close()
    def __call__(self, fn):
        @wraps(fn)
        def inner(*args, **kwargs):
            with ConnectionContext(self.db):
                return fn(*args, **kwargs)
        return inner


class Database(_callable_context_manager):
    context_class = Context
    field_types = {}
    operations = {}
    param = '?'
    quote = '""'
    server_version = None

    # Feature toggles.
    compound_select_parentheses = CSQ_PARENTHESES_NEVER
    for_update = False
    index_schema_prefix = False
    index_using_precedes_table = False
    limit_max = None
    nulls_ordering = False
    returning_clause = False
    safe_create_index = True
    safe_drop_index = True
    sequences = False
    truncate_table = True

    def __init__(self, database, thread_safe=True, autorollback=False,
                 field_types=None, operations=None, autocommit=None,
                 autoconnect=True, **kwargs):
        self._field_types = merge_dict(FIELD, self.field_types)
        self._operations = merge_dict(OP, self.operations)
        if field_types:
            self._field_types.update(field_types)
        if operations:
            self._operations.update(operations)

        self.autoconnect = autoconnect
        self.thread_safe = thread_safe
        if thread_safe:
            self._state = _ConnectionLocal()
            self._lock = threading.Lock()
        else:
            self._state = _ConnectionState()
            self._lock = _NoopLock()

        if autorollback:
            __deprecated__('Peewee no longer uses the "autorollback" option, '
                           'as we always run in autocommit-mode now. This '
                           'changes psycopg2\'s semantics so that the conn '
                           'is not left in a transaction-aborted state.')

        if autocommit is not None:
            __deprecated__('Peewee no longer uses the "autocommit" option, as '
                           'the semantics now require it to always be True. '
                           'Because some database-drivers also use the '
                           '"autocommit" parameter, you are receiving a '
                           'warning so you may update your code and remove '
                           'the parameter, as in the future, specifying '
                           'autocommit could impact the behavior of the '
                           'database driver you are using.')

        self.connect_params = {}
        self.init(database, **kwargs)

    def init(self, database, **kwargs):
        if not self.is_closed():
            self.close()
        self.database = database
        self.connect_params.update(kwargs)
        self.deferred = not bool(database)

    def __enter__(self):
        if self.is_closed():
            self.connect()
        ctx = self.atomic()
        self._state.ctx.append(ctx)
        ctx.__enter__()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        ctx = self._state.ctx.pop()
        try:
            ctx.__exit__(exc_type, exc_val, exc_tb)
        finally:
            if not self._state.ctx:
                self.close()

    def connection_context(self):
        return ConnectionContext(self)

    def _connect(self):
        raise NotImplementedError

    def connect(self, reuse_if_open=False):
        with self._lock:
            if self.deferred:
                raise InterfaceError('Error, database must be initialized '
                                     'before opening a connection.')
            if not self._state.closed:
                if reuse_if_open:
                    return False
                raise OperationalError('Connection already opened.')

            self._state.reset()
            with __exception_wrapper__:
                self._state.set_connection(self._connect())
                if self.server_version is None:
                    self._set_server_version(self._state.conn)
                self._initialize_connection(self._state.conn)
        return True

    def _initialize_connection(self, conn):
        pass

    def _set_server_version(self, conn):
        self.server_version = 0

    def close(self):
        with self._lock:
            if self.deferred:
                raise InterfaceError('Error, database must be initialized '
                                     'before opening a connection.')
            if self.in_transaction():
                raise OperationalError('Attempting to close database while '
                                       'transaction is open.')
            is_open = not self._state.closed
            try:
                if is_open:
                    with __exception_wrapper__:
                        self._close(self._state.conn)
            finally:
                self._state.reset()
            return is_open

    def _close(self, conn):
        conn.close()

    def is_closed(self):
        return self._state.closed

    def is_connection_usable(self):
        return not self._state.closed

    def connection(self):
        if self.is_closed():
            self.connect()
        return self._state.conn

    def cursor(self, commit=None, named_cursor=None):
        if commit is not None:
            __deprecated__('"commit" has been deprecated and is a no-op.')
        if self.is_closed():
            if self.autoconnect:
                self.connect()
            else:
                raise InterfaceError('Error, database connection not opened.')
        return self._state.conn.cursor()

    def execute_sql(self, sql, params=None, commit=None):
        if commit is not None:
            __deprecated__('"commit" has been deprecated and is a no-op.')
        logger.debug((sql, params))
        with __exception_wrapper__:
            cursor = self.cursor()
            cursor.execute(sql, params or ())
        return cursor

    def execute(self, query, commit=None, **context_options):
        if commit is not None:
            __deprecated__('"commit" has been deprecated and is a no-op.')
        ctx = self.get_sql_context(**context_options)
        sql, params = ctx.sql(query).query()
        return self.execute_sql(sql, params)

    def get_context_options(self):
        return {
            'field_types': self._field_types,
            'operations': self._operations,
            'param': self.param,
            'quote': self.quote,
            'compound_select_parentheses': self.compound_select_parentheses,
            'conflict_statement': self.conflict_statement,
            'conflict_update': self.conflict_update,
            'for_update': self.for_update,
            'index_schema_prefix': self.index_schema_prefix,
            'index_using_precedes_table': self.index_using_precedes_table,
            'limit_max': self.limit_max,
            'nulls_ordering': self.nulls_ordering,
        }

    def get_sql_context(self, **context_options):
        context = self.get_context_options()
        if context_options:
            context.update(context_options)
        return self.context_class(**context)

    def conflict_statement(self, on_conflict, query):
        raise NotImplementedError

    def conflict_update(self, on_conflict, query):
        raise NotImplementedError

    def _build_on_conflict_update(self, on_conflict, query):
        if on_conflict._conflict_target:
            stmt = SQL('ON CONFLICT')
            target = EnclosedNodeList([
                Entity(col) if isinstance(col, basestring) else col
                for col in on_conflict._conflict_target])
            if on_conflict._conflict_where is not None:
                target = NodeList([target, SQL('WHERE'),
                                   on_conflict._conflict_where])
        else:
            stmt = SQL('ON CONFLICT ON CONSTRAINT')
            target = on_conflict._conflict_constraint
            if isinstance(target, basestring):
                target = Entity(target)

        updates = []
        if on_conflict._preserve:
            for column in on_conflict._preserve:
                excluded = NodeList((SQL('EXCLUDED'), ensure_entity(column)),
                                    glue='.')
                expression = NodeList((ensure_entity(column), SQL('='),
                                       excluded))
                updates.append(expression)

        if on_conflict._update:
            for k, v in on_conflict._update.items():
                if not isinstance(v, Node):
                    # Attempt to resolve string field-names to their respective
                    # field object, to apply data-type conversions.
                    if isinstance(k, basestring):
                        k = getattr(query.table, k)
                    if isinstance(k, Field):
                        v = k.to_value(v)
                    else:
                        v = Value(v, unpack=False)
                else:
                    v = QualifiedNames(v)
                updates.append(NodeList((ensure_entity(k), SQL('='), v)))

        parts = [stmt, target, SQL('DO UPDATE SET'), CommaNodeList(updates)]
        if on_conflict._where:
            parts.extend((SQL('WHERE'), QualifiedNames(on_conflict._where)))

        return NodeList(parts)

    def last_insert_id(self, cursor, query_type=None):
        return cursor.lastrowid

    def rows_affected(self, cursor):
        return cursor.rowcount

    def default_values_insert(self, ctx):
        return ctx.literal('DEFAULT VALUES')

    def session_start(self):
        return self.transaction().__enter__()

    def session_commit(self):
        try:
            txn = self.pop_transaction()
        except IndexError:
            return False
        txn.commit(begin=self.in_transaction())
        return True

    def session_rollback(self):
        try:
            txn = self.pop_transaction()
        except IndexError:
            return False
        txn.rollback(begin=self.in_transaction())
        return True

    def in_transaction(self):
        return bool(self._state.transactions)

    def push_transaction(self, transaction):
        self._state.transactions.append(transaction)

    def pop_transaction(self):
        return self._state.transactions.pop()

    def transaction_depth(self):
        return len(self._state.transactions)

    def top_transaction(self):
        if self._state.transactions:
            return self._state.transactions[-1]

    def atomic(self, *args, **kwargs):
        return _atomic(self, *args, **kwargs)

    def manual_commit(self):
        return _manual(self)

    def transaction(self, *args, **kwargs):
        return _transaction(self, *args, **kwargs)

    def savepoint(self):
        return _savepoint(self)

    def begin(self):
        if self.is_closed():
            self.connect()
        with __exception_wrapper__:
            self.cursor().execute('BEGIN')

    def rollback(self):
        with __exception_wrapper__:
            self.cursor().execute('ROLLBACK')

    def commit(self):
        with __exception_wrapper__:
            self.cursor().execute('COMMIT')

    def batch_commit(self, it, n):
        for group in chunked(it, n):
            with self.atomic():
                for obj in group:
                    yield obj

    def table_exists(self, table_name, schema=None):
        if is_model(table_name):
            model = table_name
            table_name = model._meta.table_name
            schema = model._meta.schema
        return table_name in self.get_tables(schema=schema)

    def get_tables(self, schema=None):
        raise NotImplementedError

    def get_indexes(self, table, schema=None):
        raise NotImplementedError

    def get_columns(self, table, schema=None):
        raise NotImplementedError

    def get_primary_keys(self, table, schema=None):
        raise NotImplementedError

    def get_foreign_keys(self, table, schema=None):
        raise NotImplementedError

    def sequence_exists(self, seq):
        raise NotImplementedError

    def create_tables(self, models, **options):
        for model in sort_models(models):
            model.create_table(**options)

    def drop_tables(self, models, **kwargs):
        for model in reversed(sort_models(models)):
            model.drop_table(**kwargs)

    def extract_date(self, date_part, date_field):
        raise NotImplementedError

    def truncate_date(self, date_part, date_field):
        raise NotImplementedError

    def to_timestamp(self, date_field):
        raise NotImplementedError

    def from_timestamp(self, date_field):
        raise NotImplementedError

    def random(self):
        return fn.random()

    def bind(self, models, bind_refs=True, bind_backrefs=True):
        for model in models:
            model.bind(self, bind_refs=bind_refs, bind_backrefs=bind_backrefs)

    def bind_ctx(self, models, bind_refs=True, bind_backrefs=True):
        return _BoundModelsContext(models, self, bind_refs, bind_backrefs)

    def get_noop_select(self, ctx):
        return ctx.sql(Select().columns(SQL('0')).where(SQL('0')))

    @property
    def Model(self):
        if not hasattr(self, '_Model'):
            class Meta: database = self
            self._Model = type('BaseModel', (Model,), {'Meta': Meta})
        return self._Model


def __pragma__(name):
    def __get__(self):
        return self.pragma(name)
    def __set__(self, value):
        return self.pragma(name, value)
    return property(__get__, __set__)


class SqliteDatabase(Database):
    field_types = {
        'BIGAUTO': FIELD.AUTO,
        'BIGINT': FIELD.INT,
        'BOOL': FIELD.INT,
        'DOUBLE': FIELD.FLOAT,
        'SMALLINT': FIELD.INT,
        'UUID': FIELD.TEXT}
    operations = {
        'LIKE': 'GLOB',
        'ILIKE': 'LIKE'}
    index_schema_prefix = True
    limit_max = -1
    server_version = __sqlite_version__
    truncate_table = False

    def __init__(self, database, *args, **kwargs):
        self._pragmas = kwargs.pop('pragmas', ())
        super(SqliteDatabase, self).__init__(database, *args, **kwargs)
        self._aggregates = {}
        self._collations = {}
        self._functions = {}
        self._window_functions = {}
        self._table_functions = []
        self._extensions = set()
        self._attached = {}
        self.register_function(_sqlite_date_part, 'date_part', 2)
        self.register_function(_sqlite_date_trunc, 'date_trunc', 2)
        self.nulls_ordering = self.server_version >= (3, 30, 0)

    def init(self, database, pragmas=None, timeout=5, returning_clause=None,
             **kwargs):
        if pragmas is not None:
            self._pragmas = pragmas
        if isinstance(self._pragmas, dict):
            self._pragmas = list(self._pragmas.items())
        if returning_clause is not None:
            if __sqlite_version__ < (3, 35, 0):
                warnings.warn('RETURNING clause requires Sqlite 3.35 or newer')
            self.returning_clause = returning_clause
        self._timeout = timeout
        super(SqliteDatabase, self).init(database, **kwargs)

    def _set_server_version(self, conn):
        pass

    def _connect(self):
        if sqlite3 is None:
            raise ImproperlyConfigured('SQLite driver not installed!')
        conn = sqlite3.connect(self.database, timeout=self._timeout,
                               isolation_level=None, **self.connect_params)
        try:
            self._add_conn_hooks(conn)
        except:
            conn.close()
            raise
        return conn

    def _add_conn_hooks(self, conn):
        if self._attached:
            self._attach_databases(conn)
        if self._pragmas:
            self._set_pragmas(conn)
        self._load_aggregates(conn)
        self._load_collations(conn)
        self._load_functions(conn)
        if self.server_version >= (3, 25, 0):
            self._load_window_functions(conn)
        if self._table_functions:
            for table_function in self._table_functions:
                table_function.register(conn)
        if self._extensions:
            self._load_extensions(conn)

    def _set_pragmas(self, conn):
        cursor = conn.cursor()
        for pragma, value in self._pragmas:
            cursor.execute('PRAGMA %s = %s;' % (pragma, value))
        cursor.close()

    def _attach_databases(self, conn):
        cursor = conn.cursor()
        for name, db in self._attached.items():
            cursor.execute('ATTACH DATABASE "%s" AS "%s"' % (db, name))
        cursor.close()

    def pragma(self, key, value=SENTINEL, permanent=False, schema=None):
        if schema is not None:
            key = '"%s".%s' % (schema, key)
        sql = 'PRAGMA %s' % key
        if value is not SENTINEL:
            sql += ' = %s' % (value or 0)
            if permanent:
                pragmas = dict(self._pragmas or ())
                pragmas[key] = value
                self._pragmas = list(pragmas.items())
        elif permanent:
            raise ValueError('Cannot specify a permanent pragma without value')
        row = self.execute_sql(sql).fetchone()
        if row:
            return row[0]

    cache_size = __pragma__('cache_size')
    foreign_keys = __pragma__('foreign_keys')
    journal_mode = __pragma__('journal_mode')
    journal_size_limit = __pragma__('journal_size_limit')
    mmap_size = __pragma__('mmap_size')
    page_size = __pragma__('page_size')
    read_uncommitted = __pragma__('read_uncommitted')
    synchronous = __pragma__('synchronous')
    wal_autocheckpoint = __pragma__('wal_autocheckpoint')
    application_id = __pragma__('application_id')
    user_version = __pragma__('user_version')
    data_version = __pragma__('data_version')

    @property
    def timeout(self):
        return self._timeout

    @timeout.setter
    def timeout(self, seconds):
        if self._timeout == seconds:
            return

        self._timeout = seconds
        if not self.is_closed():
            # PySQLite multiplies user timeout by 1000, but the unit of the
            # timeout PRAGMA is actually milliseconds.
            self.execute_sql('PRAGMA busy_timeout=%d;' % (seconds * 1000))

    def _load_aggregates(self, conn):
        for name, (klass, num_params) in self._aggregates.items():
            conn.create_aggregate(name, num_params, klass)

    def _load_collations(self, conn):
        for name, fn in self._collations.items():
            conn.create_collation(name, fn)

    def _load_functions(self, conn):
        for name, (fn, n_params, deterministic) in self._functions.items():
            kwargs = {'deterministic': deterministic} if deterministic else {}
            conn.create_function(name, n_params, fn, **kwargs)

    def _load_window_functions(self, conn):
        for name, (klass, num_params) in self._window_functions.items():
            conn.create_window_function(name, num_params, klass)

    def register_aggregate(self, klass, name=None, num_params=-1):
        self._aggregates[name or klass.__name__.lower()] = (klass, num_params)
        if not self.is_closed():
            self._load_aggregates(self.connection())

    def aggregate(self, name=None, num_params=-1):
        def decorator(klass):
            self.register_aggregate(klass, name, num_params)
            return klass
        return decorator

    def register_collation(self, fn, name=None):
        name = name or fn.__name__
        def _collation(*args):
            expressions = args + (SQL('collate %s' % name),)
            return NodeList(expressions)
        fn.collation = _collation
        self._collations[name] = fn
        if not self.is_closed():
            self._load_collations(self.connection())

    def collation(self, name=None):
        def decorator(fn):
            self.register_collation(fn, name)
            return fn
        return decorator

    def register_function(self, fn, name=None, num_params=-1,
                          deterministic=None):
        self._functions[name or fn.__name__] = (fn, num_params, deterministic)
        if not self.is_closed():
            self._load_functions(self.connection())

    def func(self, name=None, num_params=-1, deterministic=None):
        def decorator(fn):
            self.register_function(fn, name, num_params, deterministic)
            return fn
        return decorator

    def register_window_function(self, klass, name=None, num_params=-1):
        name = name or klass.__name__.lower()
        self._window_functions[name] = (klass, num_params)
        if not self.is_closed():
            self._load_window_functions(self.connection())

    def window_function(self, name=None, num_params=-1):
        def decorator(klass):
            self.register_window_function(klass, name, num_params)
            return klass
        return decorator

    def register_table_function(self, klass, name=None):
        if name is not None:
            klass.name = name
        self._table_functions.append(klass)
        if not self.is_closed():
            klass.register(self.connection())

    def table_function(self, name=None):
        def decorator(klass):
            self.register_table_function(klass, name)
            return klass
        return decorator

    def unregister_aggregate(self, name):
        del(self._aggregates[name])

    def unregister_collation(self, name):
        del(self._collations[name])

    def unregister_function(self, name):
        del(self._functions[name])

    def unregister_window_function(self, name):
        del(self._window_functions[name])

    def unregister_table_function(self, name):
        for idx, klass in enumerate(self._table_functions):
            if klass.name == name:
                break
        else:
            return False
        self._table_functions.pop(idx)
        return True

    def _load_extensions(self, conn):
        conn.enable_load_extension(True)
        for extension in self._extensions:
            conn.load_extension(extension)

    def load_extension(self, extension):
        self._extensions.add(extension)
        if not self.is_closed():
            conn = self.connection()
            conn.enable_load_extension(True)
            conn.load_extension(extension)

    def unload_extension(self, extension):
        self._extensions.remove(extension)

    def attach(self, filename, name):
        if name in self._attached:
            if self._attached[name] == filename:
                return False
            raise OperationalError('schema "%s" already attached.' % name)

        self._attached[name] = filename
        if not self.is_closed():
            self.execute_sql('ATTACH DATABASE "%s" AS "%s"' % (filename, name))
        return True

    def detach(self, name):
        if name not in self._attached:
            return False

        del self._attached[name]
        if not self.is_closed():
            self.execute_sql('DETACH DATABASE "%s"' % name)
        return True

    def last_insert_id(self, cursor, query_type=None):
        if not self.returning_clause:
            return cursor.lastrowid
        elif query_type == Insert.SIMPLE:
            try:
                return cursor[0][0]
            except (IndexError, KeyError, TypeError):
                pass
        return cursor

    def rows_affected(self, cursor):
        try:
            return cursor.rowcount
        except AttributeError:
            return cursor.cursor.rowcount  # This was a RETURNING query.

    def begin(self, lock_type=None):
        statement = 'BEGIN %s' % lock_type if lock_type else 'BEGIN'
        self.execute_sql(statement)

    def commit(self):
        with __exception_wrapper__:
            return self._state.conn.commit()

    def rollback(self):
        with __exception_wrapper__:
            return self._state.conn.rollback()

    def get_tables(self, schema=None):
        schema = schema or 'main'
        cursor = self.execute_sql('SELECT name FROM "%s".sqlite_master WHERE '
                                  'type=? ORDER BY name' % schema, ('table',))
        return [row for row, in cursor.fetchall()]

    def get_views(self, schema=None):
        sql = ('SELECT name, sql FROM "%s".sqlite_master WHERE type=? '
               'ORDER BY name') % (schema or 'main')
        return [ViewMetadata(*row) for row in self.execute_sql(sql, ('view',))]

    def get_indexes(self, table, schema=None):
        schema = schema or 'main'
        query = ('SELECT name, sql FROM "%s".sqlite_master '
                 'WHERE tbl_name = ? AND type = ? ORDER BY name') % schema
        cursor = self.execute_sql(query, (table, 'index'))
        index_to_sql = dict(cursor.fetchall())

        # Determine which indexes have a unique constraint.
        unique_indexes = set()
        cursor = self.execute_sql('PRAGMA "%s".index_list("%s")' %
                                  (schema, table))
        for row in cursor.fetchall():
            name = row[1]
            is_unique = int(row[2]) == 1
            if is_unique:
                unique_indexes.add(name)

        # Retrieve the indexed columns.
        index_columns = {}
        for index_name in sorted(index_to_sql):
            cursor = self.execute_sql('PRAGMA "%s".index_info("%s")' %
                                      (schema, index_name))
            index_columns[index_name] = [row[2] for row in cursor.fetchall()]

        return [
            IndexMetadata(
                name,
                index_to_sql[name],
                index_columns[name],
                name in unique_indexes,
                table)
            for name in sorted(index_to_sql)]

    def get_columns(self, table, schema=None):
        cursor = self.execute_sql('PRAGMA "%s".table_info("%s")' %
                                  (schema or 'main', table))
        return [ColumnMetadata(r[1], r[2], not r[3], bool(r[5]), table, r[4])
                for r in cursor.fetchall()]

    def get_primary_keys(self, table, schema=None):
        cursor = self.execute_sql('PRAGMA "%s".table_info("%s")' %
                                  (schema or 'main', table))
        return [row[1] for row in filter(lambda r: r[-1], cursor.fetchall())]

    def get_foreign_keys(self, table, schema=None):
        cursor = self.execute_sql('PRAGMA "%s".foreign_key_list("%s")' %
                                  (schema or 'main', table))
        return [ForeignKeyMetadata(row[3], row[2], row[4], table)
                for row in cursor.fetchall()]

    def get_binary_type(self):
        return sqlite3.Binary

    def conflict_statement(self, on_conflict, query):
        action = on_conflict._action.lower() if on_conflict._action else ''
        if action and action not in ('nothing', 'update'):
            return SQL('INSERT OR %s' % on_conflict._action.upper())

    def conflict_update(self, oc, query):
        # Sqlite prior to 3.24.0 does not support Postgres-style upsert.
        if self.server_version < (3, 24, 0) and \
           any((oc._preserve, oc._update, oc._where, oc._conflict_target,
                oc._conflict_constraint)):
            raise ValueError('SQLite does not support specifying which values '
                             'to preserve or update.')

        action = oc._action.lower() if oc._action else ''
        if action and action not in ('nothing', 'update', ''):
            return

        if action == 'nothing':
            return SQL('ON CONFLICT DO NOTHING')
        elif not oc._update and not oc._preserve:
            raise ValueError('If you are not performing any updates (or '
                             'preserving any INSERTed values), then the '
                             'conflict resolution action should be set to '
                             '"NOTHING".')
        elif oc._conflict_constraint:
            raise ValueError('SQLite does not support specifying named '
                             'constraints for conflict resolution.')
        elif not oc._conflict_target:
            raise ValueError('SQLite requires that a conflict target be '
                             'specified when doing an upsert.')

        return self._build_on_conflict_update(oc, query)

    def extract_date(self, date_part, date_field):
        return fn.date_part(date_part, date_field, python_value=int)

    def truncate_date(self, date_part, date_field):
        return fn.date_trunc(date_part, date_field,
                             python_value=simple_date_time)

    def to_timestamp(self, date_field):
        return fn.strftime('%s', date_field).cast('integer')

    def from_timestamp(self, date_field):
        return fn.datetime(date_field, 'unixepoch')


class PostgresqlDatabase(Database):
    field_types = {
        'AUTO': 'SERIAL',
        'BIGAUTO': 'BIGSERIAL',
        'BLOB': 'BYTEA',
        'BOOL': 'BOOLEAN',
        'DATETIME': 'TIMESTAMP',
        'DECIMAL': 'NUMERIC',
        'DOUBLE': 'DOUBLE PRECISION',
        'UUID': 'UUID',
        'UUIDB': 'BYTEA'}
    operations = {'REGEXP': '~', 'IREGEXP': '~*'}
    param = '%s'

    compound_select_parentheses = CSQ_PARENTHESES_ALWAYS
    for_update = True
    nulls_ordering = True
    returning_clause = True
    safe_create_index = False
    sequences = True

    def init(self, database, register_unicode=True, encoding=None,
             isolation_level=None, **kwargs):
        self._register_unicode = register_unicode
        self._encoding = encoding
        self._isolation_level = isolation_level
        super(PostgresqlDatabase, self).init(database, **kwargs)

    def _connect(self):
        if psycopg2 is None:
            raise ImproperlyConfigured('Postgres driver not installed!')

        # Handle connection-strings nicely, since psycopg2 will accept them,
        # and they may be easier when lots of parameters are specified.
        params = self.connect_params.copy()
        if self.database.startswith('postgresql://'):
            params.setdefault('dsn', self.database)
        else:
            params.setdefault('dbname', self.database)

        conn = psycopg2.connect(**params)
        if self._register_unicode:
            pg_extensions.register_type(pg_extensions.UNICODE, conn)
            pg_extensions.register_type(pg_extensions.UNICODEARRAY, conn)
        if self._encoding:
            conn.set_client_encoding(self._encoding)
        if self._isolation_level:
            conn.set_isolation_level(self._isolation_level)
        conn.autocommit = True
        return conn

    def _set_server_version(self, conn):
        self.server_version = conn.server_version
        if self.server_version >= 90600:
            self.safe_create_index = True

    def is_connection_usable(self):
        if self._state.closed:
            return False

        # Returns True if we are idle, running a command, or in an active
        # connection. If the connection is in an error state or the connection
        # is otherwise unusable, return False.
        txn_status = self._state.conn.get_transaction_status()
        return txn_status < pg_extensions.TRANSACTION_STATUS_INERROR

    def last_insert_id(self, cursor, query_type=None):
        try:
            return cursor if query_type != Insert.SIMPLE else cursor[0][0]
        except (IndexError, KeyError, TypeError):
            pass

    def rows_affected(self, cursor):
        try:
            return cursor.rowcount
        except AttributeError:
            return cursor.cursor.rowcount

    def begin(self, isolation_level=None):
        if self.is_closed():
            self.connect()
        if isolation_level:
            stmt = 'BEGIN TRANSACTION ISOLATION LEVEL %s' % isolation_level
        else:
            stmt = 'BEGIN'
        with __exception_wrapper__:
            self.cursor().execute(stmt)

    def get_tables(self, schema=None):
        query = ('SELECT tablename FROM pg_catalog.pg_tables '
                 'WHERE schemaname = %s ORDER BY tablename')
        cursor = self.execute_sql(query, (schema or 'public',))
        return [table for table, in cursor.fetchall()]

    def get_views(self, schema=None):
        query = ('SELECT viewname, definition FROM pg_catalog.pg_views '
                 'WHERE schemaname = %s ORDER BY viewname')
        cursor = self.execute_sql(query, (schema or 'public',))
        return [ViewMetadata(view_name, sql.strip(' \t;'))
                for (view_name, sql) in cursor.fetchall()]

    def get_indexes(self, table, schema=None):
        query = """
            SELECT
                i.relname, idxs.indexdef, idx.indisunique,
                array_to_string(ARRAY(
                    SELECT pg_get_indexdef(idx.indexrelid, k + 1, TRUE)
                    FROM generate_subscripts(idx.indkey, 1) AS k
                    ORDER BY k), ',')
            FROM pg_catalog.pg_class AS t
            INNER JOIN pg_catalog.pg_index AS idx ON t.oid = idx.indrelid
            INNER JOIN pg_catalog.pg_class AS i ON idx.indexrelid = i.oid
            INNER JOIN pg_catalog.pg_indexes AS idxs ON
                (idxs.tablename = t.relname AND idxs.indexname = i.relname)
            WHERE t.relname = %s AND t.relkind = %s AND idxs.schemaname = %s
            ORDER BY idx.indisunique DESC, i.relname;"""
        cursor = self.execute_sql(query, (table, 'r', schema or 'public'))
        return [IndexMetadata(name, sql.rstrip(' ;'), columns.split(','),
                              is_unique, table)
                for name, sql, is_unique, columns in cursor.fetchall()]

    def get_columns(self, table, schema=None):
        query = """
            SELECT column_name, is_nullable, data_type, column_default
            FROM information_schema.columns
            WHERE table_name = %s AND table_schema = %s
            ORDER BY ordinal_position"""
        cursor = self.execute_sql(query, (table, schema or 'public'))
        pks = set(self.get_primary_keys(table, schema))
        return [ColumnMetadata(name, dt, null == 'YES', name in pks, table, df)
                for name, null, dt, df in cursor.fetchall()]

    def get_primary_keys(self, table, schema=None):
        query = """
            SELECT kc.column_name
            FROM information_schema.table_constraints AS tc
            INNER JOIN information_schema.key_column_usage AS kc ON (
                tc.table_name = kc.table_name AND
                tc.table_schema = kc.table_schema AND
                tc.constraint_name = kc.constraint_name)
            WHERE
                tc.constraint_type = %s AND
                tc.table_name = %s AND
                tc.table_schema = %s"""
        ctype = 'PRIMARY KEY'
        cursor = self.execute_sql(query, (ctype, table, schema or 'public'))
        return [pk for pk, in cursor.fetchall()]

    def get_foreign_keys(self, table, schema=None):
        sql = """
            SELECT DISTINCT
                kcu.column_name, ccu.table_name, ccu.column_name
            FROM information_schema.table_constraints AS tc
            JOIN information_schema.key_column_usage AS kcu
                ON (tc.constraint_name = kcu.constraint_name AND
                    tc.constraint_schema = kcu.constraint_schema AND
                    tc.table_name = kcu.table_name AND
                    tc.table_schema = kcu.table_schema)
            JOIN information_schema.constraint_column_usage AS ccu
                ON (ccu.constraint_name = tc.constraint_name AND
                    ccu.constraint_schema = tc.constraint_schema)
            WHERE
                tc.constraint_type = 'FOREIGN KEY' AND
                tc.table_name = %s AND
                tc.table_schema = %s"""
        cursor = self.execute_sql(sql, (table, schema or 'public'))
        return [ForeignKeyMetadata(row[0], row[1], row[2], table)
                for row in cursor.fetchall()]

    def sequence_exists(self, sequence):
        res = self.execute_sql("""
            SELECT COUNT(*) FROM pg_class, pg_namespace
            WHERE relkind='S'
                AND pg_class.relnamespace = pg_namespace.oid
                AND relname=%s""", (sequence,))
        return bool(res.fetchone()[0])

    def get_binary_type(self):
        return psycopg2.Binary

    def conflict_statement(self, on_conflict, query):
        return

    def conflict_update(self, oc, query):
        action = oc._action.lower() if oc._action else ''
        if action in ('ignore', 'nothing'):
            parts = [SQL('ON CONFLICT')]
            if oc._conflict_target:
                parts.append(EnclosedNodeList([
                    Entity(col) if isinstance(col, basestring) else col
                    for col in oc._conflict_target]))
            parts.append(SQL('DO NOTHING'))
            return NodeList(parts)
        elif action and action != 'update':
            raise ValueError('The only supported actions for conflict '
                             'resolution with Postgresql are "ignore" or '
                             '"update".')
        elif not oc._update and not oc._preserve:
            raise ValueError('If you are not performing any updates (or '
                             'preserving any INSERTed values), then the '
                             'conflict resolution action should be set to '
                             '"IGNORE".')
        elif not (oc._conflict_target or oc._conflict_constraint):
            raise ValueError('Postgres requires that a conflict target be '
                             'specified when doing an upsert.')

        return self._build_on_conflict_update(oc, query)

    def extract_date(self, date_part, date_field):
        return fn.EXTRACT(NodeList((date_part, SQL('FROM'), date_field)))

    def truncate_date(self, date_part, date_field):
        return fn.DATE_TRUNC(date_part, date_field)

    def to_timestamp(self, date_field):
        return self.extract_date('EPOCH', date_field)

    def from_timestamp(self, date_field):
        # Ironically, here, Postgres means "to the Postgresql timestamp type".
        return fn.to_timestamp(date_field)

    def get_noop_select(self, ctx):
        return ctx.sql(Select().columns(SQL('0')).where(SQL('false')))

    def set_time_zone(self, timezone):
        self.execute_sql('set time zone "%s";' % timezone)


class MySQLDatabase(Database):
    field_types = {
        'AUTO': 'INTEGER AUTO_INCREMENT',
        'BIGAUTO': 'BIGINT AUTO_INCREMENT',
        'BOOL': 'BOOL',
        'DECIMAL': 'NUMERIC',
        'DOUBLE': 'DOUBLE PRECISION',
        'FLOAT': 'FLOAT',
        'UUID': 'VARCHAR(40)',
        'UUIDB': 'VARBINARY(16)'}
    operations = {
        'LIKE': 'LIKE BINARY',
        'ILIKE': 'LIKE',
        'REGEXP': 'REGEXP BINARY',
        'IREGEXP': 'REGEXP',
        'XOR': 'XOR'}
    param = '%s'
    quote = '``'

    compound_select_parentheses = CSQ_PARENTHESES_UNNESTED
    for_update = True
    index_using_precedes_table = True
    limit_max = 2 ** 64 - 1
    safe_create_index = False
    safe_drop_index = False
    sql_mode = 'PIPES_AS_CONCAT'

    def init(self, database, **kwargs):
        params = {
            'charset': 'utf8',
            'sql_mode': self.sql_mode,
            'use_unicode': True}
        params.update(kwargs)
        if 'password' in params and mysql_passwd:
            params['passwd'] = params.pop('password')
        super(MySQLDatabase, self).init(database, **params)

    def _connect(self):
        if mysql is None:
            raise ImproperlyConfigured('MySQL driver not installed!')
        conn = mysql.connect(db=self.database, autocommit=True,
                             **self.connect_params)
        return conn

    def _set_server_version(self, conn):
        try:
            version_raw = conn.server_version
        except AttributeError:
            version_raw = conn.get_server_info()
        self.server_version = self._extract_server_version(version_raw)

    def _extract_server_version(self, version):
        version = version.lower()
        if 'maria' in version:
            match_obj = re.search(r'(1\d\.\d+\.\d+)', version)
        else:
            match_obj = re.search(r'(\d\.\d+\.\d+)', version)
        if match_obj is not None:
            return tuple(int(num) for num in match_obj.groups()[0].split('.'))

        warnings.warn('Unable to determine MySQL version: "%s"' % version)
        return (0, 0, 0)  # Unable to determine version!

    def is_connection_usable(self):
        if self._state.closed:
            return False

        conn = self._state.conn
        if hasattr(conn, 'ping'):
            if self.server_version[0] == 8:
                args = ()
            else:
                args = (False,)
            try:
                conn.ping(*args)
            except Exception:
                return False
        return True

    def default_values_insert(self, ctx):
        return ctx.literal('() VALUES ()')

    def begin(self, isolation_level=None):
        if self.is_closed():
            self.connect()
        with __exception_wrapper__:
            curs = self.cursor()
            if isolation_level:
                curs.execute('SET TRANSACTION ISOLATION LEVEL %s' %
                             isolation_level)
            curs.execute('BEGIN')

    def get_tables(self, schema=None):
        query = ('SELECT table_name FROM information_schema.tables '
                 'WHERE table_schema = DATABASE() AND table_type != %s '
                 'ORDER BY table_name')
        return [table for table, in self.execute_sql(query, ('VIEW',))]

    def get_views(self, schema=None):
        query = ('SELECT table_name, view_definition '
                 'FROM information_schema.views '
                 'WHERE table_schema = DATABASE() ORDER BY table_name')
        cursor = self.execute_sql(query)
        return [ViewMetadata(*row) for row in cursor.fetchall()]

    def get_indexes(self, table, schema=None):
        cursor = self.execute_sql('SHOW INDEX FROM `%s`' % table)
        unique = set()
        indexes = {}
        for row in cursor.fetchall():
            if not row[1]:
                unique.add(row[2])
            indexes.setdefault(row[2], [])
            indexes[row[2]].append(row[4])
        return [IndexMetadata(name, None, indexes[name], name in unique, table)
                for name in indexes]

    def get_columns(self, table, schema=None):
        sql = """
            SELECT column_name, is_nullable, data_type, column_default
            FROM information_schema.columns
            WHERE table_name = %s AND table_schema = DATABASE()
            ORDER BY ordinal_position"""
        cursor = self.execute_sql(sql, (table,))
        pks = set(self.get_primary_keys(table))
        return [ColumnMetadata(name, dt, null == 'YES', name in pks, table, df)
                for name, null, dt, df in cursor.fetchall()]

    def get_primary_keys(self, table, schema=None):
        cursor = self.execute_sql('SHOW INDEX FROM `%s`' % table)
        return [row[4] for row in
                filter(lambda row: row[2] == 'PRIMARY', cursor.fetchall())]

    def get_foreign_keys(self, table, schema=None):
        query = """
            SELECT column_name, referenced_table_name, referenced_column_name
            FROM information_schema.key_column_usage
            WHERE table_name = %s
                AND table_schema = DATABASE()
                AND referenced_table_name IS NOT NULL
                AND referenced_column_name IS NOT NULL"""
        cursor = self.execute_sql(query, (table,))
        return [
            ForeignKeyMetadata(column, dest_table, dest_column, table)
            for column, dest_table, dest_column in cursor.fetchall()]

    def get_binary_type(self):
        return mysql.Binary

    def conflict_statement(self, on_conflict, query):
        if not on_conflict._action: return

        action = on_conflict._action.lower()
        if action == 'replace':
            return SQL('REPLACE')
        elif action == 'ignore':
            return SQL('INSERT IGNORE')
        elif action != 'update':
            raise ValueError('Un-supported action for conflict resolution. '
                             'MySQL supports REPLACE, IGNORE and UPDATE.')

    def conflict_update(self, on_conflict, query):
        if on_conflict._where or on_conflict._conflict_target or \
           on_conflict._conflict_constraint:
            raise ValueError('MySQL does not support the specification of '
                             'where clauses or conflict targets for conflict '
                             'resolution.')

        updates = []
        if on_conflict._preserve:
            # Here we need to determine which function to use, which varies
            # depending on the MySQL server version. MySQL and MariaDB prior to
            # 10.3.3 use "VALUES", while MariaDB 10.3.3+ use "VALUE".
            version = self.server_version or (0,)
            if version[0] == 10 and version >= (10, 3, 3):
                VALUE_FN = fn.VALUE
            else:
                VALUE_FN = fn.VALUES

            for column in on_conflict._preserve:
                entity = ensure_entity(column)
                expression = NodeList((
                    ensure_entity(column),
                    SQL('='),
                    VALUE_FN(entity)))
                updates.append(expression)

        if on_conflict._update:
            for k, v in on_conflict._update.items():
                if not isinstance(v, Node):
                    # Attempt to resolve string field-names to their respective
                    # field object, to apply data-type conversions.
                    if isinstance(k, basestring):
                        k = getattr(query.table, k)
                    if isinstance(k, Field):
                        v = k.to_value(v)
                    else:
                        v = Value(v, unpack=False)
                updates.append(NodeList((ensure_entity(k), SQL('='), v)))

        if updates:
            return NodeList((SQL('ON DUPLICATE KEY UPDATE'),
                             CommaNodeList(updates)))

    def extract_date(self, date_part, date_field):
        return fn.EXTRACT(NodeList((SQL(date_part), SQL('FROM'), date_field)))

    def truncate_date(self, date_part, date_field):
        return fn.DATE_FORMAT(date_field, __mysql_date_trunc__[date_part],
                              python_value=simple_date_time)

    def to_timestamp(self, date_field):
        return fn.UNIX_TIMESTAMP(date_field)

    def from_timestamp(self, date_field):
        return fn.FROM_UNIXTIME(date_field)

    def random(self):
        return fn.rand()

    def get_noop_select(self, ctx):
        return ctx.literal('DO 0')


# TRANSACTION CONTROL.


class _manual(object):
    def __init__(self, db):
        self.db = db

    def __call__(self, fn):
        @wraps(fn)
        def inner(*args, **kwargs):
            with _manual(self.db):
                return fn(*args, **kwargs)
        return inner

    def __enter__(self):
        top = self.db.top_transaction()
        if top is not None and not isinstance(top, _manual):
            raise ValueError('Cannot enter manual commit block while a '
                             'transaction is active.')
        self.db.push_transaction(self)

    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.db.pop_transaction() is not self:
            raise ValueError('Transaction stack corrupted while exiting '
                             'manual commit block.')


class _atomic(object):
    def __init__(self, db, *args, **kwargs):
        self.db = db
        self._transaction_args = (args, kwargs)

    def __call__(self, fn):
        @wraps(fn)
        def inner(*args, **kwargs):
            a, k = self._transaction_args
            with _atomic(self.db, *a, **k):
                return fn(*args, **kwargs)
        return inner

    def __enter__(self):
        if self.db.transaction_depth() == 0:
            args, kwargs = self._transaction_args
            self._helper = self.db.transaction(*args, **kwargs)
        elif isinstance(self.db.top_transaction(), _manual):
            raise ValueError('Cannot enter atomic commit block while in '
                             'manual commit mode.')
        else:
            self._helper = self.db.savepoint()
        return self._helper.__enter__()

    def __exit__(self, exc_type, exc_val, exc_tb):
        return self._helper.__exit__(exc_type, exc_val, exc_tb)


class _transaction(object):
    def __init__(self, db, *args, **kwargs):
        self.db = db
        self._begin_args = (args, kwargs)

    def __call__(self, fn):
        @wraps(fn)
        def inner(*args, **kwargs):
            a, k = self._begin_args
            with _transaction(self.db, *a, **k):
                return fn(*args, **kwargs)
        return inner

    def _begin(self):
        args, kwargs = self._begin_args
        self.db.begin(*args, **kwargs)

    def commit(self, begin=True):
        self.db.commit()
        if begin:
            self._begin()

    def rollback(self, begin=True):
        self.db.rollback()
        if begin:
            self._begin()

    def __enter__(self):
        if self.db.transaction_depth() == 0:
            self._begin()
        self.db.push_transaction(self)
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        depth = self.db.transaction_depth()
        try:
            if exc_type and depth == 1:
                self.rollback(False)
            elif depth == 1:
                try:
                    self.commit(False)
                except:
                    self.rollback(False)
                    raise
        finally:
            self.db.pop_transaction()


class _savepoint(object):
    def __init__(self, db, sid=None):
        self.db = db
        self.sid = sid or 's' + uuid.uuid4().hex
        self.quoted_sid = self.sid.join(self.db.quote)

    def __call__(self, fn):
        @wraps(fn)
        def inner(*args, **kwargs):
            with _savepoint(self.db):
                return fn(*args, **kwargs)
        return inner

    def _begin(self):
        self.db.execute_sql('SAVEPOINT %s;' % self.quoted_sid)

    def commit(self, begin=True):
        self.db.execute_sql('RELEASE SAVEPOINT %s;' % self.quoted_sid)
        if begin: self._begin()

    def rollback(self):
        self.db.execute_sql('ROLLBACK TO SAVEPOINT %s;' % self.quoted_sid)

    def __enter__(self):
        self._begin()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        if exc_type:
            self.rollback()
        else:
            try:
                self.commit(begin=False)
            except:
                self.rollback()
                raise


# CURSOR REPRESENTATIONS.


class CursorWrapper(object):
    def __init__(self, cursor):
        self.cursor = cursor
        self.count = 0
        self.index = 0
        self.initialized = False
        self.populated = False
        self.row_cache = []

    def __iter__(self):
        if self.populated:
            return iter(self.row_cache)
        return ResultIterator(self)

    def __getitem__(self, item):
        if isinstance(item, slice):
            stop = item.stop
            if stop is None or stop < 0:
                self.fill_cache()
            else:
                self.fill_cache(stop)
            return self.row_cache[item]
        elif isinstance(item, int):
            self.fill_cache(item if item > 0 else 0)
            return self.row_cache[item]
        else:
            raise ValueError('CursorWrapper only supports integer and slice '
                             'indexes.')

    def __len__(self):
        self.fill_cache()
        return self.count

    def initialize(self):
        pass

    def iterate(self, cache=True):
        row = self.cursor.fetchone()
        if row is None:
            self.populated = True
            self.cursor.close()
            raise StopIteration
        elif not self.initialized:
            self.initialize()  # Lazy initialization.
            self.initialized = True
        self.count += 1
        result = self.process_row(row)
        if cache:
            self.row_cache.append(result)
        return result

    def process_row(self, row):
        return row

    def iterator(self):
        """Efficient one-pass iteration over the result set."""
        while True:
            try:
                yield self.iterate(False)
            except StopIteration:
                return

    def fill_cache(self, n=0):
        n = n or float('Inf')
        if n < 0:
            raise ValueError('Negative values are not supported.')

        iterator = ResultIterator(self)
        iterator.index = self.count
        while not self.populated and (n > self.count):
            try:
                iterator.next()
            except StopIteration:
                break


class DictCursorWrapper(CursorWrapper):
    def _initialize_columns(self):
        description = self.cursor.description
        self.columns = [t[0][t[0].rfind('.') + 1:].strip('()"`')
                        for t in description]
        self.ncols = len(description)

    initialize = _initialize_columns

    def _row_to_dict(self, row):
        result = {}
        for i in range(self.ncols):
            result.setdefault(self.columns[i], row[i])  # Do not overwrite.
        return result

    process_row = _row_to_dict


class NamedTupleCursorWrapper(CursorWrapper):
    def initialize(self):
        description = self.cursor.description
        self.tuple_class = collections.namedtuple('Row', [
            t[0][t[0].rfind('.') + 1:].strip('()"`') for t in description])

    def process_row(self, row):
        return self.tuple_class(*row)


class ObjectCursorWrapper(DictCursorWrapper):
    def __init__(self, cursor, constructor):
        super(ObjectCursorWrapper, self).__init__(cursor)
        self.constructor = constructor

    def process_row(self, row):
        row_dict = self._row_to_dict(row)
        return self.constructor(**row_dict)


class ResultIterator(object):
    def __init__(self, cursor_wrapper):
        self.cursor_wrapper = cursor_wrapper
        self.index = 0

    def __iter__(self):
        return self

    def next(self):
        if self.index < self.cursor_wrapper.count:
            obj = self.cursor_wrapper.row_cache[self.index]
        elif not self.cursor_wrapper.populated:
            self.cursor_wrapper.iterate()
            obj = self.cursor_wrapper.row_cache[self.index]
        else:
            raise StopIteration
        self.index += 1
        return obj

    __next__ = next

# FIELDS

class FieldAccessor(object):
    def __init__(self, model, field, name):
        self.model = model
        self.field = field
        self.name = name

    def __get__(self, instance, instance_type=None):
        if instance is not None:
            return instance.__data__.get(self.name)
        return self.field

    def __set__(self, instance, value):
        instance.__data__[self.name] = value
        instance._dirty.add(self.name)


class ForeignKeyAccessor(FieldAccessor):
    def __init__(self, model, field, name):
        super(ForeignKeyAccessor, self).__init__(model, field, name)
        self.rel_model = field.rel_model

    def get_rel_instance(self, instance):
        value = instance.__data__.get(self.name)
        if value is not None or self.name in instance.__rel__:
            if self.name not in instance.__rel__ and self.field.lazy_load:
                obj = self.rel_model.get(self.field.rel_field == value)
                instance.__rel__[self.name] = obj
            return instance.__rel__.get(self.name, value)
        elif not self.field.null and self.field.lazy_load:
            raise self.rel_model.DoesNotExist
        return value

    def __get__(self, instance, instance_type=None):
        if instance is not None:
            return self.get_rel_instance(instance)
        return self.field

    def __set__(self, instance, obj):
        if isinstance(obj, self.rel_model):
            instance.__data__[self.name] = getattr(obj, self.field.rel_field.name)
            instance.__rel__[self.name] = obj
        else:
            fk_value = instance.__data__.get(self.name)
            instance.__data__[self.name] = obj
            if (obj != fk_value or obj is None) and \
               self.name in instance.__rel__:
                del instance.__rel__[self.name]
        instance._dirty.add(self.name)


class BackrefAccessor(object):
    def __init__(self, field):
        self.field = field
        self.model = field.rel_model
        self.rel_model = field.model

    def __get__(self, instance, instance_type=None):
        if instance is not None:
            dest = self.field.rel_field.name
            return (self.rel_model
                    .select()
                    .where(self.field == getattr(instance, dest)))
        return self


class ObjectIdAccessor(object):
    """Gives direct access to the underlying id"""
    def __init__(self, field):
        self.field = field

    def __get__(self, instance, instance_type=None):
        if instance is not None:
            value = instance.__data__.get(self.field.name)
            # Pull the object-id from the related object if it is not set.
            if value is None and self.field.name in instance.__rel__:
                rel_obj = instance.__rel__[self.field.name]
                value = getattr(rel_obj, self.field.rel_field.name)
            return value
        return self.field

    def __set__(self, instance, value):
        setattr(instance, self.field.name, value)


class Field(ColumnBase):
    _field_counter = 0
    _order = 0
    accessor_class = FieldAccessor
    auto_increment = False
    default_index_type = None
    field_type = 'DEFAULT'
    unpack = True

    def __init__(self, null=False, index=False, unique=False, column_name=None,
                 default=None, primary_key=False, constraints=None,
                 sequence=None, collation=None, unindexed=False, choices=None,
                 help_text=None, verbose_name=None, index_type=None,
                 db_column=None, _hidden=False):
        if db_column is not None:
            __deprecated__('"db_column" has been deprecated in favor of '
                           '"column_name" for Field objects.')
            column_name = db_column

        self.null = null
        self.index = index
        self.unique = unique
        self.column_name = column_name
        self.default = default
        self.primary_key = primary_key
        self.constraints = constraints  # List of column constraints.
        self.sequence = sequence  # Name of sequence, e.g. foo_id_seq.
        self.collation = collation
        self.unindexed = unindexed
        self.choices = choices
        self.help_text = help_text
        self.verbose_name = verbose_name
        self.index_type = index_type or self.default_index_type
        self._hidden = _hidden

        # Used internally for recovering the order in which Fields were defined
        # on the Model class.
        Field._field_counter += 1
        self._order = Field._field_counter
        self._sort_key = (self.primary_key and 1 or 2), self._order

    def __hash__(self):
        return hash(self.name + '.' + self.model.__name__)

    def __repr__(self):
        if hasattr(self, 'model') and getattr(self, 'name', None):
            return '<%s: %s.%s>' % (type(self).__name__,
                                    self.model.__name__,
                                    self.name)
        return '<%s: (unbound)>' % type(self).__name__

    def bind(self, model, name, set_attribute=True):
        self.model = model
        self.name = self.safe_name = name
        self.column_name = self.column_name or name
        if set_attribute:
            setattr(model, name, self.accessor_class(model, self, name))

    @property
    def column(self):
        return Column(self.model._meta.table, self.column_name)

    def adapt(self, value):
        return value

    def db_value(self, value):
        return value if value is None else self.adapt(value)

    def python_value(self, value):
        return value if value is None else self.adapt(value)

    def to_value(self, value):
        return Value(value, self.db_value, unpack=False)

    def get_sort_key(self, ctx):
        return self._sort_key

    def __sql__(self, ctx):
        return ctx.sql(self.column)

    def get_modifiers(self):
        pass

    def ddl_datatype(self, ctx):
        if ctx and ctx.state.field_types:
            column_type = ctx.state.field_types.get(self.field_type,
                                                    self.field_type)
        else:
            column_type = self.field_type

        modifiers = self.get_modifiers()
        if column_type and modifiers:
            modifier_literal = ', '.join([str(m) for m in modifiers])
            return SQL('%s(%s)' % (column_type, modifier_literal))
        else:
            return SQL(column_type)

    def ddl(self, ctx):
        accum = [Entity(self.column_name)]
        data_type = self.ddl_datatype(ctx)
        if data_type:
            accum.append(data_type)
        if self.unindexed:
            accum.append(SQL('UNINDEXED'))
        if not self.null:
            accum.append(SQL('NOT NULL'))
        if self.primary_key:
            accum.append(SQL('PRIMARY KEY'))
        if self.sequence:
            accum.append(SQL("DEFAULT NEXTVAL('%s')" % self.sequence))
        if self.constraints:
            accum.extend(self.constraints)
        if self.collation:
            accum.append(SQL('COLLATE %s' % self.collation))
        return NodeList(accum)


class AnyField(Field):
    field_type = 'ANY'


class IntegerField(Field):
    field_type = 'INT'

    def adapt(self, value):
        try:
            return int(value)
        except ValueError:
            return value


class BigIntegerField(IntegerField):
    field_type = 'BIGINT'


class SmallIntegerField(IntegerField):
    field_type = 'SMALLINT'


class AutoField(IntegerField):
    auto_increment = True
    field_type = 'AUTO'

    def __init__(self, *args, **kwargs):
        if kwargs.get('primary_key') is False:
            raise ValueError('%s must always be a primary key.' % type(self))
        kwargs['primary_key'] = True
        super(AutoField, self).__init__(*args, **kwargs)


class BigAutoField(AutoField):
    field_type = 'BIGAUTO'


class IdentityField(AutoField):
    field_type = 'INT GENERATED BY DEFAULT AS IDENTITY'

    def __init__(self, generate_always=False, **kwargs):
        if generate_always:
            self.field_type = 'INT GENERATED ALWAYS AS IDENTITY'
        super(IdentityField, self).__init__(**kwargs)


class PrimaryKeyField(AutoField):
    def __init__(self, *args, **kwargs):
        __deprecated__('"PrimaryKeyField" has been renamed to "AutoField". '
                       'Please update your code accordingly as this will be '
                       'completely removed in a subsequent release.')
        super(PrimaryKeyField, self).__init__(*args, **kwargs)


class FloatField(Field):
    field_type = 'FLOAT'

    def adapt(self, value):
        try:
            return float(value)
        except ValueError:
            return value


class DoubleField(FloatField):
    field_type = 'DOUBLE'


class DecimalField(Field):
    field_type = 'DECIMAL'

    def __init__(self, max_digits=10, decimal_places=5, auto_round=False,
                 rounding=None, *args, **kwargs):
        self.max_digits = max_digits
        self.decimal_places = decimal_places
        self.auto_round = auto_round
        self.rounding = rounding or decimal.DefaultContext.rounding
        self._exp = decimal.Decimal(10) ** (-self.decimal_places)
        super(DecimalField, self).__init__(*args, **kwargs)

    def get_modifiers(self):
        return [self.max_digits, self.decimal_places]

    def db_value(self, value):
        D = decimal.Decimal
        if not value:
            return value if value is None else D(0)
        if self.auto_round:
            decimal_value = D(text_type(value))
            return decimal_value.quantize(self._exp, rounding=self.rounding)
        return value

    def python_value(self, value):
        if value is not None:
            if isinstance(value, decimal.Decimal):
                return value
            return decimal.Decimal(text_type(value))


class _StringField(Field):
    def adapt(self, value):
        if isinstance(value, text_type):
            return value
        elif isinstance(value, bytes_type):
            return value.decode('utf-8')
        return text_type(value)

    def __add__(self, other): return StringExpression(self, OP.CONCAT, other)
    def __radd__(self, other): return StringExpression(other, OP.CONCAT, self)


class CharField(_StringField):
    field_type = 'VARCHAR'

    def __init__(self, max_length=255, *args, **kwargs):
        self.max_length = max_length
        super(CharField, self).__init__(*args, **kwargs)

    def get_modifiers(self):
        return self.max_length and [self.max_length] or None


class FixedCharField(CharField):
    field_type = 'CHAR'

    def python_value(self, value):
        value = super(FixedCharField, self).python_value(value)
        if value:
            value = value.strip()
        return value


class TextField(_StringField):
    field_type = 'TEXT'


class BlobField(Field):
    field_type = 'BLOB'

    def _db_hook(self, database):
        if database is None:
            self._constructor = bytearray
        else:
            self._constructor = database.get_binary_type()

    def bind(self, model, name, set_attribute=True):
        self._constructor = bytearray
        if model._meta.database:
            if isinstance(model._meta.database, Proxy):
                model._meta.database.attach_callback(self._db_hook)
            else:
                self._db_hook(model._meta.database)

        # Attach a hook to the model metadata; in the event the database is
        # changed or set at run-time, we will be sure to apply our callback and
        # use the proper data-type for our database driver.
        model._meta._db_hooks.append(self._db_hook)
        return super(BlobField, self).bind(model, name, set_attribute)

    def db_value(self, value):
        if isinstance(value, text_type):
            value = value.encode('raw_unicode_escape')
        if isinstance(value, bytes_type):
            return self._constructor(value)
        return value


class BitField(BitwiseMixin, BigIntegerField):
    def __init__(self, *args, **kwargs):
        kwargs.setdefault('default', 0)
        super(BitField, self).__init__(*args, **kwargs)
        self.__current_flag = 1

    def flag(self, value=None):
        if value is None:
            value = self.__current_flag
            self.__current_flag <<= 1
        else:
            self.__current_flag = value << 1

        class FlagDescriptor(ColumnBase):
            def __init__(self, field, value):
                self._field = field
                self._value = value
                super(FlagDescriptor, self).__init__()
            def clear(self):
                return self._field.bin_and(~self._value)
            def set(self):
                return self._field.bin_or(self._value)
            def __get__(self, instance, instance_type=None):
                if instance is None:
                    return self
                value = getattr(instance, self._field.name) or 0
                return (value & self._value) != 0
            def __set__(self, instance, is_set):
                if is_set not in (True, False):
                    raise ValueError('Value must be either True or False')
                value = getattr(instance, self._field.name) or 0
                if is_set:
                    value |= self._value
                else:
                    value &= ~self._value
                setattr(instance, self._field.name, value)
            def __sql__(self, ctx):
                return ctx.sql(self._field.bin_and(self._value) != 0)
        return FlagDescriptor(self, value)


class BigBitFieldData(object):
    def __init__(self, instance, name):
        self.instance = instance
        self.name = name
        value = self.instance.__data__.get(self.name)
        if not value:
            value = bytearray()
        elif not isinstance(value, bytearray):
            value = bytearray(value)
        self._buffer = self.instance.__data__[self.name] = value

    def clear(self):
        self._buffer.clear()

    def _ensure_length(self, idx):
        byte_num, byte_offset = divmod(idx, 8)
        cur_size = len(self._buffer)
        if cur_size <= byte_num:
            self._buffer.extend(b'\x00' * ((byte_num + 1) - cur_size))
        return byte_num, byte_offset

    def set_bit(self, idx):
        byte_num, byte_offset = self._ensure_length(idx)
        self._buffer[byte_num] |= (1 << byte_offset)

    def clear_bit(self, idx):
        byte_num, byte_offset = self._ensure_length(idx)
        self._buffer[byte_num] &= ~(1 << byte_offset)

    def toggle_bit(self, idx):
        byte_num, byte_offset = self._ensure_length(idx)
        self._buffer[byte_num] ^= (1 << byte_offset)
        return bool(self._buffer[byte_num] & (1 << byte_offset))

    def is_set(self, idx):
        byte_num, byte_offset = divmod(idx, 8)
        cur_size = len(self._buffer)
        if cur_size <= byte_num:
            return False
        return bool(self._buffer[byte_num] & (1 << byte_offset))

    __getitem__ = is_set
    def __setitem__(self, item, value):
        self.set_bit(item) if value else self.clear_bit(item)
    __delitem__ = clear_bit

    def __len__(self):
        return len(self._buffer)

    def _get_compatible_data(self, other):
        if isinstance(other, BigBitFieldData):
            data = other._buffer
        elif isinstance(other, (bytes, bytearray, memoryview)):
            data = other
        else:
            raise ValueError('Incompatible data-type')
        diff = len(data) - len(self)
        if diff > 0: self._buffer.extend(b'\x00' * diff)
        return data

    def _bitwise_op(self, other, op):
        if isinstance(other, BigBitFieldData):
            data = other._buffer
        elif isinstance(other, (bytes, bytearray, memoryview)):
            data = other
        else:
            raise ValueError('Incompatible data-type')
        buf = bytearray(b'\x00' * max(len(self), len(other)))
        it = itertools.zip_longest(self._buffer, data, fillvalue=0)
        for i, (a, b) in enumerate(it):
            buf[i] = op(a, b)
        return buf

    def __and__(self, other):
        return self._bitwise_op(other, operator.and_)
    def __or__(self, other):
        return self._bitwise_op(other, operator.or_)
    def __xor__(self, other):
        return self._bitwise_op(other, operator.xor)

    def __iter__(self):
        for b in self._buffer:
            for j in range(8):
                yield 1 if (b & (1 << j)) else 0

    def __repr__(self):
        return repr(self._buffer)
    if sys.version_info[0] < 3:
        def __str__(self):
            return bytes_type(self._buffer)
    else:
        def __bytes__(self):
            return bytes_type(self._buffer)


class BigBitFieldAccessor(FieldAccessor):
    def __get__(self, instance, instance_type=None):
        if instance is None:
            return self.field
        return BigBitFieldData(instance, self.name)
    def __set__(self, instance, value):
        if isinstance(value, memoryview):
            value = value.tobytes()
        elif isinstance(value, buffer_type):
            value = bytes(value)
        elif isinstance(value, bytearray):
            value = bytes_type(value)
        elif isinstance(value, BigBitFieldData):
            value = bytes_type(value._buffer)
        elif isinstance(value, text_type):
            value = value.encode('utf-8')
        elif not isinstance(value, bytes_type):
            raise ValueError('Value must be either a bytes, memoryview or '
                             'BigBitFieldData instance.')
        super(BigBitFieldAccessor, self).__set__(instance, value)


class BigBitField(BlobField):
    accessor_class = BigBitFieldAccessor

    def __init__(self, *args, **kwargs):
        kwargs.setdefault('default', bytes_type)
        super(BigBitField, self).__init__(*args, **kwargs)

    def db_value(self, value):
        return bytes_type(value) if value is not None else value


class UUIDField(Field):
    field_type = 'UUID'

    def db_value(self, value):
        if isinstance(value, basestring) and len(value) == 32:
            # Hex string. No transformation is necessary.
            return value
        elif isinstance(value, bytes) and len(value) == 16:
            # Allow raw binary representation.
            value = uuid.UUID(bytes=value)
        if isinstance(value, uuid.UUID):
            return value.hex
        try:
            return uuid.UUID(value).hex
        except:
            return value

    def python_value(self, value):
        if isinstance(value, uuid.UUID):
            return value
        return uuid.UUID(value) if value is not None else None


class BinaryUUIDField(BlobField):
    field_type = 'UUIDB'

    def db_value(self, value):
        if isinstance(value, bytes) and len(value) == 16:
            # Raw binary value. No transformation is necessary.
            return self._constructor(value)
        elif isinstance(value, basestring) and len(value) == 32:
            # Allow hex string representation.
            value = uuid.UUID(hex=value)
        if isinstance(value, uuid.UUID):
            return self._constructor(value.bytes)
        elif value is not None:
            raise ValueError('value for binary UUID field must be UUID(), '
                             'a hexadecimal string, or a bytes object.')

    def python_value(self, value):
        if isinstance(value, uuid.UUID):
            return value
        elif isinstance(value, memoryview):
            value = value.tobytes()
        elif value and not isinstance(value, bytes):
            value = bytes(value)
        return uuid.UUID(bytes=value) if value is not None else None


def _date_part(date_part):
    def dec(self):
        return self.model._meta.database.extract_date(date_part, self)
    return dec

def format_date_time(value, formats, post_process=None):
    post_process = post_process or (lambda x: x)
    for fmt in formats:
        try:
            return post_process(datetime.datetime.strptime(value, fmt))
        except ValueError:
            pass
    return value

def simple_date_time(value):
    try:
        return datetime.datetime.strptime(value, '%Y-%m-%d %H:%M:%S')
    except (TypeError, ValueError):
        return value


class _BaseFormattedField(Field):
    formats = None

    def __init__(self, formats=None, *args, **kwargs):
        if formats is not None:
            self.formats = formats
        super(_BaseFormattedField, self).__init__(*args, **kwargs)


class DateTimeField(_BaseFormattedField):
    field_type = 'DATETIME'
    formats = [
        '%Y-%m-%d %H:%M:%S.%f',
        '%Y-%m-%d %H:%M:%S',
        '%Y-%m-%d',
    ]

    def adapt(self, value):
        if value and isinstance(value, basestring):
            return format_date_time(value, self.formats)
        return value

    def to_timestamp(self):
        return self.model._meta.database.to_timestamp(self)

    def truncate(self, part):
        return self.model._meta.database.truncate_date(part, self)

    year = property(_date_part('year'))
    month = property(_date_part('month'))
    day = property(_date_part('day'))
    hour = property(_date_part('hour'))
    minute = property(_date_part('minute'))
    second = property(_date_part('second'))


class DateField(_BaseFormattedField):
    field_type = 'DATE'
    formats = [
        '%Y-%m-%d',
        '%Y-%m-%d %H:%M:%S',
        '%Y-%m-%d %H:%M:%S.%f',
    ]

    def adapt(self, value):
        if value and isinstance(value, basestring):
            pp = lambda x: x.date()
            return format_date_time(value, self.formats, pp)
        elif value and isinstance(value, datetime.datetime):
            return value.date()
        return value

    def to_timestamp(self):
        return self.model._meta.database.to_timestamp(self)

    def truncate(self, part):
        return self.model._meta.database.truncate_date(part, self)

    year = property(_date_part('year'))
    month = property(_date_part('month'))
    day = property(_date_part('day'))


class TimeField(_BaseFormattedField):
    field_type = 'TIME'
    formats = [
        '%H:%M:%S.%f',
        '%H:%M:%S',
        '%H:%M',
        '%Y-%m-%d %H:%M:%S.%f',
        '%Y-%m-%d %H:%M:%S',
    ]

    def adapt(self, value):
        if value:
            if isinstance(value, basestring):
                pp = lambda x: x.time()
                return format_date_time(value, self.formats, pp)
            elif isinstance(value, datetime.datetime):
                return value.time()
        if value is not None and isinstance(value, datetime.timedelta):
            return (datetime.datetime.min + value).time()
        return value

    hour = property(_date_part('hour'))
    minute = property(_date_part('minute'))
    second = property(_date_part('second'))


def _timestamp_date_part(date_part):
    def dec(self):
        db = self.model._meta.database
        expr = ((self / Value(self.resolution, converter=False))
                if self.resolution > 1 else self)
        return db.extract_date(date_part, db.from_timestamp(expr))
    return dec


class TimestampField(BigIntegerField):
    # Support second -> microsecond resolution.
    valid_resolutions = [10**i for i in range(7)]

    def __init__(self, *args, **kwargs):
        self.resolution = kwargs.pop('resolution', None)

        if not self.resolution:
            self.resolution = 1
        elif self.resolution in range(2, 7):
            self.resolution = 10 ** self.resolution
        elif self.resolution not in self.valid_resolutions:
            raise ValueError('TimestampField resolution must be one of: %s' %
                             ', '.join(str(i) for i in self.valid_resolutions))
        self.ticks_to_microsecond = 1000000 // self.resolution

        self.utc = kwargs.pop('utc', False) or False
        dflt = utcnow if self.utc else datetime.datetime.now
        kwargs.setdefault('default', dflt)
        super(TimestampField, self).__init__(*args, **kwargs)

    def local_to_utc(self, dt):
        # Convert naive local datetime into naive UTC, e.g.:
        # 2019-03-01T12:00:00 (local=US/Central) -> 2019-03-01T18:00:00.
        # 2019-05-01T12:00:00 (local=US/Central) -> 2019-05-01T17:00:00.
        # 2019-03-01T12:00:00 (local=UTC)        -> 2019-03-01T12:00:00.
        return datetime.datetime(*time.gmtime(time.mktime(dt.timetuple()))[:6])

    def utc_to_local(self, dt):
        # Convert a naive UTC datetime into local time, e.g.:
        # 2019-03-01T18:00:00 (local=US/Central) -> 2019-03-01T12:00:00.
        # 2019-05-01T17:00:00 (local=US/Central) -> 2019-05-01T12:00:00.
        # 2019-03-01T12:00:00 (local=UTC)        -> 2019-03-01T12:00:00.
        ts = calendar.timegm(dt.utctimetuple())
        return datetime.datetime.fromtimestamp(ts)

    def get_timestamp(self, value):
        if self.utc:
            # If utc-mode is on, then we assume all naive datetimes are in UTC.
            return calendar.timegm(value.utctimetuple())
        else:
            return time.mktime(value.timetuple())

    def db_value(self, value):
        if value is None:
            return

        if isinstance(value, datetime.datetime):
            pass
        elif isinstance(value, datetime.date):
            value = datetime.datetime(value.year, value.month, value.day)
        else:
            return int(round(value * self.resolution))

        timestamp = self.get_timestamp(value)
        if self.resolution > 1:
            timestamp += (value.microsecond * .000001)
            timestamp *= self.resolution
        return int(round(timestamp))

    def python_value(self, value):
        if value is not None and isinstance(value, (int, float, long)):
            if self.resolution > 1:
                value, ticks = divmod(value, self.resolution)
                microseconds = int(ticks * self.ticks_to_microsecond)
            else:
                microseconds = 0

            if self.utc:
                value = utcfromtimestamp(value)
            else:
                value = datetime.datetime.fromtimestamp(value)

            if microseconds:
                value = value.replace(microsecond=microseconds)

        return value

    def from_timestamp(self):
        expr = ((self / Value(self.resolution, converter=False))
                if self.resolution > 1 else self)
        return self.model._meta.database.from_timestamp(expr)

    year = property(_timestamp_date_part('year'))
    month = property(_timestamp_date_part('month'))
    day = property(_timestamp_date_part('day'))
    hour = property(_timestamp_date_part('hour'))
    minute = property(_timestamp_date_part('minute'))
    second = property(_timestamp_date_part('second'))


class IPField(BigIntegerField):
    def db_value(self, val):
        if val is not None:
            return struct.unpack('!I', socket.inet_aton(val))[0]

    def python_value(self, val):
        if val is not None:
            return socket.inet_ntoa(struct.pack('!I', val))


class BooleanField(Field):
    field_type = 'BOOL'
    adapt = bool


class BareField(Field):
    def __init__(self, adapt=None, *args, **kwargs):
        super(BareField, self).__init__(*args, **kwargs)
        if adapt is not None:
            self.adapt = adapt

    def ddl_datatype(self, ctx):
        return


class ForeignKeyField(Field):
    accessor_class = ForeignKeyAccessor
    backref_accessor_class = BackrefAccessor

    def __init__(self, model, field=None, backref=None, on_delete=None,
                 on_update=None, deferrable=None, _deferred=None,
                 rel_model=None, to_field=None, object_id_name=None,
                 lazy_load=True, constraint_name=None, related_name=None,
                 *args, **kwargs):
        kwargs.setdefault('index', True)

        super(ForeignKeyField, self).__init__(*args, **kwargs)

        if rel_model is not None:
            __deprecated__('"rel_model" has been deprecated in favor of '
                           '"model" for ForeignKeyField objects.')
            model = rel_model
        if to_field is not None:
            __deprecated__('"to_field" has been deprecated in favor of '
                           '"field" for ForeignKeyField objects.')
            field = to_field
        if related_name is not None:
            __deprecated__('"related_name" has been deprecated in favor of '
                           '"backref" for Field objects.')
            backref = related_name

        self._is_self_reference = model == 'self'
        self.rel_model = model
        self.rel_field = field
        self.declared_backref = backref
        self.backref = None
        self.on_delete = on_delete
        self.on_update = on_update
        self.deferrable = deferrable
        self.deferred = _deferred
        self.object_id_name = object_id_name
        self.lazy_load = lazy_load
        self.constraint_name = constraint_name

    @property
    def field_type(self):
        if not isinstance(self.rel_field, AutoField):
            return self.rel_field.field_type
        elif isinstance(self.rel_field, BigAutoField):
            return BigIntegerField.field_type
        return IntegerField.field_type

    def get_modifiers(self):
        if not isinstance(self.rel_field, AutoField):
            return self.rel_field.get_modifiers()
        return super(ForeignKeyField, self).get_modifiers()

    def adapt(self, value):
        return self.rel_field.adapt(value)

    def db_value(self, value):
        if isinstance(value, self.rel_model):
            value = getattr(value, self.rel_field.name)
        return self.rel_field.db_value(value)

    def python_value(self, value):
        if isinstance(value, self.rel_model):
            return value
        return self.rel_field.python_value(value)

    def bind(self, model, name, set_attribute=True):
        if not self.column_name:
            self.column_name = name if name.endswith('_id') else name + '_id'
        if not self.object_id_name:
            self.object_id_name = self.column_name
            if self.object_id_name == name:
                self.object_id_name += '_id'
        elif self.object_id_name == name:
            raise ValueError('ForeignKeyField "%s"."%s" specifies an '
                             'object_id_name that conflicts with its field '
                             'name.' % (model._meta.name, name))
        if self._is_self_reference:
            self.rel_model = model
        if isinstance(self.rel_field, basestring):
            self.rel_field = getattr(self.rel_model, self.rel_field)
        elif self.rel_field is None:
            self.rel_field = self.rel_model._meta.primary_key

        # Bind field before assigning backref, so field is bound when
        # calling declared_backref() (if callable).
        super(ForeignKeyField, self).bind(model, name, set_attribute)
        self.safe_name = self.object_id_name

        if callable_(self.declared_backref):
            self.backref = self.declared_backref(self)
        else:
            self.backref, self.declared_backref = self.declared_backref, None
        if not self.backref:
            self.backref = '%s_set' % model._meta.name

        if set_attribute:
            setattr(model, self.object_id_name, ObjectIdAccessor(self))
            if self.backref not in '!+':
                setattr(self.rel_model, self.backref,
                        self.backref_accessor_class(self))

    def foreign_key_constraint(self):
        parts = []
        if self.constraint_name:
            parts.extend((SQL('CONSTRAINT'), Entity(self.constraint_name)))
        parts.extend([
            SQL('FOREIGN KEY'),
            EnclosedNodeList((self,)),
            SQL('REFERENCES'),
            self.rel_model,
            EnclosedNodeList((self.rel_field,))])
        if self.on_delete:
            parts.append(SQL('ON DELETE %s' % self.on_delete))
        if self.on_update:
            parts.append(SQL('ON UPDATE %s' % self.on_update))
        if self.deferrable:
            parts.append(SQL('DEFERRABLE %s' % self.deferrable))
        return NodeList(parts)

    def __getattr__(self, attr):
        if attr.startswith('__'):
            # Prevent recursion error when deep-copying.
            raise AttributeError('Cannot look-up non-existant "__" methods.')
        if attr in self.rel_model._meta.fields:
            return self.rel_model._meta.fields[attr]
        raise AttributeError('Foreign-key has no attribute %s, nor is it a '
                             'valid field on the related model.' % attr)


class DeferredForeignKey(Field):
    _unresolved = set()

    def __init__(self, rel_model_name, **kwargs):
        self.field_kwargs = kwargs
        self.rel_model_name = rel_model_name.lower()
        DeferredForeignKey._unresolved.add(self)
        super(DeferredForeignKey, self).__init__(
            column_name=kwargs.get('column_name'),
            null=kwargs.get('null'),
            primary_key=kwargs.get('primary_key'))

    __hash__ = object.__hash__

    def __deepcopy__(self, memo=None):
        return DeferredForeignKey(self.rel_model_name, **self.field_kwargs)

    def set_model(self, rel_model):
        field = ForeignKeyField(rel_model, _deferred=True, **self.field_kwargs)
        if field.primary_key:
            # NOTE: this calls add_field() under-the-hood.
            self.model._meta.set_primary_key(self.name, field)
        else:
            self.model._meta.add_field(self.name, field)

    @staticmethod
    def resolve(model_cls):
        unresolved = sorted(DeferredForeignKey._unresolved,
                            key=operator.attrgetter('_order'))
        for dr in unresolved:
            if dr.rel_model_name == model_cls.__name__.lower():
                dr.set_model(model_cls)
                DeferredForeignKey._unresolved.discard(dr)


class DeferredThroughModel(object):
    def __init__(self):
        self._refs = []

    def set_field(self, model, field, name):
        self._refs.append((model, field, name))

    def set_model(self, through_model):
        for src_model, m2mfield, name in self._refs:
            m2mfield.through_model = through_model
            src_model._meta.add_field(name, m2mfield)


class MetaField(Field):
    column_name = default = model = name = None
    primary_key = False


class ManyToManyFieldAccessor(FieldAccessor):
    def __init__(self, model, field, name):
        super(ManyToManyFieldAccessor, self).__init__(model, field, name)
        self.model = field.model
        self.rel_model = field.rel_model
        self.through_model = field.through_model
        src_fks = self.through_model._meta.model_refs[self.model]
        dest_fks = self.through_model._meta.model_refs[self.rel_model]
        if not src_fks:
            raise ValueError('Cannot find foreign-key to "%s" on "%s" model.' %
                             (self.model, self.through_model))
        elif not dest_fks:
            raise ValueError('Cannot find foreign-key to "%s" on "%s" model.' %
                             (self.rel_model, self.through_model))
        self.src_fk = src_fks[0]
        self.dest_fk = dest_fks[0]

    def __get__(self, instance, instance_type=None, force_query=False):
        if instance is not None:
            if not force_query and self.src_fk.backref != '+':
                backref = getattr(instance, self.src_fk.backref)
                if isinstance(backref, list):
                    return [getattr(obj, self.dest_fk.name) for obj in backref]

            src_id = getattr(instance, self.src_fk.rel_field.name)
            if src_id is None and self.field._prevent_unsaved:
                raise ValueError('Cannot get many-to-many "%s" for unsaved '
                                 'instance "%s".' % (self.field, instance))
            return (ManyToManyQuery(instance, self, self.rel_model)
                    .join(self.through_model)
                    .join(self.model)
                    .where(self.src_fk == src_id))

        return self.field

    def __set__(self, instance, value):
        src_id = getattr(instance, self.src_fk.rel_field.name)
        if src_id is None and self.field._prevent_unsaved:
            raise ValueError('Cannot set many-to-many "%s" for unsaved '
                             'instance "%s".' % (self.field, instance))
        query = self.__get__(instance, force_query=True)
        query.add(value, clear_existing=True)


class ManyToManyField(MetaField):
    accessor_class = ManyToManyFieldAccessor

    def __init__(self, model, backref=None, through_model=None, on_delete=None,
                 on_update=None, prevent_unsaved=True, _is_backref=False):
        if through_model is not None:
            if not (isinstance(through_model, DeferredThroughModel) or
                    is_model(through_model)):
                raise TypeError('Unexpected value for through_model. Expected '
                                'Model or DeferredThroughModel.')
            if not _is_backref and (on_delete is not None or on_update is not None):
                raise ValueError('Cannot specify on_delete or on_update when '
                                 'through_model is specified.')
        self.rel_model = model
        self.backref = backref
        self._through_model = through_model
        self._on_delete = on_delete
        self._on_update = on_update
        self._prevent_unsaved = prevent_unsaved
        self._is_backref = _is_backref

    def _get_descriptor(self):
        return ManyToManyFieldAccessor(self)

    def bind(self, model, name, set_attribute=True):
        if isinstance(self._through_model, DeferredThroughModel):
            self._through_model.set_field(model, self, name)
            return

        super(ManyToManyField, self).bind(model, name, set_attribute)

        if not self._is_backref:
            many_to_many_field = ManyToManyField(
                self.model,
                backref=name,
                through_model=self.through_model,
                on_delete=self._on_delete,
                on_update=self._on_update,
                _is_backref=True)
            self.backref = self.backref or model._meta.name + 's'
            self.rel_model._meta.add_field(self.backref, many_to_many_field)

    def get_models(self):
        return [model for _, model in sorted((
            (self._is_backref, self.model),
            (not self._is_backref, self.rel_model)))]

    @property
    def through_model(self):
        if self._through_model is None:
            self._through_model = self._create_through_model()
        return self._through_model

    @through_model.setter
    def through_model(self, value):
        self._through_model = value

    def _create_through_model(self):
        lhs, rhs = self.get_models()
        tables = [model._meta.table_name for model in (lhs, rhs)]

        class Meta:
            database = self.model._meta.database
            schema = self.model._meta.schema
            table_name = '%s_%s_through' % tuple(tables)
            indexes = (
                ((lhs._meta.name, rhs._meta.name),
                 True),)

        params = {'on_delete': self._on_delete, 'on_update': self._on_update}
        attrs = {
            lhs._meta.name: ForeignKeyField(lhs, **params),
            rhs._meta.name: ForeignKeyField(rhs, **params),
            'Meta': Meta}

        klass_name = '%s%sThrough' % (lhs.__name__, rhs.__name__)
        return type(klass_name, (Model,), attrs)

    def get_through_model(self):
        # XXX: Deprecated. Just use the "through_model" property.
        return self.through_model


class VirtualField(MetaField):
    field_class = None

    def __init__(self, field_class=None, *args, **kwargs):
        Field = field_class if field_class is not None else self.field_class
        self.field_instance = Field() if Field is not None else None
        super(VirtualField, self).__init__(*args, **kwargs)

    def db_value(self, value):
        if self.field_instance is not None:
            return self.field_instance.db_value(value)
        return value

    def python_value(self, value):
        if self.field_instance is not None:
            return self.field_instance.python_value(value)
        return value

    def bind(self, model, name, set_attribute=True):
        self.model = model
        self.column_name = self.name = self.safe_name = name
        setattr(model, name, self.accessor_class(model, self, name))


class CompositeKey(MetaField):
    sequence = None

    def __init__(self, *field_names):
        self.field_names = field_names
        self._safe_field_names = None

    @property
    def safe_field_names(self):
        if self._safe_field_names is None:
            if self.model is None:
                return self.field_names

            self._safe_field_names = [self.model._meta.fields[f].safe_name
                                      for f in self.field_names]
        return self._safe_field_names

    def __get__(self, instance, instance_type=None):
        if instance is not None:
            return tuple([getattr(instance, f) for f in self.safe_field_names])
        return self

    def __set__(self, instance, value):
        if not isinstance(value, (list, tuple)):
            raise TypeError('A list or tuple must be used to set the value of '
                            'a composite primary key.')
        if len(value) != len(self.field_names):
            raise ValueError('The length of the value must equal the number '
                             'of columns of the composite primary key.')
        for idx, field_value in enumerate(value):
            setattr(instance, self.field_names[idx], field_value)

    def __eq__(self, other):
        expressions = [(self.model._meta.fields[field] == value)
                       for field, value in zip(self.field_names, other)]
        return reduce(operator.and_, expressions)

    def __ne__(self, other):
        return ~(self == other)

    def __hash__(self):
        return hash((self.model.__name__, self.field_names))

    def __sql__(self, ctx):
        # If the composite PK is being selected, do not use parens. Elsewhere,
        # such as in an expression, we want to use parentheses and treat it as
        # a row value.
        parens = ctx.scope != SCOPE_SOURCE
        return ctx.sql(NodeList([self.model._meta.fields[field]
                                 for field in self.field_names], ', ', parens))

    def bind(self, model, name, set_attribute=True):
        self.model = model
        self.column_name = self.name = self.safe_name = name
        setattr(model, self.name, self)


class _SortedFieldList(object):
    __slots__ = ('_keys', '_items')

    def __init__(self):
        self._keys = []
        self._items = []

    def __getitem__(self, i):
        return self._items[i]

    def __iter__(self):
        return iter(self._items)

    def __contains__(self, item):
        k = item._sort_key
        i = bisect_left(self._keys, k)
        j = bisect_right(self._keys, k)
        return item in self._items[i:j]

    def index(self, field):
        return self._keys.index(field._sort_key)

    def insert(self, item):
        k = item._sort_key
        i = bisect_left(self._keys, k)
        self._keys.insert(i, k)
        self._items.insert(i, item)

    def remove(self, item):
        idx = self.index(item)
        del self._items[idx]
        del self._keys[idx]


# MODELS


class SchemaManager(object):
    def __init__(self, model, database=None, **context_options):
        self.model = model
        self._database = database
        context_options.setdefault('scope', SCOPE_VALUES)
        self.context_options = context_options

    @property
    def database(self):
        db = self._database or self.model._meta.database
        if db is None:
            raise ImproperlyConfigured('database attribute does not appear to '
                                       'be set on the model: %s' % self.model)
        return db

    @database.setter
    def database(self, value):
        self._database = value

    def _create_context(self):
        return self.database.get_sql_context(**self.context_options)

    def _create_table(self, safe=True, **options):
        is_temp = options.pop('temporary', False)
        ctx = self._create_context()
        ctx.literal('CREATE TEMPORARY TABLE ' if is_temp else 'CREATE TABLE ')
        if safe:
            ctx.literal('IF NOT EXISTS ')
        ctx.sql(self.model).literal(' ')

        columns = []
        constraints = []
        meta = self.model._meta
        if meta.composite_key:
            pk_columns = [meta.fields[field_name].column
                          for field_name in meta.primary_key.field_names]
            constraints.append(NodeList((SQL('PRIMARY KEY'),
                                         EnclosedNodeList(pk_columns))))

        for field in meta.sorted_fields:
            columns.append(field.ddl(ctx))
            if isinstance(field, ForeignKeyField) and not field.deferred:
                constraints.append(field.foreign_key_constraint())

        if meta.constraints:
            constraints.extend(meta.constraints)

        constraints.extend(self._create_table_option_sql(options))
        ctx.sql(EnclosedNodeList(columns + constraints))

        if meta.table_settings is not None:
            table_settings = ensure_tuple(meta.table_settings)
            for setting in table_settings:
                if not isinstance(setting, basestring):
                    raise ValueError('table_settings must be strings')
                ctx.literal(' ').literal(setting)

        extra_opts = []
        if meta.strict_tables: extra_opts.append('STRICT')
        if meta.without_rowid: extra_opts.append('WITHOUT ROWID')
        if extra_opts:
            ctx.literal(' %s' % ', '.join(extra_opts))
        return ctx

    def _create_table_option_sql(self, options):
        accum = []
        options = merge_dict(self.model._meta.options or {}, options)
        if not options:
            return accum

        for key, value in sorted(options.items()):
            if not isinstance(value, Node):
                if is_model(value):
                    value = value._meta.table
                else:
                    value = SQL(str(value))
            accum.append(NodeList((SQL(key), value), glue='='))
        return accum

    def create_table(self, safe=True, **options):
        self.database.execute(self._create_table(safe=safe, **options))

    def _create_table_as(self, table_name, query, safe=True, **meta):
        ctx = (self._create_context()
               .literal('CREATE TEMPORARY TABLE '
                        if meta.get('temporary') else 'CREATE TABLE '))
        if safe:
            ctx.literal('IF NOT EXISTS ')
        return (ctx
                .sql(Entity(*ensure_tuple(table_name)))
                .literal(' AS ')
                .sql(query))

    def create_table_as(self, table_name, query, safe=True, **meta):
        ctx = self._create_table_as(table_name, query, safe=safe, **meta)
        self.database.execute(ctx)

    def _drop_table(self, safe=True, **options):
        ctx = (self._create_context()
               .literal('DROP TABLE IF EXISTS ' if safe else 'DROP TABLE ')
               .sql(self.model))
        if options.get('cascade'):
            ctx = ctx.literal(' CASCADE')
        elif options.get('restrict'):
            ctx = ctx.literal(' RESTRICT')
        return ctx

    def drop_table(self, safe=True, **options):
        self.database.execute(self._drop_table(safe=safe, **options))

    def _truncate_table(self, restart_identity=False, cascade=False):
        db = self.database
        if not db.truncate_table:
            return (self._create_context()
                    .literal('DELETE FROM ').sql(self.model))

        ctx = self._create_context().literal('TRUNCATE TABLE ').sql(self.model)
        if restart_identity:
            ctx = ctx.literal(' RESTART IDENTITY')
        if cascade:
            ctx = ctx.literal(' CASCADE')
        return ctx

    def truncate_table(self, restart_identity=False, cascade=False):
        self.database.execute(self._truncate_table(restart_identity, cascade))

    def _create_indexes(self, safe=True):
        return [self._create_index(index, safe)
                for index in self.model._meta.fields_to_index()]

    def _create_index(self, index, safe=True):
        if isinstance(index, Index):
            if not self.database.safe_create_index:
                index = index.safe(False)
            elif index._safe != safe:
                index = index.safe(safe)
            if isinstance(self._database, SqliteDatabase):
                # Ensure we do not use value placeholders with Sqlite, as they
                # are not supported.
                index = ValueLiterals(index)
        return self._create_context().sql(index)

    def create_indexes(self, safe=True):
        for query in self._create_indexes(safe=safe):
            self.database.execute(query)

    def _drop_indexes(self, safe=True):
        return [self._drop_index(index, safe)
                for index in self.model._meta.fields_to_index()
                if isinstance(index, Index)]

    def _drop_index(self, index, safe):
        statement = 'DROP INDEX '
        if safe and self.database.safe_drop_index:
            statement += 'IF EXISTS '
        if isinstance(index._table, Table) and index._table._schema:
            index_name = Entity(index._table._schema, index._name)
        else:
            index_name = Entity(index._name)
        return (self
                ._create_context()
                .literal(statement)
                .sql(index_name))

    def drop_indexes(self, safe=True):
        for query in self._drop_indexes(safe=safe):
            self.database.execute(query)

    def _check_sequences(self, field):
        if not field.sequence or not self.database.sequences:
            raise ValueError('Sequences are either not supported, or are not '
                             'defined for "%s".' % field.name)

    def _sequence_for_field(self, field):
        if field.model._meta.schema:
            return Entity(field.model._meta.schema, field.sequence)
        else:
            return Entity(field.sequence)

    def _create_sequence(self, field):
        self._check_sequences(field)
        if not self.database.sequence_exists(field.sequence):
            return (self
                    ._create_context()
                    .literal('CREATE SEQUENCE ')
                    .sql(self._sequence_for_field(field)))

    def create_sequence(self, field):
        seq_ctx = self._create_sequence(field)
        if seq_ctx is not None:
            self.database.execute(seq_ctx)

    def _drop_sequence(self, field):
        self._check_sequences(field)
        if self.database.sequence_exists(field.sequence):
            return (self
                    ._create_context()
                    .literal('DROP SEQUENCE ')
                    .sql(self._sequence_for_field(field)))

    def drop_sequence(self, field):
        seq_ctx = self._drop_sequence(field)
        if seq_ctx is not None:
            self.database.execute(seq_ctx)

    def _create_foreign_key(self, field):
        name = 'fk_%s_%s_refs_%s' % (field.model._meta.table_name,
                                     field.column_name,
                                     field.rel_model._meta.table_name)
        return (self
                ._create_context()
                .literal('ALTER TABLE ')
                .sql(field.model)
                .literal(' ADD CONSTRAINT ')
                .sql(Entity(_truncate_constraint_name(name)))
                .literal(' ')
                .sql(field.foreign_key_constraint()))

    def create_foreign_key(self, field):
        self.database.execute(self._create_foreign_key(field))

    def create_sequences(self):
        if self.database.sequences:
            for field in self.model._meta.sorted_fields:
                if field.sequence:
                    self.create_sequence(field)

    def create_all(self, safe=True, **table_options):
        self.create_sequences()
        self.create_table(safe, **table_options)
        self.create_indexes(safe=safe)

    def drop_sequences(self):
        if self.database.sequences:
            for field in self.model._meta.sorted_fields:
                if field.sequence:
                    self.drop_sequence(field)

    def drop_all(self, safe=True, drop_sequences=True, **options):
        self.drop_table(safe, **options)
        if drop_sequences:
            self.drop_sequences()


class Metadata(object):
    def __init__(self, model, database=None, table_name=None, indexes=None,
                 primary_key=None, constraints=None, schema=None,
                 only_save_dirty=False, depends_on=None, options=None,
                 db_table=None, table_function=None, table_settings=None,
                 without_rowid=False, temporary=False, strict_tables=None,
                 legacy_table_names=True, **kwargs):
        if db_table is not None:
            __deprecated__('"db_table" has been deprecated in favor of '
                           '"table_name" for Models.')
            table_name = db_table
        self.model = model
        self.database = database

        self.fields = {}
        self.columns = {}
        self.combined = {}

        self._sorted_field_list = _SortedFieldList()
        self.sorted_fields = []
        self.sorted_field_names = []

        self.defaults = {}
        self._default_by_name = {}
        self._default_dict = {}
        self._default_callables = {}
        self._default_callable_list = []

        self.name = model.__name__.lower()
        self.table_function = table_function
        self.legacy_table_names = legacy_table_names
        if not table_name:
            table_name = (self.table_function(model)
                          if self.table_function
                          else self.make_table_name())
        self.table_name = table_name
        self._table = None

        self.indexes = list(indexes) if indexes else []
        self.constraints = constraints
        self._schema = schema
        self.primary_key = primary_key
        self.composite_key = self.auto_increment = None
        self.only_save_dirty = only_save_dirty
        self.depends_on = depends_on
        self.table_settings = table_settings
        self.without_rowid = without_rowid
        self.strict_tables = strict_tables
        self.temporary = temporary

        self.refs = {}
        self.backrefs = {}
        self.model_refs = collections.defaultdict(list)
        self.model_backrefs = collections.defaultdict(list)
        self.manytomany = {}

        self.options = options or {}
        for key, value in kwargs.items():
            setattr(self, key, value)
        self._additional_keys = set(kwargs.keys())

        # Allow objects to register hooks that are called if the model is bound
        # to a different database. For example, BlobField uses a different
        # Python data-type depending on the db driver / python version. When
        # the database changes, we need to update any BlobField so they can use
        # the appropriate data-type.
        self._db_hooks = []

    def make_table_name(self):
        if self.legacy_table_names:
            return re.sub(r'[^\w]+', '_', self.name)
        return make_snake_case(self.model.__name__)

    def model_graph(self, refs=True, backrefs=True, depth_first=True):
        if not refs and not backrefs:
            raise ValueError('One of `refs` or `backrefs` must be True.')

        accum = [(None, self.model, None)]
        seen = set()
        queue = collections.deque((self,))
        method = queue.pop if depth_first else queue.popleft

        while queue:
            curr = method()
            if curr in seen: continue
            seen.add(curr)

            if refs:
                for fk, model in curr.refs.items():
                    accum.append((fk, model, False))
                    queue.append(model._meta)
            if backrefs:
                for fk, model in curr.backrefs.items():
                    accum.append((fk, model, True))
                    queue.append(model._meta)

        return accum

    def add_ref(self, field):
        rel = field.rel_model
        self.refs[field] = rel
        self.model_refs[rel].append(field)
        rel._meta.backrefs[field] = self.model
        rel._meta.model_backrefs[self.model].append(field)

    def remove_ref(self, field):
        rel = field.rel_model
        del self.refs[field]
        self.model_refs[rel].remove(field)
        del rel._meta.backrefs[field]
        rel._meta.model_backrefs[self.model].remove(field)

    def add_manytomany(self, field):
        self.manytomany[field.name] = field

    def remove_manytomany(self, field):
        del self.manytomany[field.name]

    @property
    def table(self):
        if self._table is None:
            self._table = Table(
                self.table_name,
                [field.column_name for field in self.sorted_fields],
                schema=self.schema,
                _model=self.model,
                _database=self.database)
        return self._table

    @table.setter
    def table(self, value):
        raise AttributeError('Cannot set the "table".')

    @table.deleter
    def table(self):
        self._table = None

    @property
    def schema(self):
        return self._schema

    @schema.setter
    def schema(self, value):
        self._schema = value
        del self.table

    @property
    def entity(self):
        if self._schema:
            return Entity(self._schema, self.table_name)
        else:
            return Entity(self.table_name)

    def _update_sorted_fields(self):
        self.sorted_fields = list(self._sorted_field_list)
        self.sorted_field_names = [f.name for f in self.sorted_fields]

    def get_rel_for_model(self, model):
        if isinstance(model, ModelAlias):
            model = model.model
        forwardrefs = self.model_refs.get(model, [])
        backrefs = self.model_backrefs.get(model, [])
        return (forwardrefs, backrefs)

    def add_field(self, field_name, field, set_attribute=True):
        if field_name in self.fields:
            self.remove_field(field_name)
        elif field_name in self.manytomany:
            self.remove_manytomany(self.manytomany[field_name])

        if not isinstance(field, MetaField):
            del self.table
            field.bind(self.model, field_name, set_attribute)
            self.fields[field.name] = field
            self.columns[field.column_name] = field
            self.combined[field.name] = field
            self.combined[field.column_name] = field

            self._sorted_field_list.insert(field)
            self._update_sorted_fields()

            if field.default is not None:
                # This optimization helps speed up model instance construction.
                self.defaults[field] = field.default
                if callable_(field.default):
                    self._default_callables[field] = field.default
                    self._default_callable_list.append((field.name,
                                                        field.default))
                else:
                    self._default_dict[field] = field.default
                    self._default_by_name[field.name] = field.default
        else:
            field.bind(self.model, field_name, set_attribute)

        if isinstance(field, ForeignKeyField):
            self.add_ref(field)
        elif isinstance(field, ManyToManyField) and field.name:
            self.add_manytomany(field)

    def remove_field(self, field_name):
        if field_name not in self.fields:
            return

        del self.table
        original = self.fields.pop(field_name)
        del self.columns[original.column_name]
        del self.combined[field_name]
        try:
            del self.combined[original.column_name]
        except KeyError:
            pass
        self._sorted_field_list.remove(original)
        self._update_sorted_fields()

        if original.default is not None:
            del self.defaults[original]
            if self._default_callables.pop(original, None):
                for i, (name, _) in enumerate(self._default_callable_list):
                    if name == field_name:
                        self._default_callable_list.pop(i)
                        break
            else:
                self._default_dict.pop(original, None)
                self._default_by_name.pop(original.name, None)

        if isinstance(original, ForeignKeyField):
            self.remove_ref(original)

    def set_primary_key(self, name, field):
        self.composite_key = isinstance(field, CompositeKey)
        self.add_field(name, field)
        self.primary_key = field
        self.auto_increment = (
            field.auto_increment or
            bool(field.sequence))

    def get_primary_keys(self):
        if self.composite_key:
            return tuple([self.fields[field_name]
                          for field_name in self.primary_key.field_names])
        else:
            return (self.primary_key,) if self.primary_key is not False else ()

    def get_default_dict(self):
        dd = self._default_by_name.copy()
        for field_name, default in self._default_callable_list:
            dd[field_name] = default()
        return dd

    def fields_to_index(self):
        indexes = []
        for f in self.sorted_fields:
            if f.primary_key:
                continue
            if f.index or f.unique:
                indexes.append(ModelIndex(self.model, (f,), unique=f.unique,
                                          using=f.index_type))

        for index_obj in self.indexes:
            if isinstance(index_obj, Node):
                indexes.append(index_obj)
            elif isinstance(index_obj, (list, tuple)):
                index_parts, unique = index_obj
                fields = []
                for part in index_parts:
                    if isinstance(part, basestring):
                        fields.append(self.combined[part])
                    elif isinstance(part, Node):
                        fields.append(part)
                    else:
                        raise ValueError('Expected either a field name or a '
                                         'subclass of Node. Got: %s' % part)
                indexes.append(ModelIndex(self.model, fields, unique=unique))

        return indexes

    def set_database(self, database):
        self.database = database
        self.model._schema._database = database
        del self.table

        # Apply any hooks that have been registered. If we have an
        # uninitialized proxy object, we will treat that as `None`.
        if isinstance(database, Proxy) and database.obj is None:
            database = None

        for hook in self._db_hooks:
            hook(database)

    def set_table_name(self, table_name):
        self.table_name = table_name
        del self.table


class SubclassAwareMetadata(Metadata):
    models = []

    def __init__(self, model, *args, **kwargs):
        super(SubclassAwareMetadata, self).__init__(model, *args, **kwargs)
        self.models.append(model)

    def map_models(self, fn):
        for model in self.models:
            fn(model)


class DoesNotExist(Exception): pass


class ModelBase(type):
    inheritable = set(['constraints', 'database', 'indexes', 'primary_key',
                       'options', 'schema', 'table_function', 'temporary',
                       'only_save_dirty', 'legacy_table_names',
                       'table_settings', 'strict_tables'])

    def __new__(cls, name, bases, attrs, **kwargs):
        if name == MODEL_BASE or bases[0].__name__ == MODEL_BASE:
            return super(ModelBase, cls).__new__(cls, name, bases, attrs,
                                                 **kwargs)

        meta_options = {}
        meta = attrs.pop('Meta', None)
        if meta:
            for k, v in meta.__dict__.items():
                if not k.startswith('_'):
                    meta_options[k] = v

        pk = getattr(meta, 'primary_key', None)
        pk_name = parent_pk = None

        # Inherit any field descriptors by deep copying the underlying field
        # into the attrs of the new model, additionally see if the bases define
        # inheritable model options and swipe them.
        for b in bases:
            if not hasattr(b, '_meta'):
                continue

            base_meta = b._meta
            if parent_pk is None:
                parent_pk = deepcopy(base_meta.primary_key)
            all_inheritable = cls.inheritable | base_meta._additional_keys
            for k in base_meta.__dict__:
                if k in all_inheritable and k not in meta_options:
                    meta_options[k] = base_meta.__dict__[k]
            meta_options.setdefault('database', base_meta.database)
            meta_options.setdefault('schema', base_meta.schema)

            for (k, v) in b.__dict__.items():
                if k in attrs: continue

                if isinstance(v, FieldAccessor) and not v.field.primary_key:
                    attrs[k] = deepcopy(v.field)

        sopts = meta_options.pop('schema_options', None) or {}
        Meta = meta_options.get('model_metadata_class', Metadata)
        Schema = meta_options.get('schema_manager_class', SchemaManager)

        # Construct the new class.
        cls = super(ModelBase, cls).__new__(cls, name, bases, attrs, **kwargs)
        cls.__data__ = cls.__rel__ = None

        cls._meta = Meta(cls, **meta_options)
        cls._schema = Schema(cls, **sopts)

        fields = []
        for key, value in cls.__dict__.items():
            if isinstance(value, Field):
                if value.primary_key and pk:
                    raise ValueError('over-determined primary key %s.' % name)
                elif value.primary_key:
                    pk, pk_name = value, key
                else:
                    fields.append((key, value))

        if pk is None:
            if parent_pk is not False:
                pk, pk_name = ((parent_pk, parent_pk.name)
                               if parent_pk is not None else
                               (AutoField(), 'id'))
            else:
                pk = False
        elif isinstance(pk, CompositeKey):
            pk_name = '__composite_key__'
            cls._meta.composite_key = True

        if pk is not False:
            cls._meta.set_primary_key(pk_name, pk)

        for name, field in fields:
            cls._meta.add_field(name, field)

        # Create a repr and error class before finalizing.
        if hasattr(cls, '__str__') and '__repr__' not in attrs:
            setattr(cls, '__repr__', lambda self: '<%s: %s>' % (
                cls.__name__, self.__str__()))

        exc_name = '%sDoesNotExist' % cls.__name__
        exc_attrs = {'__module__': cls.__module__}
        exception_class = type(exc_name, (DoesNotExist,), exc_attrs)
        cls.DoesNotExist = exception_class

        # Call validation hook, allowing additional model validation.
        cls.validate_model()
        DeferredForeignKey.resolve(cls)
        return cls

    def __repr__(self):
        return '<Model: %s>' % self.__name__

    def __iter__(self):
        return iter(self.select())

    def __getitem__(self, key):
        return self.get_by_id(key)

    def __setitem__(self, key, value):
        self.set_by_id(key, value)

    def __delitem__(self, key):
        self.delete_by_id(key)

    def __contains__(self, key):
        try:
            self.get_by_id(key)
        except self.DoesNotExist:
            return False
        else:
            return True

    def __len__(self):
        return self.select().count()
    def __bool__(self): return True
    __nonzero__ = __bool__  # Python 2.

    def __sql__(self, ctx):
        return ctx.sql(self._meta.table)


class _BoundModelsContext(object):
    def __init__(self, models, database, bind_refs, bind_backrefs):
        self.models = models
        self.database = database
        self.bind_refs = bind_refs
        self.bind_backrefs = bind_backrefs

    def __enter__(self):
        self._orig_database = []
        for model in self.models:
            self._orig_database.append(model._meta.database)
            model.bind(self.database, self.bind_refs, self.bind_backrefs,
                       _exclude=set(self.models))
        return self.models

    def __exit__(self, exc_type, exc_val, exc_tb):
        for model, db in zip(self.models, self._orig_database):
            model.bind(db, self.bind_refs, self.bind_backrefs,
                       _exclude=set(self.models))


class Model(with_metaclass(ModelBase, Node)):
    def __init__(self, *args, **kwargs):
        if kwargs.pop('__no_default__', None):
            self.__data__ = {}
        else:
            self.__data__ = self._meta.get_default_dict()
        self._dirty = set(self.__data__)
        self.__rel__ = {}

        for k in kwargs:
            setattr(self, k, kwargs[k])

    def __str__(self):
        return str(self._pk) if self._meta.primary_key is not False else 'n/a'

    @classmethod
    def validate_model(cls):
        pass

    @classmethod
    def alias(cls, alias=None):
        return ModelAlias(cls, alias)

    @classmethod
    def select(cls, *fields):
        is_default = not fields
        if not fields:
            fields = cls._meta.sorted_fields
        return ModelSelect(cls, fields, is_default=is_default)

    @classmethod
    def _normalize_data(cls, data, kwargs):
        normalized = {}
        if data:
            if not isinstance(data, dict):
                if kwargs:
                    raise ValueError('Data cannot be mixed with keyword '
                                     'arguments: %s' % data)
                return data
            for key in data:
                try:
                    field = (key if isinstance(key, Field)
                             else cls._meta.combined[key])
                except KeyError:
                    if not isinstance(key, Node):
                        raise ValueError('Unrecognized field name: "%s" in %s.'
                                         % (key, data))
                    field = key
                normalized[field] = data[key]
        if kwargs:
            for key in kwargs:
                try:
                    normalized[cls._meta.combined[key]] = kwargs[key]
                except KeyError:
                    normalized[getattr(cls, key)] = kwargs[key]
        return normalized

    @classmethod
    def update(cls, __data=None, **update):
        return ModelUpdate(cls, cls._normalize_data(__data, update))

    @classmethod
    def insert(cls, __data=None, **insert):
        return ModelInsert(cls, cls._normalize_data(__data, insert))

    @classmethod
    def insert_many(cls, rows, fields=None):
        return ModelInsert(cls, insert=rows, columns=fields)

    @classmethod
    def insert_from(cls, query, fields):
        columns = [getattr(cls, field) if isinstance(field, basestring)
                   else field for field in fields]
        return ModelInsert(cls, insert=query, columns=columns)

    @classmethod
    def replace(cls, __data=None, **insert):
        return cls.insert(__data, **insert).on_conflict('REPLACE')

    @classmethod
    def replace_many(cls, rows, fields=None):
        return (cls
                .insert_many(rows=rows, fields=fields)
                .on_conflict('REPLACE'))

    @classmethod
    def raw(cls, sql, *params):
        return ModelRaw(cls, sql, params)

    @classmethod
    def delete(cls):
        return ModelDelete(cls)

    @classmethod
    def create(cls, **query):
        inst = cls(**query)
        inst.save(force_insert=True)
        return inst

    @classmethod
    def bulk_create(cls, model_list, batch_size=None):
        if batch_size is not None:
            batches = chunked(model_list, batch_size)
        else:
            batches = [model_list]

        field_names = list(cls._meta.sorted_field_names)
        if cls._meta.auto_increment:
            pk_name = cls._meta.primary_key.name
            field_names.remove(pk_name)

        if cls._meta.database.returning_clause and \
           cls._meta.primary_key is not False:
            pk_fields = cls._meta.get_primary_keys()
        else:
            pk_fields = None

        fields = [cls._meta.fields[field_name] for field_name in field_names]
        attrs = []
        for field in fields:
            if isinstance(field, ForeignKeyField):
                attrs.append(field.object_id_name)
            else:
                attrs.append(field.name)

        for batch in batches:
            accum = ([getattr(model, f) for f in attrs]
                     for model in batch)
            res = cls.insert_many(accum, fields=fields).execute()
            if pk_fields and res is not None:
                for row, model in zip(res, batch):
                    for (pk_field, obj_id) in zip(pk_fields, row):
                        setattr(model, pk_field.name, obj_id)

    @classmethod
    def bulk_update(cls, model_list, fields, batch_size=None):
        if isinstance(cls._meta.primary_key, CompositeKey):
            raise ValueError('bulk_update() is not supported for models with '
                             'a composite primary key.')

        # First normalize list of fields so all are field instances.
        fields = [cls._meta.fields[f] if isinstance(f, basestring) else f
                  for f in fields]
        # Now collect list of attribute names to use for values.
        attrs = [field.object_id_name if isinstance(field, ForeignKeyField)
                 else field.name for field in fields]

        if batch_size is not None:
            batches = chunked(model_list, batch_size)
        else:
            batches = [model_list]

        n = 0
        pk = cls._meta.primary_key

        for batch in batches:
            id_list = [model._pk for model in batch]
            update = {}
            for field, attr in zip(fields, attrs):
                accum = []
                for model in batch:
                    value = getattr(model, attr)
                    if not isinstance(value, Node):
                        value = field.to_value(value)
                    accum.append((pk.to_value(model._pk), value))
                case = Case(pk, accum)
                update[field] = case

            n += (cls.update(update)
                  .where(cls._meta.primary_key.in_(id_list))
                  .execute())
        return n

    @classmethod
    def noop(cls):
        return NoopModelSelect(cls, ())

    @classmethod
    def get(cls, *query, **filters):
        sq = cls.select()
        if query:
            # Handle simple lookup using just the primary key.
            if len(query) == 1 and isinstance(query[0], int):
                sq = sq.where(cls._meta.primary_key == query[0])
            else:
                sq = sq.where(*query)
        if filters:
            sq = sq.filter(**filters)
        return sq.get()

    @classmethod
    def get_or_none(cls, *query, **filters):
        try:
            return cls.get(*query, **filters)
        except DoesNotExist:
            pass

    @classmethod
    def get_by_id(cls, pk):
        return cls.get(cls._meta.primary_key == pk)

    @classmethod
    def set_by_id(cls, key, value):
        if key is None:
            return cls.insert(value).execute()
        else:
            return (cls.update(value)
                    .where(cls._meta.primary_key == key).execute())

    @classmethod
    def delete_by_id(cls, pk):
        return cls.delete().where(cls._meta.primary_key == pk).execute()

    @classmethod
    def get_or_create(cls, **kwargs):
        defaults = kwargs.pop('defaults', {})
        query = cls.select()
        for field, value in kwargs.items():
            query = query.where(getattr(cls, field) == value)

        try:
            return query.get(), False
        except cls.DoesNotExist:
            try:
                if defaults:
                    kwargs.update(defaults)
                with cls._meta.database.atomic():
                    return cls.create(**kwargs), True
            except IntegrityError as exc:
                try:
                    return query.get(), False
                except cls.DoesNotExist:
                    raise exc

    @classmethod
    def filter(cls, *dq_nodes, **filters):
        return cls.select().filter(*dq_nodes, **filters)

    def get_id(self):
        # Using getattr(self, pk-name) could accidentally trigger a query if
        # the primary-key is a foreign-key. So we use the safe_name attribute,
        # which defaults to the field-name, but will be the object_id_name for
        # foreign-key fields.
        if self._meta.primary_key is not False:
            return getattr(self, self._meta.primary_key.safe_name)

    _pk = property(get_id)

    @_pk.setter
    def _pk(self, value):
        setattr(self, self._meta.primary_key.name, value)

    def _pk_expr(self):
        return self._meta.primary_key == self._pk

    def _prune_fields(self, field_dict, only):
        new_data = {}
        for field in only:
            if isinstance(field, basestring):
                field = self._meta.combined[field]
            if field.name in field_dict:
                new_data[field.name] = field_dict[field.name]
        return new_data

    def _populate_unsaved_relations(self, field_dict):
        for foreign_key_field in self._meta.refs:
            foreign_key = foreign_key_field.name
            conditions = (
                foreign_key in field_dict and
                field_dict[foreign_key] is None and
                self.__rel__.get(foreign_key) is not None)
            if conditions:
                setattr(self, foreign_key, getattr(self, foreign_key))
                field_dict[foreign_key] = self.__data__[foreign_key]

    def save(self, force_insert=False, only=None):
        field_dict = self.__data__.copy()
        if self._meta.primary_key is not False:
            pk_field = self._meta.primary_key
            pk_value = self._pk
        else:
            pk_field = pk_value = None
        if only is not None:
            field_dict = self._prune_fields(field_dict, only)
        elif self._meta.only_save_dirty and not force_insert:
            field_dict = self._prune_fields(field_dict, self.dirty_fields)
            if not field_dict:
                self._dirty.clear()
                return False

        self._populate_unsaved_relations(field_dict)
        rows = 1

        if self._meta.auto_increment and pk_value is None:
            field_dict.pop(pk_field.name, None)

        if pk_value is not None and not force_insert:
            if self._meta.composite_key:
                for pk_part_name in pk_field.field_names:
                    field_dict.pop(pk_part_name, None)
            else:
                field_dict.pop(pk_field.name, None)
            if not field_dict:
                raise ValueError('no data to save!')
            rows = self.update(**field_dict).where(self._pk_expr()).execute()
        elif pk_field is not None:
            pk = self.insert(**field_dict).execute()
            if pk is not None and (self._meta.auto_increment or
                                   pk_value is None):
                self._pk = pk
                # Although we set the primary-key, do not mark it as dirty.
                self._dirty.discard(pk_field.name)
        else:
            self.insert(**field_dict).execute()

        self._dirty -= set(field_dict)  # Remove any fields we saved.
        return rows

    def is_dirty(self):
        return bool(self._dirty)

    @property
    def dirty_fields(self):
        return [f for f in self._meta.sorted_fields if f.name in self._dirty]

    def dependencies(self, search_nullable=True):
        model_class = type(self)
        stack = [(type(self), None)]
        queries = {}
        seen = set()

        while stack:
            klass, query = stack.pop()
            if klass in seen:
                continue
            seen.add(klass)
            for fk, rel_model in klass._meta.backrefs.items():
                if rel_model is model_class or query is None:
                    node = (fk == self.__data__[fk.rel_field.name])
                else:
                    node = fk << query
                subquery = (rel_model.select(rel_model._meta.primary_key)
                            .where(node))
                if not fk.null or search_nullable:
                    queries.setdefault(rel_model, []).append((node, fk))
                    stack.append((rel_model, subquery))

        for m in reversed(sort_models(seen)):
            for sq, q in queries.get(m, ()):
                yield sq, q

    def delete_instance(self, recursive=False, delete_nullable=False):
        if recursive:
            for query, fk in self.dependencies():
                model = fk.model
                if fk.null and not delete_nullable:
                    model.update(**{fk.name: None}).where(query).execute()
                else:
                    model.delete().where(query).execute()
        return type(self).delete().where(self._pk_expr()).execute()

    def __hash__(self):
        return hash((self.__class__, self._pk))

    def __eq__(self, other):
        return (
            other.__class__ == self.__class__ and
            self._pk is not None and
            self._pk == other._pk)

    def __ne__(self, other):
        return not self == other

    def __sql__(self, ctx):
        # NOTE: when comparing a foreign-key field whose related-field is not a
        # primary-key, then doing an equality test for the foreign-key with a
        # model instance will return the wrong value; since we would return
        # the primary key for a given model instance.
        #
        # This checks to see if we have a converter in the scope, and that we
        # are converting a foreign-key expression. If so, we hand the model
        # instance to the converter rather than blindly grabbing the primary-
        # key. In the event the provided converter fails to handle the model
        # instance, then we will return the primary-key.
        if ctx.state.converter is not None and ctx.state.is_fk_expr:
            try:
                return ctx.sql(Value(self, converter=ctx.state.converter))
            except (TypeError, ValueError):
                pass

        return ctx.sql(Value(getattr(self, self._meta.primary_key.name),
                             converter=self._meta.primary_key.db_value))

    @classmethod
    def bind(cls, database, bind_refs=True, bind_backrefs=True, _exclude=None):
        is_different = cls._meta.database is not database
        cls._meta.set_database(database)
        if bind_refs or bind_backrefs:
            if _exclude is None:
                _exclude = set()
            G = cls._meta.model_graph(refs=bind_refs, backrefs=bind_backrefs)
            for _, model, is_backref in G:
                if model not in _exclude:
                    model._meta.set_database(database)
                    _exclude.add(model)
        return is_different

    @classmethod
    def bind_ctx(cls, database, bind_refs=True, bind_backrefs=True):
        return _BoundModelsContext((cls,), database, bind_refs, bind_backrefs)

    @classmethod
    def table_exists(cls):
        M = cls._meta
        return cls._schema.database.table_exists(M.table.__name__, M.schema)

    @classmethod
    def create_table(cls, safe=True, **options):
        if 'fail_silently' in options:
            __deprecated__('"fail_silently" has been deprecated in favor of '
                           '"safe" for the create_table() method.')
            safe = options.pop('fail_silently')

        if safe and not cls._schema.database.safe_create_index \
           and cls.table_exists():
            return
        if cls._meta.temporary:
            options.setdefault('temporary', cls._meta.temporary)
        cls._schema.create_all(safe, **options)

    @classmethod
    def drop_table(cls, safe=True, drop_sequences=True, **options):
        if safe and not cls._schema.database.safe_drop_index \
           and not cls.table_exists():
            return
        if cls._meta.temporary:
            options.setdefault('temporary', cls._meta.temporary)
        cls._schema.drop_all(safe, drop_sequences, **options)

    @classmethod
    def truncate_table(cls, **options):
        cls._schema.truncate_table(**options)

    @classmethod
    def index(cls, *fields, **kwargs):
        return ModelIndex(cls, fields, **kwargs)

    @classmethod
    def add_index(cls, *fields, **kwargs):
        if len(fields) == 1 and isinstance(fields[0], (SQL, Index)):
            cls._meta.indexes.append(fields[0])
        else:
            cls._meta.indexes.append(ModelIndex(cls, fields, **kwargs))


class ModelAlias(Node):
    """Provide a separate reference to a model in a query."""
    def __init__(self, model, alias=None):
        self.__dict__['model'] = model
        self.__dict__['alias'] = alias

    def __getattr__(self, attr):
        # Hack to work-around the fact that properties or other objects
        # implementing the descriptor protocol (on the model being aliased),
        # will not work correctly when we use getattr(). So we explicitly pass
        # the model alias to the descriptor's getter.
        for b in (self.model,) + self.model.__bases__:
            try:
                obj = b.__dict__[attr]
                if isinstance(obj, ModelDescriptor):
                    return obj.__get__(None, self)
            except KeyError:
                continue

        model_attr = getattr(self.model, attr)
        if isinstance(model_attr, Field):
            self.__dict__[attr] = FieldAlias.create(self, model_attr)
            return self.__dict__[attr]
        return model_attr

    def __setattr__(self, attr, value):
        raise AttributeError('Cannot set attributes on model aliases.')

    def get_field_aliases(self):
        return [getattr(self, n) for n in self.model._meta.sorted_field_names]

    def select(self, *selection):
        if not selection:
            selection = self.get_field_aliases()
        return ModelSelect(self, selection)

    def __call__(self, **kwargs):
        return self.model(**kwargs)

    def __sql__(self, ctx):
        if ctx.scope == SCOPE_VALUES:
            # Return the quoted table name.
            return ctx.sql(self.model)

        if self.alias:
            ctx.alias_manager[self] = self.alias

        if ctx.scope == SCOPE_SOURCE:
            # Define the table and its alias.
            return (ctx
                    .sql(self.model._meta.entity)
                    .literal(' AS ')
                    .sql(Entity(ctx.alias_manager[self])))
        else:
            # Refer to the table using the alias.
            return ctx.sql(Entity(ctx.alias_manager[self]))


class FieldAlias(Field):
    def __init__(self, source, field):
        self.source = source
        self.model = source.model
        self.field = field

    @classmethod
    def create(cls, source, field):
        class _FieldAlias(cls, type(field)):
            pass
        return _FieldAlias(source, field)

    def clone(self):
        return FieldAlias(self.source, self.field)

    def adapt(self, value): return self.field.adapt(value)
    def python_value(self, value): return self.field.python_value(value)
    def db_value(self, value): return self.field.db_value(value)
    def __getattr__(self, attr):
        return self.source if attr == 'model' else getattr(self.field, attr)

    def __sql__(self, ctx):
        return ctx.sql(Column(self.source, self.field.column_name))


def sort_models(models):
    models = set(models)
    seen = set()
    ordering = []
    def dfs(model):
        if model in models and model not in seen:
            seen.add(model)
            for foreign_key, rel_model in model._meta.refs.items():
                # Do not depth-first search deferred foreign-keys as this can
                # cause tables to be created in the incorrect order.
                if not foreign_key.deferred:
                    dfs(rel_model)
            if model._meta.depends_on:
                for dependency in model._meta.depends_on:
                    dfs(dependency)
            ordering.append(model)

    names = lambda m: (m._meta.name, m._meta.table_name)
    for m in sorted(models, key=names):
        dfs(m)
    return ordering


class _ModelQueryHelper(object):
    default_row_type = ROW.MODEL

    def __init__(self, *args, **kwargs):
        super(_ModelQueryHelper, self).__init__(*args, **kwargs)
        if not self._database:
            self._database = self.model._meta.database

    @Node.copy
    def objects(self, constructor=None):
        self._row_type = ROW.CONSTRUCTOR
        self._constructor = self.model if constructor is None else constructor

    def _get_cursor_wrapper(self, cursor):
        row_type = self._row_type or self.default_row_type
        if row_type == ROW.MODEL:
            return self._get_model_cursor_wrapper(cursor)
        elif row_type == ROW.DICT:
            return ModelDictCursorWrapper(cursor, self.model, self._returning)
        elif row_type == ROW.TUPLE:
            return ModelTupleCursorWrapper(cursor, self.model, self._returning)
        elif row_type == ROW.NAMED_TUPLE:
            return ModelNamedTupleCursorWrapper(cursor, self.model,
                                                self._returning)
        elif row_type == ROW.CONSTRUCTOR:
            return ModelObjectCursorWrapper(cursor, self.model,
                                            self._returning, self._constructor)
        else:
            raise ValueError('Unrecognized row type: "%s".' % row_type)

    def _get_model_cursor_wrapper(self, cursor):
        return ModelObjectCursorWrapper(cursor, self.model, [], self.model)


class ModelRaw(_ModelQueryHelper, RawQuery):
    def __init__(self, model, sql, params, **kwargs):
        self.model = model
        self._returning = ()
        super(ModelRaw, self).__init__(sql=sql, params=params, **kwargs)

    def get(self):
        try:
            return self.execute()[0]
        except IndexError:
            sql, params = self.sql()
            raise self.model.DoesNotExist('%s instance matching query does '
                                          'not exist:\nSQL: %s\nParams: %s' %
                                          (self.model, sql, params))


class BaseModelSelect(_ModelQueryHelper):
    def union_all(self, rhs):
        return ModelCompoundSelectQuery(self.model, self, 'UNION ALL', rhs)
    __add__ = union_all

    def union(self, rhs):
        return ModelCompoundSelectQuery(self.model, self, 'UNION', rhs)
    __or__ = union

    def intersect(self, rhs):
        return ModelCompoundSelectQuery(self.model, self, 'INTERSECT', rhs)
    __and__ = intersect

    def except_(self, rhs):
        return ModelCompoundSelectQuery(self.model, self, 'EXCEPT', rhs)
    __sub__ = except_

    def __iter__(self):
        if not self._cursor_wrapper:
            self.execute()
        return iter(self._cursor_wrapper)

    def prefetch(self, *subqueries, **kwargs):
        return prefetch(self, *subqueries, **kwargs)

    def get(self, database=None):
        clone = self.paginate(1, 1)
        clone._cursor_wrapper = None
        try:
            return clone.execute(database)[0]
        except IndexError:
            sql, params = clone.sql()
            raise self.model.DoesNotExist('%s instance matching query does '
                                          'not exist:\nSQL: %s\nParams: %s' %
                                          (clone.model, sql, params))

    def get_or_none(self, database=None):
        try:
            return self.get(database=database)
        except self.model.DoesNotExist:
            pass

    @Node.copy
    def group_by(self, *columns):
        grouping = []
        for column in columns:
            if is_model(column):
                grouping.extend(column._meta.sorted_fields)
            elif isinstance(column, Table):
                if not column._columns:
                    raise ValueError('Cannot pass a table to group_by() that '
                                     'does not have columns explicitly '
                                     'declared.')
                grouping.extend([getattr(column, col_name)
                                 for col_name in column._columns])
            else:
                grouping.append(column)
        self._group_by = grouping


class ModelCompoundSelectQuery(BaseModelSelect, CompoundSelectQuery):
    def __init__(self, model, *args, **kwargs):
        self.model = model
        super(ModelCompoundSelectQuery, self).__init__(*args, **kwargs)

    def _get_model_cursor_wrapper(self, cursor):
        return self.lhs._get_model_cursor_wrapper(cursor)


def _normalize_model_select(fields_or_models):
    fields = []
    for fm in fields_or_models:
        if is_model(fm):
            fields.extend(fm._meta.sorted_fields)
        elif isinstance(fm, ModelAlias):
            fields.extend(fm.get_field_aliases())
        elif isinstance(fm, Table) and fm._columns:
            fields.extend([getattr(fm, col) for col in fm._columns])
        else:
            fields.append(fm)
    return fields


class ModelSelect(BaseModelSelect, Select):
    def __init__(self, model, fields_or_models, is_default=False):
        self.model = self._join_ctx = model
        self._joins = {}
        self._is_default = is_default
        fields = _normalize_model_select(fields_or_models)
        super(ModelSelect, self).__init__([model], fields)

    def clone(self):
        clone = super(ModelSelect, self).clone()
        if clone._joins:
            clone._joins = dict(clone._joins)
        return clone

    def select(self, *fields_or_models):
        if fields_or_models or not self._is_default:
            self._is_default = False
            fields = _normalize_model_select(fields_or_models)
            return super(ModelSelect, self).select(*fields)
        return self

    def select_extend(self, *columns):
        self._is_default = False
        fields = _normalize_model_select(columns)
        return super(ModelSelect, self).select_extend(*fields)

    def switch(self, ctx=None):
        self._join_ctx = self.model if ctx is None else ctx
        return self

    def _get_model(self, src):
        if is_model(src):
            return src, True
        elif isinstance(src, Table) and src._model:
            return src._model, False
        elif isinstance(src, ModelAlias):
            return src.model, False
        elif isinstance(src, ModelSelect):
            return src.model, False
        return None, False

    def _normalize_join(self, src, dest, on, attr):
        # Allow "on" expression to have an alias that determines the
        # destination attribute for the joined data.
        on_alias = isinstance(on, Alias)
        if on_alias:
            attr = attr or on._alias
            on = on.alias()

        # Obtain references to the source and destination models being joined.
        src_model, src_is_model = self._get_model(src)
        dest_model, dest_is_model = self._get_model(dest)

        if src_model and dest_model:
            self._join_ctx = dest
            constructor = dest_model

            # In the case where the "on" clause is a Column or Field, we will
            # convert that field into the appropriate predicate expression.
            if not (src_is_model and dest_is_model) and isinstance(on, Column):
                if on.source is src:
                    to_field = src_model._meta.columns[on.name]
                elif on.source is dest:
                    to_field = dest_model._meta.columns[on.name]
                else:
                    raise AttributeError('"on" clause Column %s does not '
                                         'belong to %s or %s.' %
                                         (on, src_model, dest_model))
                on = None
            elif isinstance(on, Field):
                to_field = on
                on = None
            else:
                to_field = None

            fk_field, is_backref = self._generate_on_clause(
                src_model, dest_model, to_field, on)

            if on is None:
                src_attr = 'name' if src_is_model else 'column_name'
                dest_attr = 'name' if dest_is_model else 'column_name'
                if is_backref:
                    lhs = getattr(dest, getattr(fk_field, dest_attr))
                    rhs = getattr(src, getattr(fk_field.rel_field, src_attr))
                else:
                    lhs = getattr(src, getattr(fk_field, src_attr))
                    rhs = getattr(dest, getattr(fk_field.rel_field, dest_attr))
                on = (lhs == rhs)

            if not attr:
                if fk_field is not None and not is_backref:
                    attr = fk_field.name
                else:
                    attr = dest_model._meta.name
            elif on_alias and fk_field is not None and \
                    attr == fk_field.object_id_name and not is_backref:
                raise ValueError('Cannot assign join alias to "%s", as this '
                                 'attribute is the object_id_name for the '
                                 'foreign-key field "%s"' % (attr, fk_field))

        elif isinstance(dest, Source):
            constructor = dict
            attr = attr or dest._alias
            if not attr and isinstance(dest, Table):
                attr = attr or dest.__name__

        return (on, attr, constructor)

    def _generate_on_clause(self, src, dest, to_field=None, on=None):
        meta = src._meta
        is_backref = fk_fields = False

        # Get all the foreign keys between source and dest, and determine if
        # the join is via a back-reference.
        if dest in meta.model_refs:
            fk_fields = meta.model_refs[dest]
        elif dest in meta.model_backrefs:
            fk_fields = meta.model_backrefs[dest]
            is_backref = True

        if not fk_fields:
            if on is not None:
                return None, False
            raise ValueError('Unable to find foreign key between %s and %s. '
                             'Please specify an explicit join condition.' %
                             (src, dest))
        elif to_field is not None:
            # If the foreign-key field was specified explicitly, remove all
            # other foreign-key fields from the list.
            target = (to_field.field if isinstance(to_field, FieldAlias)
                      else to_field)
            fk_fields = [f for f in fk_fields if (
                         (f is target) or
                         (is_backref and f.rel_field is to_field))]

        if len(fk_fields) == 1:
            return fk_fields[0], is_backref

        if on is None:
            # If multiple foreign-keys exist, try using the FK whose name
            # matches that of the related model. If not, raise an error as this
            # is ambiguous.
            for fk in fk_fields:
                if fk.name == dest._meta.name:
                    return fk, is_backref

            raise ValueError('More than one foreign key between %s and %s.'
                             ' Please specify which you are joining on.' %
                             (src, dest))

        # If there are multiple foreign-keys to choose from and the join
        # predicate is an expression, we'll try to figure out which
        # foreign-key field we're joining on so that we can assign to the
        # correct attribute when resolving the model graph.
        to_field = None
        if isinstance(on, Expression):
            lhs, rhs = on.lhs, on.rhs
            # Coerce to set() so that we force Python to compare using the
            # object's hash rather than equality test, which returns a
            # false-positive due to overriding __eq__.
            fk_set = set(fk_fields)

            if isinstance(lhs, Field):
                lhs_f = lhs.field if isinstance(lhs, FieldAlias) else lhs
                if lhs_f in fk_set:
                    to_field = lhs_f
            elif isinstance(rhs, Field):
                rhs_f = rhs.field if isinstance(rhs, FieldAlias) else rhs
                if rhs_f in fk_set:
                    to_field = rhs_f

        return to_field, False

    @Node.copy
    def join(self, dest, join_type=JOIN.INNER, on=None, src=None, attr=None):
        src = self._join_ctx if src is None else src

        if join_type == JOIN.LATERAL or join_type == JOIN.LEFT_LATERAL:
            on = True
        elif join_type != JOIN.CROSS:
            on, attr, constructor = self._normalize_join(src, dest, on, attr)
            if attr:
                self._joins.setdefault(src, [])
                self._joins[src].append((dest, attr, constructor, join_type))
        elif on is not None:
            raise ValueError('Cannot specify on clause with cross join.')

        if not self._from_list:
            raise ValueError('No sources to join on.')

        item = self._from_list.pop()
        self._from_list.append(Join(item, dest, join_type, on))

    def left_outer_join(self, dest, on=None, src=None, attr=None):
        return self.join(dest, JOIN.LEFT_OUTER, on, src, attr)

    def join_from(self, src, dest, join_type=JOIN.INNER, on=None, attr=None):
        return self.join(dest, join_type, on, src, attr)

    def _get_model_cursor_wrapper(self, cursor):
        if len(self._from_list) == 1 and not self._joins:
            return ModelObjectCursorWrapper(cursor, self.model,
                                            self._returning, self.model)
        return ModelCursorWrapper(cursor, self.model, self._returning,
                                  self._from_list, self._joins)

    def ensure_join(self, lm, rm, on=None, **join_kwargs):
        join_ctx = self._join_ctx
        for dest, _, constructor, _ in self._joins.get(lm, []):
            if dest == rm:
                return self
        return self.switch(lm).join(rm, on=on, **join_kwargs).switch(join_ctx)

    def convert_dict_to_node(self, qdict):
        accum = []
        joins = []
        fks = (ForeignKeyField, BackrefAccessor)
        for key, value in sorted(qdict.items()):
            curr = self.model
            if '__' in key and key.rsplit('__', 1)[1] in DJANGO_MAP:
                key, op = key.rsplit('__', 1)
                op = DJANGO_MAP[op]
            elif value is None:
                op = DJANGO_MAP['is']
            else:
                op = DJANGO_MAP['eq']

            if '__' not in key:
                # Handle simplest case. This avoids joining over-eagerly when a
                # direct FK lookup is all that is required.
                model_attr = getattr(curr, key)
            else:
                for piece in key.split('__'):
                    for dest, attr, _, _ in self._joins.get(curr, ()):
                        try: model_attr = getattr(curr, piece, None)
                        except: pass
                        if attr == piece or (isinstance(dest, ModelAlias) and
                                             dest.alias == piece):
                            curr = dest
                            break
                    else:
                        model_attr = getattr(curr, piece)
                        if value is not None and isinstance(model_attr, fks):
                            curr = model_attr.rel_model
                            joins.append(model_attr)
            accum.append(op(model_attr, value))
        return accum, joins

    def filter(self, *args, **kwargs):
        # normalize args and kwargs into a new expression
        if args and kwargs:
            dq_node = (reduce(operator.and_, [a.clone() for a in args]) &
                       DQ(**kwargs))
        elif args:
            dq_node = (reduce(operator.and_, [a.clone() for a in args]) &
                       ColumnBase())
        elif kwargs:
            dq_node = DQ(**kwargs) & ColumnBase()
        else:
            return self.clone()

        # dq_node should now be an Expression, lhs = Node(), rhs = ...
        q = collections.deque([dq_node])
        dq_joins = []
        seen_joins = set()
        while q:
            curr = q.popleft()
            if not isinstance(curr, Expression):
                continue
            for side, piece in (('lhs', curr.lhs), ('rhs', curr.rhs)):
                if isinstance(piece, DQ):
                    query, joins = self.convert_dict_to_node(piece.query)
                    for join in joins:
                        if join not in seen_joins:
                            dq_joins.append(join)
                            seen_joins.add(join)
                    expression = reduce(operator.and_, query)
                    # Apply values from the DQ object.
                    if piece._negated:
                        expression = Negated(expression)
                    #expression._alias = piece._alias
                    setattr(curr, side, expression)
                else:
                    q.append(piece)

        if not args or not kwargs:
            dq_node = dq_node.lhs

        query = self.clone()
        for field in dq_joins:
            if isinstance(field, ForeignKeyField):
                lm, rm = field.model, field.rel_model
                field_obj = field
            elif isinstance(field, BackrefAccessor):
                lm, rm = field.model, field.rel_model
                field_obj = field.field
            query = query.ensure_join(lm, rm, field_obj)
        return query.where(dq_node)

    def create_table(self, name, safe=True, **meta):
        return self.model._schema.create_table_as(name, self, safe, **meta)

    def __sql_selection__(self, ctx, is_subquery=False):
        if self._is_default and is_subquery and len(self._returning) > 1 and \
           self.model._meta.primary_key is not False:
            return ctx.sql(self.model._meta.primary_key)

        return ctx.sql(CommaNodeList(self._returning))


class NoopModelSelect(ModelSelect):
    def __sql__(self, ctx):
        return self.model._meta.database.get_noop_select(ctx)

    def _get_cursor_wrapper(self, cursor):
        return CursorWrapper(cursor)


class _ModelWriteQueryHelper(_ModelQueryHelper):
    def __init__(self, model, *args, **kwargs):
        self.model = model
        super(_ModelWriteQueryHelper, self).__init__(model, *args, **kwargs)

    def returning(self, *returning):
        accum = []
        for item in returning:
            if is_model(item):
                accum.extend(item._meta.sorted_fields)
            else:
                accum.append(item)
        return super(_ModelWriteQueryHelper, self).returning(*accum)

    def _set_table_alias(self, ctx):
        table = self.model._meta.table
        ctx.alias_manager[table] = table.__name__


class ModelUpdate(_ModelWriteQueryHelper, Update):
    pass


class ModelInsert(_ModelWriteQueryHelper, Insert):
    default_row_type = ROW.TUPLE

    def __init__(self, *args, **kwargs):
        super(ModelInsert, self).__init__(*args, **kwargs)
        if self._returning is None and self.model._meta.database is not None:
            if self.model._meta.database.returning_clause:
                self._returning = self.model._meta.get_primary_keys()

    def returning(self, *returning):
        # By default ModelInsert will yield a `tuple` containing the
        # primary-key of the newly inserted row. But if we are explicitly
        # specifying a returning clause and have not set a row type, we will
        # default to returning model instances instead.
        if returning and self._row_type is None:
            self._row_type = ROW.MODEL
        return super(ModelInsert, self).returning(*returning)

    def get_default_data(self):
        return self.model._meta.defaults

    def get_default_columns(self):
        fields = self.model._meta.sorted_fields
        return fields[1:] if self.model._meta.auto_increment else fields


class ModelDelete(_ModelWriteQueryHelper, Delete):
    pass


class ManyToManyQuery(ModelSelect):
    def __init__(self, instance, accessor, rel, *args, **kwargs):
        self._instance = instance
        self._accessor = accessor
        self._src_attr = accessor.src_fk.rel_field.name
        self._dest_attr = accessor.dest_fk.rel_field.name
        super(ManyToManyQuery, self).__init__(rel, (rel,), *args, **kwargs)

    def _id_list(self, model_or_id_list):
        if isinstance(model_or_id_list[0], Model):
            return [getattr(obj, self._dest_attr) for obj in model_or_id_list]
        return model_or_id_list

    def add(self, value, clear_existing=False):
        if clear_existing:
            self.clear()

        accessor = self._accessor
        src_id = getattr(self._instance, self._src_attr)
        if isinstance(value, SelectQuery):
            query = value.columns(
                Value(src_id),
                accessor.dest_fk.rel_field)
            accessor.through_model.insert_from(
                fields=[accessor.src_fk, accessor.dest_fk],
                query=query).execute()
        else:
            value = ensure_tuple(value)
            if not value: return

            inserts = [{
                accessor.src_fk.name: src_id,
                accessor.dest_fk.name: rel_id}
                for rel_id in self._id_list(value)]
            accessor.through_model.insert_many(inserts).execute()

    def remove(self, value):
        src_id = getattr(self._instance, self._src_attr)
        if isinstance(value, SelectQuery):
            column = getattr(value.model, self._dest_attr)
            subquery = value.columns(column)
            return (self._accessor.through_model
                    .delete()
                    .where(
                        (self._accessor.dest_fk << subquery) &
                        (self._accessor.src_fk == src_id))
                    .execute())
        else:
            value = ensure_tuple(value)
            if not value:
                return
            return (self._accessor.through_model
                    .delete()
                    .where(
                        (self._accessor.dest_fk << self._id_list(value)) &
                        (self._accessor.src_fk == src_id))
                    .execute())

    def clear(self):
        src_id = getattr(self._instance, self._src_attr)
        return (self._accessor.through_model
                .delete()
                .where(self._accessor.src_fk == src_id)
                .execute())


def safe_python_value(conv_func):
    def validate(value):
        try:
            return conv_func(value)
        except (TypeError, ValueError):
            return value
    return validate


class BaseModelCursorWrapper(DictCursorWrapper):
    def __init__(self, cursor, model, columns):
        super(BaseModelCursorWrapper, self).__init__(cursor)
        self.model = model
        self.select = columns or []

    def _initialize_columns(self):
        combined = self.model._meta.combined
        table = self.model._meta.table
        description = self.cursor.description

        self.ncols = len(self.cursor.description)
        self.columns = []
        self.converters = converters = [None] * self.ncols
        self.fields = fields = [None] * self.ncols

        for idx, description_item in enumerate(description):
            column = orig_column = description_item[0]

            # Try to clean-up messy column descriptions when people do not
            # provide an alias. The idea is that we take something like:
            # SUM("t1"."price") -> "price") -> price
            dot_index = column.rfind('.')
            if dot_index != -1:
                column = column[dot_index + 1:]
            column = column.strip('()"`')
            self.columns.append(column)

            # Now we'll see what they selected and see if we can improve the
            # column-name being returned - e.g. by mapping it to the selected
            # field's name.
            try:
                raw_node = self.select[idx]
            except IndexError:
                if column in combined:
                    raw_node = node = combined[column]
                else:
                    continue
            else:
                node = raw_node.unwrap()

            # If this column was given an alias, then we will use whatever
            # alias was returned by the cursor.
            is_alias = raw_node.is_alias()
            if is_alias:
                self.columns[idx] = orig_column

            # Heuristics used to attempt to get the field associated with a
            # given SELECT column, so that we can accurately convert the value
            # returned by the database-cursor into a Python object.
            if isinstance(node, Field):
                if raw_node._coerce:
                    converters[idx] = node.python_value
                fields[idx] = node
                if not is_alias:
                    self.columns[idx] = node.name
            elif isinstance(node, ColumnBase) and raw_node._converter:
                converters[idx] = raw_node._converter
            elif isinstance(node, Function) and node._coerce:
                if node._python_value is not None:
                    converters[idx] = node._python_value
                elif node.arguments and isinstance(node.arguments[0], Node):
                    # If the first argument is a field or references a column
                    # on a Model, try using that field's conversion function.
                    # This usually works, but we use "safe_python_value()" so
                    # that if a TypeError or ValueError occurs during
                    # conversion we can just fall-back to the raw cursor value.
                    first = node.arguments[0].unwrap()
                    if isinstance(first, Entity):
                        path = first._path[-1]  # Try to look-up by name.
                        first = combined.get(path)
                    if isinstance(first, Field):
                        converters[idx] = safe_python_value(first.python_value)
            elif column in combined:
                if node._coerce:
                    converters[idx] = combined[column].python_value
                if isinstance(node, Column) and node.source == table:
                    fields[idx] = combined[column]

    initialize = _initialize_columns

    def process_row(self, row):
        raise NotImplementedError


class ModelDictCursorWrapper(BaseModelCursorWrapper):
    def process_row(self, row):
        result = {}
        columns, converters = self.columns, self.converters
        fields = self.fields

        for i in range(self.ncols):
            attr = columns[i]
            if attr in result: continue  # Don't overwrite if we have dupes.
            if converters[i] is not None:
                result[attr] = converters[i](row[i])
            else:
                result[attr] = row[i]

        return result


class ModelTupleCursorWrapper(ModelDictCursorWrapper):
    constructor = tuple

    def process_row(self, row):
        columns, converters = self.columns, self.converters
        return self.constructor([
            (converters[i](row[i]) if converters[i] is not None else row[i])
            for i in range(self.ncols)])


class ModelNamedTupleCursorWrapper(ModelTupleCursorWrapper):
    def initialize(self):
        self._initialize_columns()
        attributes = []
        for i in range(self.ncols):
            attributes.append(self.columns[i])
        self.tuple_class = collections.namedtuple('Row', attributes)
        self.constructor = lambda row: self.tuple_class(*row)


class ModelObjectCursorWrapper(ModelDictCursorWrapper):
    def __init__(self, cursor, model, select, constructor):
        self.constructor = constructor
        self.is_model = is_model(constructor)
        super(ModelObjectCursorWrapper, self).__init__(cursor, model, select)

    def process_row(self, row):
        data = super(ModelObjectCursorWrapper, self).process_row(row)
        if self.is_model:
            # Clear out any dirty fields before returning to the user.
            obj = self.constructor(__no_default__=1, **data)
            obj._dirty.clear()
            return obj
        else:
            return self.constructor(**data)


class ModelCursorWrapper(BaseModelCursorWrapper):
    def __init__(self, cursor, model, select, from_list, joins):
        super(ModelCursorWrapper, self).__init__(cursor, model, select)
        self.from_list = from_list
        self.joins = joins

    def initialize(self):
        self._initialize_columns()
        selected_src = set([field.model for field in self.fields
                            if field is not None])
        select, columns = self.select, self.columns

        self.key_to_constructor = {self.model: self.model}
        self.src_is_dest = {}
        self.src_to_dest = []
        accum = collections.deque(self.from_list)
        dests = set()

        while accum:
            curr = accum.popleft()
            if isinstance(curr, Join):
                accum.append(curr.lhs)
                accum.append(curr.rhs)
                continue

            if curr not in self.joins:
                continue

            is_dict = isinstance(curr, dict)
            for key, attr, constructor, join_type in self.joins[curr]:
                if key not in self.key_to_constructor:
                    self.key_to_constructor[key] = constructor

                    # (src, attr, dest, is_dict, join_type).
                    self.src_to_dest.append((curr, attr, key, is_dict,
                                             join_type))
                    dests.add(key)
                    accum.append(key)

        # Ensure that we accommodate everything selected.
        for src in selected_src:
            if src not in self.key_to_constructor:
                if is_model(src):
                    self.key_to_constructor[src] = src
                elif isinstance(src, ModelAlias):
                    self.key_to_constructor[src] = src.model

        # Indicate which sources are also dests.
        for src, _, dest, _, _ in self.src_to_dest:
            self.src_is_dest[src] = src in dests and (dest in selected_src
                                                      or src in selected_src)

        self.column_keys = []
        for idx, node in enumerate(select):
            key = self.model
            field = self.fields[idx]
            if field is not None:
                if isinstance(field, FieldAlias):
                    key = field.source
                else:
                    key = field.model
            elif isinstance(node, BindTo):
                if node.dest not in self.key_to_constructor:
                    raise ValueError('%s specifies bind-to %s, but %s is not '
                                     'among the selected sources.' %
                                     (node.unwrap(), node.dest, node.dest))
                key = node.dest
            else:
                if isinstance(node, Node):
                    node = node.unwrap()
                if isinstance(node, Column):
                    key = node.source

            self.column_keys.append(key)

    def process_row(self, row):
        objects = {}
        object_list = []
        for key, constructor in self.key_to_constructor.items():
            objects[key] = constructor(__no_default__=True)
            object_list.append(objects[key])

        default_instance = objects[self.model]

        set_keys = set()
        for idx, key in enumerate(self.column_keys):
            # Get the instance corresponding to the selected column/value,
            # falling back to the "root" model instance.
            instance = objects.get(key, default_instance)
            column = self.columns[idx]
            value = row[idx]
            if value is not None:
                set_keys.add(key)
            if self.converters[idx]:
                value = self.converters[idx](value)

            if isinstance(instance, dict):
                instance[column] = value
            else:
                setattr(instance, column, value)

        # Need to do some analysis on the joins before this.
        for (src, attr, dest, is_dict, join_type) in self.src_to_dest:
            instance = objects[src]
            try:
                joined_instance = objects[dest]
            except KeyError:
                continue

            # If no fields were set on the destination instance then do not
            # assign an "empty" instance.
            if instance is None or dest is None or \
               (dest not in set_keys and not self.src_is_dest.get(dest)):
                continue

            # If no fields were set on either the source or the destination,
            # then we have nothing to do here.
            if instance not in set_keys and dest not in set_keys \
               and join_type.endswith('OUTER JOIN'):
                continue

            if is_dict:
                instance[attr] = joined_instance
            else:
                setattr(instance, attr, joined_instance)

        # When instantiating models from a cursor, we clear the dirty fields.
        for instance in object_list:
            if isinstance(instance, Model):
                instance._dirty.clear()

        return objects[self.model]


class PrefetchQuery(collections.namedtuple('_PrefetchQuery', (
    'query', 'fields', 'is_backref', 'rel_models', 'field_to_name', 'model'))):
    def __new__(cls, query, fields=None, is_backref=None, rel_models=None,
                field_to_name=None, model=None):
        if fields:
            if is_backref:
                if rel_models is None:
                    rel_models = [field.model for field in fields]
                foreign_key_attrs = [field.rel_field.name for field in fields]
            else:
                if rel_models is None:
                    rel_models = [field.rel_model for field in fields]
                foreign_key_attrs = [field.name for field in fields]
            field_to_name = list(zip(fields, foreign_key_attrs))
        model = query.model
        return super(PrefetchQuery, cls).__new__(
            cls, query, fields, is_backref, rel_models, field_to_name, model)

    def populate_instance(self, instance, id_map):
        if self.is_backref:
            for field in self.fields:
                identifier = instance.__data__[field.name]
                key = (field, identifier)
                if key in id_map:
                    setattr(instance, field.name, id_map[key])
        else:
            for field, attname in self.field_to_name:
                identifier = instance.__data__[field.rel_field.name]
                key = (field, identifier)
                rel_instances = id_map.get(key, [])
                for inst in rel_instances:
                    setattr(inst, attname, instance)
                    inst._dirty.clear()
                setattr(instance, field.backref, rel_instances)

    def store_instance(self, instance, id_map):
        for field, attname in self.field_to_name:
            identity = field.rel_field.python_value(instance.__data__[attname])
            key = (field, identity)
            if self.is_backref:
                id_map[key] = instance
            else:
                id_map.setdefault(key, [])
                id_map[key].append(instance)


def prefetch_add_subquery(sq, subqueries, prefetch_type):
    fixed_queries = [PrefetchQuery(sq)]
    for i, subquery in enumerate(subqueries):
        if isinstance(subquery, tuple):
            subquery, target_model = subquery
        else:
            target_model = None
        if not isinstance(subquery, Query) and is_model(subquery) or \
           isinstance(subquery, ModelAlias):
            subquery = subquery.select()
        subquery_model = subquery.model
        for j in reversed(range(i + 1)):
            fks = backrefs = None
            fixed = fixed_queries[j]
            last_query = fixed.query
            last_model = last_obj = fixed.model
            if isinstance(last_model, ModelAlias):
                last_model = last_model.model
            rels = subquery_model._meta.model_refs.get(last_model, [])
            if rels:
                fks = [getattr(subquery_model, fk.name) for fk in rels]
                pks = [getattr(last_obj, fk.rel_field.name) for fk in rels]
            else:
                backrefs = subquery_model._meta.model_backrefs.get(last_model)
            if (fks or backrefs) and ((target_model is last_obj) or
                                      (target_model is None)):
                break

        else:
            tgt_err = ' using %s' % target_model if target_model else ''
            raise AttributeError('Error: unable to find foreign key for '
                                 'query: %s%s' % (subquery, tgt_err))

        dest = (target_model,) if target_model else None

        if fks:
            if prefetch_type == PREFETCH_TYPE.WHERE:
                expr = reduce(operator.or_, [
                    (fk << last_query.select(pk))
                    for (fk, pk) in zip(fks, pks)])
                subquery = subquery.where(expr)
            elif prefetch_type == PREFETCH_TYPE.JOIN:
                expr = []
                select_pks = set()
                for fk, pk in zip(fks, pks):
                    expr.append(getattr(last_query.c, pk.column_name) == fk)
                    select_pks.add(pk)
                subquery = subquery.distinct().join(
                    last_query.select(*select_pks),
                    on=reduce(operator.or_, expr))
            fixed_queries.append(PrefetchQuery(subquery, fks, False, dest))
        elif backrefs:
            expr = []
            fields = []
            for backref in backrefs:
                rel_field = getattr(subquery_model, backref.rel_field.name)
                fk_field = getattr(last_obj, backref.name)
                fields.append((rel_field, fk_field))

            if prefetch_type == PREFETCH_TYPE.WHERE:
                for rel_field, fk_field in fields:
                    expr.append(rel_field << last_query.select(fk_field))
                subquery = subquery.where(reduce(operator.or_, expr))
            elif prefetch_type == PREFETCH_TYPE.JOIN:
                select_fks = []
                for rel_field, fk_field in fields:
                    select_fks.append(fk_field)
                    target = getattr(last_query.c, fk_field.column_name)
                    expr.append(rel_field == target)
                subquery = subquery.distinct().join(
                    last_query.select(*select_fks),
                    on=reduce(operator.or_, expr))
            fixed_queries.append(PrefetchQuery(subquery, backrefs, True, dest))

    return fixed_queries


def prefetch(sq, *subqueries, **kwargs):
    if not subqueries:
        return sq
    prefetch_type = kwargs.pop('prefetch_type', PREFETCH_TYPE.WHERE)
    if kwargs:
        raise ValueError('Unrecognized arguments: %s' % kwargs)

    fixed_queries = prefetch_add_subquery(sq, subqueries, prefetch_type)
    deps = {}
    rel_map = {}
    for pq in reversed(fixed_queries):
        query_model = pq.model
        if pq.fields:
            for rel_model in pq.rel_models:
                rel_map.setdefault(rel_model, [])
                rel_map[rel_model].append(pq)

        deps.setdefault(query_model, {})
        id_map = deps[query_model]
        has_relations = bool(rel_map.get(query_model))

        for instance in pq.query:
            if pq.fields:
                pq.store_instance(instance, id_map)
            if has_relations:
                for rel in rel_map[query_model]:
                    rel.populate_instance(instance, deps[rel.model])

    return list(pq.query)




############################################################
### File: plugin.py
############################################################
import re
import codecs
from xml.sax.saxutils import escape

import arrow
from six.moves.urllib_parse import urlparse, parse_qsl, quote_plus

from slyguy import plugin, signals, mem_cache
from slyguy.exceptions import PluginError
from slyguy.constants import ROUTE_LIVE_TAG

from .api import API
from .language import _
from .settings import settings
from .constants import *


api = API()

@signals.on(signals.BEFORE_DISPATCH)
def before_dispatch():
    api.new_session()
    plugin.logged_in = api.logged_in


@plugin.route('')
def home(**kwargs):
    folder = plugin.Folder(cacheToDisc=False)

    folder.add_item(label=_(_.LIVE_TV, _bold=True), path=plugin.url_for(live_tv))
    folder.add_item(label=_(_.FEATURED, _bold=True), path=plugin.url_for(content, slug='ctv-home'))
    _nav(folder)
    folder.add_item(label=_(_.NEWS, _bold=True), path=plugin.url_for(content, slug='news'))
    folder.add_item(label=_(_.CATEGORIES, _bold=True), path=plugin.url_for(content, slug='all-categories'))
    folder.add_item(label=_(_.SEARCH, _bold=True), path=plugin.url_for(search))

    if settings.getBool('bookmarks', True):
        folder.add_item(label=_(_.BOOKMARKS, _bold=True),  path=plugin.url_for(plugin.ROUTE_BOOKMARKS), bookmark=False)

    folder.add_item(label=_.SETTINGS, path=plugin.url_for(plugin.ROUTE_SETTINGS), _kiosk=False, bookmark=False)

    return folder


def _get_url(url):
    url = url.rstrip('/').split('/')[-1]

    parsed = urlparse(url)
    params = dict(parse_qsl(parsed.query))
    if not params or 'channel-id' not in params:
        return url

    return params['channel-id']


@mem_cache.cached(60*5)
def _nav(folder):
    skips = ['live-tv']

    replaces = {
        'shows': plugin.url_for(shows),
    }

    for row in api.nav():
        slug = row['contentLink'].lstrip('/')
        if slug in skips:
            continue
        path = replaces.get(slug, plugin.url_for(content, slug=slug))
        folder.add_item(
            label = _(row['title'], _bold=True),
            path = path,
        )


@plugin.route()
@plugin.search()
def search(query, page, **kwargs):
    return _process_rows(api.search(query)), False


def _image(url, width=IMAGE_WIDTH):
    return IMAGE_URL.format(url=quote_plus(url.encode('utf8')), width=width)


def _process_rows(rows, slug='', expand_media=False, season_num=0, thumb=None):
    items = []
    now = arrow.now()

    count = len(rows)
    for row in rows:
        if not row:
            # probably api version needs bumping
            continue

        item = None
        if row['type'] in ('mediaShelf', 'channelShelf') and row['cName'] not in ('My Watchlist', 'Continue Watching'):
            if expand_media:
                items.extend(_process_rows(row.get('mediaItems', []), slug=slug))
            else:
                item = plugin.Item(
                    label = row['title'],
                    info = {'plot': row.get('description')},
                    path = plugin.url_for(component, slug=slug, id=row['id'], label=row['title']),
                )

        if row['type'] == 'EpisodeContainer':
            title = re.sub('^([0-9]+\.)', '', row['cardData']['title'])

            info = {
                'plot': row['cardData'].get('synopsis') or row.get('infoPanelData', {}).get('shortSynopsis') or row['cardData'].get('subtitle'),
            }

            if 'infoPanelData' in row:
                info['tvshowtitle'] = row['infoPanelData']['seriesLogo']['name']

            def _get_duration(row):
                patterns = [
                    ['([0-9]+)h ([0-9]+)m ([0-9]+)s', lambda match: int(match.group(1))*3600 + int(match.group(2))*60 + int(match.group(3))],
                    ['([0-9]+)h ([0-9]+)m', lambda match: int(match.group(1))*3600 + int(match.group(2))*60],
                    ['([0-9]+)m$', lambda match: int(match.group(1))*60],
                    ['([0-9]+)s$', lambda match: int(match.group(1))],
                ]

                strings = [row['cardData'].get('duration','')]
                if 'infoPanelData' in row:
                    strings.insert(0, row['infoPanelData']['subtitle'])

                for string in strings:
                    for pattern in patterns:
                        match = re.search(pattern[0], string)
                        if match:
                            return pattern[1](match)

                return 0

            def _get_season_episode(row):
                titles = [row['cardData']['title'], row['cardData']['image'].get('altTag','')]
                if 'infoPanelData' in row:
                    titles.insert(0, row['infoPanelData']['title'])

                patterns = ['(S([0-9]+) E([0-9]+))', '(Season ([0-9]+)) Episode ([0-9]+)', '(Year ([0-9]+)) Episode ([0-9]+)']

                for title in titles:
                    title = re.sub('^([0-9]+\.)', '', title)

                    for pattern in patterns:
                        match = re.search(pattern, title)
                        if match:
                            return int(match.group(2)), int(match.group(3))

                return None, None

            info['season'], info['episode'] = _get_season_episode(row)
            info['duration'] = _get_duration(row)

            if not info['season'] and not info['episode'] and count == 1:
                info['mediatype'] = 'movie'
                info['year'] = season_num
                art  = {'thumb': _image(thumb)}
            else:
                info['mediatype'] = 'episode'
                art  = {'thumb': _image(row['cardData']['image']['url'])}

            if 'seriesLogo' in row['cardData']:
                art['clearlogo'] = _image(row['cardData']['seriesLogo']['url'])

            item = plugin.Item(
                label = title,
                info = info,
                art = art,
                playable = True,
            )

            if 'playerData' in row:
                parsed = urlparse(row['playerData']['videoUrl'])
                params = dict(parse_qsl(parsed.query))
                item.path = plugin.url_for(play, account=params['accountId'], reference=params['referenceId'])
            else:
                item.path = plugin.url_for(play_vod, slug=_get_url(row['cardData']['contentLink']['url']))

        if row['type'] == 'carousel':
            item = plugin.Item(
                label = _.FEATURED,
                info = {'plot': row.get('description')},
                path = plugin.url_for(component, slug=slug, id=row['id'], label=_.FEATURED),
            )

        if row['type'] in ('SeriesCard', 'contentLinkedImage'):
            art = {'thumb': _image(row['image']['url'])}
            art['fanart'] = _fanart(row)

            item = plugin.Item(
                label = row.get('title') or row['image']['altTag'] or row.get('cName'),
                info = {
                    'plot': row.get('description'),
                    'mediatype': 'tvshow',
                },
                art = art,
            )

            if '/live/' in row['contentLink']['url'] or LIVE_TV_SLUG in row['contentLink']['url']:
                item.path = plugin.url_for(play_channel, slug=_get_url(row['contentLink']['url']), _is_live=True)
                item.playable = True
                if 'channelLogo' in row:
                    item.art['fanart'] = _image(row['channelLogo']['url'], width=1000)
            else:
                item.path = plugin.url_for(content, slug=_get_url(row['contentLink']['url']), thumb=row['image']['url'])

        if row['type'] == 'ChannelItem':
            plot = u''
            count = 0
            image = _image(row['channelLogo']['url'])
            fanart = None

            for epg in row['schedules']['items']:
                start = arrow.get(epg['startTime'])
                stop  = arrow.get(epg['endTime'])

                if (now > start and now < stop) or start > now:
                    if count == 0:
                        fanart = _image(epg['mediaImage']['url'], width=1000)
                    plot += u'[{}] {}\n'.format(start.to('local').format('h:mma'), epg['title'])
                    count += 1

            item = plugin.Item(
                label = row['name'],
                info = {'plot': plot},
                art = {'thumb': image, 'fanart': fanart},
                path = plugin.url_for(play_channel, slug=_get_url(row['contentLink']['url']), _is_live=True),
                playable = True,
            )

        if item:
            items.append(item)

    return items


@plugin.route()
def shows(**kwargs):
    folder = plugin.Folder(_.SHOWS)

    data = api.content(SHOWS_SLUG)
    folder.add_item(label=_(_.ALL, _bold=True), path=plugin.url_for(component, slug=SHOWS_SLUG, id=data['id'], label=_.ALL, expand_media=1))

    items = _process_rows(data['items'], SHOWS_SLUG)
    folder.add_items(items)

    return folder


@plugin.route()
def live_tv(**kwargs):
    folder = plugin.Folder(_.LIVE_TV)

    rows = _get_live_channels()
    items = _process_rows(rows, LIVE_TV_SLUG)
    folder.add_items(items)

    return folder


@plugin.route()
def content(slug, label=None, thumb=None, expand_media=0, **kwargs):
    data = api.content(slug)

    if data['pageMetaData']['pageEventName'] == 'vodPage':
        return show(slug, data, thumb)

    folder = plugin.Folder(label or data['title'])
    items = _process_rows(data['items'], slug, int(expand_media), thumb=thumb)
    folder.add_items(items)

    return folder


def _fanart(row):
    for key in ['backgroundImage', 'backgroundImageLandscape', 'seriesBackgroundImage']:
        if key in row:
            return _image(row[key]['url'], width=1000)
    return None


def show(slug, data, thumb=None):
    show_name = data['pageMetaData']['pageTitle']
    plot = data['pageMetaData']['description']
    thumb = _image(thumb or data['pageMetaData']['objectGraphImage']['url'])
    fanart = _fanart(data['items'][0])

    folder = plugin.Folder(data['title'], fanart=fanart)

    seasons = []
    similiar = None
    clips = None

    for section in data['items']:
        for row in section.get('items') or []:
            if row.get('cName') == 'Clips':
                clips = row['id']
                continue

            if row.get('cName') == 'More Like This':
                similiar = row['id']
                continue

            for row2 in row.get('items') or []:
                for row3 in row2.get('items') or []:
                    for row4 in row3.get('items') or []:
                        if row4.get('childType') == 'EpisodeContainer':
                            try: season_num = int(row3['title'])
                            except: season_num = None

                            if season_num:
                                label = _(_.SEASON, number=season_num)
                                sort = season_num
                            else:
                                label = row3['title']
                                sort = 0

                            seasons.append([sort, label, row4])

    seasons = sorted(seasons, key=lambda x: x[0])
    if len(seasons) == 1 and (settings.getBool('flatten_single_season', True) or len(seasons[0][2].get('mediaItems', [])) <= 1):
        items = _process_rows(seasons[0][2].get('mediaItems', []), season_num=seasons[0][0], thumb=thumb)
        folder.add_items(items)
    else:
        for season in seasons:
            folder.add_item(
                label = season[1],
                art = {'thumb': thumb, 'fanart': fanart},
                info = {
                    'plot': plot,
                    'mediatype': 'season',
                    'tvshowtitle': data['title'],
                },
                path = plugin.url_for(component, slug=slug, id=season[2]['id'], label=show_name, fanart=fanart),
            )

    if clips and not settings.getBool('hide_clips', False):
        folder.add_item(
            label = 'Clips',
            art = {'thumb': thumb, 'fanart': fanart},
            info = {'plot': plot},
            path = plugin.url_for(component, slug=slug, id=clips, label=show_name, fanart=fanart, expand_media=1),
            specialsort = 'bottom',
        )

    if similiar and not settings.getBool('hide_suggested', False):
        folder.add_item(
            label = _.SUGGESTED,
            art = {'thumb': thumb, 'fanart': fanart},
            info = {'plot': plot},
            path = plugin.url_for(component, slug=slug, id=similiar, label=show_name, fanart=fanart, expand_media=1),
            specialsort = 'bottom',
        )

    return folder


@plugin.route()
def component(slug, id, label, expand_media=0, fanart=None, **kwargs):
    expand_media = int(expand_media)

    folder = plugin.Folder(label, fanart=fanart)
    items = _process_rows(api.component(slug, id)['items'], slug, expand_media)
    folder.add_items(items)
    return folder


@plugin.route()
def play_vod(slug, **kwargs):
    data = api.content(slug)

    url = None
    for row in data.get('items') or []:
        for row2 in row.get('items') or []:
            if row2.get('videoUrl'):
                url = row2['videoUrl']
                break

    if not url:
        raise PluginError(_.NO_VIDEO)

    parsed = urlparse(url)
    params = dict(parse_qsl(parsed.query))
    return _play(params['accountId'], params['referenceId'], live=False)


@plugin.route()
def play_channel(slug, **kwargs):
    data = api.video_player(slug)
    url = data['videoUrl']

    parsed = urlparse(url)
    params = dict(parse_qsl(parsed.query))

    item = _play(params['accountId'], params['referenceId'], live=True)
    item.label = data['posterImage']['altTag']
    item.art = {'thumb': _image(data['posterImage']['url'])}
    return item


@plugin.route()
def play(account, reference, **kwargs):
    return _play(account, reference, live=ROUTE_LIVE_TAG in kwargs)


def _play(account, reference, live=False):
    item = api.play(account, reference, live)
    item.headers = HEADERS

    if live and item.inputstream:
        item.inputstream.live = True
        item.inputstream.force = True
    return item


def _get_live_channels():
    data = api.content(LIVE_TV_SLUG)

    added = []
    channels = []

    for section in data['items']:
        if section.get('childType') != 'channelItem':
            continue

        for row in section.get('mediaItems', []):
            if row.get('type') == 'ChannelItem' and row['channelId'] not in added:
                channels.append(row)
                added.append(row['channelId'])

    return sorted(channels, key=lambda x: int(x['channelId']))


@plugin.route()
@plugin.merge()
def playlist(output, **kwargs):
    with codecs.open(output, 'w', encoding='utf8') as f:
        f.write(u'#EXTM3U x-tvg-url="{}"'.format(plugin.url_for(epg, output='$FILE')))

        for channel in _get_live_channels():
            f.write(u'\n#EXTINF:-1 tvg-chno="{chno}" tvg-id="{id}" tvg-name="{name}" tvg-logo="{logo}",{name}\n{url}'.format(
                chno=channel['channelId'], id=channel['channelId'], name=channel['name'], logo=_image(channel['channelLogo']['url']),
                    url=plugin.url_for(play_channel, slug=_get_url(channel['contentLink']['url']), _is_live=True),
            ))


@plugin.route()
@plugin.merge()
def epg(output, **kwargs):
    with codecs.open(output, 'w', encoding='utf8') as f:
        f.write(u'<?xml version="1.0" encoding="utf-8" ?><tv>')

        for channel in _get_live_channels():
            f.write(u'<channel id="{id}"></channel>'.format(id=channel['channelId']))
            for epg in channel['schedules']['items']:
                start = arrow.get(epg['startTime'])
                stop  = arrow.get(epg['endTime'])

                icon = u'<icon src="{}"/>'.format(escape(_image(epg['mediaImage']['url']))) if epg['mediaImage'].get('url') else ''
                desc = u'<desc>{}</desc>'.format(escape(epg['synopsis'])) if epg['synopsis'] else ''
                genre = u'<category lang="en">{}</category>'.format(escape(epg['genre'])) if epg['genre'] else ''

                subtitle = u'<subtitle>{}</subtitle>'.format(escape(epg['subTitle']).strip()) if epg['subTitle'] else ''
                if not subtitle:
                    subtitle = u'<subtitle>{}</subtitle>'.format(escape(epg['subTitle2']).strip()) if epg['subTitle2'] else ''

                f.write(u'<programme channel="{id}" start="{start}" stop="{stop}"><title>{title}</title>{subtitle}{desc}{icon}{genre}</programme>'.format(
                    id=channel['channelId'], start=start.format('YYYYMMDDHHmmss Z'), stop=stop.format('YYYYMMDDHHmmss Z'), title=escape(epg['title']),
                    subtitle=subtitle, desc=desc, icon=icon, genre=genre,
                ))

        f.write(u'</tv>')




############################################################
### File: poolmanager.py
############################################################
from __future__ import absolute_import

import collections
import functools
import logging

from ._collections import RecentlyUsedContainer
from .connectionpool import HTTPConnectionPool, HTTPSConnectionPool, port_by_scheme
from .exceptions import (
    LocationValueError,
    MaxRetryError,
    ProxySchemeUnknown,
    ProxySchemeUnsupported,
    URLSchemeUnknown,
)
from .packages import six
from .packages.six.moves.urllib.parse import urljoin
from .request import RequestMethods
from .util.proxy import connection_requires_http_tunnel
from .util.retry import Retry
from .util.url import parse_url

__all__ = ["PoolManager", "ProxyManager", "proxy_from_url"]


log = logging.getLogger(__name__)

SSL_KEYWORDS = (
    "key_file",
    "cert_file",
    "cert_reqs",
    "ca_certs",
    "ssl_version",
    "ca_cert_dir",
    "ssl_context",
    "key_password",
    "server_hostname",
)

# All known keyword arguments that could be provided to the pool manager, its
# pools, or the underlying connections. This is used to construct a pool key.
_key_fields = (
    "key_scheme",  # str
    "key_host",  # str
    "key_port",  # int
    "key_timeout",  # int or float or Timeout
    "key_retries",  # int or Retry
    "key_strict",  # bool
    "key_block",  # bool
    "key_source_address",  # str
    "key_key_file",  # str
    "key_key_password",  # str
    "key_cert_file",  # str
    "key_cert_reqs",  # str
    "key_ca_certs",  # str
    "key_ssl_version",  # str
    "key_ca_cert_dir",  # str
    "key_ssl_context",  # instance of ssl.SSLContext or urllib3.util.ssl_.SSLContext
    "key_maxsize",  # int
    "key_headers",  # dict
    "key__proxy",  # parsed proxy url
    "key__proxy_headers",  # dict
    "key__proxy_config",  # class
    "key_socket_options",  # list of (level (int), optname (int), value (int or str)) tuples
    "key__socks_options",  # dict
    "key_assert_hostname",  # bool or string
    "key_assert_fingerprint",  # str
    "key_server_hostname",  # str
)

#: The namedtuple class used to construct keys for the connection pool.
#: All custom key schemes should include the fields in this key at a minimum.
PoolKey = collections.namedtuple("PoolKey", _key_fields)

_proxy_config_fields = ("ssl_context", "use_forwarding_for_https")
ProxyConfig = collections.namedtuple("ProxyConfig", _proxy_config_fields)


def _default_key_normalizer(key_class, request_context):
    """
    Create a pool key out of a request context dictionary.

    According to RFC 3986, both the scheme and host are case-insensitive.
    Therefore, this function normalizes both before constructing the pool
    key for an HTTPS request. If you wish to change this behaviour, provide
    alternate callables to ``key_fn_by_scheme``.

    :param key_class:
        The class to use when constructing the key. This should be a namedtuple
        with the ``scheme`` and ``host`` keys at a minimum.
    :type  key_class: namedtuple
    :param request_context:
        A dictionary-like object that contain the context for a request.
    :type  request_context: dict

    :return: A namedtuple that can be used as a connection pool key.
    :rtype:  PoolKey
    """
    # Since we mutate the dictionary, make a copy first
    context = request_context.copy()
    context["scheme"] = context["scheme"].lower()
    context["host"] = context["host"].lower()

    # These are both dictionaries and need to be transformed into frozensets
    for key in ("headers", "_proxy_headers", "_socks_options"):
        if key in context and context[key] is not None:
            context[key] = frozenset(context[key].items())

    # The socket_options key may be a list and needs to be transformed into a
    # tuple.
    socket_opts = context.get("socket_options")
    if socket_opts is not None:
        context["socket_options"] = tuple(socket_opts)

    # Map the kwargs to the names in the namedtuple - this is necessary since
    # namedtuples can't have fields starting with '_'.
    for key in list(context.keys()):
        context["key_" + key] = context.pop(key)

    # Default to ``None`` for keys missing from the context
    for field in key_class._fields:
        if field not in context:
            context[field] = None

    return key_class(**context)


#: A dictionary that maps a scheme to a callable that creates a pool key.
#: This can be used to alter the way pool keys are constructed, if desired.
#: Each PoolManager makes a copy of this dictionary so they can be configured
#: globally here, or individually on the instance.
key_fn_by_scheme = {
    "http": functools.partial(_default_key_normalizer, PoolKey),
    "https": functools.partial(_default_key_normalizer, PoolKey),
}

pool_classes_by_scheme = {"http": HTTPConnectionPool, "https": HTTPSConnectionPool}


class PoolManager(RequestMethods):
    """
    Allows for arbitrary requests while transparently keeping track of
    necessary connection pools for you.

    :param num_pools:
        Number of connection pools to cache before discarding the least
        recently used pool.

    :param headers:
        Headers to include with all requests, unless other headers are given
        explicitly.

    :param \\**connection_pool_kw:
        Additional parameters are used to create fresh
        :class:`urllib3.connectionpool.ConnectionPool` instances.

    Example::

        >>> manager = PoolManager(num_pools=2)
        >>> r = manager.request('GET', 'http://google.com/')
        >>> r = manager.request('GET', 'http://google.com/mail')
        >>> r = manager.request('GET', 'http://yahoo.com/')
        >>> len(manager.pools)
        2

    """

    proxy = None
    proxy_config = None

    def __init__(self, num_pools=10, headers=None, **connection_pool_kw):
        RequestMethods.__init__(self, headers)
        self.connection_pool_kw = connection_pool_kw
        self.pools = RecentlyUsedContainer(num_pools, dispose_func=lambda p: p.close())

        # Locally set the pool classes and keys so other PoolManagers can
        # override them.
        self.pool_classes_by_scheme = pool_classes_by_scheme
        self.key_fn_by_scheme = key_fn_by_scheme.copy()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.clear()
        # Return False to re-raise any potential exceptions
        return False

    def _new_pool(self, scheme, host, port, request_context=None):
        """
        Create a new :class:`urllib3.connectionpool.ConnectionPool` based on host, port, scheme, and
        any additional pool keyword arguments.

        If ``request_context`` is provided, it is provided as keyword arguments
        to the pool class used. This method is used to actually create the
        connection pools handed out by :meth:`connection_from_url` and
        companion methods. It is intended to be overridden for customization.
        """
        pool_cls = self.pool_classes_by_scheme[scheme]
        if request_context is None:
            request_context = self.connection_pool_kw.copy()

        # Although the context has everything necessary to create the pool,
        # this function has historically only used the scheme, host, and port
        # in the positional args. When an API change is acceptable these can
        # be removed.
        for key in ("scheme", "host", "port"):
            request_context.pop(key, None)

        if scheme == "http":
            for kw in SSL_KEYWORDS:
                request_context.pop(kw, None)

        return pool_cls(host, port, **request_context)

    def clear(self):
        """
        Empty our store of pools and direct them all to close.

        This will not affect in-flight connections, but they will not be
        re-used after completion.
        """
        self.pools.clear()

    def connection_from_host(self, host, port=None, scheme="http", pool_kwargs=None):
        """
        Get a :class:`urllib3.connectionpool.ConnectionPool` based on the host, port, and scheme.

        If ``port`` isn't given, it will be derived from the ``scheme`` using
        ``urllib3.connectionpool.port_by_scheme``. If ``pool_kwargs`` is
        provided, it is merged with the instance's ``connection_pool_kw``
        variable and used to create the new connection pool, if one is
        needed.
        """

        if not host:
            raise LocationValueError("No host specified.")

        request_context = self._merge_pool_kwargs(pool_kwargs)
        request_context["scheme"] = scheme or "http"
        if not port:
            port = port_by_scheme.get(request_context["scheme"].lower(), 80)
        request_context["port"] = port
        request_context["host"] = host

        return self.connection_from_context(request_context)

    def connection_from_context(self, request_context):
        """
        Get a :class:`urllib3.connectionpool.ConnectionPool` based on the request context.

        ``request_context`` must at least contain the ``scheme`` key and its
        value must be a key in ``key_fn_by_scheme`` instance variable.
        """
        scheme = request_context["scheme"].lower()
        pool_key_constructor = self.key_fn_by_scheme.get(scheme)
        if not pool_key_constructor:
            raise URLSchemeUnknown(scheme)
        pool_key = pool_key_constructor(request_context)

        return self.connection_from_pool_key(pool_key, request_context=request_context)

    def connection_from_pool_key(self, pool_key, request_context=None):
        """
        Get a :class:`urllib3.connectionpool.ConnectionPool` based on the provided pool key.

        ``pool_key`` should be a namedtuple that only contains immutable
        objects. At a minimum it must have the ``scheme``, ``host``, and
        ``port`` fields.
        """
        with self.pools.lock:
            # If the scheme, host, or port doesn't match existing open
            # connections, open a new ConnectionPool.
            pool = self.pools.get(pool_key)
            if pool:
                return pool

            # Make a fresh ConnectionPool of the desired type
            scheme = request_context["scheme"]
            host = request_context["host"]
            port = request_context["port"]
            pool = self._new_pool(scheme, host, port, request_context=request_context)
            self.pools[pool_key] = pool

        return pool

    def connection_from_url(self, url, pool_kwargs=None):
        """
        Similar to :func:`urllib3.connectionpool.connection_from_url`.

        If ``pool_kwargs`` is not provided and a new pool needs to be
        constructed, ``self.connection_pool_kw`` is used to initialize
        the :class:`urllib3.connectionpool.ConnectionPool`. If ``pool_kwargs``
        is provided, it is used instead. Note that if a new pool does not
        need to be created for the request, the provided ``pool_kwargs`` are
        not used.
        """
        u = parse_url(url)
        return self.connection_from_host(
            u.host, port=u.port, scheme=u.scheme, pool_kwargs=pool_kwargs
        )

    def _merge_pool_kwargs(self, override):
        """
        Merge a dictionary of override values for self.connection_pool_kw.

        This does not modify self.connection_pool_kw and returns a new dict.
        Any keys in the override dictionary with a value of ``None`` are
        removed from the merged dictionary.
        """
        base_pool_kwargs = self.connection_pool_kw.copy()
        if override:
            for key, value in override.items():
                if value is None:
                    try:
                        del base_pool_kwargs[key]
                    except KeyError:
                        pass
                else:
                    base_pool_kwargs[key] = value
        return base_pool_kwargs

    def _proxy_requires_url_absolute_form(self, parsed_url):
        """
        Indicates if the proxy requires the complete destination URL in the
        request.  Normally this is only needed when not using an HTTP CONNECT
        tunnel.
        """
        if self.proxy is None:
            return False

        return not connection_requires_http_tunnel(
            self.proxy, self.proxy_config, parsed_url.scheme
        )

    def _validate_proxy_scheme_url_selection(self, url_scheme):
        """
        Validates that were not attempting to do TLS in TLS connections on
        Python2 or with unsupported SSL implementations.
        """
        if self.proxy is None or url_scheme != "https":
            return

        if self.proxy.scheme != "https":
            return

        if six.PY2 and not self.proxy_config.use_forwarding_for_https:
            raise ProxySchemeUnsupported(
                "Contacting HTTPS destinations through HTTPS proxies "
                "'via CONNECT tunnels' is not supported in Python 2"
            )

    def urlopen(self, method, url, redirect=True, **kw):
        """
        Same as :meth:`urllib3.HTTPConnectionPool.urlopen`
        with custom cross-host redirect logic and only sends the request-uri
        portion of the ``url``.

        The given ``url`` parameter must be absolute, such that an appropriate
        :class:`urllib3.connectionpool.ConnectionPool` can be chosen for it.
        """
        u = parse_url(url)
        self._validate_proxy_scheme_url_selection(u.scheme)

        conn = self.connection_from_host(u.host, port=u.port, scheme=u.scheme)

        kw["assert_same_host"] = False
        kw["redirect"] = False

        if "headers" not in kw:
            kw["headers"] = self.headers.copy()

        if self._proxy_requires_url_absolute_form(u):
            response = conn.urlopen(method, url, **kw)
        else:
            response = conn.urlopen(method, u.request_uri, **kw)

        redirect_location = redirect and response.get_redirect_location()
        if not redirect_location:
            return response

        # Support relative URLs for redirecting.
        redirect_location = urljoin(url, redirect_location)

        # RFC 7231, Section 6.4.4
        if response.status == 303:
            method = "GET"

        retries = kw.get("retries")
        if not isinstance(retries, Retry):
            retries = Retry.from_int(retries, redirect=redirect)

        # Strip headers marked as unsafe to forward to the redirected location.
        # Check remove_headers_on_redirect to avoid a potential network call within
        # conn.is_same_host() which may use socket.gethostbyname() in the future.
        if retries.remove_headers_on_redirect and not conn.is_same_host(
            redirect_location
        ):
            headers = list(six.iterkeys(kw["headers"]))
            for header in headers:
                if header.lower() in retries.remove_headers_on_redirect:
                    kw["headers"].pop(header, None)

        try:
            retries = retries.increment(method, url, response=response, _pool=conn)
        except MaxRetryError:
            if retries.raise_on_redirect:
                response.drain_conn()
                raise
            return response

        kw["retries"] = retries
        kw["redirect"] = redirect

        log.info("Redirecting %s -> %s", url, redirect_location)

        response.drain_conn()
        return self.urlopen(method, redirect_location, **kw)


class ProxyManager(PoolManager):
    """
    Behaves just like :class:`PoolManager`, but sends all requests through
    the defined proxy, using the CONNECT method for HTTPS URLs.

    :param proxy_url:
        The URL of the proxy to be used.

    :param proxy_headers:
        A dictionary containing headers that will be sent to the proxy. In case
        of HTTP they are being sent with each request, while in the
        HTTPS/CONNECT case they are sent only once. Could be used for proxy
        authentication.

    :param proxy_ssl_context:
        The proxy SSL context is used to establish the TLS connection to the
        proxy when using HTTPS proxies.

    :param use_forwarding_for_https:
        (Defaults to False) If set to True will forward requests to the HTTPS
        proxy to be made on behalf of the client instead of creating a TLS
        tunnel via the CONNECT method. **Enabling this flag means that request
        and response headers and content will be visible from the HTTPS proxy**
        whereas tunneling keeps request and response headers and content
        private.  IP address, target hostname, SNI, and port are always visible
        to an HTTPS proxy even when this flag is disabled.

    Example:
        >>> proxy = urllib3.ProxyManager('http://localhost:3128/')
        >>> r1 = proxy.request('GET', 'http://google.com/')
        >>> r2 = proxy.request('GET', 'http://httpbin.org/')
        >>> len(proxy.pools)
        1
        >>> r3 = proxy.request('GET', 'https://httpbin.org/')
        >>> r4 = proxy.request('GET', 'https://twitter.com/')
        >>> len(proxy.pools)
        3

    """

    def __init__(
        self,
        proxy_url,
        num_pools=10,
        headers=None,
        proxy_headers=None,
        proxy_ssl_context=None,
        use_forwarding_for_https=False,
        **connection_pool_kw
    ):

        if isinstance(proxy_url, HTTPConnectionPool):
            proxy_url = "%s://%s:%i" % (
                proxy_url.scheme,
                proxy_url.host,
                proxy_url.port,
            )
        proxy = parse_url(proxy_url)

        if proxy.scheme not in ("http", "https"):
            raise ProxySchemeUnknown(proxy.scheme)

        if not proxy.port:
            port = port_by_scheme.get(proxy.scheme, 80)
            proxy = proxy._replace(port=port)

        self.proxy = proxy
        self.proxy_headers = proxy_headers or {}
        self.proxy_ssl_context = proxy_ssl_context
        self.proxy_config = ProxyConfig(proxy_ssl_context, use_forwarding_for_https)

        connection_pool_kw["_proxy"] = self.proxy
        connection_pool_kw["_proxy_headers"] = self.proxy_headers
        connection_pool_kw["_proxy_config"] = self.proxy_config

        super(ProxyManager, self).__init__(num_pools, headers, **connection_pool_kw)

    def connection_from_host(self, host, port=None, scheme="http", pool_kwargs=None):
        if scheme == "https":
            return super(ProxyManager, self).connection_from_host(
                host, port, scheme, pool_kwargs=pool_kwargs
            )

        return super(ProxyManager, self).connection_from_host(
            self.proxy.host, self.proxy.port, self.proxy.scheme, pool_kwargs=pool_kwargs
        )

    def _set_proxy_headers(self, url, headers=None):
        """
        Sets headers needed by proxies: specifically, the Accept and Host
        headers. Only sets headers not provided by the user.
        """
        headers_ = {"Accept": "*/*"}

        netloc = parse_url(url).netloc
        if netloc:
            headers_["Host"] = netloc

        if headers:
            headers_.update(headers)
        return headers_

    def urlopen(self, method, url, redirect=True, **kw):
        "Same as HTTP(S)ConnectionPool.urlopen, ``url`` must be absolute."
        u = parse_url(url)
        if not connection_requires_http_tunnel(self.proxy, self.proxy_config, u.scheme):
            # For connections using HTTP CONNECT, httplib sets the necessary
            # headers on the CONNECT to the proxy. If we're not using CONNECT,
            # we'll definitely need to set 'Host' at the very least.
            headers = kw.get("headers", self.headers)
            kw["headers"] = self._set_proxy_headers(url, headers)

        return super(ProxyManager, self).urlopen(method, url, redirect=redirect, **kw)


def proxy_from_url(url, **kw):
    return ProxyManager(proxy_url=url, **kw)




############################################################
### File: pyjs.py
############################################################
from .base import *
from .constructors.jsmath import Math
from .constructors.jsdate import Date
from .constructors.jsobject import Object
from .constructors.jsfunction import Function
from .constructors.jsstring import String
from .constructors.jsnumber import Number
from .constructors.jsboolean import Boolean
from .constructors.jsregexp import RegExp
from .constructors.jsarray import Array
from .constructors.jsarraybuffer import ArrayBuffer
from .constructors.jsint8array import Int8Array
from .constructors.jsuint8array import Uint8Array
from .constructors.jsuint8clampedarray import Uint8ClampedArray
from .constructors.jsint16array import Int16Array
from .constructors.jsuint16array import Uint16Array
from .constructors.jsint32array import Int32Array
from .constructors.jsuint32array import Uint32Array
from .constructors.jsfloat32array import Float32Array
from .constructors.jsfloat64array import Float64Array
from .prototypes.jsjson import JSON
from .host.console import console
from .host.jseval import Eval
from .host.jsfunctions import parseFloat, parseInt, isFinite, \
    isNaN, escape, unescape, encodeURI, decodeURI, encodeURIComponent, decodeURIComponent

# Now we have all the necessary items to create global environment for script
__all__ = [
    'Js', 'PyJsComma', 'PyJsStrictEq', 'PyJsStrictNeq', 'PyJsException',
    'PyJsBshift', 'Scope', 'PyExceptionToJs', 'JsToPyException', 'JS_BUILTINS',
    'appengine', 'set_global_object', 'JsRegExp', 'PyJsException',
    'PyExceptionToJs', 'JsToPyException', 'PyJsSwitchException'
]

# these were defined in base.py
builtins = (
    'true',
    'false',
    'null',
    'undefined',
    'Infinity',
    'NaN',
    'console',
    'String',
    'Number',
    'Boolean',
    'RegExp',
    'Math',
    'Date',
    'Object',
    'Function',
    'Array',
    'Int8Array',
    'Uint8Array',
    'Uint8ClampedArray',
    'Int16Array',
    'Uint16Array',
    'Int32Array',
    'Uint32Array',
    'Float32Array',
    'Float64Array',
    'ArrayBuffer',
    'parseFloat',
    'parseInt',
    'isFinite',
    'isNaN',
    'escape',
    'unescape',
    'encodeURI',
    'decodeURI',
    'encodeURIComponent',
    'decodeURIComponent',
)

#Array, Function, JSON,   Error is done later :)
# also some built in functions like eval...


def set_global_object(obj):
    obj.IS_CHILD_SCOPE = False
    this = This({})
    this.own = obj.own
    this.prototype = obj.prototype
    PyJs.GlobalObject = this
    # make this available
    obj.register('this')
    obj.put('this', this)
    # also add window and set it to be a global object for compatibility
    obj.register('window')
    obj.put('window', this)


scope = dict(zip(builtins, [globals()[e] for e in builtins]))
# Now add errors:
for name, error in ERRORS.items():
    scope[name] = error
#add eval
scope['eval'] = Eval
scope['JSON'] = JSON
JS_BUILTINS = dict((k, v) for k, v in scope.items())




############################################################
### File: pyjsparserdata.py
############################################################
# The MIT License
#
# Copyright 2014, 2015 Piotr Dabkowski
#
# Permission is hereby granted, free of charge, to any person obtaining
# a copy of this software and associated documentation files (the 'Software'),
# to deal in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
# the Software, and to permit persons to whom the Software is furnished to do so, subject
# to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all copies or
# substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT
# LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
# IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
# WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE
#  OR THE USE OR OTHER DEALINGS IN THE SOFTWARE
from __future__ import unicode_literals

import sys
import unicodedata
from collections import defaultdict

PY3 = sys.version_info >= (3, 0)

if PY3:
    unichr = chr
    xrange = range
    unicode = str

token = {
    'BooleanLiteral': 1,
    'EOF': 2,
    'Identifier': 3,
    'Keyword': 4,
    'NullLiteral': 5,
    'NumericLiteral': 6,
    'Punctuator': 7,
    'StringLiteral': 8,
    'RegularExpression': 9,
    'Template': 10
}

TokenName = dict((v, k) for k, v in token.items())

FnExprTokens = [
    '(',
    '{',
    '[',
    'in',
    'typeof',
    'instanceof',
    'new',
    'return',
    'case',
    'delete',
    'throw',
    'void',
    # assignment operators
    '=',
    '+=',
    '-=',
    '*=',
    '/=',
    '%=',
    '<<=',
    '>>=',
    '>>>=',
    '&=',
    '|=',
    '^=',
    ',',
    # binary/unary operators
    '+',
    '-',
    '*',
    '/',
    '%',
    '++',
    '--',
    '<<',
    '>>',
    '>>>',
    '&',
    '|',
    '^',
    '!',
    '~',
    '&&',
    '||',
    '?',
    ':',
    '===',
    '==',
    '>=',
    '<=',
    '<',
    '>',
    '!=',
    '!=='
]

syntax = set(
    ('AssignmentExpression', 'AssignmentPattern', 'ArrayExpression',
     'ArrayPattern', 'ArrowFunctionExpression', 'BlockStatement',
     'BinaryExpression', 'BreakStatement', 'CallExpression', 'CatchClause',
     'ClassBody', 'ClassDeclaration', 'ClassExpression',
     'ConditionalExpression', 'ContinueStatement', 'DoWhileStatement',
     'DebuggerStatement', 'EmptyStatement', 'ExportAllDeclaration',
     'ExportDefaultDeclaration', 'ExportNamedDeclaration', 'ExportSpecifier',
     'ExpressionStatement', 'ForStatement', 'ForInStatement',
     'FunctionDeclaration', 'FunctionExpression', 'Identifier', 'IfStatement',
     'ImportDeclaration', 'ImportDefaultSpecifier', 'ImportNamespaceSpecifier',
     'ImportSpecifier', 'Literal', 'LabeledStatement', 'LogicalExpression',
     'MemberExpression', 'MethodDefinition', 'NewExpression',
     'ObjectExpression', 'ObjectPattern', 'Program', 'Property', 'RestElement',
     'ReturnStatement', 'SequenceExpression', 'SpreadElement', 'Super',
     'SwitchCase', 'SwitchStatement', 'TaggedTemplateExpression',
     'TemplateElement', 'TemplateLiteral', 'ThisExpression', 'ThrowStatement',
     'TryStatement', 'UnaryExpression', 'UpdateExpression',
     'VariableDeclaration', 'VariableDeclarator', 'WhileStatement',
     'WithStatement'))

supported_syntax = set(
    ('AssignmentExpression', 'ArrayExpression', 'BlockStatement',
     'BinaryExpression', 'BreakStatement', 'CallExpression', 'CatchClause',
     'ConditionalExpression', 'ContinueStatement', 'DoWhileStatement',
     'DebuggerStatement', 'EmptyStatement', 'ExpressionStatement',
     'ForStatement', 'ForInStatement', 'FunctionDeclaration',
     'FunctionExpression', 'Identifier', 'IfStatement', 'Literal',
     'LabeledStatement', 'LogicalExpression', 'MemberExpression',
     'MethodDefinition', 'NewExpression', 'ObjectExpression', 'Program',
     'Property', 'ReturnStatement', 'SequenceExpression', 'SwitchCase',
     'SwitchStatement', 'ThisExpression', 'ThrowStatement', 'TryStatement',
     'UnaryExpression', 'UpdateExpression', 'VariableDeclaration',
     'VariableDeclarator', 'WhileStatement', 'WithStatement'))

# Error messages should be identical to V8.
messages = {
    'UnexpectedToken':
    'Unexpected token %s',
    'UnexpectedNumber':
    'Unexpected number',
    'UnexpectedString':
    'Unexpected string',
    'UnexpectedIdentifier':
    'Unexpected identifier',
    'UnexpectedReserved':
    'Unexpected reserved word',
    'UnexpectedTemplate':
    'Unexpected quasi %s',
    'UnexpectedEOS':
    'Unexpected end of input',
    'NewlineAfterThrow':
    'Illegal newline after throw',
    'InvalidRegExp':
    'Invalid regular expression',
    'UnterminatedRegExp':
    'Invalid regular expression: missing /',
    'InvalidLHSInAssignment':
    'Invalid left-hand side in assignment',
    'InvalidLHSInForIn':
    'Invalid left-hand side in for-in',
    'MultipleDefaultsInSwitch':
    'More than one default clause in switch statement',
    'NoCatchOrFinally':
    'Missing catch or finally after try',
    'UnknownLabel':
    'Undefined label \'%s\'',
    'Redeclaration':
    '%s \'%s\' has already been declared',
    'IllegalContinue':
    'Illegal continue statement',
    'IllegalBreak':
    'Illegal break statement',
    'IllegalReturn':
    'Illegal return statement',
    'StrictModeWith':
    'Strict mode code may not include a with statement',
    'StrictCatchVariable':
    'Catch variable may not be eval or arguments in strict mode',
    'StrictVarName':
    'Variable name may not be eval or arguments in strict mode',
    'StrictParamName':
    'Parameter name eval or arguments is not allowed in strict mode',
    'StrictParamDupe':
    'Strict mode function may not have duplicate parameter names',
    'StrictFunctionName':
    'Function name may not be eval or arguments in strict mode',
    'StrictOctalLiteral':
    'Octal literals are not allowed in strict mode.',
    'StrictDelete':
    'Delete of an unqualified identifier in strict mode.',
    'StrictLHSAssignment':
    'Assignment to eval or arguments is not allowed in strict mode',
    'StrictLHSPostfix':
    'Postfix increment/decrement may not have eval or arguments operand in strict mode',
    'StrictLHSPrefix':
    'Prefix increment/decrement may not have eval or arguments operand in strict mode',
    'StrictReservedWord':
    'Use of future reserved word in strict mode',
    'TemplateOctalLiteral':
    'Octal literals are not allowed in template strings.',
    'ParameterAfterRestParameter':
    'Rest parameter must be last formal parameter',
    'DefaultRestParameter':
    'Unexpected token =',
    'ObjectPatternAsRestParameter':
    'Unexpected token {',
    'DuplicateProtoProperty':
    'Duplicate __proto__ fields are not allowed in object literals',
    'ConstructorSpecialMethod':
    'Class constructor may not be an accessor',
    'DuplicateConstructor':
    'A class may only have one constructor',
    'StaticPrototype':
    'Classes may not have static property named prototype',
    'MissingFromClause':
    'Unexpected token',
    'NoAsAfterImportNamespace':
    'Unexpected token',
    'InvalidModuleSpecifier':
    'Unexpected token',
    'IllegalImportDeclaration':
    'Unexpected token',
    'IllegalExportDeclaration':
    'Unexpected token'
}

PRECEDENCE = {
    '||': 1,
    '&&': 2,
    '|': 3,
    '^': 4,
    '&': 5,
    '==': 6,
    '!=': 6,
    '===': 6,
    '!==': 6,
    '<': 7,
    '>': 7,
    '<=': 7,
    '>=': 7,
    'instanceof': 7,
    'in': 7,
    '<<': 8,
    '>>': 8,
    '>>>': 8,
    '+': 9,
    '-': 9,
    '*': 11,
    '/': 11,
    '%': 11
}


class Token:
    pass


class Syntax:
    pass


class Messages:
    pass


class PlaceHolders:
    ArrowParameterPlaceHolder = 'ArrowParameterPlaceHolder'


for k, v in token.items():
    setattr(Token, k, v)

for e in syntax:
    setattr(Syntax, e, e)

for k, v in messages.items():
    setattr(Messages, k, v)

#http://stackoverflow.com/questions/14245893/efficiently-list-all-characters-in-a-given-unicode-category
BOM = u'\uFEFF'
ZWJ = u'\u200D'
ZWNJ = u'\u200C'
TAB = u'\u0009'
VT = u'\u000B'
FF = u'\u000C'
SP = u'\u0020'
NBSP = u'\u00A0'
LF = u'\u000A'
CR = u'\u000D'
LS = u'\u2028'
PS = u'\u2029'


LETTER_CATEGORIES = set(['Lu', 'Ll', 'Lt', 'Lm', 'Lo', 'Nl'])

COMBINING_MARK_CATEGORIES = set(['Mn', 'Mc'])
DIGIT_CATEGORIES = set(['Nd'])
CONNECTOR_PUNCTUATION_CATEGORIES = set(['Pc'])
IDENTIFIER_START_CATEGORIES = LETTER_CATEGORIES.copy()  # and some fucking unicode escape sequence
IDENTIFIER_PART_CATEGORIES = IDENTIFIER_START_CATEGORIES.union(COMBINING_MARK_CATEGORIES).union(DIGIT_CATEGORIES)\
    .union(CONNECTOR_PUNCTUATION_CATEGORIES)

EXTRA_IDENTIFIER_START_CHARS = set(('$','_', '\\'))
EXTRA_IDENTIFIER_PART_CHARS = EXTRA_IDENTIFIER_START_CHARS.union(set((ZWJ, ZWNJ)))

WHITE_SPACE = set((0x20, 0x09, 0x0B, 0x0C, 0xA0, 0x1680, 0x180E, 0x2000,
                   0x2001, 0x2002, 0x2003, 0x2004, 0x2005, 0x2006, 0x2007,
                   0x2008, 0x2009, 0x200A, 0x202F, 0x205F, 0x3000, 0xFEFF))

LINE_TERMINATORS = set((0x0A, 0x0D, 0x2028, 0x2029))


def isIdentifierStart(ch):
    uch = (ch if isinstance(ch, unicode) else unichr(ch))
    return unicodedata.category(uch) in IDENTIFIER_START_CATEGORIES or uch in EXTRA_IDENTIFIER_START_CHARS


def isIdentifierPart(ch):
    uch =  (ch if isinstance(ch, unicode) else unichr(ch))
    return unicodedata.category(uch) in IDENTIFIER_PART_CATEGORIES or uch in EXTRA_IDENTIFIER_PART_CHARS


def isValidIdentifier(name):
    if not name or isKeyword(name):
        return False
    check = isIdentifierStart
    for e in name:
        if not check(e):
            return False
        check = isIdentifierPart
    return True


def isWhiteSpace(ch):
    return (ord(ch) if isinstance(ch, unicode) else ch) in WHITE_SPACE


def isLineTerminator(ch):
    return (ord(ch) if isinstance(ch, unicode) else ch) in LINE_TERMINATORS


OCTAL = set(('0', '1', '2', '3', '4', '5', '6', '7'))
DEC = set(('0', '1', '2', '3', '4', '5', '6', '7', '8', '9'))
HEX = set('0123456789abcdefABCDEF')
HEX_CONV = dict(('0123456789abcdef' [n], n) for n in xrange(16))
for i, e in enumerate('ABCDEF', 10):
    HEX_CONV[e] = i


def isDecimalDigit(ch):
    return (ch if isinstance(ch, unicode) else unichr(ch)) in DEC


def isHexDigit(ch):
    return (ch if isinstance(ch, unicode) else unichr(ch)) in HEX


def isOctalDigit(ch):
    return (ch if isinstance(ch, unicode) else unichr(ch)) in OCTAL


def isFutureReservedWord(w):
    return w in ('enum', 'export', 'import', 'super')


RESERVED_WORD = set(('implements', 'interface', 'package', 'private',
                     'protected', 'public', 'static', 'yield', 'let'))


def isStrictModeReservedWord(w):
    return w in RESERVED_WORD


def isRestrictedWord(w):
    return w in ('eval', 'arguments')


KEYWORDS = set(
    ('if', 'in', 'do', 'var', 'for', 'new', 'try', 'let', 'this', 'else',
     'case', 'void', 'with', 'enum', 'while', 'break', 'catch', 'throw',
     'const', 'yield', 'class', 'super', 'return', 'typeof', 'delete',
     'switch', 'export', 'import', 'default', 'finally', 'extends', 'function',
     'continue', 'debugger', 'instanceof', 'pyimport'))


def isKeyword(w):
    # 'const' is specialized as Keyword in V8.
    # 'yield' and 'let' are for compatibility with SpiderMonkey and ES.next.
    # Some others are from future reserved words.
    return w in KEYWORDS


class JsSyntaxError(Exception):
    pass


if __name__ == '__main__':
    assert isLineTerminator('\n')
    assert isLineTerminator(0x0A)
    assert isIdentifierStart('$')
    assert isIdentifierStart(100)
    assert isWhiteSpace(' ')




############################################################
### File: query.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""Talk to a DNS server."""

from __future__ import generators

import errno
import select
import socket
import struct
import sys
import time

import dns.exception
import dns.inet
import dns.name
import dns.message
import dns.rcode
import dns.rdataclass
import dns.rdatatype
from ._compat import long, string_types, PY3

if PY3:
    select_error = OSError
else:
    select_error = select.error

# Function used to create a socket.  Can be overridden if needed in special
# situations.
socket_factory = socket.socket

class UnexpectedSource(dns.exception.DNSException):
    """A DNS query response came from an unexpected address or port."""


class BadResponse(dns.exception.FormError):
    """A DNS query response does not respond to the question asked."""


class TransferError(dns.exception.DNSException):
    """A zone transfer response got a non-zero rcode."""

    def __init__(self, rcode):
        message = 'Zone transfer error: %s' % dns.rcode.to_text(rcode)
        super(TransferError, self).__init__(message)
        self.rcode = rcode


def _compute_expiration(timeout):
    if timeout is None:
        return None
    else:
        return time.time() + timeout

# This module can use either poll() or select() as the "polling backend".
#
# A backend function takes an fd, bools for readability, writablity, and
# error detection, and a timeout.

def _poll_for(fd, readable, writable, error, timeout):
    """Poll polling backend."""

    event_mask = 0
    if readable:
        event_mask |= select.POLLIN
    if writable:
        event_mask |= select.POLLOUT
    if error:
        event_mask |= select.POLLERR

    pollable = select.poll()
    pollable.register(fd, event_mask)

    if timeout:
        event_list = pollable.poll(long(timeout * 1000))
    else:
        event_list = pollable.poll()

    return bool(event_list)


def _select_for(fd, readable, writable, error, timeout):
    """Select polling backend."""

    rset, wset, xset = [], [], []

    if readable:
        rset = [fd]
    if writable:
        wset = [fd]
    if error:
        xset = [fd]

    if timeout is None:
        (rcount, wcount, xcount) = select.select(rset, wset, xset)
    else:
        (rcount, wcount, xcount) = select.select(rset, wset, xset, timeout)

    return bool((rcount or wcount or xcount))


def _wait_for(fd, readable, writable, error, expiration):
    # Use the selected polling backend to wait for any of the specified
    # events.  An "expiration" absolute time is converted into a relative
    # timeout.

    done = False
    while not done:
        if expiration is None:
            timeout = None
        else:
            timeout = expiration - time.time()
            if timeout <= 0.0:
                raise dns.exception.Timeout
        try:
            if not _polling_backend(fd, readable, writable, error, timeout):
                raise dns.exception.Timeout
        except select_error as e:
            if e.args[0] != errno.EINTR:
                raise e
        done = True


def _set_polling_backend(fn):
    # Internal API. Do not use.

    global _polling_backend

    _polling_backend = fn

if hasattr(select, 'poll'):
    # Prefer poll() on platforms that support it because it has no
    # limits on the maximum value of a file descriptor (plus it will
    # be more efficient for high values).
    _polling_backend = _poll_for
else:
    _polling_backend = _select_for


def _wait_for_readable(s, expiration):
    _wait_for(s, True, False, True, expiration)


def _wait_for_writable(s, expiration):
    _wait_for(s, False, True, True, expiration)


def _addresses_equal(af, a1, a2):
    # Convert the first value of the tuple, which is a textual format
    # address into binary form, so that we are not confused by different
    # textual representations of the same address
    try:
        n1 = dns.inet.inet_pton(af, a1[0])
        n2 = dns.inet.inet_pton(af, a2[0])
    except dns.exception.SyntaxError:
        return False
    return n1 == n2 and a1[1:] == a2[1:]


def _destination_and_source(af, where, port, source, source_port):
    # Apply defaults and compute destination and source tuples
    # suitable for use in connect(), sendto(), or bind().
    if af is None:
        try:
            af = dns.inet.af_for_address(where)
        except Exception:
            af = dns.inet.AF_INET
    if af == dns.inet.AF_INET:
        destination = (where, port)
        if source is not None or source_port != 0:
            if source is None:
                source = '0.0.0.0'
            source = (source, source_port)
    elif af == dns.inet.AF_INET6:
        destination = (where, port, 0, 0)
        if source is not None or source_port != 0:
            if source is None:
                source = '::'
            source = (source, source_port, 0, 0)
    return (af, destination, source)


def send_udp(sock, what, destination, expiration=None):
    """Send a DNS message to the specified UDP socket.

    *sock*, a ``socket``.

    *what*, a ``binary`` or ``dns.message.Message``, the message to send.

    *destination*, a destination tuple appropriate for the address family
    of the socket, specifying where to send the query.

    *expiration*, a ``float`` or ``None``, the absolute time at which
    a timeout exception should be raised.  If ``None``, no timeout will
    occur.

    Returns an ``(int, float)`` tuple of bytes sent and the sent time.
    """

    if isinstance(what, dns.message.Message):
        what = what.to_wire()
    _wait_for_writable(sock, expiration)
    sent_time = time.time()
    n = sock.sendto(what, destination)
    return (n, sent_time)


def receive_udp(sock, destination, expiration=None,
                ignore_unexpected=False, one_rr_per_rrset=False,
                keyring=None, request_mac=b'', ignore_trailing=False):
    """Read a DNS message from a UDP socket.

    *sock*, a ``socket``.

    *destination*, a destination tuple appropriate for the address family
    of the socket, specifying where the associated query was sent.

    *expiration*, a ``float`` or ``None``, the absolute time at which
    a timeout exception should be raised.  If ``None``, no timeout will
    occur.

    *ignore_unexpected*, a ``bool``.  If ``True``, ignore responses from
    unexpected sources.

    *one_rr_per_rrset*, a ``bool``.  If ``True``, put each RR into its own
    RRset.

    *keyring*, a ``dict``, the keyring to use for TSIG.

    *request_mac*, a ``binary``, the MAC of the request (for TSIG).

    *ignore_trailing*, a ``bool``.  If ``True``, ignore trailing
    junk at end of the received message.

    Raises if the message is malformed, if network errors occur, of if
    there is a timeout.

    Returns a ``dns.message.Message`` object.
    """

    wire = b''
    while 1:
        _wait_for_readable(sock, expiration)
        (wire, from_address) = sock.recvfrom(65535)
        if _addresses_equal(sock.family, from_address, destination) or \
           (dns.inet.is_multicast(destination[0]) and
            from_address[1:] == destination[1:]):
            break
        if not ignore_unexpected:
            raise UnexpectedSource('got a response from '
                                   '%s instead of %s' % (from_address,
                                                         destination))
    received_time = time.time()
    r = dns.message.from_wire(wire, keyring=keyring, request_mac=request_mac,
                              one_rr_per_rrset=one_rr_per_rrset,
                              ignore_trailing=ignore_trailing)
    return (r, received_time)

def udp(q, where, timeout=None, port=53, af=None, source=None, source_port=0,
        ignore_unexpected=False, one_rr_per_rrset=False, ignore_trailing=False):
    """Return the response obtained after sending a query via UDP.

    *q*, a ``dns.message.Message``, the query to send

    *where*, a ``text`` containing an IPv4 or IPv6 address,  where
    to send the message.

    *timeout*, a ``float`` or ``None``, the number of seconds to wait before the
    query times out.  If ``None``, the default, wait forever.

    *port*, an ``int``, the port send the message to.  The default is 53.

    *af*, an ``int``, the address family to use.  The default is ``None``,
    which causes the address family to use to be inferred from the form of
    *where*.  If the inference attempt fails, AF_INET is used.  This
    parameter is historical; you need never set it.

    *source*, a ``text`` containing an IPv4 or IPv6 address, specifying
    the source address.  The default is the wildcard address.

    *source_port*, an ``int``, the port from which to send the message.
    The default is 0.

    *ignore_unexpected*, a ``bool``.  If ``True``, ignore responses from
    unexpected sources.

    *one_rr_per_rrset*, a ``bool``.  If ``True``, put each RR into its own
    RRset.

    *ignore_trailing*, a ``bool``.  If ``True``, ignore trailing
    junk at end of the received message.

    Returns a ``dns.message.Message``.
    """

    wire = q.to_wire()
    (af, destination, source) = _destination_and_source(af, where, port,
                                                        source, source_port)
    s = socket_factory(af, socket.SOCK_DGRAM, 0)
    received_time = None
    sent_time = None
    try:
        expiration = _compute_expiration(timeout)
        s.setblocking(0)
        if source is not None:
            s.bind(source)
        (_, sent_time) = send_udp(s, wire, destination, expiration)
        (r, received_time) = receive_udp(s, destination, expiration,
                                         ignore_unexpected, one_rr_per_rrset,
                                         q.keyring, q.mac, ignore_trailing)
    finally:
        if sent_time is None or received_time is None:
            response_time = 0
        else:
            response_time = received_time - sent_time
        s.close()
    r.time = response_time
    if not q.is_response(r):
        raise BadResponse
    return r


def _net_read(sock, count, expiration):
    """Read the specified number of bytes from sock.  Keep trying until we
    either get the desired amount, or we hit EOF.
    A Timeout exception will be raised if the operation is not completed
    by the expiration time.
    """
    s = b''
    while count > 0:
        _wait_for_readable(sock, expiration)
        n = sock.recv(count)
        if n == b'':
            raise EOFError
        count = count - len(n)
        s = s + n
    return s


def _net_write(sock, data, expiration):
    """Write the specified data to the socket.
    A Timeout exception will be raised if the operation is not completed
    by the expiration time.
    """
    current = 0
    l = len(data)
    while current < l:
        _wait_for_writable(sock, expiration)
        current += sock.send(data[current:])


def send_tcp(sock, what, expiration=None):
    """Send a DNS message to the specified TCP socket.

    *sock*, a ``socket``.

    *what*, a ``binary`` or ``dns.message.Message``, the message to send.

    *expiration*, a ``float`` or ``None``, the absolute time at which
    a timeout exception should be raised.  If ``None``, no timeout will
    occur.

    Returns an ``(int, float)`` tuple of bytes sent and the sent time.
    """

    if isinstance(what, dns.message.Message):
        what = what.to_wire()
    l = len(what)
    # copying the wire into tcpmsg is inefficient, but lets us
    # avoid writev() or doing a short write that would get pushed
    # onto the net
    tcpmsg = struct.pack("!H", l) + what
    _wait_for_writable(sock, expiration)
    sent_time = time.time()
    _net_write(sock, tcpmsg, expiration)
    return (len(tcpmsg), sent_time)

def receive_tcp(sock, expiration=None, one_rr_per_rrset=False,
                keyring=None, request_mac=b'', ignore_trailing=False):
    """Read a DNS message from a TCP socket.

    *sock*, a ``socket``.

    *expiration*, a ``float`` or ``None``, the absolute time at which
    a timeout exception should be raised.  If ``None``, no timeout will
    occur.

    *one_rr_per_rrset*, a ``bool``.  If ``True``, put each RR into its own
    RRset.

    *keyring*, a ``dict``, the keyring to use for TSIG.

    *request_mac*, a ``binary``, the MAC of the request (for TSIG).

    *ignore_trailing*, a ``bool``.  If ``True``, ignore trailing
    junk at end of the received message.

    Raises if the message is malformed, if network errors occur, of if
    there is a timeout.

    Returns a ``dns.message.Message`` object.
    """

    ldata = _net_read(sock, 2, expiration)
    (l,) = struct.unpack("!H", ldata)
    wire = _net_read(sock, l, expiration)
    received_time = time.time()
    r = dns.message.from_wire(wire, keyring=keyring, request_mac=request_mac,
                              one_rr_per_rrset=one_rr_per_rrset,
                              ignore_trailing=ignore_trailing)
    return (r, received_time)

def _connect(s, address):
    try:
        s.connect(address)
    except socket.error:
        (ty, v) = sys.exc_info()[:2]

        if hasattr(v, 'errno'):
            v_err = v.errno
        else:
            v_err = v[0]
        if v_err not in [errno.EINPROGRESS, errno.EWOULDBLOCK, errno.EALREADY]:
            raise v


def tcp(q, where, timeout=None, port=53, af=None, source=None, source_port=0,
        one_rr_per_rrset=False, ignore_trailing=False):
    """Return the response obtained after sending a query via TCP.

    *q*, a ``dns.message.Message``, the query to send

    *where*, a ``text`` containing an IPv4 or IPv6 address,  where
    to send the message.

    *timeout*, a ``float`` or ``None``, the number of seconds to wait before the
    query times out.  If ``None``, the default, wait forever.

    *port*, an ``int``, the port send the message to.  The default is 53.

    *af*, an ``int``, the address family to use.  The default is ``None``,
    which causes the address family to use to be inferred from the form of
    *where*.  If the inference attempt fails, AF_INET is used.  This
    parameter is historical; you need never set it.

    *source*, a ``text`` containing an IPv4 or IPv6 address, specifying
    the source address.  The default is the wildcard address.

    *source_port*, an ``int``, the port from which to send the message.
    The default is 0.

    *one_rr_per_rrset*, a ``bool``.  If ``True``, put each RR into its own
    RRset.

    *ignore_trailing*, a ``bool``.  If ``True``, ignore trailing
    junk at end of the received message.

    Returns a ``dns.message.Message``.
    """

    wire = q.to_wire()
    (af, destination, source) = _destination_and_source(af, where, port,
                                                        source, source_port)
    s = socket_factory(af, socket.SOCK_STREAM, 0)
    begin_time = None
    received_time = None
    try:
        expiration = _compute_expiration(timeout)
        s.setblocking(0)
        begin_time = time.time()
        if source is not None:
            s.bind(source)
        _connect(s, destination)
        send_tcp(s, wire, expiration)
        (r, received_time) = receive_tcp(s, expiration, one_rr_per_rrset,
                                         q.keyring, q.mac, ignore_trailing)
    finally:
        if begin_time is None or received_time is None:
            response_time = 0
        else:
            response_time = received_time - begin_time
        s.close()
    r.time = response_time
    if not q.is_response(r):
        raise BadResponse
    return r


def xfr(where, zone, rdtype=dns.rdatatype.AXFR, rdclass=dns.rdataclass.IN,
        timeout=None, port=53, keyring=None, keyname=None, relativize=True,
        af=None, lifetime=None, source=None, source_port=0, serial=0,
        use_udp=False, keyalgorithm=dns.tsig.default_algorithm):
    """Return a generator for the responses to a zone transfer.

    *where*.  If the inference attempt fails, AF_INET is used.  This
    parameter is historical; you need never set it.

    *zone*, a ``dns.name.Name`` or ``text``, the name of the zone to transfer.

    *rdtype*, an ``int`` or ``text``, the type of zone transfer.  The
    default is ``dns.rdatatype.AXFR``.  ``dns.rdatatype.IXFR`` can be
    used to do an incremental transfer instead.

    *rdclass*, an ``int`` or ``text``, the class of the zone transfer.
    The default is ``dns.rdataclass.IN``.

    *timeout*, a ``float``, the number of seconds to wait for each
    response message.  If None, the default, wait forever.

    *port*, an ``int``, the port send the message to.  The default is 53.

    *keyring*, a ``dict``, the keyring to use for TSIG.

    *keyname*, a ``dns.name.Name`` or ``text``, the name of the TSIG
    key to use.

    *relativize*, a ``bool``.  If ``True``, all names in the zone will be
    relativized to the zone origin.  It is essential that the
    relativize setting matches the one specified to
    ``dns.zone.from_xfr()`` if using this generator to make a zone.

    *af*, an ``int``, the address family to use.  The default is ``None``,
    which causes the address family to use to be inferred from the form of
    *where*.  If the inference attempt fails, AF_INET is used.  This
    parameter is historical; you need never set it.

    *lifetime*, a ``float``, the total number of seconds to spend
    doing the transfer.  If ``None``, the default, then there is no
    limit on the time the transfer may take.

    *source*, a ``text`` containing an IPv4 or IPv6 address, specifying
    the source address.  The default is the wildcard address.

    *source_port*, an ``int``, the port from which to send the message.
    The default is 0.

    *serial*, an ``int``, the SOA serial number to use as the base for
    an IXFR diff sequence (only meaningful if *rdtype* is
    ``dns.rdatatype.IXFR``).

    *use_udp*, a ``bool``.  If ``True``, use UDP (only meaningful for IXFR).

    *keyalgorithm*, a ``dns.name.Name`` or ``text``, the TSIG algorithm to use.

    Raises on errors, and so does the generator.

    Returns a generator of ``dns.message.Message`` objects.
    """

    if isinstance(zone, string_types):
        zone = dns.name.from_text(zone)
    if isinstance(rdtype, string_types):
        rdtype = dns.rdatatype.from_text(rdtype)
    q = dns.message.make_query(zone, rdtype, rdclass)
    if rdtype == dns.rdatatype.IXFR:
        rrset = dns.rrset.from_text(zone, 0, 'IN', 'SOA',
                                    '. . %u 0 0 0 0' % serial)
        q.authority.append(rrset)
    if keyring is not None:
        q.use_tsig(keyring, keyname, algorithm=keyalgorithm)
    wire = q.to_wire()
    (af, destination, source) = _destination_and_source(af, where, port,
                                                        source, source_port)
    if use_udp:
        if rdtype != dns.rdatatype.IXFR:
            raise ValueError('cannot do a UDP AXFR')
        s = socket_factory(af, socket.SOCK_DGRAM, 0)
    else:
        s = socket_factory(af, socket.SOCK_STREAM, 0)
    s.setblocking(0)
    if source is not None:
        s.bind(source)
    expiration = _compute_expiration(lifetime)
    _connect(s, destination)
    l = len(wire)
    if use_udp:
        _wait_for_writable(s, expiration)
        s.send(wire)
    else:
        tcpmsg = struct.pack("!H", l) + wire
        _net_write(s, tcpmsg, expiration)
    done = False
    delete_mode = True
    expecting_SOA = False
    soa_rrset = None
    if relativize:
        origin = zone
        oname = dns.name.empty
    else:
        origin = None
        oname = zone
    tsig_ctx = None
    first = True
    while not done:
        mexpiration = _compute_expiration(timeout)
        if mexpiration is None or mexpiration > expiration:
            mexpiration = expiration
        if use_udp:
            _wait_for_readable(s, expiration)
            (wire, from_address) = s.recvfrom(65535)
        else:
            ldata = _net_read(s, 2, mexpiration)
            (l,) = struct.unpack("!H", ldata)
            wire = _net_read(s, l, mexpiration)
        is_ixfr = (rdtype == dns.rdatatype.IXFR)
        r = dns.message.from_wire(wire, keyring=q.keyring, request_mac=q.mac,
                                  xfr=True, origin=origin, tsig_ctx=tsig_ctx,
                                  multi=True, first=first,
                                  one_rr_per_rrset=is_ixfr)
        rcode = r.rcode()
        if rcode != dns.rcode.NOERROR:
            raise TransferError(rcode)
        tsig_ctx = r.tsig_ctx
        first = False
        answer_index = 0
        if soa_rrset is None:
            if not r.answer or r.answer[0].name != oname:
                raise dns.exception.FormError(
                    "No answer or RRset not for qname")
            rrset = r.answer[0]
            if rrset.rdtype != dns.rdatatype.SOA:
                raise dns.exception.FormError("first RRset is not an SOA")
            answer_index = 1
            soa_rrset = rrset.copy()
            if rdtype == dns.rdatatype.IXFR:
                if soa_rrset[0].serial <= serial:
                    #
                    # We're already up-to-date.
                    #
                    done = True
                else:
                    expecting_SOA = True
        #
        # Process SOAs in the answer section (other than the initial
        # SOA in the first message).
        #
        for rrset in r.answer[answer_index:]:
            if done:
                raise dns.exception.FormError("answers after final SOA")
            if rrset.rdtype == dns.rdatatype.SOA and rrset.name == oname:
                if expecting_SOA:
                    if rrset[0].serial != serial:
                        raise dns.exception.FormError(
                            "IXFR base serial mismatch")
                    expecting_SOA = False
                elif rdtype == dns.rdatatype.IXFR:
                    delete_mode = not delete_mode
                #
                # If this SOA RRset is equal to the first we saw then we're
                # finished. If this is an IXFR we also check that we're seeing
                # the record in the expected part of the response.
                #
                if rrset == soa_rrset and \
                        (rdtype == dns.rdatatype.AXFR or
                         (rdtype == dns.rdatatype.IXFR and delete_mode)):
                    done = True
            elif expecting_SOA:
                #
                # We made an IXFR request and are expecting another
                # SOA RR, but saw something else, so this must be an
                # AXFR response.
                #
                rdtype = dns.rdatatype.AXFR
                expecting_SOA = False
        if done and q.keyring and not r.had_tsig:
            raise dns.exception.FormError("missing TSIG")
        yield r
    s.close()




############################################################
### File: rcode.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Result Codes."""

import dns.exception
from ._compat import long

#: No error
NOERROR = 0
#: Form error
FORMERR = 1
#: Server failure
SERVFAIL = 2
#: Name does not exist ("Name Error" in RFC 1025 terminology).
NXDOMAIN = 3
#: Not implemented
NOTIMP = 4
#: Refused
REFUSED = 5
#: Name exists.
YXDOMAIN = 6
#: RRset exists.
YXRRSET = 7
#: RRset does not exist.
NXRRSET = 8
#: Not authoritative.
NOTAUTH = 9
#: Name not in zone.
NOTZONE = 10
#: Bad EDNS version.
BADVERS = 16

_by_text = {
    'NOERROR': NOERROR,
    'FORMERR': FORMERR,
    'SERVFAIL': SERVFAIL,
    'NXDOMAIN': NXDOMAIN,
    'NOTIMP': NOTIMP,
    'REFUSED': REFUSED,
    'YXDOMAIN': YXDOMAIN,
    'YXRRSET': YXRRSET,
    'NXRRSET': NXRRSET,
    'NOTAUTH': NOTAUTH,
    'NOTZONE': NOTZONE,
    'BADVERS': BADVERS
}

# We construct the inverse mapping programmatically to ensure that we
# cannot make any mistakes (e.g. omissions, cut-and-paste errors) that
# would cause the mapping not to be a true inverse.

_by_value = {y: x for x, y in _by_text.items()}


class UnknownRcode(dns.exception.DNSException):
    """A DNS rcode is unknown."""


def from_text(text):
    """Convert text into an rcode.

    *text*, a ``text``, the textual rcode or an integer in textual form.

    Raises ``dns.rcode.UnknownRcode`` if the rcode mnemonic is unknown.

    Returns an ``int``.
    """

    if text.isdigit():
        v = int(text)
        if v >= 0 and v <= 4095:
            return v
    v = _by_text.get(text.upper())
    if v is None:
        raise UnknownRcode
    return v


def from_flags(flags, ednsflags):
    """Return the rcode value encoded by flags and ednsflags.

    *flags*, an ``int``, the DNS flags field.

    *ednsflags*, an ``int``, the EDNS flags field.

    Raises ``ValueError`` if rcode is < 0 or > 4095

    Returns an ``int``.
    """

    value = (flags & 0x000f) | ((ednsflags >> 20) & 0xff0)
    if value < 0 or value > 4095:
        raise ValueError('rcode must be >= 0 and <= 4095')
    return value


def to_flags(value):
    """Return a (flags, ednsflags) tuple which encodes the rcode.

    *value*, an ``int``, the rcode.

    Raises ``ValueError`` if rcode is < 0 or > 4095.

    Returns an ``(int, int)`` tuple.
    """

    if value < 0 or value > 4095:
        raise ValueError('rcode must be >= 0 and <= 4095')
    v = value & 0xf
    ev = long(value & 0xff0) << 20
    return (v, ev)


def to_text(value):
    """Convert rcode into text.

    *value*, and ``int``, the rcode.

    Raises ``ValueError`` if rcode is < 0 or > 4095.

    Returns a ``text``.
    """

    if value < 0 or value > 4095:
        raise ValueError('rcode must be >= 0 and <= 4095')
    text = _by_value.get(value)
    if text is None:
        text = str(value)
    return text




############################################################
### File: rdata.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS rdata."""

from io import BytesIO
import base64
import binascii

import dns.exception
import dns.name
import dns.rdataclass
import dns.rdatatype
import dns.tokenizer
import dns.wiredata
from ._compat import xrange, string_types, text_type

try:
    import threading as _threading
except ImportError:
    import dummy_threading as _threading

_hex_chunksize = 32


def _hexify(data, chunksize=_hex_chunksize):
    """Convert a binary string into its hex encoding, broken up into chunks
    of chunksize characters separated by a space.
    """

    line = binascii.hexlify(data)
    return b' '.join([line[i:i + chunksize]
                      for i
                      in range(0, len(line), chunksize)]).decode()

_base64_chunksize = 32


def _base64ify(data, chunksize=_base64_chunksize):
    """Convert a binary string into its base64 encoding, broken up into chunks
    of chunksize characters separated by a space.
    """

    line = base64.b64encode(data)
    return b' '.join([line[i:i + chunksize]
                      for i
                      in range(0, len(line), chunksize)]).decode()

__escaped = bytearray(b'"\\')

def _escapify(qstring):
    """Escape the characters in a quoted string which need it."""

    if isinstance(qstring, text_type):
        qstring = qstring.encode()
    if not isinstance(qstring, bytearray):
        qstring = bytearray(qstring)

    text = ''
    for c in qstring:
        if c in __escaped:
            text += '\\' + chr(c)
        elif c >= 0x20 and c < 0x7F:
            text += chr(c)
        else:
            text += '\\%03d' % c
    return text


def _truncate_bitmap(what):
    """Determine the index of greatest byte that isn't all zeros, and
    return the bitmap that contains all the bytes less than that index.
    """

    for i in xrange(len(what) - 1, -1, -1):
        if what[i] != 0:
            return what[0: i + 1]
    return what[0:1]


class Rdata(object):
    """Base class for all DNS rdata types."""

    __slots__ = ['rdclass', 'rdtype']

    def __init__(self, rdclass, rdtype):
        """Initialize an rdata.

        *rdclass*, an ``int`` is the rdataclass of the Rdata.
        *rdtype*, an ``int`` is the rdatatype of the Rdata.
        """

        self.rdclass = rdclass
        self.rdtype = rdtype

    def covers(self):
        """Return the type a Rdata covers.

        DNS SIG/RRSIG rdatas apply to a specific type; this type is
        returned by the covers() function.  If the rdata type is not
        SIG or RRSIG, dns.rdatatype.NONE is returned.  This is useful when
        creating rdatasets, allowing the rdataset to contain only RRSIGs
        of a particular type, e.g. RRSIG(NS).

        Returns an ``int``.
        """

        return dns.rdatatype.NONE

    def extended_rdatatype(self):
        """Return a 32-bit type value, the least significant 16 bits of
        which are the ordinary DNS type, and the upper 16 bits of which are
        the "covered" type, if any.

        Returns an ``int``.
        """

        return self.covers() << 16 | self.rdtype

    def to_text(self, origin=None, relativize=True, **kw):
        """Convert an rdata to text format.

        Returns a ``text``.
        """

        raise NotImplementedError

    def to_wire(self, file, compress=None, origin=None):
        """Convert an rdata to wire format.

        Returns a ``binary``.
        """

        raise NotImplementedError

    def to_digestable(self, origin=None):
        """Convert rdata to a format suitable for digesting in hashes.  This
        is also the DNSSEC canonical form.

        Returns a ``binary``.
        """

        f = BytesIO()
        self.to_wire(f, None, origin)
        return f.getvalue()

    def validate(self):
        """Check that the current contents of the rdata's fields are
        valid.

        If you change an rdata by assigning to its fields,
        it is a good idea to call validate() when you are done making
        changes.

        Raises various exceptions if there are problems.

        Returns ``None``.
        """

        dns.rdata.from_text(self.rdclass, self.rdtype, self.to_text())

    def __repr__(self):
        covers = self.covers()
        if covers == dns.rdatatype.NONE:
            ctext = ''
        else:
            ctext = '(' + dns.rdatatype.to_text(covers) + ')'
        return '<DNS ' + dns.rdataclass.to_text(self.rdclass) + ' ' + \
               dns.rdatatype.to_text(self.rdtype) + ctext + ' rdata: ' + \
               str(self) + '>'

    def __str__(self):
        return self.to_text()

    def _cmp(self, other):
        """Compare an rdata with another rdata of the same rdtype and
        rdclass.

        Return < 0 if self < other in the DNSSEC ordering, 0 if self
        == other, and > 0 if self > other.

        """
        our = self.to_digestable(dns.name.root)
        their = other.to_digestable(dns.name.root)
        if our == their:
            return 0
        elif our > their:
            return 1
        else:
            return -1

    def __eq__(self, other):
        if not isinstance(other, Rdata):
            return False
        if self.rdclass != other.rdclass or self.rdtype != other.rdtype:
            return False
        return self._cmp(other) == 0

    def __ne__(self, other):
        if not isinstance(other, Rdata):
            return True
        if self.rdclass != other.rdclass or self.rdtype != other.rdtype:
            return True
        return self._cmp(other) != 0

    def __lt__(self, other):
        if not isinstance(other, Rdata) or \
                self.rdclass != other.rdclass or self.rdtype != other.rdtype:

            return NotImplemented
        return self._cmp(other) < 0

    def __le__(self, other):
        if not isinstance(other, Rdata) or \
                self.rdclass != other.rdclass or self.rdtype != other.rdtype:
            return NotImplemented
        return self._cmp(other) <= 0

    def __ge__(self, other):
        if not isinstance(other, Rdata) or \
                self.rdclass != other.rdclass or self.rdtype != other.rdtype:
            return NotImplemented
        return self._cmp(other) >= 0

    def __gt__(self, other):
        if not isinstance(other, Rdata) or \
                self.rdclass != other.rdclass or self.rdtype != other.rdtype:
            return NotImplemented
        return self._cmp(other) > 0

    def __hash__(self):
        return hash(self.to_digestable(dns.name.root))

    @classmethod
    def from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True):
        raise NotImplementedError

    @classmethod
    def from_wire(cls, rdclass, rdtype, wire, current, rdlen, origin=None):
        raise NotImplementedError

    def choose_relativity(self, origin=None, relativize=True):
        """Convert any domain names in the rdata to the specified
        relativization.
        """

class GenericRdata(Rdata):

    """Generic Rdata Class

    This class is used for rdata types for which we have no better
    implementation.  It implements the DNS "unknown RRs" scheme.
    """

    __slots__ = ['data']

    def __init__(self, rdclass, rdtype, data):
        super(GenericRdata, self).__init__(rdclass, rdtype)
        self.data = data

    def to_text(self, origin=None, relativize=True, **kw):
        return r'\# %d ' % len(self.data) + _hexify(self.data)

    @classmethod
    def from_text(cls, rdclass, rdtype, tok, origin=None, relativize=True):
        token = tok.get()
        if not token.is_identifier() or token.value != r'\#':
            raise dns.exception.SyntaxError(
                r'generic rdata does not start with \#')
        length = tok.get_int()
        chunks = []
        while 1:
            token = tok.get()
            if token.is_eol_or_eof():
                break
            chunks.append(token.value.encode())
        hex = b''.join(chunks)
        data = binascii.unhexlify(hex)
        if len(data) != length:
            raise dns.exception.SyntaxError(
                'generic rdata hex data has wrong length')
        return cls(rdclass, rdtype, data)

    def to_wire(self, file, compress=None, origin=None):
        file.write(self.data)

    @classmethod
    def from_wire(cls, rdclass, rdtype, wire, current, rdlen, origin=None):
        return cls(rdclass, rdtype, wire[current: current + rdlen])

_rdata_modules = {}
_module_prefix = 'dns.rdtypes'
_import_lock = _threading.Lock()

def get_rdata_class(rdclass, rdtype):

    def import_module(name):
        with _import_lock:
            mod = __import__(name)
            components = name.split('.')
            for comp in components[1:]:
                mod = getattr(mod, comp)
            return mod

    mod = _rdata_modules.get((rdclass, rdtype))
    rdclass_text = dns.rdataclass.to_text(rdclass)
    rdtype_text = dns.rdatatype.to_text(rdtype)
    rdtype_text = rdtype_text.replace('-', '_')
    if not mod:
        mod = _rdata_modules.get((dns.rdatatype.ANY, rdtype))
        if not mod:
            try:
                mod = import_module('.'.join([_module_prefix,
                                              rdclass_text, rdtype_text]))
                _rdata_modules[(rdclass, rdtype)] = mod
            except ImportError:
                try:
                    mod = import_module('.'.join([_module_prefix,
                                                  'ANY', rdtype_text]))
                    _rdata_modules[(dns.rdataclass.ANY, rdtype)] = mod
                except ImportError:
                    mod = None
    if mod:
        cls = getattr(mod, rdtype_text)
    else:
        cls = GenericRdata
    return cls


def from_text(rdclass, rdtype, tok, origin=None, relativize=True):
    """Build an rdata object from text format.

    This function attempts to dynamically load a class which
    implements the specified rdata class and type.  If there is no
    class-and-type-specific implementation, the GenericRdata class
    is used.

    Once a class is chosen, its from_text() class method is called
    with the parameters to this function.

    If *tok* is a ``text``, then a tokenizer is created and the string
    is used as its input.

    *rdclass*, an ``int``, the rdataclass.

    *rdtype*, an ``int``, the rdatatype.

    *tok*, a ``dns.tokenizer.Tokenizer`` or a ``text``.

    *origin*, a ``dns.name.Name`` (or ``None``), the
    origin to use for relative names.

    *relativize*, a ``bool``.  If true, name will be relativized to
    the specified origin.

    Returns an instance of the chosen Rdata subclass.
    """

    if isinstance(tok, string_types):
        tok = dns.tokenizer.Tokenizer(tok)
    cls = get_rdata_class(rdclass, rdtype)
    if cls != GenericRdata:
        # peek at first token
        token = tok.get()
        tok.unget(token)
        if token.is_identifier() and \
           token.value == r'\#':
            #
            # Known type using the generic syntax.  Extract the
            # wire form from the generic syntax, and then run
            # from_wire on it.
            #
            rdata = GenericRdata.from_text(rdclass, rdtype, tok, origin,
                                           relativize)
            return from_wire(rdclass, rdtype, rdata.data, 0, len(rdata.data),
                             origin)
    return cls.from_text(rdclass, rdtype, tok, origin, relativize)


def from_wire(rdclass, rdtype, wire, current, rdlen, origin=None):
    """Build an rdata object from wire format

    This function attempts to dynamically load a class which
    implements the specified rdata class and type.  If there is no
    class-and-type-specific implementation, the GenericRdata class
    is used.

    Once a class is chosen, its from_wire() class method is called
    with the parameters to this function.

    *rdclass*, an ``int``, the rdataclass.

    *rdtype*, an ``int``, the rdatatype.

    *wire*, a ``binary``, the wire-format message.

    *current*, an ``int``, the offset in wire of the beginning of
    the rdata.

    *rdlen*, an ``int``, the length of the wire-format rdata

    *origin*, a ``dns.name.Name`` (or ``None``).  If not ``None``,
    then names will be relativized to this origin.

    Returns an instance of the chosen Rdata subclass.
    """

    wire = dns.wiredata.maybe_wrap(wire)
    cls = get_rdata_class(rdclass, rdtype)
    return cls.from_wire(rdclass, rdtype, wire, current, rdlen, origin)


class RdatatypeExists(dns.exception.DNSException):
    """DNS rdatatype already exists."""
    supp_kwargs = {'rdclass', 'rdtype'}
    fmt = "The rdata type with class {rdclass} and rdtype {rdtype} " + \
        "already exists."


def register_type(implementation, rdtype, rdtype_text, is_singleton=False,
                  rdclass=dns.rdataclass.IN):
    """Dynamically register a module to handle an rdatatype.

    *implementation*, a module implementing the type in the usual dnspython
    way.

    *rdtype*, an ``int``, the rdatatype to register.

    *rdtype_text*, a ``text``, the textual form of the rdatatype.

    *is_singleton*, a ``bool``, indicating if the type is a singleton (i.e.
    RRsets of the type can have only one member.)

    *rdclass*, the rdataclass of the type, or ``dns.rdataclass.ANY`` if
    it applies to all classes.
    """

    existing_cls = get_rdata_class(rdclass, rdtype)
    if existing_cls != GenericRdata:
        raise RdatatypeExists(rdclass=rdclass, rdtype=rdtype)
    _rdata_modules[(rdclass, rdtype)] = implementation
    dns.rdatatype.register_type(rdtype, rdtype_text, is_singleton)




############################################################
### File: rdataclass.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Rdata Classes."""

import re

import dns.exception

RESERVED0 = 0
IN = 1
CH = 3
HS = 4
NONE = 254
ANY = 255

_by_text = {
    'RESERVED0': RESERVED0,
    'IN': IN,
    'CH': CH,
    'HS': HS,
    'NONE': NONE,
    'ANY': ANY
}

# We construct the inverse mapping programmatically to ensure that we
# cannot make any mistakes (e.g. omissions, cut-and-paste errors) that
# would cause the mapping not to be true inverse.

_by_value = {y: x for x, y in _by_text.items()}

# Now that we've built the inverse map, we can add class aliases to
# the _by_text mapping.

_by_text.update({
    'INTERNET': IN,
    'CHAOS': CH,
    'HESIOD': HS
})

_metaclasses = {
    NONE: True,
    ANY: True
}

_unknown_class_pattern = re.compile('CLASS([0-9]+)$', re.I)


class UnknownRdataclass(dns.exception.DNSException):
    """A DNS class is unknown."""


def from_text(text):
    """Convert text into a DNS rdata class value.

    The input text can be a defined DNS RR class mnemonic or
    instance of the DNS generic class syntax.

    For example, "IN" and "CLASS1" will both result in a value of 1.

    Raises ``dns.rdatatype.UnknownRdataclass`` if the class is unknown.

    Raises ``ValueError`` if the rdata class value is not >= 0 and <= 65535.

    Returns an ``int``.
    """

    value = _by_text.get(text.upper())
    if value is None:
        match = _unknown_class_pattern.match(text)
        if match is None:
            raise UnknownRdataclass
        value = int(match.group(1))
        if value < 0 or value > 65535:
            raise ValueError("class must be between >= 0 and <= 65535")
    return value


def to_text(value):
    """Convert a DNS rdata type value to text.

    If the value has a known mnemonic, it will be used, otherwise the
    DNS generic class syntax will be used.

    Raises ``ValueError`` if the rdata class value is not >= 0 and <= 65535.

    Returns a ``str``.
    """

    if value < 0 or value > 65535:
        raise ValueError("class must be between >= 0 and <= 65535")
    text = _by_value.get(value)
    if text is None:
        text = 'CLASS' + repr(value)
    return text


def is_metaclass(rdclass):
    """True if the specified class is a metaclass.

    The currently defined metaclasses are ANY and NONE.

    *rdclass* is an ``int``.
    """

    if rdclass in _metaclasses:
        return True
    return False




############################################################
### File: rdataset.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS rdatasets (an rdataset is a set of rdatas of a given type and class)"""

import random
from io import StringIO
import struct

import dns.exception
import dns.rdatatype
import dns.rdataclass
import dns.rdata
import dns.set
from ._compat import string_types

# define SimpleSet here for backwards compatibility
SimpleSet = dns.set.Set


class DifferingCovers(dns.exception.DNSException):
    """An attempt was made to add a DNS SIG/RRSIG whose covered type
    is not the same as that of the other rdatas in the rdataset."""


class IncompatibleTypes(dns.exception.DNSException):
    """An attempt was made to add DNS RR data of an incompatible type."""


class Rdataset(dns.set.Set):

    """A DNS rdataset."""

    __slots__ = ['rdclass', 'rdtype', 'covers', 'ttl']

    def __init__(self, rdclass, rdtype, covers=dns.rdatatype.NONE, ttl=0):
        """Create a new rdataset of the specified class and type.

        *rdclass*, an ``int``, the rdataclass.

        *rdtype*, an ``int``, the rdatatype.

        *covers*, an ``int``, the covered rdatatype.

        *ttl*, an ``int``, the TTL.
        """

        super(Rdataset, self).__init__()
        self.rdclass = rdclass
        self.rdtype = rdtype
        self.covers = covers
        self.ttl = ttl

    def _clone(self):
        obj = super(Rdataset, self)._clone()
        obj.rdclass = self.rdclass
        obj.rdtype = self.rdtype
        obj.covers = self.covers
        obj.ttl = self.ttl
        return obj

    def update_ttl(self, ttl):
        """Perform TTL minimization.

        Set the TTL of the rdataset to be the lesser of the set's current
        TTL or the specified TTL.  If the set contains no rdatas, set the TTL
        to the specified TTL.

        *ttl*, an ``int``.
        """

        if len(self) == 0:
            self.ttl = ttl
        elif ttl < self.ttl:
            self.ttl = ttl

    def add(self, rd, ttl=None):
        """Add the specified rdata to the rdataset.

        If the optional *ttl* parameter is supplied, then
        ``self.update_ttl(ttl)`` will be called prior to adding the rdata.

        *rd*, a ``dns.rdata.Rdata``, the rdata

        *ttl*, an ``int``, the TTL.

        Raises ``dns.rdataset.IncompatibleTypes`` if the type and class
        do not match the type and class of the rdataset.

        Raises ``dns.rdataset.DifferingCovers`` if the type is a signature
        type and the covered type does not match that of the rdataset.
        """

        #
        # If we're adding a signature, do some special handling to
        # check that the signature covers the same type as the
        # other rdatas in this rdataset.  If this is the first rdata
        # in the set, initialize the covers field.
        #
        if self.rdclass != rd.rdclass or self.rdtype != rd.rdtype:
            raise IncompatibleTypes
        if ttl is not None:
            self.update_ttl(ttl)
        if self.rdtype == dns.rdatatype.RRSIG or \
           self.rdtype == dns.rdatatype.SIG:
            covers = rd.covers()
            if len(self) == 0 and self.covers == dns.rdatatype.NONE:
                self.covers = covers
            elif self.covers != covers:
                raise DifferingCovers
        if dns.rdatatype.is_singleton(rd.rdtype) and len(self) > 0:
            self.clear()
        super(Rdataset, self).add(rd)

    def union_update(self, other):
        self.update_ttl(other.ttl)
        super(Rdataset, self).union_update(other)

    def intersection_update(self, other):
        self.update_ttl(other.ttl)
        super(Rdataset, self).intersection_update(other)

    def update(self, other):
        """Add all rdatas in other to self.

        *other*, a ``dns.rdataset.Rdataset``, the rdataset from which
        to update.
        """

        self.update_ttl(other.ttl)
        super(Rdataset, self).update(other)

    def __repr__(self):
        if self.covers == 0:
            ctext = ''
        else:
            ctext = '(' + dns.rdatatype.to_text(self.covers) + ')'
        return '<DNS ' + dns.rdataclass.to_text(self.rdclass) + ' ' + \
               dns.rdatatype.to_text(self.rdtype) + ctext + ' rdataset>'

    def __str__(self):
        return self.to_text()

    def __eq__(self, other):
        if not isinstance(other, Rdataset):
            return False
        if self.rdclass != other.rdclass or \
           self.rdtype != other.rdtype or \
           self.covers != other.covers:
            return False
        return super(Rdataset, self).__eq__(other)

    def __ne__(self, other):
        return not self.__eq__(other)

    def to_text(self, name=None, origin=None, relativize=True,
                override_rdclass=None, **kw):
        """Convert the rdataset into DNS master file format.

        See ``dns.name.Name.choose_relativity`` for more information
        on how *origin* and *relativize* determine the way names
        are emitted.

        Any additional keyword arguments are passed on to the rdata
        ``to_text()`` method.

        *name*, a ``dns.name.Name``.  If name is not ``None``, emit RRs with
        *name* as the owner name.

        *origin*, a ``dns.name.Name`` or ``None``, the origin for relative
        names.

        *relativize*, a ``bool``.  If ``True``, names will be relativized
        to *origin*.
        """

        if name is not None:
            name = name.choose_relativity(origin, relativize)
            ntext = str(name)
            pad = ' '
        else:
            ntext = ''
            pad = ''
        s = StringIO()
        if override_rdclass is not None:
            rdclass = override_rdclass
        else:
            rdclass = self.rdclass
        if len(self) == 0:
            #
            # Empty rdatasets are used for the question section, and in
            # some dynamic updates, so we don't need to print out the TTL
            # (which is meaningless anyway).
            #
            s.write(u'{}{}{} {}\n'.format(ntext, pad,
                                          dns.rdataclass.to_text(rdclass),
                                          dns.rdatatype.to_text(self.rdtype)))
        else:
            for rd in self:
                s.write(u'%s%s%d %s %s %s\n' %
                        (ntext, pad, self.ttl, dns.rdataclass.to_text(rdclass),
                         dns.rdatatype.to_text(self.rdtype),
                         rd.to_text(origin=origin, relativize=relativize,
                         **kw)))
        #
        # We strip off the final \n for the caller's convenience in printing
        #
        return s.getvalue()[:-1]

    def to_wire(self, name, file, compress=None, origin=None,
                override_rdclass=None, want_shuffle=True):
        """Convert the rdataset to wire format.

        *name*, a ``dns.name.Name`` is the owner name to use.

        *file* is the file where the name is emitted (typically a
        BytesIO file).

        *compress*, a ``dict``, is the compression table to use.  If
        ``None`` (the default), names will not be compressed.

        *origin* is a ``dns.name.Name`` or ``None``.  If the name is
        relative and origin is not ``None``, then *origin* will be appended
        to it.

        *override_rdclass*, an ``int``, is used as the class instead of the
        class of the rdataset.  This is useful when rendering rdatasets
        associated with dynamic updates.

        *want_shuffle*, a ``bool``.  If ``True``, then the order of the
        Rdatas within the Rdataset will be shuffled before rendering.

        Returns an ``int``, the number of records emitted.
        """

        if override_rdclass is not None:
            rdclass = override_rdclass
            want_shuffle = False
        else:
            rdclass = self.rdclass
        file.seek(0, 2)
        if len(self) == 0:
            name.to_wire(file, compress, origin)
            stuff = struct.pack("!HHIH", self.rdtype, rdclass, 0, 0)
            file.write(stuff)
            return 1
        else:
            if want_shuffle:
                l = list(self)
                random.shuffle(l)
            else:
                l = self
            for rd in l:
                name.to_wire(file, compress, origin)
                stuff = struct.pack("!HHIH", self.rdtype, rdclass,
                                    self.ttl, 0)
                file.write(stuff)
                start = file.tell()
                rd.to_wire(file, compress, origin)
                end = file.tell()
                assert end - start < 65536
                file.seek(start - 2)
                stuff = struct.pack("!H", end - start)
                file.write(stuff)
                file.seek(0, 2)
            return len(self)

    def match(self, rdclass, rdtype, covers):
        """Returns ``True`` if this rdataset matches the specified class,
        type, and covers.
        """
        if self.rdclass == rdclass and \
           self.rdtype == rdtype and \
           self.covers == covers:
            return True
        return False


def from_text_list(rdclass, rdtype, ttl, text_rdatas):
    """Create an rdataset with the specified class, type, and TTL, and with
    the specified list of rdatas in text format.

    Returns a ``dns.rdataset.Rdataset`` object.
    """

    if isinstance(rdclass, string_types):
        rdclass = dns.rdataclass.from_text(rdclass)
    if isinstance(rdtype, string_types):
        rdtype = dns.rdatatype.from_text(rdtype)
    r = Rdataset(rdclass, rdtype)
    r.update_ttl(ttl)
    for t in text_rdatas:
        rd = dns.rdata.from_text(r.rdclass, r.rdtype, t)
        r.add(rd)
    return r


def from_text(rdclass, rdtype, ttl, *text_rdatas):
    """Create an rdataset with the specified class, type, and TTL, and with
    the specified rdatas in text format.

    Returns a ``dns.rdataset.Rdataset`` object.
    """

    return from_text_list(rdclass, rdtype, ttl, text_rdatas)


def from_rdata_list(ttl, rdatas):
    """Create an rdataset with the specified TTL, and with
    the specified list of rdata objects.

    Returns a ``dns.rdataset.Rdataset`` object.
    """

    if len(rdatas) == 0:
        raise ValueError("rdata list must not be empty")
    r = None
    for rd in rdatas:
        if r is None:
            r = Rdataset(rd.rdclass, rd.rdtype)
            r.update_ttl(ttl)
        r.add(rd)
    return r


def from_rdata(ttl, *rdatas):
    """Create an rdataset with the specified TTL, and with
    the specified rdata objects.

    Returns a ``dns.rdataset.Rdataset`` object.
    """

    return from_rdata_list(ttl, rdatas)




############################################################
### File: rdatatype.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Rdata Types."""

import re

import dns.exception

NONE = 0
A = 1
NS = 2
MD = 3
MF = 4
CNAME = 5
SOA = 6
MB = 7
MG = 8
MR = 9
NULL = 10
WKS = 11
PTR = 12
HINFO = 13
MINFO = 14
MX = 15
TXT = 16
RP = 17
AFSDB = 18
X25 = 19
ISDN = 20
RT = 21
NSAP = 22
NSAP_PTR = 23
SIG = 24
KEY = 25
PX = 26
GPOS = 27
AAAA = 28
LOC = 29
NXT = 30
SRV = 33
NAPTR = 35
KX = 36
CERT = 37
A6 = 38
DNAME = 39
OPT = 41
APL = 42
DS = 43
SSHFP = 44
IPSECKEY = 45
RRSIG = 46
NSEC = 47
DNSKEY = 48
DHCID = 49
NSEC3 = 50
NSEC3PARAM = 51
TLSA = 52
HIP = 55
CDS = 59
CDNSKEY = 60
OPENPGPKEY = 61
CSYNC = 62
SPF = 99
UNSPEC = 103
EUI48 = 108
EUI64 = 109
TKEY = 249
TSIG = 250
IXFR = 251
AXFR = 252
MAILB = 253
MAILA = 254
ANY = 255
URI = 256
CAA = 257
AVC = 258
TA = 32768
DLV = 32769

_by_text = {
    'NONE': NONE,
    'A': A,
    'NS': NS,
    'MD': MD,
    'MF': MF,
    'CNAME': CNAME,
    'SOA': SOA,
    'MB': MB,
    'MG': MG,
    'MR': MR,
    'NULL': NULL,
    'WKS': WKS,
    'PTR': PTR,
    'HINFO': HINFO,
    'MINFO': MINFO,
    'MX': MX,
    'TXT': TXT,
    'RP': RP,
    'AFSDB': AFSDB,
    'X25': X25,
    'ISDN': ISDN,
    'RT': RT,
    'NSAP': NSAP,
    'NSAP-PTR': NSAP_PTR,
    'SIG': SIG,
    'KEY': KEY,
    'PX': PX,
    'GPOS': GPOS,
    'AAAA': AAAA,
    'LOC': LOC,
    'NXT': NXT,
    'SRV': SRV,
    'NAPTR': NAPTR,
    'KX': KX,
    'CERT': CERT,
    'A6': A6,
    'DNAME': DNAME,
    'OPT': OPT,
    'APL': APL,
    'DS': DS,
    'SSHFP': SSHFP,
    'IPSECKEY': IPSECKEY,
    'RRSIG': RRSIG,
    'NSEC': NSEC,
    'DNSKEY': DNSKEY,
    'DHCID': DHCID,
    'NSEC3': NSEC3,
    'NSEC3PARAM': NSEC3PARAM,
    'TLSA': TLSA,
    'HIP': HIP,
    'CDS': CDS,
    'CDNSKEY': CDNSKEY,
    'OPENPGPKEY': OPENPGPKEY,
    'CSYNC': CSYNC,
    'SPF': SPF,
    'UNSPEC': UNSPEC,
    'EUI48': EUI48,
    'EUI64': EUI64,
    'TKEY': TKEY,
    'TSIG': TSIG,
    'IXFR': IXFR,
    'AXFR': AXFR,
    'MAILB': MAILB,
    'MAILA': MAILA,
    'ANY': ANY,
    'URI': URI,
    'CAA': CAA,
    'AVC': AVC,
    'TA': TA,
    'DLV': DLV,
}

# We construct the inverse mapping programmatically to ensure that we
# cannot make any mistakes (e.g. omissions, cut-and-paste errors) that
# would cause the mapping not to be true inverse.

_by_value = {y: x for x, y in _by_text.items()}

_metatypes = {
    OPT: True
}

_singletons = {
    SOA: True,
    NXT: True,
    DNAME: True,
    NSEC: True,
    CNAME: True,
}

_unknown_type_pattern = re.compile('TYPE([0-9]+)$', re.I)


class UnknownRdatatype(dns.exception.DNSException):
    """DNS resource record type is unknown."""


def from_text(text):
    """Convert text into a DNS rdata type value.

    The input text can be a defined DNS RR type mnemonic or
    instance of the DNS generic type syntax.

    For example, "NS" and "TYPE2" will both result in a value of 2.

    Raises ``dns.rdatatype.UnknownRdatatype`` if the type is unknown.

    Raises ``ValueError`` if the rdata type value is not >= 0 and <= 65535.

    Returns an ``int``.
    """

    value = _by_text.get(text.upper())
    if value is None:
        match = _unknown_type_pattern.match(text)
        if match is None:
            raise UnknownRdatatype
        value = int(match.group(1))
        if value < 0 or value > 65535:
            raise ValueError("type must be between >= 0 and <= 65535")
    return value


def to_text(value):
    """Convert a DNS rdata type value to text.

    If the value has a known mnemonic, it will be used, otherwise the
    DNS generic type syntax will be used.

    Raises ``ValueError`` if the rdata type value is not >= 0 and <= 65535.

    Returns a ``str``.
    """

    if value < 0 or value > 65535:
        raise ValueError("type must be between >= 0 and <= 65535")
    text = _by_value.get(value)
    if text is None:
        text = 'TYPE' + repr(value)
    return text


def is_metatype(rdtype):
    """True if the specified type is a metatype.

    *rdtype* is an ``int``.

    The currently defined metatypes are TKEY, TSIG, IXFR, AXFR, MAILA,
    MAILB, ANY, and OPT.

    Returns a ``bool``.
    """

    if rdtype >= TKEY and rdtype <= ANY or rdtype in _metatypes:
        return True
    return False


def is_singleton(rdtype):
    """Is the specified type a singleton type?

    Singleton types can only have a single rdata in an rdataset, or a single
    RR in an RRset.

    The currently defined singleton types are CNAME, DNAME, NSEC, NXT, and
    SOA.

    *rdtype* is an ``int``.

    Returns a ``bool``.
    """

    if rdtype in _singletons:
        return True
    return False


def register_type(rdtype, rdtype_text, is_singleton=False):  # pylint: disable=redefined-outer-name
    """Dynamically register an rdatatype.

    *rdtype*, an ``int``, the rdatatype to register.

    *rdtype_text*, a ``text``, the textual form of the rdatatype.

    *is_singleton*, a ``bool``, indicating if the type is a singleton (i.e.
    RRsets of the type can have only one member.)
    """

    _by_text[rdtype_text] = rdtype
    _by_value[rdtype] = rdtype_text
    if is_singleton:
        _singletons[rdtype] = True




############################################################
### File: reference.py
############################################################
'''
Reference tzinfo implementations from the Python docs.
Used for testing against as they are only correct for the years
1987 to 2006. Do not use these for real code.
'''

from datetime import tzinfo, timedelta, datetime
from pytz import HOUR, ZERO, UTC

__all__ = [
    'FixedOffset',
    'LocalTimezone',
    'USTimeZone',
    'Eastern',
    'Central',
    'Mountain',
    'Pacific',
    'UTC'
]


# A class building tzinfo objects for fixed-offset time zones.
# Note that FixedOffset(0, "UTC") is a different way to build a
# UTC tzinfo object.
class FixedOffset(tzinfo):
    """Fixed offset in minutes east from UTC."""

    def __init__(self, offset, name):
        self.__offset = timedelta(minutes=offset)
        self.__name = name

    def utcoffset(self, dt):
        return self.__offset

    def tzname(self, dt):
        return self.__name

    def dst(self, dt):
        return ZERO


import time as _time

STDOFFSET = timedelta(seconds=-_time.timezone)
if _time.daylight:
    DSTOFFSET = timedelta(seconds=-_time.altzone)
else:
    DSTOFFSET = STDOFFSET

DSTDIFF = DSTOFFSET - STDOFFSET


# A class capturing the platform's idea of local time.
class LocalTimezone(tzinfo):

    def utcoffset(self, dt):
        if self._isdst(dt):
            return DSTOFFSET
        else:
            return STDOFFSET

    def dst(self, dt):
        if self._isdst(dt):
            return DSTDIFF
        else:
            return ZERO

    def tzname(self, dt):
        return _time.tzname[self._isdst(dt)]

    def _isdst(self, dt):
        tt = (dt.year, dt.month, dt.day,
              dt.hour, dt.minute, dt.second,
              dt.weekday(), 0, -1)
        stamp = _time.mktime(tt)
        tt = _time.localtime(stamp)
        return tt.tm_isdst > 0

Local = LocalTimezone()


def first_sunday_on_or_after(dt):
    days_to_go = 6 - dt.weekday()
    if days_to_go:
        dt += timedelta(days_to_go)
    return dt


# In the US, DST starts at 2am (standard time) on the first Sunday in April.
DSTSTART = datetime(1, 4, 1, 2)
# and ends at 2am (DST time; 1am standard time) on the last Sunday of Oct.
# which is the first Sunday on or after Oct 25.
DSTEND = datetime(1, 10, 25, 1)


# A complete implementation of current DST rules for major US time zones.
class USTimeZone(tzinfo):

    def __init__(self, hours, reprname, stdname, dstname):
        self.stdoffset = timedelta(hours=hours)
        self.reprname = reprname
        self.stdname = stdname
        self.dstname = dstname

    def __repr__(self):
        return self.reprname

    def tzname(self, dt):
        if self.dst(dt):
            return self.dstname
        else:
            return self.stdname

    def utcoffset(self, dt):
        return self.stdoffset + self.dst(dt)

    def dst(self, dt):
        if dt is None or dt.tzinfo is None:
            # An exception may be sensible here, in one or both cases.
            # It depends on how you want to treat them.  The default
            # fromutc() implementation (called by the default astimezone()
            # implementation) passes a datetime with dt.tzinfo is self.
            return ZERO
        assert dt.tzinfo is self

        # Find first Sunday in April & the last in October.
        start = first_sunday_on_or_after(DSTSTART.replace(year=dt.year))
        end = first_sunday_on_or_after(DSTEND.replace(year=dt.year))

        # Can't compare naive to aware objects, so strip the timezone from
        # dt first.
        if start <= dt.replace(tzinfo=None) < end:
            return HOUR
        else:
            return ZERO

Eastern = USTimeZone(-5, "Eastern", "EST", "EDT")
Central = USTimeZone(-6, "Central", "CST", "CDT")
Mountain = USTimeZone(-7, "Mountain", "MST", "MDT")
Pacific = USTimeZone(-8, "Pacific", "PST", "PDT")




############################################################
### File: relativedelta.py
############################################################
# -*- coding: utf-8 -*-
import datetime
import calendar

import operator
from math import copysign

from six import integer_types
from warnings import warn

from ._common import weekday

MO, TU, WE, TH, FR, SA, SU = weekdays = tuple(weekday(x) for x in range(7))

__all__ = ["relativedelta", "MO", "TU", "WE", "TH", "FR", "SA", "SU"]


class relativedelta(object):
    """
    The relativedelta type is designed to be applied to an existing datetime and
    can replace specific components of that datetime, or represents an interval
    of time.

    It is based on the specification of the excellent work done by M.-A. Lemburg
    in his
    `mx.DateTime <https://www.egenix.com/products/python/mxBase/mxDateTime/>`_ extension.
    However, notice that this type does *NOT* implement the same algorithm as
    his work. Do *NOT* expect it to behave like mx.DateTime's counterpart.

    There are two different ways to build a relativedelta instance. The
    first one is passing it two date/datetime classes::

        relativedelta(datetime1, datetime2)

    The second one is passing it any number of the following keyword arguments::

        relativedelta(arg1=x,arg2=y,arg3=z...)

        year, month, day, hour, minute, second, microsecond:
            Absolute information (argument is singular); adding or subtracting a
            relativedelta with absolute information does not perform an arithmetic
            operation, but rather REPLACES the corresponding value in the
            original datetime with the value(s) in relativedelta.

        years, months, weeks, days, hours, minutes, seconds, microseconds:
            Relative information, may be negative (argument is plural); adding
            or subtracting a relativedelta with relative information performs
            the corresponding arithmetic operation on the original datetime value
            with the information in the relativedelta.

        weekday: 
            One of the weekday instances (MO, TU, etc) available in the
            relativedelta module. These instances may receive a parameter N,
            specifying the Nth weekday, which could be positive or negative
            (like MO(+1) or MO(-2)). Not specifying it is the same as specifying
            +1. You can also use an integer, where 0=MO. This argument is always
            relative e.g. if the calculated date is already Monday, using MO(1)
            or MO(-1) won't change the day. To effectively make it absolute, use
            it in combination with the day argument (e.g. day=1, MO(1) for first
            Monday of the month).

        leapdays:
            Will add given days to the date found, if year is a leap
            year, and the date found is post 28 of february.

        yearday, nlyearday:
            Set the yearday or the non-leap year day (jump leap days).
            These are converted to day/month/leapdays information.

    There are relative and absolute forms of the keyword
    arguments. The plural is relative, and the singular is
    absolute. For each argument in the order below, the absolute form
    is applied first (by setting each attribute to that value) and
    then the relative form (by adding the value to the attribute).

    The order of attributes considered when this relativedelta is
    added to a datetime is:

    1. Year
    2. Month
    3. Day
    4. Hours
    5. Minutes
    6. Seconds
    7. Microseconds

    Finally, weekday is applied, using the rule described above.

    For example

    >>> from datetime import datetime
    >>> from dateutil.relativedelta import relativedelta, MO
    >>> dt = datetime(2018, 4, 9, 13, 37, 0)
    >>> delta = relativedelta(hours=25, day=1, weekday=MO(1))
    >>> dt + delta
    datetime.datetime(2018, 4, 2, 14, 37)

    First, the day is set to 1 (the first of the month), then 25 hours
    are added, to get to the 2nd day and 14th hour, finally the
    weekday is applied, but since the 2nd is already a Monday there is
    no effect.

    """

    def __init__(self, dt1=None, dt2=None,
                 years=0, months=0, days=0, leapdays=0, weeks=0,
                 hours=0, minutes=0, seconds=0, microseconds=0,
                 year=None, month=None, day=None, weekday=None,
                 yearday=None, nlyearday=None,
                 hour=None, minute=None, second=None, microsecond=None):

        if dt1 and dt2:
            # datetime is a subclass of date. So both must be date
            if not (isinstance(dt1, datetime.date) and
                    isinstance(dt2, datetime.date)):
                raise TypeError("relativedelta only diffs datetime/date")

            # We allow two dates, or two datetimes, so we coerce them to be
            # of the same type
            if (isinstance(dt1, datetime.datetime) !=
                    isinstance(dt2, datetime.datetime)):
                if not isinstance(dt1, datetime.datetime):
                    dt1 = datetime.datetime.fromordinal(dt1.toordinal())
                elif not isinstance(dt2, datetime.datetime):
                    dt2 = datetime.datetime.fromordinal(dt2.toordinal())

            self.years = 0
            self.months = 0
            self.days = 0
            self.leapdays = 0
            self.hours = 0
            self.minutes = 0
            self.seconds = 0
            self.microseconds = 0
            self.year = None
            self.month = None
            self.day = None
            self.weekday = None
            self.hour = None
            self.minute = None
            self.second = None
            self.microsecond = None
            self._has_time = 0

            # Get year / month delta between the two
            months = (dt1.year - dt2.year) * 12 + (dt1.month - dt2.month)
            self._set_months(months)

            # Remove the year/month delta so the timedelta is just well-defined
            # time units (seconds, days and microseconds)
            dtm = self.__radd__(dt2)

            # If we've overshot our target, make an adjustment
            if dt1 < dt2:
                compare = operator.gt
                increment = 1
            else:
                compare = operator.lt
                increment = -1

            while compare(dt1, dtm):
                months += increment
                self._set_months(months)
                dtm = self.__radd__(dt2)

            # Get the timedelta between the "months-adjusted" date and dt1
            delta = dt1 - dtm
            self.seconds = delta.seconds + delta.days * 86400
            self.microseconds = delta.microseconds
        else:
            # Check for non-integer values in integer-only quantities
            if any(x is not None and x != int(x) for x in (years, months)):
                raise ValueError("Non-integer years and months are "
                                 "ambiguous and not currently supported.")

            # Relative information
            self.years = int(years)
            self.months = int(months)
            self.days = days + weeks * 7
            self.leapdays = leapdays
            self.hours = hours
            self.minutes = minutes
            self.seconds = seconds
            self.microseconds = microseconds

            # Absolute information
            self.year = year
            self.month = month
            self.day = day
            self.hour = hour
            self.minute = minute
            self.second = second
            self.microsecond = microsecond

            if any(x is not None and int(x) != x
                   for x in (year, month, day, hour,
                             minute, second, microsecond)):
                # For now we'll deprecate floats - later it'll be an error.
                warn("Non-integer value passed as absolute information. " +
                     "This is not a well-defined condition and will raise " +
                     "errors in future versions.", DeprecationWarning)

            if isinstance(weekday, integer_types):
                self.weekday = weekdays[weekday]
            else:
                self.weekday = weekday

            yday = 0
            if nlyearday:
                yday = nlyearday
            elif yearday:
                yday = yearday
                if yearday > 59:
                    self.leapdays = -1
            if yday:
                ydayidx = [31, 59, 90, 120, 151, 181, 212,
                           243, 273, 304, 334, 366]
                for idx, ydays in enumerate(ydayidx):
                    if yday <= ydays:
                        self.month = idx+1
                        if idx == 0:
                            self.day = yday
                        else:
                            self.day = yday-ydayidx[idx-1]
                        break
                else:
                    raise ValueError("invalid year day (%d)" % yday)

        self._fix()

    def _fix(self):
        if abs(self.microseconds) > 999999:
            s = _sign(self.microseconds)
            div, mod = divmod(self.microseconds * s, 1000000)
            self.microseconds = mod * s
            self.seconds += div * s
        if abs(self.seconds) > 59:
            s = _sign(self.seconds)
            div, mod = divmod(self.seconds * s, 60)
            self.seconds = mod * s
            self.minutes += div * s
        if abs(self.minutes) > 59:
            s = _sign(self.minutes)
            div, mod = divmod(self.minutes * s, 60)
            self.minutes = mod * s
            self.hours += div * s
        if abs(self.hours) > 23:
            s = _sign(self.hours)
            div, mod = divmod(self.hours * s, 24)
            self.hours = mod * s
            self.days += div * s
        if abs(self.months) > 11:
            s = _sign(self.months)
            div, mod = divmod(self.months * s, 12)
            self.months = mod * s
            self.years += div * s
        if (self.hours or self.minutes or self.seconds or self.microseconds
                or self.hour is not None or self.minute is not None or
                self.second is not None or self.microsecond is not None):
            self._has_time = 1
        else:
            self._has_time = 0

    @property
    def weeks(self):
        return int(self.days / 7.0)

    @weeks.setter
    def weeks(self, value):
        self.days = self.days - (self.weeks * 7) + value * 7

    def _set_months(self, months):
        self.months = months
        if abs(self.months) > 11:
            s = _sign(self.months)
            div, mod = divmod(self.months * s, 12)
            self.months = mod * s
            self.years = div * s
        else:
            self.years = 0

    def normalized(self):
        """
        Return a version of this object represented entirely using integer
        values for the relative attributes.

        >>> relativedelta(days=1.5, hours=2).normalized()
        relativedelta(days=+1, hours=+14)

        :return:
            Returns a :class:`dateutil.relativedelta.relativedelta` object.
        """
        # Cascade remainders down (rounding each to roughly nearest microsecond)
        days = int(self.days)

        hours_f = round(self.hours + 24 * (self.days - days), 11)
        hours = int(hours_f)

        minutes_f = round(self.minutes + 60 * (hours_f - hours), 10)
        minutes = int(minutes_f)

        seconds_f = round(self.seconds + 60 * (minutes_f - minutes), 8)
        seconds = int(seconds_f)

        microseconds = round(self.microseconds + 1e6 * (seconds_f - seconds))

        # Constructor carries overflow back up with call to _fix()
        return self.__class__(years=self.years, months=self.months,
                              days=days, hours=hours, minutes=minutes,
                              seconds=seconds, microseconds=microseconds,
                              leapdays=self.leapdays, year=self.year,
                              month=self.month, day=self.day,
                              weekday=self.weekday, hour=self.hour,
                              minute=self.minute, second=self.second,
                              microsecond=self.microsecond)

    def __add__(self, other):
        if isinstance(other, relativedelta):
            return self.__class__(years=other.years + self.years,
                                 months=other.months + self.months,
                                 days=other.days + self.days,
                                 hours=other.hours + self.hours,
                                 minutes=other.minutes + self.minutes,
                                 seconds=other.seconds + self.seconds,
                                 microseconds=(other.microseconds +
                                               self.microseconds),
                                 leapdays=other.leapdays or self.leapdays,
                                 year=(other.year if other.year is not None
                                       else self.year),
                                 month=(other.month if other.month is not None
                                        else self.month),
                                 day=(other.day if other.day is not None
                                      else self.day),
                                 weekday=(other.weekday if other.weekday is not None
                                          else self.weekday),
                                 hour=(other.hour if other.hour is not None
                                       else self.hour),
                                 minute=(other.minute if other.minute is not None
                                         else self.minute),
                                 second=(other.second if other.second is not None
                                         else self.second),
                                 microsecond=(other.microsecond if other.microsecond
                                              is not None else
                                              self.microsecond))
        if isinstance(other, datetime.timedelta):
            return self.__class__(years=self.years,
                                  months=self.months,
                                  days=self.days + other.days,
                                  hours=self.hours,
                                  minutes=self.minutes,
                                  seconds=self.seconds + other.seconds,
                                  microseconds=self.microseconds + other.microseconds,
                                  leapdays=self.leapdays,
                                  year=self.year,
                                  month=self.month,
                                  day=self.day,
                                  weekday=self.weekday,
                                  hour=self.hour,
                                  minute=self.minute,
                                  second=self.second,
                                  microsecond=self.microsecond)
        if not isinstance(other, datetime.date):
            return NotImplemented
        elif self._has_time and not isinstance(other, datetime.datetime):
            other = datetime.datetime.fromordinal(other.toordinal())
        year = (self.year or other.year)+self.years
        month = self.month or other.month
        if self.months:
            assert 1 <= abs(self.months) <= 12
            month += self.months
            if month > 12:
                year += 1
                month -= 12
            elif month < 1:
                year -= 1
                month += 12
        day = min(calendar.monthrange(year, month)[1],
                  self.day or other.day)
        repl = {"year": year, "month": month, "day": day}
        for attr in ["hour", "minute", "second", "microsecond"]:
            value = getattr(self, attr)
            if value is not None:
                repl[attr] = value
        days = self.days
        if self.leapdays and month > 2 and calendar.isleap(year):
            days += self.leapdays
        ret = (other.replace(**repl)
               + datetime.timedelta(days=days,
                                    hours=self.hours,
                                    minutes=self.minutes,
                                    seconds=self.seconds,
                                    microseconds=self.microseconds))
        if self.weekday:
            weekday, nth = self.weekday.weekday, self.weekday.n or 1
            jumpdays = (abs(nth) - 1) * 7
            if nth > 0:
                jumpdays += (7 - ret.weekday() + weekday) % 7
            else:
                jumpdays += (ret.weekday() - weekday) % 7
                jumpdays *= -1
            ret += datetime.timedelta(days=jumpdays)
        return ret

    def __radd__(self, other):
        return self.__add__(other)

    def __rsub__(self, other):
        return self.__neg__().__radd__(other)

    def __sub__(self, other):
        if not isinstance(other, relativedelta):
            return NotImplemented   # In case the other object defines __rsub__
        return self.__class__(years=self.years - other.years,
                             months=self.months - other.months,
                             days=self.days - other.days,
                             hours=self.hours - other.hours,
                             minutes=self.minutes - other.minutes,
                             seconds=self.seconds - other.seconds,
                             microseconds=self.microseconds - other.microseconds,
                             leapdays=self.leapdays or other.leapdays,
                             year=(self.year if self.year is not None
                                   else other.year),
                             month=(self.month if self.month is not None else
                                    other.month),
                             day=(self.day if self.day is not None else
                                  other.day),
                             weekday=(self.weekday if self.weekday is not None else
                                      other.weekday),
                             hour=(self.hour if self.hour is not None else
                                   other.hour),
                             minute=(self.minute if self.minute is not None else
                                     other.minute),
                             second=(self.second if self.second is not None else
                                     other.second),
                             microsecond=(self.microsecond if self.microsecond
                                          is not None else
                                          other.microsecond))

    def __abs__(self):
        return self.__class__(years=abs(self.years),
                              months=abs(self.months),
                              days=abs(self.days),
                              hours=abs(self.hours),
                              minutes=abs(self.minutes),
                              seconds=abs(self.seconds),
                              microseconds=abs(self.microseconds),
                              leapdays=self.leapdays,
                              year=self.year,
                              month=self.month,
                              day=self.day,
                              weekday=self.weekday,
                              hour=self.hour,
                              minute=self.minute,
                              second=self.second,
                              microsecond=self.microsecond)

    def __neg__(self):
        return self.__class__(years=-self.years,
                             months=-self.months,
                             days=-self.days,
                             hours=-self.hours,
                             minutes=-self.minutes,
                             seconds=-self.seconds,
                             microseconds=-self.microseconds,
                             leapdays=self.leapdays,
                             year=self.year,
                             month=self.month,
                             day=self.day,
                             weekday=self.weekday,
                             hour=self.hour,
                             minute=self.minute,
                             second=self.second,
                             microsecond=self.microsecond)

    def __bool__(self):
        return not (not self.years and
                    not self.months and
                    not self.days and
                    not self.hours and
                    not self.minutes and
                    not self.seconds and
                    not self.microseconds and
                    not self.leapdays and
                    self.year is None and
                    self.month is None and
                    self.day is None and
                    self.weekday is None and
                    self.hour is None and
                    self.minute is None and
                    self.second is None and
                    self.microsecond is None)
    # Compatibility with Python 2.x
    __nonzero__ = __bool__

    def __mul__(self, other):
        try:
            f = float(other)
        except TypeError:
            return NotImplemented

        return self.__class__(years=int(self.years * f),
                             months=int(self.months * f),
                             days=int(self.days * f),
                             hours=int(self.hours * f),
                             minutes=int(self.minutes * f),
                             seconds=int(self.seconds * f),
                             microseconds=int(self.microseconds * f),
                             leapdays=self.leapdays,
                             year=self.year,
                             month=self.month,
                             day=self.day,
                             weekday=self.weekday,
                             hour=self.hour,
                             minute=self.minute,
                             second=self.second,
                             microsecond=self.microsecond)

    __rmul__ = __mul__

    def __eq__(self, other):
        if not isinstance(other, relativedelta):
            return NotImplemented
        if self.weekday or other.weekday:
            if not self.weekday or not other.weekday:
                return False
            if self.weekday.weekday != other.weekday.weekday:
                return False
            n1, n2 = self.weekday.n, other.weekday.n
            if n1 != n2 and not ((not n1 or n1 == 1) and (not n2 or n2 == 1)):
                return False
        return (self.years == other.years and
                self.months == other.months and
                self.days == other.days and
                self.hours == other.hours and
                self.minutes == other.minutes and
                self.seconds == other.seconds and
                self.microseconds == other.microseconds and
                self.leapdays == other.leapdays and
                self.year == other.year and
                self.month == other.month and
                self.day == other.day and
                self.hour == other.hour and
                self.minute == other.minute and
                self.second == other.second and
                self.microsecond == other.microsecond)

    def __hash__(self):
        return hash((
            self.weekday,
            self.years,
            self.months,
            self.days,
            self.hours,
            self.minutes,
            self.seconds,
            self.microseconds,
            self.leapdays,
            self.year,
            self.month,
            self.day,
            self.hour,
            self.minute,
            self.second,
            self.microsecond,
        ))

    def __ne__(self, other):
        return not self.__eq__(other)

    def __div__(self, other):
        try:
            reciprocal = 1 / float(other)
        except TypeError:
            return NotImplemented

        return self.__mul__(reciprocal)

    __truediv__ = __div__

    def __repr__(self):
        l = []
        for attr in ["years", "months", "days", "leapdays",
                     "hours", "minutes", "seconds", "microseconds"]:
            value = getattr(self, attr)
            if value:
                l.append("{attr}={value:+g}".format(attr=attr, value=value))
        for attr in ["year", "month", "day", "weekday",
                     "hour", "minute", "second", "microsecond"]:
            value = getattr(self, attr)
            if value is not None:
                l.append("{attr}={value}".format(attr=attr, value=repr(value)))
        return "{classname}({attrs})".format(classname=self.__class__.__name__,
                                             attrs=", ".join(l))


def _sign(x):
    return int(copysign(1, x))

# vim:ts=4:sw=4:et




############################################################
### File: renderer.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""Help for building DNS wire format messages"""

from io import BytesIO
import struct
import random
import time

import dns.exception
import dns.tsig
from ._compat import long


QUESTION = 0
ANSWER = 1
AUTHORITY = 2
ADDITIONAL = 3


class Renderer(object):
    """Helper class for building DNS wire-format messages.

    Most applications can use the higher-level L{dns.message.Message}
    class and its to_wire() method to generate wire-format messages.
    This class is for those applications which need finer control
    over the generation of messages.

    Typical use::

        r = dns.renderer.Renderer(id=1, flags=0x80, max_size=512)
        r.add_question(qname, qtype, qclass)
        r.add_rrset(dns.renderer.ANSWER, rrset_1)
        r.add_rrset(dns.renderer.ANSWER, rrset_2)
        r.add_rrset(dns.renderer.AUTHORITY, ns_rrset)
        r.add_edns(0, 0, 4096)
        r.add_rrset(dns.renderer.ADDTIONAL, ad_rrset_1)
        r.add_rrset(dns.renderer.ADDTIONAL, ad_rrset_2)
        r.write_header()
        r.add_tsig(keyname, secret, 300, 1, 0, '', request_mac)
        wire = r.get_wire()

    output, a BytesIO, where rendering is written

    id: the message id

    flags: the message flags

    max_size: the maximum size of the message

    origin: the origin to use when rendering relative names

    compress: the compression table

    section: an int, the section currently being rendered

    counts: list of the number of RRs in each section

    mac: the MAC of the rendered message (if TSIG was used)
    """

    def __init__(self, id=None, flags=0, max_size=65535, origin=None):
        """Initialize a new renderer."""

        self.output = BytesIO()
        if id is None:
            self.id = random.randint(0, 65535)
        else:
            self.id = id
        self.flags = flags
        self.max_size = max_size
        self.origin = origin
        self.compress = {}
        self.section = QUESTION
        self.counts = [0, 0, 0, 0]
        self.output.write(b'\x00' * 12)
        self.mac = ''

    def _rollback(self, where):
        """Truncate the output buffer at offset *where*, and remove any
        compression table entries that pointed beyond the truncation
        point.
        """

        self.output.seek(where)
        self.output.truncate()
        keys_to_delete = []
        for k, v in self.compress.items():
            if v >= where:
                keys_to_delete.append(k)
        for k in keys_to_delete:
            del self.compress[k]

    def _set_section(self, section):
        """Set the renderer's current section.

        Sections must be rendered order: QUESTION, ANSWER, AUTHORITY,
        ADDITIONAL.  Sections may be empty.

        Raises dns.exception.FormError if an attempt was made to set
        a section value less than the current section.
        """

        if self.section != section:
            if self.section > section:
                raise dns.exception.FormError
            self.section = section

    def add_question(self, qname, rdtype, rdclass=dns.rdataclass.IN):
        """Add a question to the message."""

        self._set_section(QUESTION)
        before = self.output.tell()
        qname.to_wire(self.output, self.compress, self.origin)
        self.output.write(struct.pack("!HH", rdtype, rdclass))
        after = self.output.tell()
        if after >= self.max_size:
            self._rollback(before)
            raise dns.exception.TooBig
        self.counts[QUESTION] += 1

    def add_rrset(self, section, rrset, **kw):
        """Add the rrset to the specified section.

        Any keyword arguments are passed on to the rdataset's to_wire()
        routine.
        """

        self._set_section(section)
        before = self.output.tell()
        n = rrset.to_wire(self.output, self.compress, self.origin, **kw)
        after = self.output.tell()
        if after >= self.max_size:
            self._rollback(before)
            raise dns.exception.TooBig
        self.counts[section] += n

    def add_rdataset(self, section, name, rdataset, **kw):
        """Add the rdataset to the specified section, using the specified
        name as the owner name.

        Any keyword arguments are passed on to the rdataset's to_wire()
        routine.
        """

        self._set_section(section)
        before = self.output.tell()
        n = rdataset.to_wire(name, self.output, self.compress, self.origin,
                             **kw)
        after = self.output.tell()
        if after >= self.max_size:
            self._rollback(before)
            raise dns.exception.TooBig
        self.counts[section] += n

    def add_edns(self, edns, ednsflags, payload, options=None):
        """Add an EDNS OPT record to the message."""

        # make sure the EDNS version in ednsflags agrees with edns
        ednsflags &= long(0xFF00FFFF)
        ednsflags |= (edns << 16)
        self._set_section(ADDITIONAL)
        before = self.output.tell()
        self.output.write(struct.pack('!BHHIH', 0, dns.rdatatype.OPT, payload,
                                      ednsflags, 0))
        if options is not None:
            lstart = self.output.tell()
            for opt in options:
                stuff = struct.pack("!HH", opt.otype, 0)
                self.output.write(stuff)
                start = self.output.tell()
                opt.to_wire(self.output)
                end = self.output.tell()
                assert end - start < 65536
                self.output.seek(start - 2)
                stuff = struct.pack("!H", end - start)
                self.output.write(stuff)
                self.output.seek(0, 2)
            lend = self.output.tell()
            assert lend - lstart < 65536
            self.output.seek(lstart - 2)
            stuff = struct.pack("!H", lend - lstart)
            self.output.write(stuff)
            self.output.seek(0, 2)
        after = self.output.tell()
        if after >= self.max_size:
            self._rollback(before)
            raise dns.exception.TooBig
        self.counts[ADDITIONAL] += 1

    def add_tsig(self, keyname, secret, fudge, id, tsig_error, other_data,
                 request_mac, algorithm=dns.tsig.default_algorithm):
        """Add a TSIG signature to the message."""

        s = self.output.getvalue()
        (tsig_rdata, self.mac, ctx) = dns.tsig.sign(s,
                                                    keyname,
                                                    secret,
                                                    int(time.time()),
                                                    fudge,
                                                    id,
                                                    tsig_error,
                                                    other_data,
                                                    request_mac,
                                                    algorithm=algorithm)
        self._write_tsig(tsig_rdata, keyname)

    def add_multi_tsig(self, ctx, keyname, secret, fudge, id, tsig_error,
                       other_data, request_mac,
                       algorithm=dns.tsig.default_algorithm):
        """Add a TSIG signature to the message. Unlike add_tsig(), this can be
        used for a series of consecutive DNS envelopes, e.g. for a zone
        transfer over TCP [RFC2845, 4.4].

        For the first message in the sequence, give ctx=None. For each
        subsequent message, give the ctx that was returned from the
        add_multi_tsig() call for the previous message."""

        s = self.output.getvalue()
        (tsig_rdata, self.mac, ctx) = dns.tsig.sign(s,
                                                    keyname,
                                                    secret,
                                                    int(time.time()),
                                                    fudge,
                                                    id,
                                                    tsig_error,
                                                    other_data,
                                                    request_mac,
                                                    ctx=ctx,
                                                    first=ctx is None,
                                                    multi=True,
                                                    algorithm=algorithm)
        self._write_tsig(tsig_rdata, keyname)
        return ctx

    def _write_tsig(self, tsig_rdata, keyname):
        self._set_section(ADDITIONAL)
        before = self.output.tell()

        keyname.to_wire(self.output, self.compress, self.origin)
        self.output.write(struct.pack('!HHIH', dns.rdatatype.TSIG,
                                      dns.rdataclass.ANY, 0, 0))
        rdata_start = self.output.tell()
        self.output.write(tsig_rdata)

        after = self.output.tell()
        assert after - rdata_start < 65536
        if after >= self.max_size:
            self._rollback(before)
            raise dns.exception.TooBig

        self.output.seek(rdata_start - 2)
        self.output.write(struct.pack('!H', after - rdata_start))
        self.counts[ADDITIONAL] += 1
        self.output.seek(10)
        self.output.write(struct.pack('!H', self.counts[ADDITIONAL]))
        self.output.seek(0, 2)

    def write_header(self):
        """Write the DNS message header.

        Writing the DNS message header is done after all sections
        have been rendered, but before the optional TSIG signature
        is added.
        """

        self.output.seek(0)
        self.output.write(struct.pack('!HHHHHH', self.id, self.flags,
                                      self.counts[0], self.counts[1],
                                      self.counts[2], self.counts[3]))
        self.output.seek(0, 2)

    def get_wire(self):
        """Return the wire format message."""

        return self.output.getvalue()




############################################################
### File: request.py
############################################################
from __future__ import absolute_import

from .filepost import encode_multipart_formdata
from .packages.six.moves.urllib.parse import urlencode

__all__ = ["RequestMethods"]


class RequestMethods(object):
    """
    Convenience mixin for classes who implement a :meth:`urlopen` method, such
    as :class:`urllib3.HTTPConnectionPool` and
    :class:`urllib3.PoolManager`.

    Provides behavior for making common types of HTTP request methods and
    decides which type of request field encoding to use.

    Specifically,

    :meth:`.request_encode_url` is for sending requests whose fields are
    encoded in the URL (such as GET, HEAD, DELETE).

    :meth:`.request_encode_body` is for sending requests whose fields are
    encoded in the *body* of the request using multipart or www-form-urlencoded
    (such as for POST, PUT, PATCH).

    :meth:`.request` is for making any kind of request, it will look up the
    appropriate encoding format and use one of the above two methods to make
    the request.

    Initializer parameters:

    :param headers:
        Headers to include with all requests, unless other headers are given
        explicitly.
    """

    _encode_url_methods = {"DELETE", "GET", "HEAD", "OPTIONS"}

    def __init__(self, headers=None):
        self.headers = headers or {}

    def urlopen(
        self,
        method,
        url,
        body=None,
        headers=None,
        encode_multipart=True,
        multipart_boundary=None,
        **kw
    ):  # Abstract
        raise NotImplementedError(
            "Classes extending RequestMethods must implement "
            "their own ``urlopen`` method."
        )

    def request(self, method, url, fields=None, headers=None, **urlopen_kw):
        """
        Make a request using :meth:`urlopen` with the appropriate encoding of
        ``fields`` based on the ``method`` used.

        This is a convenience method that requires the least amount of manual
        effort. It can be used in most situations, while still having the
        option to drop down to more specific methods when necessary, such as
        :meth:`request_encode_url`, :meth:`request_encode_body`,
        or even the lowest level :meth:`urlopen`.
        """
        method = method.upper()

        urlopen_kw["request_url"] = url

        if method in self._encode_url_methods:
            return self.request_encode_url(
                method, url, fields=fields, headers=headers, **urlopen_kw
            )
        else:
            return self.request_encode_body(
                method, url, fields=fields, headers=headers, **urlopen_kw
            )

    def request_encode_url(self, method, url, fields=None, headers=None, **urlopen_kw):
        """
        Make a request using :meth:`urlopen` with the ``fields`` encoded in
        the url. This is useful for request methods like GET, HEAD, DELETE, etc.
        """
        if headers is None:
            headers = self.headers

        extra_kw = {"headers": headers}
        extra_kw.update(urlopen_kw)

        if fields:
            url += "?" + urlencode(fields)

        return self.urlopen(method, url, **extra_kw)

    def request_encode_body(
        self,
        method,
        url,
        fields=None,
        headers=None,
        encode_multipart=True,
        multipart_boundary=None,
        **urlopen_kw
    ):
        """
        Make a request using :meth:`urlopen` with the ``fields`` encoded in
        the body. This is useful for request methods like POST, PUT, PATCH, etc.

        When ``encode_multipart=True`` (default), then
        :func:`urllib3.encode_multipart_formdata` is used to encode
        the payload with the appropriate content type. Otherwise
        :func:`urllib.parse.urlencode` is used with the
        'application/x-www-form-urlencoded' content type.

        Multipart encoding must be used when posting files, and it's reasonably
        safe to use it in other times too. However, it may break request
        signing, such as with OAuth.

        Supports an optional ``fields`` parameter of key/value strings AND
        key/filetuple. A filetuple is a (filename, data, MIME type) tuple where
        the MIME type is optional. For example::

            fields = {
                'foo': 'bar',
                'fakefile': ('foofile.txt', 'contents of foofile'),
                'realfile': ('barfile.txt', open('realfile').read()),
                'typedfile': ('bazfile.bin', open('bazfile').read(),
                              'image/jpeg'),
                'nonamefile': 'contents of nonamefile field',
            }

        When uploading a file, providing a filename (the first parameter of the
        tuple) is optional but recommended to best mimic behavior of browsers.

        Note that if ``headers`` are supplied, the 'Content-Type' header will
        be overwritten because it depends on the dynamic random boundary string
        which is used to compose the body of the request. The random boundary
        string can be explicitly set with the ``multipart_boundary`` parameter.
        """
        if headers is None:
            headers = self.headers

        extra_kw = {"headers": {}}

        if fields:
            if "body" in urlopen_kw:
                raise TypeError(
                    "request got values for both 'fields' and 'body', can only specify one."
                )

            if encode_multipart:
                body, content_type = encode_multipart_formdata(
                    fields, boundary=multipart_boundary
                )
            else:
                body, content_type = (
                    urlencode(fields),
                    "application/x-www-form-urlencoded",
                )

            extra_kw["body"] = body
            extra_kw["headers"] = {"Content-Type": content_type}

        extra_kw["headers"].update(headers)
        extra_kw.update(urlopen_kw)

        return self.urlopen(method, url, **extra_kw)




############################################################
### File: resolver.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS stub resolver."""

import socket
import sys
import time
import random

try:
    import threading as _threading
except ImportError:
    import dummy_threading as _threading

import dns.exception
import dns.flags
import dns.ipv4
import dns.ipv6
import dns.message
import dns.name
import dns.query
import dns.rcode
import dns.rdataclass
import dns.rdatatype
import dns.reversename
import dns.tsig
from ._compat import xrange, string_types

if sys.platform == 'win32':
    try:
        import winreg as _winreg
    except ImportError:
        try:
            import _winreg  # pylint: disable=import-error
        except ImportError:
            # UWP
            _winreg = None

class NXDOMAIN(dns.exception.DNSException):
    """The DNS query name does not exist."""
    supp_kwargs = {'qnames', 'responses'}
    fmt = None  # we have our own __str__ implementation

    def _check_kwargs(self, qnames, responses=None):
        if not isinstance(qnames, (list, tuple, set)):
            raise AttributeError("qnames must be a list, tuple or set")
        if len(qnames) == 0:
            raise AttributeError("qnames must contain at least one element")
        if responses is None:
            responses = {}
        elif not isinstance(responses, dict):
            raise AttributeError("responses must be a dict(qname=response)")
        kwargs = dict(qnames=qnames, responses=responses)
        return kwargs

    def __str__(self):
        if 'qnames' not in self.kwargs:
            return super(NXDOMAIN, self).__str__()
        qnames = self.kwargs['qnames']
        if len(qnames) > 1:
            msg = 'None of DNS query names exist'
        else:
            msg = 'The DNS query name does not exist'
        qnames = ', '.join(map(str, qnames))
        return "{}: {}".format(msg, qnames)

    def canonical_name(self):
        if not 'qnames' in self.kwargs:
            raise TypeError("parametrized exception required")
        IN = dns.rdataclass.IN
        CNAME = dns.rdatatype.CNAME
        cname = None
        for qname in self.kwargs['qnames']:
            response = self.kwargs['responses'][qname]
            for answer in response.answer:
                if answer.rdtype != CNAME or answer.rdclass != IN:
                    continue
                cname = answer.items[0].target.to_text()
            if cname is not None:
                return dns.name.from_text(cname)
        return self.kwargs['qnames'][0]
    canonical_name = property(canonical_name, doc=(
        "Return the unresolved canonical name."))

    def __add__(self, e_nx):
        """Augment by results from another NXDOMAIN exception."""
        qnames0 = list(self.kwargs.get('qnames', []))
        responses0 = dict(self.kwargs.get('responses', {}))
        responses1 = e_nx.kwargs.get('responses', {})
        for qname1 in e_nx.kwargs.get('qnames', []):
            if qname1 not in qnames0:
                qnames0.append(qname1)
            if qname1 in responses1:
                responses0[qname1] = responses1[qname1]
        return NXDOMAIN(qnames=qnames0, responses=responses0)

    def qnames(self):
        """All of the names that were tried.

        Returns a list of ``dns.name.Name``.
        """
        return self.kwargs['qnames']

    def responses(self):
        """A map from queried names to their NXDOMAIN responses.

        Returns a dict mapping a ``dns.name.Name`` to a
        ``dns.message.Message``.
        """
        return self.kwargs['responses']

    def response(self, qname):
        """The response for query *qname*.

        Returns a ``dns.message.Message``.
        """
        return self.kwargs['responses'][qname]


class YXDOMAIN(dns.exception.DNSException):
    """The DNS query name is too long after DNAME substitution."""

# The definition of the Timeout exception has moved from here to the
# dns.exception module.  We keep dns.resolver.Timeout defined for
# backwards compatibility.

Timeout = dns.exception.Timeout


class NoAnswer(dns.exception.DNSException):
    """The DNS response does not contain an answer to the question."""
    fmt = 'The DNS response does not contain an answer ' + \
          'to the question: {query}'
    supp_kwargs = {'response'}

    def _fmt_kwargs(self, **kwargs):
        return super(NoAnswer, self)._fmt_kwargs(
            query=kwargs['response'].question)


class NoNameservers(dns.exception.DNSException):
    """All nameservers failed to answer the query.

    errors: list of servers and respective errors
    The type of errors is
    [(server IP address, any object convertible to string)].
    Non-empty errors list will add explanatory message ()
    """

    msg = "All nameservers failed to answer the query."
    fmt = "%s {query}: {errors}" % msg[:-1]
    supp_kwargs = {'request', 'errors'}

    def _fmt_kwargs(self, **kwargs):
        srv_msgs = []
        for err in kwargs['errors']:
            srv_msgs.append('Server {} {} port {} answered {}'.format(err[0],
                            'TCP' if err[1] else 'UDP', err[2], err[3]))
        return super(NoNameservers, self)._fmt_kwargs(
            query=kwargs['request'].question, errors='; '.join(srv_msgs))


class NotAbsolute(dns.exception.DNSException):
    """An absolute domain name is required but a relative name was provided."""


class NoRootSOA(dns.exception.DNSException):
    """There is no SOA RR at the DNS root name. This should never happen!"""


class NoMetaqueries(dns.exception.DNSException):
    """DNS metaqueries are not allowed."""


class Answer(object):
    """DNS stub resolver answer.

    Instances of this class bundle up the result of a successful DNS
    resolution.

    For convenience, the answer object implements much of the sequence
    protocol, forwarding to its ``rrset`` attribute.  E.g.
    ``for a in answer`` is equivalent to ``for a in answer.rrset``.
    ``answer[i]`` is equivalent to ``answer.rrset[i]``, and
    ``answer[i:j]`` is equivalent to ``answer.rrset[i:j]``.

    Note that CNAMEs or DNAMEs in the response may mean that answer
    RRset's name might not be the query name.
    """

    def __init__(self, qname, rdtype, rdclass, response,
                 raise_on_no_answer=True):
        self.qname = qname
        self.rdtype = rdtype
        self.rdclass = rdclass
        self.response = response
        min_ttl = -1
        rrset = None
        for count in xrange(0, 15):
            try:
                rrset = response.find_rrset(response.answer, qname,
                                            rdclass, rdtype)
                if min_ttl == -1 or rrset.ttl < min_ttl:
                    min_ttl = rrset.ttl
                break
            except KeyError:
                if rdtype != dns.rdatatype.CNAME:
                    try:
                        crrset = response.find_rrset(response.answer,
                                                     qname,
                                                     rdclass,
                                                     dns.rdatatype.CNAME)
                        if min_ttl == -1 or crrset.ttl < min_ttl:
                            min_ttl = crrset.ttl
                        for rd in crrset:
                            qname = rd.target
                            break
                        continue
                    except KeyError:
                        if raise_on_no_answer:
                            raise NoAnswer(response=response)
                if raise_on_no_answer:
                    raise NoAnswer(response=response)
        if rrset is None and raise_on_no_answer:
            raise NoAnswer(response=response)
        self.canonical_name = qname
        self.rrset = rrset
        if rrset is None:
            while 1:
                # Look for a SOA RR whose owner name is a superdomain
                # of qname.
                try:
                    srrset = response.find_rrset(response.authority, qname,
                                                 rdclass, dns.rdatatype.SOA)
                    if min_ttl == -1 or srrset.ttl < min_ttl:
                        min_ttl = srrset.ttl
                    if srrset[0].minimum < min_ttl:
                        min_ttl = srrset[0].minimum
                    break
                except KeyError:
                    try:
                        qname = qname.parent()
                    except dns.name.NoParent:
                        break
        self.expiration = time.time() + min_ttl

    def __getattr__(self, attr):
        if attr == 'name':
            return self.rrset.name
        elif attr == 'ttl':
            return self.rrset.ttl
        elif attr == 'covers':
            return self.rrset.covers
        elif attr == 'rdclass':
            return self.rrset.rdclass
        elif attr == 'rdtype':
            return self.rrset.rdtype
        else:
            raise AttributeError(attr)

    def __len__(self):
        return self.rrset and len(self.rrset) or 0

    def __iter__(self):
        return self.rrset and iter(self.rrset) or iter(tuple())

    def __getitem__(self, i):
        if self.rrset is None:
            raise IndexError
        return self.rrset[i]

    def __delitem__(self, i):
        if self.rrset is None:
            raise IndexError
        del self.rrset[i]


class Cache(object):
    """Simple thread-safe DNS answer cache."""

    def __init__(self, cleaning_interval=300.0):
        """*cleaning_interval*, a ``float`` is the number of seconds between
        periodic cleanings.
        """

        self.data = {}
        self.cleaning_interval = cleaning_interval
        self.next_cleaning = time.time() + self.cleaning_interval
        self.lock = _threading.Lock()

    def _maybe_clean(self):
        """Clean the cache if it's time to do so."""

        now = time.time()
        if self.next_cleaning <= now:
            keys_to_delete = []
            for (k, v) in self.data.items():
                if v.expiration <= now:
                    keys_to_delete.append(k)
            for k in keys_to_delete:
                del self.data[k]
            now = time.time()
            self.next_cleaning = now + self.cleaning_interval

    def get(self, key):
        """Get the answer associated with *key*.

        Returns None if no answer is cached for the key.

        *key*, a ``(dns.name.Name, int, int)`` tuple whose values are the
        query name, rdtype, and rdclass respectively.

        Returns a ``dns.resolver.Answer`` or ``None``.
        """

        try:
            self.lock.acquire()
            self._maybe_clean()
            v = self.data.get(key)
            if v is None or v.expiration <= time.time():
                return None
            return v
        finally:
            self.lock.release()

    def put(self, key, value):
        """Associate key and value in the cache.

        *key*, a ``(dns.name.Name, int, int)`` tuple whose values are the
        query name, rdtype, and rdclass respectively.

        *value*, a ``dns.resolver.Answer``, the answer.
        """

        try:
            self.lock.acquire()
            self._maybe_clean()
            self.data[key] = value
        finally:
            self.lock.release()

    def flush(self, key=None):
        """Flush the cache.

        If *key* is not ``None``, only that item is flushed.  Otherwise
        the entire cache is flushed.

        *key*, a ``(dns.name.Name, int, int)`` tuple whose values are the
        query name, rdtype, and rdclass respectively.
        """

        try:
            self.lock.acquire()
            if key is not None:
                if key in self.data:
                    del self.data[key]
            else:
                self.data = {}
                self.next_cleaning = time.time() + self.cleaning_interval
        finally:
            self.lock.release()


class LRUCacheNode(object):
    """LRUCache node."""

    def __init__(self, key, value):
        self.key = key
        self.value = value
        self.prev = self
        self.next = self

    def link_before(self, node):
        self.prev = node.prev
        self.next = node
        node.prev.next = self
        node.prev = self

    def link_after(self, node):
        self.prev = node
        self.next = node.next
        node.next.prev = self
        node.next = self

    def unlink(self):
        self.next.prev = self.prev
        self.prev.next = self.next


class LRUCache(object):
    """Thread-safe, bounded, least-recently-used DNS answer cache.

    This cache is better than the simple cache (above) if you're
    running a web crawler or other process that does a lot of
    resolutions.  The LRUCache has a maximum number of nodes, and when
    it is full, the least-recently used node is removed to make space
    for a new one.
    """

    def __init__(self, max_size=100000):
        """*max_size*, an ``int``, is the maximum number of nodes to cache;
        it must be greater than 0.
        """

        self.data = {}
        self.set_max_size(max_size)
        self.sentinel = LRUCacheNode(None, None)
        self.lock = _threading.Lock()

    def set_max_size(self, max_size):
        if max_size < 1:
            max_size = 1
        self.max_size = max_size

    def get(self, key):
        """Get the answer associated with *key*.

        Returns None if no answer is cached for the key.

        *key*, a ``(dns.name.Name, int, int)`` tuple whose values are the
        query name, rdtype, and rdclass respectively.

        Returns a ``dns.resolver.Answer`` or ``None``.
        """

        try:
            self.lock.acquire()
            node = self.data.get(key)
            if node is None:
                return None
            # Unlink because we're either going to move the node to the front
            # of the LRU list or we're going to free it.
            node.unlink()
            if node.value.expiration <= time.time():
                del self.data[node.key]
                return None
            node.link_after(self.sentinel)
            return node.value
        finally:
            self.lock.release()

    def put(self, key, value):
        """Associate key and value in the cache.

        *key*, a ``(dns.name.Name, int, int)`` tuple whose values are the
        query name, rdtype, and rdclass respectively.

        *value*, a ``dns.resolver.Answer``, the answer.
        """

        try:
            self.lock.acquire()
            node = self.data.get(key)
            if node is not None:
                node.unlink()
                del self.data[node.key]
            while len(self.data) >= self.max_size:
                node = self.sentinel.prev
                node.unlink()
                del self.data[node.key]
            node = LRUCacheNode(key, value)
            node.link_after(self.sentinel)
            self.data[key] = node
        finally:
            self.lock.release()

    def flush(self, key=None):
        """Flush the cache.

        If *key* is not ``None``, only that item is flushed.  Otherwise
        the entire cache is flushed.

        *key*, a ``(dns.name.Name, int, int)`` tuple whose values are the
        query name, rdtype, and rdclass respectively.
        """

        try:
            self.lock.acquire()
            if key is not None:
                node = self.data.get(key)
                if node is not None:
                    node.unlink()
                    del self.data[node.key]
            else:
                node = self.sentinel.next
                while node != self.sentinel:
                    next = node.next
                    node.prev = None
                    node.next = None
                    node = next
                self.data = {}
        finally:
            self.lock.release()


class Resolver(object):
    """DNS stub resolver."""

    def __init__(self, filename='/etc/resolv.conf', configure=True):
        """*filename*, a ``text`` or file object, specifying a file
        in standard /etc/resolv.conf format.  This parameter is meaningful
        only when *configure* is true and the platform is POSIX.

        *configure*, a ``bool``.  If True (the default), the resolver
        instance is configured in the normal fashion for the operating
        system the resolver is running on.  (I.e. by reading a
        /etc/resolv.conf file on POSIX systems and from the registry
        on Windows systems.)
        """

        self.domain = None
        self.nameservers = None
        self.nameserver_ports = None
        self.port = None
        self.search = None
        self.timeout = None
        self.lifetime = None
        self.keyring = None
        self.keyname = None
        self.keyalgorithm = None
        self.edns = None
        self.ednsflags = None
        self.payload = None
        self.cache = None
        self.flags = None
        self.retry_servfail = False
        self.rotate = False

        self.reset()
        if configure:
            if sys.platform == 'win32':
                if _winreg:
                    self.read_registry()
            elif filename:
                self.read_resolv_conf(filename)

    def reset(self):
        """Reset all resolver configuration to the defaults."""

        self.domain = \
            dns.name.Name(dns.name.from_text(socket.gethostname())[1:])
        if len(self.domain) == 0:
            self.domain = dns.name.root
        self.nameservers = []
        self.nameserver_ports = {}
        self.port = 53
        self.search = []
        self.timeout = 2.0
        self.lifetime = 30.0
        self.keyring = None
        self.keyname = None
        self.keyalgorithm = dns.tsig.default_algorithm
        self.edns = -1
        self.ednsflags = 0
        self.payload = 0
        self.cache = None
        self.flags = None
        self.retry_servfail = False
        self.rotate = False

    def read_resolv_conf(self, f):
        """Process *f* as a file in the /etc/resolv.conf format.  If f is
        a ``text``, it is used as the name of the file to open; otherwise it
        is treated as the file itself."""

        if isinstance(f, string_types):
            try:
                f = open(f, 'r')
            except IOError:
                # /etc/resolv.conf doesn't exist, can't be read, etc.
                # We'll just use the default resolver configuration.
                self.nameservers = ['127.0.0.1']
                return
            want_close = True
        else:
            want_close = False
        try:
            for l in f:
                if len(l) == 0 or l[0] == '#' or l[0] == ';':
                    continue
                tokens = l.split()

                # Any line containing less than 2 tokens is malformed
                if len(tokens) < 2:
                    continue

                if tokens[0] == 'nameserver':
                    self.nameservers.append(tokens[1])
                elif tokens[0] == 'domain':
                    self.domain = dns.name.from_text(tokens[1])
                elif tokens[0] == 'search':
                    for suffix in tokens[1:]:
                        self.search.append(dns.name.from_text(suffix))
                elif tokens[0] == 'options':
                    if 'rotate' in tokens[1:]:
                        self.rotate = True
        finally:
            if want_close:
                f.close()
        if len(self.nameservers) == 0:
            self.nameservers.append('127.0.0.1')

    def _determine_split_char(self, entry):
        #
        # The windows registry irritatingly changes the list element
        # delimiter in between ' ' and ',' (and vice-versa) in various
        # versions of windows.
        #
        if entry.find(' ') >= 0:
            split_char = ' '
        elif entry.find(',') >= 0:
            split_char = ','
        else:
            # probably a singleton; treat as a space-separated list.
            split_char = ' '
        return split_char

    def _config_win32_nameservers(self, nameservers):
        # we call str() on nameservers to convert it from unicode to ascii
        nameservers = str(nameservers)
        split_char = self._determine_split_char(nameservers)
        ns_list = nameservers.split(split_char)
        for ns in ns_list:
            if ns not in self.nameservers:
                self.nameservers.append(ns)

    def _config_win32_domain(self, domain):
        # we call str() on domain to convert it from unicode to ascii
        self.domain = dns.name.from_text(str(domain))

    def _config_win32_search(self, search):
        # we call str() on search to convert it from unicode to ascii
        search = str(search)
        split_char = self._determine_split_char(search)
        search_list = search.split(split_char)
        for s in search_list:
            if s not in self.search:
                self.search.append(dns.name.from_text(s))

    def _config_win32_fromkey(self, key, always_try_domain):
        try:
            servers, rtype = _winreg.QueryValueEx(key, 'NameServer')
        except WindowsError:  # pylint: disable=undefined-variable
            servers = None
        if servers:
            self._config_win32_nameservers(servers)
        if servers or always_try_domain:
            try:
                dom, rtype = _winreg.QueryValueEx(key, 'Domain')
                if dom:
                    self._config_win32_domain(dom)
            except WindowsError:  # pylint: disable=undefined-variable
                pass
        else:
            try:
                servers, rtype = _winreg.QueryValueEx(key, 'DhcpNameServer')
            except WindowsError:  # pylint: disable=undefined-variable
                servers = None
            if servers:
                self._config_win32_nameservers(servers)
                try:
                    dom, rtype = _winreg.QueryValueEx(key, 'DhcpDomain')
                    if dom:
                        self._config_win32_domain(dom)
                except WindowsError:  # pylint: disable=undefined-variable
                    pass
        try:
            search, rtype = _winreg.QueryValueEx(key, 'SearchList')
        except WindowsError:  # pylint: disable=undefined-variable
            search = None
        if search:
            self._config_win32_search(search)

    def read_registry(self):
        """Extract resolver configuration from the Windows registry."""

        lm = _winreg.ConnectRegistry(None, _winreg.HKEY_LOCAL_MACHINE)
        want_scan = False
        try:
            try:
                # XP, 2000
                tcp_params = _winreg.OpenKey(lm,
                                             r'SYSTEM\CurrentControlSet'
                                             r'\Services\Tcpip\Parameters')
                want_scan = True
            except EnvironmentError:
                # ME
                tcp_params = _winreg.OpenKey(lm,
                                             r'SYSTEM\CurrentControlSet'
                                             r'\Services\VxD\MSTCP')
            try:
                self._config_win32_fromkey(tcp_params, True)
            finally:
                tcp_params.Close()
            if want_scan:
                interfaces = _winreg.OpenKey(lm,
                                             r'SYSTEM\CurrentControlSet'
                                             r'\Services\Tcpip\Parameters'
                                             r'\Interfaces')
                try:
                    i = 0
                    while True:
                        try:
                            guid = _winreg.EnumKey(interfaces, i)
                            i += 1
                            key = _winreg.OpenKey(interfaces, guid)
                            if not self._win32_is_nic_enabled(lm, guid, key):
                                continue
                            try:
                                self._config_win32_fromkey(key, False)
                            finally:
                                key.Close()
                        except EnvironmentError:
                            break
                finally:
                    interfaces.Close()
        finally:
            lm.Close()

    def _win32_is_nic_enabled(self, lm, guid, interface_key):
        # Look in the Windows Registry to determine whether the network
        # interface corresponding to the given guid is enabled.
        #
        # (Code contributed by Paul Marks, thanks!)
        #
        try:
            # This hard-coded location seems to be consistent, at least
            # from Windows 2000 through Vista.
            connection_key = _winreg.OpenKey(
                lm,
                r'SYSTEM\CurrentControlSet\Control\Network'
                r'\{4D36E972-E325-11CE-BFC1-08002BE10318}'
                r'\%s\Connection' % guid)

            try:
                # The PnpInstanceID points to a key inside Enum
                (pnp_id, ttype) = _winreg.QueryValueEx(
                    connection_key, 'PnpInstanceID')

                if ttype != _winreg.REG_SZ:
                    raise ValueError

                device_key = _winreg.OpenKey(
                    lm, r'SYSTEM\CurrentControlSet\Enum\%s' % pnp_id)

                try:
                    # Get ConfigFlags for this device
                    (flags, ttype) = _winreg.QueryValueEx(
                        device_key, 'ConfigFlags')

                    if ttype != _winreg.REG_DWORD:
                        raise ValueError

                    # Based on experimentation, bit 0x1 indicates that the
                    # device is disabled.
                    return not flags & 0x1

                finally:
                    device_key.Close()
            finally:
                connection_key.Close()
        except (EnvironmentError, ValueError):
            # Pre-vista, enabled interfaces seem to have a non-empty
            # NTEContextList; this was how dnspython detected enabled
            # nics before the code above was contributed.  We've retained
            # the old method since we don't know if the code above works
            # on Windows 95/98/ME.
            try:
                (nte, ttype) = _winreg.QueryValueEx(interface_key,
                                                    'NTEContextList')
                return nte is not None
            except WindowsError:  # pylint: disable=undefined-variable
                return False

    def _compute_timeout(self, start, lifetime=None):
        lifetime = self.lifetime if lifetime is None else lifetime
        now = time.time()
        duration = now - start
        if duration < 0:
            if duration < -1:
                # Time going backwards is bad.  Just give up.
                raise Timeout(timeout=duration)
            else:
                # Time went backwards, but only a little.  This can
                # happen, e.g. under vmware with older linux kernels.
                # Pretend it didn't happen.
                now = start
        if duration >= lifetime:
            raise Timeout(timeout=duration)
        return min(lifetime - duration, self.timeout)

    def query(self, qname, rdtype=dns.rdatatype.A, rdclass=dns.rdataclass.IN,
              tcp=False, source=None, raise_on_no_answer=True, source_port=0,
              lifetime=None):
        """Query nameservers to find the answer to the question.

        The *qname*, *rdtype*, and *rdclass* parameters may be objects
        of the appropriate type, or strings that can be converted into objects
        of the appropriate type.

        *qname*, a ``dns.name.Name`` or ``text``, the query name.

        *rdtype*, an ``int`` or ``text``,  the query type.

        *rdclass*, an ``int`` or ``text``,  the query class.

        *tcp*, a ``bool``.  If ``True``, use TCP to make the query.

        *source*, a ``text`` or ``None``.  If not ``None``, bind to this IP
        address when making queries.

        *raise_on_no_answer*, a ``bool``.  If ``True``, raise
        ``dns.resolver.NoAnswer`` if there's no answer to the question.

        *source_port*, an ``int``, the port from which to send the message.

        *lifetime*, a ``float``, how long query should run before timing out.

        Raises ``dns.exception.Timeout`` if no answers could be found
        in the specified lifetime.

        Raises ``dns.resolver.NXDOMAIN`` if the query name does not exist.

        Raises ``dns.resolver.YXDOMAIN`` if the query name is too long after
        DNAME substitution.

        Raises ``dns.resolver.NoAnswer`` if *raise_on_no_answer* is
        ``True`` and the query name exists but has no RRset of the
        desired type and class.

        Raises ``dns.resolver.NoNameservers`` if no non-broken
        nameservers are available to answer the question.

        Returns a ``dns.resolver.Answer`` instance.
        """

        if isinstance(qname, string_types):
            qname = dns.name.from_text(qname, None)
        if isinstance(rdtype, string_types):
            rdtype = dns.rdatatype.from_text(rdtype)
        if dns.rdatatype.is_metatype(rdtype):
            raise NoMetaqueries
        if isinstance(rdclass, string_types):
            rdclass = dns.rdataclass.from_text(rdclass)
        if dns.rdataclass.is_metaclass(rdclass):
            raise NoMetaqueries
        qnames_to_try = []
        if qname.is_absolute():
            qnames_to_try.append(qname)
        else:
            if len(qname) > 1:
                qnames_to_try.append(qname.concatenate(dns.name.root))
            if self.search:
                for suffix in self.search:
                    qnames_to_try.append(qname.concatenate(suffix))
            else:
                qnames_to_try.append(qname.concatenate(self.domain))
        all_nxdomain = True
        nxdomain_responses = {}
        start = time.time()
        _qname = None # make pylint happy
        for _qname in qnames_to_try:
            if self.cache:
                answer = self.cache.get((_qname, rdtype, rdclass))
                if answer is not None:
                    if answer.rrset is None and raise_on_no_answer:
                        raise NoAnswer(response=answer.response)
                    else:
                        return answer
            request = dns.message.make_query(_qname, rdtype, rdclass)
            if self.keyname is not None:
                request.use_tsig(self.keyring, self.keyname,
                                 algorithm=self.keyalgorithm)
            request.use_edns(self.edns, self.ednsflags, self.payload)
            if self.flags is not None:
                request.flags = self.flags
            response = None
            #
            # make a copy of the servers list so we can alter it later.
            #
            nameservers = self.nameservers[:]
            errors = []
            if self.rotate:
                random.shuffle(nameservers)
            backoff = 0.10
            while response is None:
                if len(nameservers) == 0:
                    raise NoNameservers(request=request, errors=errors)
                for nameserver in nameservers[:]:
                    timeout = self._compute_timeout(start, lifetime)
                    port = self.nameserver_ports.get(nameserver, self.port)
                    try:
                        tcp_attempt = tcp
                        if tcp:
                            response = dns.query.tcp(request, nameserver,
                                                     timeout, port,
                                                     source=source,
                                                     source_port=source_port)
                        else:
                            response = dns.query.udp(request, nameserver,
                                                     timeout, port,
                                                     source=source,
                                                     source_port=source_port)
                            if response.flags & dns.flags.TC:
                                # Response truncated; retry with TCP.
                                tcp_attempt = True
                                timeout = self._compute_timeout(start, lifetime)
                                response = \
                                    dns.query.tcp(request, nameserver,
                                                  timeout, port,
                                                  source=source,
                                                  source_port=source_port)
                    except (socket.error, dns.exception.Timeout) as ex:
                        #
                        # Communication failure or timeout.  Go to the
                        # next server
                        #
                        errors.append((nameserver, tcp_attempt, port, ex,
                                       response))
                        response = None
                        continue
                    except dns.query.UnexpectedSource as ex:
                        #
                        # Who knows?  Keep going.
                        #
                        errors.append((nameserver, tcp_attempt, port, ex,
                                       response))
                        response = None
                        continue
                    except dns.exception.FormError as ex:
                        #
                        # We don't understand what this server is
                        # saying.  Take it out of the mix and
                        # continue.
                        #
                        nameservers.remove(nameserver)
                        errors.append((nameserver, tcp_attempt, port, ex,
                                       response))
                        response = None
                        continue
                    except EOFError as ex:
                        #
                        # We're using TCP and they hung up on us.
                        # Probably they don't support TCP (though
                        # they're supposed to!).  Take it out of the
                        # mix and continue.
                        #
                        nameservers.remove(nameserver)
                        errors.append((nameserver, tcp_attempt, port, ex,
                                       response))
                        response = None
                        continue
                    rcode = response.rcode()
                    if rcode == dns.rcode.YXDOMAIN:
                        ex = YXDOMAIN()
                        errors.append((nameserver, tcp_attempt, port, ex,
                                       response))
                        raise ex
                    if rcode == dns.rcode.NOERROR or \
                            rcode == dns.rcode.NXDOMAIN:
                        break
                    #
                    # We got a response, but we're not happy with the
                    # rcode in it.  Remove the server from the mix if
                    # the rcode isn't SERVFAIL.
                    #
                    if rcode != dns.rcode.SERVFAIL or not self.retry_servfail:
                        nameservers.remove(nameserver)
                    errors.append((nameserver, tcp_attempt, port,
                                   dns.rcode.to_text(rcode), response))
                    response = None
                if response is not None:
                    break
                #
                # All nameservers failed!
                #
                if len(nameservers) > 0:
                    #
                    # But we still have servers to try.  Sleep a bit
                    # so we don't pound them!
                    #
                    timeout = self._compute_timeout(start, lifetime)
                    sleep_time = min(timeout, backoff)
                    backoff *= 2
                    time.sleep(sleep_time)
            if response.rcode() == dns.rcode.NXDOMAIN:
                nxdomain_responses[_qname] = response
                continue
            all_nxdomain = False
            break
        if all_nxdomain:
            raise NXDOMAIN(qnames=qnames_to_try, responses=nxdomain_responses)
        answer = Answer(_qname, rdtype, rdclass, response,
                        raise_on_no_answer)
        if self.cache:
            self.cache.put((_qname, rdtype, rdclass), answer)
        return answer

    def use_tsig(self, keyring, keyname=None,
                 algorithm=dns.tsig.default_algorithm):
        """Add a TSIG signature to the query.

        See the documentation of the Message class for a complete
        description of the keyring dictionary.

        *keyring*, a ``dict``, the TSIG keyring to use.  If a
        *keyring* is specified but a *keyname* is not, then the key
        used will be the first key in the *keyring*.  Note that the
        order of keys in a dictionary is not defined, so applications
        should supply a keyname when a keyring is used, unless they
        know the keyring contains only one key.

        *keyname*, a ``dns.name.Name`` or ``None``, the name of the TSIG key
        to use; defaults to ``None``. The key must be defined in the keyring.

        *algorithm*, a ``dns.name.Name``, the TSIG algorithm to use.
        """

        self.keyring = keyring
        if keyname is None:
            self.keyname = list(self.keyring.keys())[0]
        else:
            self.keyname = keyname
        self.keyalgorithm = algorithm

    def use_edns(self, edns, ednsflags, payload):
        """Configure EDNS behavior.

        *edns*, an ``int``, is the EDNS level to use.  Specifying
        ``None``, ``False``, or ``-1`` means "do not use EDNS", and in this case
        the other parameters are ignored.  Specifying ``True`` is
        equivalent to specifying 0, i.e. "use EDNS0".

        *ednsflags*, an ``int``, the EDNS flag values.

        *payload*, an ``int``, is the EDNS sender's payload field, which is the
        maximum size of UDP datagram the sender can handle.  I.e. how big
        a response to this message can be.
        """

        if edns is None:
            edns = -1
        self.edns = edns
        self.ednsflags = ednsflags
        self.payload = payload

    def set_flags(self, flags):
        """Overrides the default flags with your own.

        *flags*, an ``int``, the message flags to use.
        """

        self.flags = flags


#: The default resolver.
default_resolver = None


def get_default_resolver():
    """Get the default resolver, initializing it if necessary."""
    if default_resolver is None:
        reset_default_resolver()
    return default_resolver


def reset_default_resolver():
    """Re-initialize default resolver.

    Note that the resolver configuration (i.e. /etc/resolv.conf on UNIX
    systems) will be re-read immediately.
    """

    global default_resolver
    default_resolver = Resolver()


def query(qname, rdtype=dns.rdatatype.A, rdclass=dns.rdataclass.IN,
          tcp=False, source=None, raise_on_no_answer=True,
          source_port=0, lifetime=None):
    """Query nameservers to find the answer to the question.

    This is a convenience function that uses the default resolver
    object to make the query.

    See ``dns.resolver.Resolver.query`` for more information on the
    parameters.
    """

    return get_default_resolver().query(qname, rdtype, rdclass, tcp, source,
                                        raise_on_no_answer, source_port,
                                        lifetime)


def zone_for_name(name, rdclass=dns.rdataclass.IN, tcp=False, resolver=None):
    """Find the name of the zone which contains the specified name.

    *name*, an absolute ``dns.name.Name`` or ``text``, the query name.

    *rdclass*, an ``int``, the query class.

    *tcp*, a ``bool``.  If ``True``, use TCP to make the query.

    *resolver*, a ``dns.resolver.Resolver`` or ``None``, the resolver to use.
    If ``None``, the default resolver is used.

    Raises ``dns.resolver.NoRootSOA`` if there is no SOA RR at the DNS
    root.  (This is only likely to happen if you're using non-default
    root servers in your network and they are misconfigured.)

    Returns a ``dns.name.Name``.
    """

    if isinstance(name, string_types):
        name = dns.name.from_text(name, dns.name.root)
    if resolver is None:
        resolver = get_default_resolver()
    if not name.is_absolute():
        raise NotAbsolute(name)
    while 1:
        try:
            answer = resolver.query(name, dns.rdatatype.SOA, rdclass, tcp)
            if answer.rrset.name == name:
                return name
            # otherwise we were CNAMEd or DNAMEd and need to look higher
        except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer):
            pass
        try:
            name = name.parent()
        except dns.name.NoParent:
            raise NoRootSOA

#
# Support for overriding the system resolver for all python code in the
# running process.
#

_protocols_for_socktype = {
    socket.SOCK_DGRAM: [socket.SOL_UDP],
    socket.SOCK_STREAM: [socket.SOL_TCP],
}

_resolver = None
_original_getaddrinfo = socket.getaddrinfo
_original_getnameinfo = socket.getnameinfo
_original_getfqdn = socket.getfqdn
_original_gethostbyname = socket.gethostbyname
_original_gethostbyname_ex = socket.gethostbyname_ex
_original_gethostbyaddr = socket.gethostbyaddr


def _getaddrinfo(host=None, service=None, family=socket.AF_UNSPEC, socktype=0,
                 proto=0, flags=0):
    if flags & (socket.AI_ADDRCONFIG | socket.AI_V4MAPPED) != 0:
        raise NotImplementedError
    if host is None and service is None:
        raise socket.gaierror(socket.EAI_NONAME)
    v6addrs = []
    v4addrs = []
    canonical_name = None
    try:
        # Is host None or a V6 address literal?
        if host is None:
            canonical_name = 'localhost'
            if flags & socket.AI_PASSIVE != 0:
                v6addrs.append('::')
                v4addrs.append('0.0.0.0')
            else:
                v6addrs.append('::1')
                v4addrs.append('127.0.0.1')
        else:
            parts = host.split('%')
            if len(parts) == 2:
                ahost = parts[0]
            else:
                ahost = host
            addr = dns.ipv6.inet_aton(ahost)
            v6addrs.append(host)
            canonical_name = host
    except Exception:
        try:
            # Is it a V4 address literal?
            addr = dns.ipv4.inet_aton(host)
            v4addrs.append(host)
            canonical_name = host
        except Exception:
            if flags & socket.AI_NUMERICHOST == 0:
                try:
                    if family == socket.AF_INET6 or family == socket.AF_UNSPEC:
                        v6 = _resolver.query(host, dns.rdatatype.AAAA,
                                             raise_on_no_answer=False)
                        # Note that setting host ensures we query the same name
                        # for A as we did for AAAA.
                        host = v6.qname
                        canonical_name = v6.canonical_name.to_text(True)
                        if v6.rrset is not None:
                            for rdata in v6.rrset:
                                v6addrs.append(rdata.address)
                    if family == socket.AF_INET or family == socket.AF_UNSPEC:
                        v4 = _resolver.query(host, dns.rdatatype.A,
                                             raise_on_no_answer=False)
                        host = v4.qname
                        canonical_name = v4.canonical_name.to_text(True)
                        if v4.rrset is not None:
                            for rdata in v4.rrset:
                                v4addrs.append(rdata.address)
                except dns.resolver.NXDOMAIN:
                    raise socket.gaierror(socket.EAI_NONAME)
                except Exception:
                    raise socket.gaierror(socket.EAI_SYSTEM)
    port = None
    try:
        # Is it a port literal?
        if service is None:
            port = 0
        else:
            port = int(service)
    except Exception:
        if flags & socket.AI_NUMERICSERV == 0:
            try:
                port = socket.getservbyname(service)
            except Exception:
                pass
    if port is None:
        raise socket.gaierror(socket.EAI_NONAME)
    tuples = []
    if socktype == 0:
        socktypes = [socket.SOCK_DGRAM, socket.SOCK_STREAM]
    else:
        socktypes = [socktype]
    if flags & socket.AI_CANONNAME != 0:
        cname = canonical_name
    else:
        cname = ''
    if family == socket.AF_INET6 or family == socket.AF_UNSPEC:
        for addr in v6addrs:
            for socktype in socktypes:
                for proto in _protocols_for_socktype[socktype]:
                    tuples.append((socket.AF_INET6, socktype, proto,
                                   cname, (addr, port, 0, 0)))
    if family == socket.AF_INET or family == socket.AF_UNSPEC:
        for addr in v4addrs:
            for socktype in socktypes:
                for proto in _protocols_for_socktype[socktype]:
                    tuples.append((socket.AF_INET, socktype, proto,
                                   cname, (addr, port)))
    if len(tuples) == 0:
        raise socket.gaierror(socket.EAI_NONAME)
    return tuples


def _getnameinfo(sockaddr, flags=0):
    host = sockaddr[0]
    port = sockaddr[1]
    if len(sockaddr) == 4:
        scope = sockaddr[3]
        family = socket.AF_INET6
    else:
        scope = None
        family = socket.AF_INET
    tuples = _getaddrinfo(host, port, family, socket.SOCK_STREAM,
                          socket.SOL_TCP, 0)
    if len(tuples) > 1:
        raise socket.error('sockaddr resolved to multiple addresses')
    addr = tuples[0][4][0]
    if flags & socket.NI_DGRAM:
        pname = 'udp'
    else:
        pname = 'tcp'
    qname = dns.reversename.from_address(addr)
    if flags & socket.NI_NUMERICHOST == 0:
        try:
            answer = _resolver.query(qname, 'PTR')
            hostname = answer.rrset[0].target.to_text(True)
        except (dns.resolver.NXDOMAIN, dns.resolver.NoAnswer):
            if flags & socket.NI_NAMEREQD:
                raise socket.gaierror(socket.EAI_NONAME)
            hostname = addr
            if scope is not None:
                hostname += '%' + str(scope)
    else:
        hostname = addr
        if scope is not None:
            hostname += '%' + str(scope)
    if flags & socket.NI_NUMERICSERV:
        service = str(port)
    else:
        service = socket.getservbyport(port, pname)
    return (hostname, service)


def _getfqdn(name=None):
    if name is None:
        name = socket.gethostname()
    try:
        return _getnameinfo(_getaddrinfo(name, 80)[0][4])[0]
    except Exception:
        return name


def _gethostbyname(name):
    return _gethostbyname_ex(name)[2][0]


def _gethostbyname_ex(name):
    aliases = []
    addresses = []
    tuples = _getaddrinfo(name, 0, socket.AF_INET, socket.SOCK_STREAM,
                          socket.SOL_TCP, socket.AI_CANONNAME)
    canonical = tuples[0][3]
    for item in tuples:
        addresses.append(item[4][0])
    # XXX we just ignore aliases
    return (canonical, aliases, addresses)


def _gethostbyaddr(ip):
    try:
        dns.ipv6.inet_aton(ip)
        sockaddr = (ip, 80, 0, 0)
        family = socket.AF_INET6
    except Exception:
        sockaddr = (ip, 80)
        family = socket.AF_INET
    (name, port) = _getnameinfo(sockaddr, socket.NI_NAMEREQD)
    aliases = []
    addresses = []
    tuples = _getaddrinfo(name, 0, family, socket.SOCK_STREAM, socket.SOL_TCP,
                          socket.AI_CANONNAME)
    canonical = tuples[0][3]
    for item in tuples:
        addresses.append(item[4][0])
    # XXX we just ignore aliases
    return (canonical, aliases, addresses)


def override_system_resolver(resolver=None):
    """Override the system resolver routines in the socket module with
    versions which use dnspython's resolver.

    This can be useful in testing situations where you want to control
    the resolution behavior of python code without having to change
    the system's resolver settings (e.g. /etc/resolv.conf).

    The resolver to use may be specified; if it's not, the default
    resolver will be used.

    resolver, a ``dns.resolver.Resolver`` or ``None``, the resolver to use.
    """

    if resolver is None:
        resolver = get_default_resolver()
    global _resolver
    _resolver = resolver
    socket.getaddrinfo = _getaddrinfo
    socket.getnameinfo = _getnameinfo
    socket.getfqdn = _getfqdn
    socket.gethostbyname = _gethostbyname
    socket.gethostbyname_ex = _gethostbyname_ex
    socket.gethostbyaddr = _gethostbyaddr


def restore_system_resolver():
    """Undo the effects of prior override_system_resolver()."""

    global _resolver
    _resolver = None
    socket.getaddrinfo = _original_getaddrinfo
    socket.getnameinfo = _original_getnameinfo
    socket.getfqdn = _original_getfqdn
    socket.gethostbyname = _original_gethostbyname
    socket.gethostbyname_ex = _original_gethostbyname_ex
    socket.gethostbyaddr = _original_gethostbyaddr




############################################################
### File: response.py
############################################################
from __future__ import absolute_import

import io
import logging
import zlib
from contextlib import contextmanager
from socket import error as SocketError
from socket import timeout as SocketTimeout

try:
    try:
        import brotlicffi as brotli
    except ImportError:
        import brotli
except ImportError:
    brotli = None

from ._collections import HTTPHeaderDict
from .connection import BaseSSLError, HTTPException
from .exceptions import (
    BodyNotHttplibCompatible,
    DecodeError,
    HTTPError,
    IncompleteRead,
    InvalidChunkLength,
    InvalidHeader,
    ProtocolError,
    ReadTimeoutError,
    ResponseNotChunked,
    SSLError,
)
from .packages import six
from .util.response import is_fp_closed, is_response_to_head

log = logging.getLogger(__name__)


class DeflateDecoder(object):
    def __init__(self):
        self._first_try = True
        self._data = b""
        self._obj = zlib.decompressobj()

    def __getattr__(self, name):
        return getattr(self._obj, name)

    def decompress(self, data):
        if not data:
            return data

        if not self._first_try:
            return self._obj.decompress(data)

        self._data += data
        try:
            decompressed = self._obj.decompress(data)
            if decompressed:
                self._first_try = False
                self._data = None
            return decompressed
        except zlib.error:
            self._first_try = False
            self._obj = zlib.decompressobj(-zlib.MAX_WBITS)
            try:
                return self.decompress(self._data)
            finally:
                self._data = None


class GzipDecoderState(object):

    FIRST_MEMBER = 0
    OTHER_MEMBERS = 1
    SWALLOW_DATA = 2


class GzipDecoder(object):
    def __init__(self):
        self._obj = zlib.decompressobj(16 + zlib.MAX_WBITS)
        self._state = GzipDecoderState.FIRST_MEMBER

    def __getattr__(self, name):
        return getattr(self._obj, name)

    def decompress(self, data):
        ret = bytearray()
        if self._state == GzipDecoderState.SWALLOW_DATA or not data:
            return bytes(ret)
        while True:
            try:
                ret += self._obj.decompress(data)
            except zlib.error:
                previous_state = self._state
                # Ignore data after the first error
                self._state = GzipDecoderState.SWALLOW_DATA
                if previous_state == GzipDecoderState.OTHER_MEMBERS:
                    # Allow trailing garbage acceptable in other gzip clients
                    return bytes(ret)
                raise
            data = self._obj.unused_data
            if not data:
                return bytes(ret)
            self._state = GzipDecoderState.OTHER_MEMBERS
            self._obj = zlib.decompressobj(16 + zlib.MAX_WBITS)


if brotli is not None:

    class BrotliDecoder(object):
        # Supports both 'brotlipy' and 'Brotli' packages
        # since they share an import name. The top branches
        # are for 'brotlipy' and bottom branches for 'Brotli'
        def __init__(self):
            self._obj = brotli.Decompressor()
            if hasattr(self._obj, "decompress"):
                self.decompress = self._obj.decompress
            else:
                self.decompress = self._obj.process

        def flush(self):
            if hasattr(self._obj, "flush"):
                return self._obj.flush()
            return b""


class MultiDecoder(object):
    """
    From RFC7231:
        If one or more encodings have been applied to a representation, the
        sender that applied the encodings MUST generate a Content-Encoding
        header field that lists the content codings in the order in which
        they were applied.
    """

    def __init__(self, modes):
        self._decoders = [_get_decoder(m.strip()) for m in modes.split(",")]

    def flush(self):
        return self._decoders[0].flush()

    def decompress(self, data):
        for d in reversed(self._decoders):
            data = d.decompress(data)
        return data


def _get_decoder(mode):
    if "," in mode:
        return MultiDecoder(mode)

    if mode == "gzip":
        return GzipDecoder()

    if brotli is not None and mode == "br":
        return BrotliDecoder()

    return DeflateDecoder()


class HTTPResponse(io.IOBase):
    """
    HTTP Response container.

    Backwards-compatible with :class:`http.client.HTTPResponse` but the response ``body`` is
    loaded and decoded on-demand when the ``data`` property is accessed.  This
    class is also compatible with the Python standard library's :mod:`io`
    module, and can hence be treated as a readable object in the context of that
    framework.

    Extra parameters for behaviour not present in :class:`http.client.HTTPResponse`:

    :param preload_content:
        If True, the response's body will be preloaded during construction.

    :param decode_content:
        If True, will attempt to decode the body based on the
        'content-encoding' header.

    :param original_response:
        When this HTTPResponse wrapper is generated from an :class:`http.client.HTTPResponse`
        object, it's convenient to include the original for debug purposes. It's
        otherwise unused.

    :param retries:
        The retries contains the last :class:`~urllib3.util.retry.Retry` that
        was used during the request.

    :param enforce_content_length:
        Enforce content length checking. Body returned by server must match
        value of Content-Length header, if present. Otherwise, raise error.
    """

    CONTENT_DECODERS = ["gzip", "deflate"]
    if brotli is not None:
        CONTENT_DECODERS += ["br"]
    REDIRECT_STATUSES = [301, 302, 303, 307, 308]

    def __init__(
        self,
        body="",
        headers=None,
        status=0,
        version=0,
        reason=None,
        strict=0,
        preload_content=True,
        decode_content=True,
        original_response=None,
        pool=None,
        connection=None,
        msg=None,
        retries=None,
        enforce_content_length=False,
        request_method=None,
        request_url=None,
        auto_close=True,
    ):

        if isinstance(headers, HTTPHeaderDict):
            self.headers = headers
        else:
            self.headers = HTTPHeaderDict(headers)
        self.status = status
        self.version = version
        self.reason = reason
        self.strict = strict
        self.decode_content = decode_content
        self.retries = retries
        self.enforce_content_length = enforce_content_length
        self.auto_close = auto_close

        self._decoder = None
        self._body = None
        self._fp = None
        self._original_response = original_response
        self._fp_bytes_read = 0
        self.msg = msg
        self._request_url = request_url

        if body and isinstance(body, (six.string_types, bytes)):
            self._body = body

        self._pool = pool
        self._connection = connection

        if hasattr(body, "read"):
            self._fp = body

        # Are we using the chunked-style of transfer encoding?
        self.chunked = False
        self.chunk_left = None
        tr_enc = self.headers.get("transfer-encoding", "").lower()
        # Don't incur the penalty of creating a list and then discarding it
        encodings = (enc.strip() for enc in tr_enc.split(","))
        if "chunked" in encodings:
            self.chunked = True

        # Determine length of response
        self.length_remaining = self._init_length(request_method)

        # If requested, preload the body.
        if preload_content and not self._body:
            self._body = self.read(decode_content=decode_content)

    def get_redirect_location(self):
        """
        Should we redirect and where to?

        :returns: Truthy redirect location string if we got a redirect status
            code and valid location. ``None`` if redirect status and no
            location. ``False`` if not a redirect status code.
        """
        if self.status in self.REDIRECT_STATUSES:
            return self.headers.get("location")

        return False

    def release_conn(self):
        if not self._pool or not self._connection:
            return

        self._pool._put_conn(self._connection)
        self._connection = None

    def drain_conn(self):
        """
        Read and discard any remaining HTTP response data in the response connection.

        Unread data in the HTTPResponse connection blocks the connection from being released back to the pool.
        """
        try:
            self.read()
        except (HTTPError, SocketError, BaseSSLError, HTTPException):
            pass

    @property
    def data(self):
        # For backwards-compat with earlier urllib3 0.4 and earlier.
        if self._body:
            return self._body

        if self._fp:
            return self.read(cache_content=True)

    @property
    def connection(self):
        return self._connection

    def isclosed(self):
        return is_fp_closed(self._fp)

    def tell(self):
        """
        Obtain the number of bytes pulled over the wire so far. May differ from
        the amount of content returned by :meth:``urllib3.response.HTTPResponse.read``
        if bytes are encoded on the wire (e.g, compressed).
        """
        return self._fp_bytes_read

    def _init_length(self, request_method):
        """
        Set initial length value for Response content if available.
        """
        length = self.headers.get("content-length")

        if length is not None:
            if self.chunked:
                # This Response will fail with an IncompleteRead if it can't be
                # received as chunked. This method falls back to attempt reading
                # the response before raising an exception.
                log.warning(
                    "Received response with both Content-Length and "
                    "Transfer-Encoding set. This is expressly forbidden "
                    "by RFC 7230 sec 3.3.2. Ignoring Content-Length and "
                    "attempting to process response as Transfer-Encoding: "
                    "chunked."
                )
                return None

            try:
                # RFC 7230 section 3.3.2 specifies multiple content lengths can
                # be sent in a single Content-Length header
                # (e.g. Content-Length: 42, 42). This line ensures the values
                # are all valid ints and that as long as the `set` length is 1,
                # all values are the same. Otherwise, the header is invalid.
                lengths = set([int(val) for val in length.split(",")])
                if len(lengths) > 1:
                    raise InvalidHeader(
                        "Content-Length contained multiple "
                        "unmatching values (%s)" % length
                    )
                length = lengths.pop()
            except ValueError:
                length = None
            else:
                if length < 0:
                    length = None

        # Convert status to int for comparison
        # In some cases, httplib returns a status of "_UNKNOWN"
        try:
            status = int(self.status)
        except ValueError:
            status = 0

        # Check for responses that shouldn't include a body
        if status in (204, 304) or 100 <= status < 200 or request_method == "HEAD":
            length = 0

        return length

    def _init_decoder(self):
        """
        Set-up the _decoder attribute if necessary.
        """
        # Note: content-encoding value should be case-insensitive, per RFC 7230
        # Section 3.2
        content_encoding = self.headers.get("content-encoding", "").lower()
        if self._decoder is None:
            if content_encoding in self.CONTENT_DECODERS:
                self._decoder = _get_decoder(content_encoding)
            elif "," in content_encoding:
                encodings = [
                    e.strip()
                    for e in content_encoding.split(",")
                    if e.strip() in self.CONTENT_DECODERS
                ]
                if len(encodings):
                    self._decoder = _get_decoder(content_encoding)

    DECODER_ERROR_CLASSES = (IOError, zlib.error)
    if brotli is not None:
        DECODER_ERROR_CLASSES += (brotli.error,)

    def _decode(self, data, decode_content, flush_decoder):
        """
        Decode the data passed in and potentially flush the decoder.
        """
        if not decode_content:
            return data

        try:
            if self._decoder:
                data = self._decoder.decompress(data)
        except self.DECODER_ERROR_CLASSES as e:
            content_encoding = self.headers.get("content-encoding", "").lower()
            raise DecodeError(
                "Received response with content-encoding: %s, but "
                "failed to decode it." % content_encoding,
                e,
            )
        if flush_decoder:
            data += self._flush_decoder()

        return data

    def _flush_decoder(self):
        """
        Flushes the decoder. Should only be called if the decoder is actually
        being used.
        """
        if self._decoder:
            buf = self._decoder.decompress(b"")
            return buf + self._decoder.flush()

        return b""

    @contextmanager
    def _error_catcher(self):
        """
        Catch low-level python exceptions, instead re-raising urllib3
        variants, so that low-level exceptions are not leaked in the
        high-level api.

        On exit, release the connection back to the pool.
        """
        clean_exit = False

        try:
            try:
                yield

            except SocketTimeout:
                # FIXME: Ideally we'd like to include the url in the ReadTimeoutError but
                # there is yet no clean way to get at it from this context.
                raise ReadTimeoutError(self._pool, None, "Read timed out.")

            except BaseSSLError as e:
                # FIXME: Is there a better way to differentiate between SSLErrors?
                if "read operation timed out" not in str(e):
                    # SSL errors related to framing/MAC get wrapped and reraised here
                    raise SSLError(e)

                raise ReadTimeoutError(self._pool, None, "Read timed out.")

            except (HTTPException, SocketError) as e:
                # This includes IncompleteRead.
                raise ProtocolError("Connection broken: %r" % e, e)

            # If no exception is thrown, we should avoid cleaning up
            # unnecessarily.
            clean_exit = True
        finally:
            # If we didn't terminate cleanly, we need to throw away our
            # connection.
            if not clean_exit:
                # The response may not be closed but we're not going to use it
                # anymore so close it now to ensure that the connection is
                # released back to the pool.
                if self._original_response:
                    self._original_response.close()

                # Closing the response may not actually be sufficient to close
                # everything, so if we have a hold of the connection close that
                # too.
                if self._connection:
                    self._connection.close()

            # If we hold the original response but it's closed now, we should
            # return the connection back to the pool.
            if self._original_response and self._original_response.isclosed():
                self.release_conn()

    def read(self, amt=None, decode_content=None, cache_content=False):
        """
        Similar to :meth:`http.client.HTTPResponse.read`, but with two additional
        parameters: ``decode_content`` and ``cache_content``.

        :param amt:
            How much of the content to read. If specified, caching is skipped
            because it doesn't make sense to cache partial content as the full
            response.

        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.

        :param cache_content:
            If True, will save the returned data such that the same result is
            returned despite of the state of the underlying file object. This
            is useful if you want the ``.data`` property to continue working
            after having ``.read()`` the file object. (Overridden if ``amt`` is
            set.)
        """
        self._init_decoder()
        if decode_content is None:
            decode_content = self.decode_content

        if self._fp is None:
            return

        flush_decoder = False
        fp_closed = getattr(self._fp, "closed", False)

        with self._error_catcher():
            if amt is None:
                # cStringIO doesn't like amt=None
                data = self._fp.read() if not fp_closed else b""
                flush_decoder = True
            else:
                cache_content = False
                data = self._fp.read(amt) if not fp_closed else b""
                if (
                    amt != 0 and not data
                ):  # Platform-specific: Buggy versions of Python.
                    # Close the connection when no data is returned
                    #
                    # This is redundant to what httplib/http.client _should_
                    # already do.  However, versions of python released before
                    # December 15, 2012 (http://bugs.python.org/issue16298) do
                    # not properly close the connection in all cases. There is
                    # no harm in redundantly calling close.
                    self._fp.close()
                    flush_decoder = True
                    if self.enforce_content_length and self.length_remaining not in (
                        0,
                        None,
                    ):
                        # This is an edge case that httplib failed to cover due
                        # to concerns of backward compatibility. We're
                        # addressing it here to make sure IncompleteRead is
                        # raised during streaming, so all calls with incorrect
                        # Content-Length are caught.
                        raise IncompleteRead(self._fp_bytes_read, self.length_remaining)

        if data:
            self._fp_bytes_read += len(data)
            if self.length_remaining is not None:
                self.length_remaining -= len(data)

            data = self._decode(data, decode_content, flush_decoder)

            if cache_content:
                self._body = data

        return data

    def stream(self, amt=2 ** 16, decode_content=None):
        """
        A generator wrapper for the read() method. A call will block until
        ``amt`` bytes have been read from the connection or until the
        connection is closed.

        :param amt:
            How much of the content to read. The generator will return up to
            much data per iteration, but may return less. This is particularly
            likely when using compressed data. However, the empty string will
            never be returned.

        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
        """
        if self.chunked and self.supports_chunked_reads():
            for line in self.read_chunked(amt, decode_content=decode_content):
                yield line
        else:
            while not is_fp_closed(self._fp):
                data = self.read(amt=amt, decode_content=decode_content)

                if data:
                    yield data

    @classmethod
    def from_httplib(ResponseCls, r, **response_kw):
        """
        Given an :class:`http.client.HTTPResponse` instance ``r``, return a
        corresponding :class:`urllib3.response.HTTPResponse` object.

        Remaining parameters are passed to the HTTPResponse constructor, along
        with ``original_response=r``.
        """
        headers = r.msg

        if not isinstance(headers, HTTPHeaderDict):
            if six.PY2:
                # Python 2.7
                headers = HTTPHeaderDict.from_httplib(headers)
            else:
                headers = HTTPHeaderDict(headers.items())

        # HTTPResponse objects in Python 3 don't have a .strict attribute
        strict = getattr(r, "strict", 0)
        resp = ResponseCls(
            body=r,
            headers=headers,
            status=r.status,
            version=r.version,
            reason=r.reason,
            strict=strict,
            original_response=r,
            **response_kw
        )
        return resp

    # Backwards-compatibility methods for http.client.HTTPResponse
    def getheaders(self):
        return self.headers

    def getheader(self, name, default=None):
        return self.headers.get(name, default)

    # Backwards compatibility for http.cookiejar
    def info(self):
        return self.headers

    # Overrides from io.IOBase
    def close(self):
        if not self.closed:
            self._fp.close()

        if self._connection:
            self._connection.close()

        if not self.auto_close:
            io.IOBase.close(self)

    @property
    def closed(self):
        if not self.auto_close:
            return io.IOBase.closed.__get__(self)
        elif self._fp is None:
            return True
        elif hasattr(self._fp, "isclosed"):
            return self._fp.isclosed()
        elif hasattr(self._fp, "closed"):
            return self._fp.closed
        else:
            return True

    def fileno(self):
        if self._fp is None:
            raise IOError("HTTPResponse has no file to get a fileno from")
        elif hasattr(self._fp, "fileno"):
            return self._fp.fileno()
        else:
            raise IOError(
                "The file-like object this HTTPResponse is wrapped "
                "around has no file descriptor"
            )

    def flush(self):
        if (
            self._fp is not None
            and hasattr(self._fp, "flush")
            and not getattr(self._fp, "closed", False)
        ):
            return self._fp.flush()

    def readable(self):
        # This method is required for `io` module compatibility.
        return True

    def readinto(self, b):
        # This method is required for `io` module compatibility.
        temp = self.read(len(b))
        if len(temp) == 0:
            return 0
        else:
            b[: len(temp)] = temp
            return len(temp)

    def supports_chunked_reads(self):
        """
        Checks if the underlying file-like object looks like a
        :class:`http.client.HTTPResponse` object. We do this by testing for
        the fp attribute. If it is present we assume it returns raw chunks as
        processed by read_chunked().
        """
        return hasattr(self._fp, "fp")

    def _update_chunk_length(self):
        # First, we'll figure out length of a chunk and then
        # we'll try to read it from socket.
        if self.chunk_left is not None:
            return
        line = self._fp.fp.readline()
        line = line.split(b";", 1)[0]
        try:
            self.chunk_left = int(line, 16)
        except ValueError:
            # Invalid chunked protocol response, abort.
            self.close()
            raise InvalidChunkLength(self, line)

    def _handle_chunk(self, amt):
        returned_chunk = None
        if amt is None:
            chunk = self._fp._safe_read(self.chunk_left)
            returned_chunk = chunk
            self._fp._safe_read(2)  # Toss the CRLF at the end of the chunk.
            self.chunk_left = None
        elif amt < self.chunk_left:
            value = self._fp._safe_read(amt)
            self.chunk_left = self.chunk_left - amt
            returned_chunk = value
        elif amt == self.chunk_left:
            value = self._fp._safe_read(amt)
            self._fp._safe_read(2)  # Toss the CRLF at the end of the chunk.
            self.chunk_left = None
            returned_chunk = value
        else:  # amt > self.chunk_left
            returned_chunk = self._fp._safe_read(self.chunk_left)
            self._fp._safe_read(2)  # Toss the CRLF at the end of the chunk.
            self.chunk_left = None
        return returned_chunk

    def read_chunked(self, amt=None, decode_content=None):
        """
        Similar to :meth:`HTTPResponse.read`, but with an additional
        parameter: ``decode_content``.

        :param amt:
            How much of the content to read. If specified, caching is skipped
            because it doesn't make sense to cache partial content as the full
            response.

        :param decode_content:
            If True, will attempt to decode the body based on the
            'content-encoding' header.
        """
        self._init_decoder()
        # FIXME: Rewrite this method and make it a class with a better structured logic.
        if not self.chunked:
            raise ResponseNotChunked(
                "Response is not chunked. "
                "Header 'transfer-encoding: chunked' is missing."
            )
        if not self.supports_chunked_reads():
            raise BodyNotHttplibCompatible(
                "Body should be http.client.HTTPResponse like. "
                "It should have have an fp attribute which returns raw chunks."
            )

        with self._error_catcher():
            # Don't bother reading the body of a HEAD request.
            if self._original_response and is_response_to_head(self._original_response):
                self._original_response.close()
                return

            # If a response is already read and closed
            # then return immediately.
            if self._fp.fp is None:
                return

            while True:
                self._update_chunk_length()
                if self.chunk_left == 0:
                    break
                chunk = self._handle_chunk(amt)
                decoded = self._decode(
                    chunk, decode_content=decode_content, flush_decoder=False
                )
                if decoded:
                    yield decoded

            if decode_content:
                # On CPython and PyPy, we should never need to flush the
                # decoder. However, on Jython we *might* need to, so
                # lets defensively do it anyway.
                decoded = self._flush_decoder()
                if decoded:  # Platform-specific: Jython.
                    yield decoded

            # Chunk content ends with \r\n: discard it.
            while True:
                line = self._fp.fp.readline()
                if not line:
                    # Some sites may not end with '\r\n'.
                    break
                if line == b"\r\n":
                    break

            # We read everything; close the "file".
            if self._original_response:
                self._original_response.close()

    def geturl(self):
        """
        Returns the URL that was the source of this response.
        If the request that generated this response redirected, this method
        will return the final redirect location.
        """
        if self.retries is not None and len(self.retries.history):
            return self.retries.history[-1].redirect_location
        else:
            return self._request_url

    def __iter__(self):
        buffer = []
        for chunk in self.stream(decode_content=True):
            if b"\n" in chunk:
                chunk = chunk.split(b"\n")
                yield b"".join(buffer) + chunk[0] + b"\n"
                for x in chunk[1:-1]:
                    yield x + b"\n"
                if chunk[-1]:
                    buffer = [chunk[-1]]
                else:
                    buffer = []
            else:
                buffer.append(chunk)
        if buffer:
            yield b"".join(buffer)




############################################################
### File: reversename.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2006-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Reverse Map Names."""

import binascii

import dns.name
import dns.ipv6
import dns.ipv4

from dns._compat import PY3

ipv4_reverse_domain = dns.name.from_text('in-addr.arpa.')
ipv6_reverse_domain = dns.name.from_text('ip6.arpa.')


def from_address(text):
    """Convert an IPv4 or IPv6 address in textual form into a Name object whose
    value is the reverse-map domain name of the address.

    *text*, a ``text``, is an IPv4 or IPv6 address in textual form
    (e.g. '127.0.0.1', '::1')

    Raises ``dns.exception.SyntaxError`` if the address is badly formed.

    Returns a ``dns.name.Name``.
    """

    try:
        v6 = dns.ipv6.inet_aton(text)
        if dns.ipv6.is_mapped(v6):
            if PY3:
                parts = ['%d' % byte for byte in v6[12:]]
            else:
                parts = ['%d' % ord(byte) for byte in v6[12:]]
            origin = ipv4_reverse_domain
        else:
            parts = [x for x in str(binascii.hexlify(v6).decode())]
            origin = ipv6_reverse_domain
    except Exception:
        parts = ['%d' %
                 byte for byte in bytearray(dns.ipv4.inet_aton(text))]
        origin = ipv4_reverse_domain
    parts.reverse()
    return dns.name.from_text('.'.join(parts), origin=origin)


def to_address(name):
    """Convert a reverse map domain name into textual address form.

    *name*, a ``dns.name.Name``, an IPv4 or IPv6 address in reverse-map name
    form.

    Raises ``dns.exception.SyntaxError`` if the name does not have a
    reverse-map form.

    Returns a ``text``.
    """

    if name.is_subdomain(ipv4_reverse_domain):
        name = name.relativize(ipv4_reverse_domain)
        labels = list(name.labels)
        labels.reverse()
        text = b'.'.join(labels)
        # run through inet_aton() to check syntax and make pretty.
        return dns.ipv4.inet_ntoa(dns.ipv4.inet_aton(text))
    elif name.is_subdomain(ipv6_reverse_domain):
        name = name.relativize(ipv6_reverse_domain)
        labels = list(name.labels)
        labels.reverse()
        parts = []
        i = 0
        l = len(labels)
        while i < l:
            parts.append(b''.join(labels[i:i + 4]))
            i += 4
        text = b':'.join(parts)
        # run through inet_aton() to check syntax and make pretty.
        return dns.ipv6.inet_ntoa(dns.ipv6.inet_aton(text))
    else:
        raise dns.exception.SyntaxError('unknown reverse-map address family')




############################################################
### File: rrset.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS RRsets (an RRset is a named rdataset)"""


import dns.name
import dns.rdataset
import dns.rdataclass
import dns.renderer
from ._compat import string_types


class RRset(dns.rdataset.Rdataset):

    """A DNS RRset (named rdataset).

    RRset inherits from Rdataset, and RRsets can be treated as
    Rdatasets in most cases.  There are, however, a few notable
    exceptions.  RRsets have different to_wire() and to_text() method
    arguments, reflecting the fact that RRsets always have an owner
    name.
    """

    __slots__ = ['name', 'deleting']

    def __init__(self, name, rdclass, rdtype, covers=dns.rdatatype.NONE,
                 deleting=None):
        """Create a new RRset."""

        super(RRset, self).__init__(rdclass, rdtype, covers)
        self.name = name
        self.deleting = deleting

    def _clone(self):
        obj = super(RRset, self)._clone()
        obj.name = self.name
        obj.deleting = self.deleting
        return obj

    def __repr__(self):
        if self.covers == 0:
            ctext = ''
        else:
            ctext = '(' + dns.rdatatype.to_text(self.covers) + ')'
        if self.deleting is not None:
            dtext = ' delete=' + dns.rdataclass.to_text(self.deleting)
        else:
            dtext = ''
        return '<DNS ' + str(self.name) + ' ' + \
               dns.rdataclass.to_text(self.rdclass) + ' ' + \
               dns.rdatatype.to_text(self.rdtype) + ctext + dtext + ' RRset>'

    def __str__(self):
        return self.to_text()

    def __eq__(self, other):
        if not isinstance(other, RRset):
            return False
        if self.name != other.name:
            return False
        return super(RRset, self).__eq__(other)

    def match(self, name, rdclass, rdtype, covers, deleting=None):
        """Returns ``True`` if this rrset matches the specified class, type,
        covers, and deletion state.
        """

        if not super(RRset, self).match(rdclass, rdtype, covers):
            return False
        if self.name != name or self.deleting != deleting:
            return False
        return True

    def to_text(self, origin=None, relativize=True, **kw):
        """Convert the RRset into DNS master file format.

        See ``dns.name.Name.choose_relativity`` for more information
        on how *origin* and *relativize* determine the way names
        are emitted.

        Any additional keyword arguments are passed on to the rdata
        ``to_text()`` method.

        *origin*, a ``dns.name.Name`` or ``None``, the origin for relative
        names.

        *relativize*, a ``bool``.  If ``True``, names will be relativized
        to *origin*.
        """

        return super(RRset, self).to_text(self.name, origin, relativize,
                                          self.deleting, **kw)

    def to_wire(self, file, compress=None, origin=None, **kw):
        """Convert the RRset to wire format.

        All keyword arguments are passed to ``dns.rdataset.to_wire()``; see
        that function for details.

        Returns an ``int``, the number of records emitted.
        """

        return super(RRset, self).to_wire(self.name, file, compress, origin,
                                          self.deleting, **kw)

    def to_rdataset(self):
        """Convert an RRset into an Rdataset.

        Returns a ``dns.rdataset.Rdataset``.
        """
        return dns.rdataset.from_rdata_list(self.ttl, list(self))


def from_text_list(name, ttl, rdclass, rdtype, text_rdatas,
                   idna_codec=None):
    """Create an RRset with the specified name, TTL, class, and type, and with
    the specified list of rdatas in text format.

    Returns a ``dns.rrset.RRset`` object.
    """

    if isinstance(name, string_types):
        name = dns.name.from_text(name, None, idna_codec=idna_codec)
    if isinstance(rdclass, string_types):
        rdclass = dns.rdataclass.from_text(rdclass)
    if isinstance(rdtype, string_types):
        rdtype = dns.rdatatype.from_text(rdtype)
    r = RRset(name, rdclass, rdtype)
    r.update_ttl(ttl)
    for t in text_rdatas:
        rd = dns.rdata.from_text(r.rdclass, r.rdtype, t)
        r.add(rd)
    return r


def from_text(name, ttl, rdclass, rdtype, *text_rdatas):
    """Create an RRset with the specified name, TTL, class, and type and with
    the specified rdatas in text format.

    Returns a ``dns.rrset.RRset`` object.
    """

    return from_text_list(name, ttl, rdclass, rdtype, text_rdatas)


def from_rdata_list(name, ttl, rdatas, idna_codec=None):
    """Create an RRset with the specified name and TTL, and with
    the specified list of rdata objects.

    Returns a ``dns.rrset.RRset`` object.
    """

    if isinstance(name, string_types):
        name = dns.name.from_text(name, None, idna_codec=idna_codec)

    if len(rdatas) == 0:
        raise ValueError("rdata list must not be empty")
    r = None
    for rd in rdatas:
        if r is None:
            r = RRset(name, rd.rdclass, rd.rdtype)
            r.update_ttl(ttl)
        r.add(rd)
    return r


def from_rdata(name, ttl, *rdatas):
    """Create an RRset with the specified name and TTL, and with
    the specified rdata objects.

    Returns a ``dns.rrset.RRset`` object.
    """

    return from_rdata_list(name, ttl, rdatas)




############################################################
### File: rrule.py
############################################################
# -*- coding: utf-8 -*-
"""
The rrule module offers a small, complete, and very fast, implementation of
the recurrence rules documented in the
`iCalendar RFC <https://tools.ietf.org/html/rfc5545>`_,
including support for caching of results.
"""
import itertools
import datetime
import calendar
import re
import sys

try:
    from math import gcd
except ImportError:
    from fractions import gcd

from six import advance_iterator, integer_types
from six.moves import _thread, range
import heapq

from ._common import weekday as weekdaybase

# For warning about deprecation of until and count
from warnings import warn

__all__ = ["rrule", "rruleset", "rrulestr",
           "YEARLY", "MONTHLY", "WEEKLY", "DAILY",
           "HOURLY", "MINUTELY", "SECONDLY",
           "MO", "TU", "WE", "TH", "FR", "SA", "SU"]

# Every mask is 7 days longer to handle cross-year weekly periods.
M366MASK = tuple([1]*31+[2]*29+[3]*31+[4]*30+[5]*31+[6]*30 +
                 [7]*31+[8]*31+[9]*30+[10]*31+[11]*30+[12]*31+[1]*7)
M365MASK = list(M366MASK)
M29, M30, M31 = list(range(1, 30)), list(range(1, 31)), list(range(1, 32))
MDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])
MDAY365MASK = list(MDAY366MASK)
M29, M30, M31 = list(range(-29, 0)), list(range(-30, 0)), list(range(-31, 0))
NMDAY366MASK = tuple(M31+M29+M31+M30+M31+M30+M31+M31+M30+M31+M30+M31+M31[:7])
NMDAY365MASK = list(NMDAY366MASK)
M366RANGE = (0, 31, 60, 91, 121, 152, 182, 213, 244, 274, 305, 335, 366)
M365RANGE = (0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334, 365)
WDAYMASK = [0, 1, 2, 3, 4, 5, 6]*55
del M29, M30, M31, M365MASK[59], MDAY365MASK[59], NMDAY365MASK[31]
MDAY365MASK = tuple(MDAY365MASK)
M365MASK = tuple(M365MASK)

FREQNAMES = ['YEARLY', 'MONTHLY', 'WEEKLY', 'DAILY', 'HOURLY', 'MINUTELY', 'SECONDLY']

(YEARLY,
 MONTHLY,
 WEEKLY,
 DAILY,
 HOURLY,
 MINUTELY,
 SECONDLY) = list(range(7))

# Imported on demand.
easter = None
parser = None


class weekday(weekdaybase):
    """
    This version of weekday does not allow n = 0.
    """
    def __init__(self, wkday, n=None):
        if n == 0:
            raise ValueError("Can't create weekday with n==0")

        super(weekday, self).__init__(wkday, n)


MO, TU, WE, TH, FR, SA, SU = weekdays = tuple(weekday(x) for x in range(7))


def _invalidates_cache(f):
    """
    Decorator for rruleset methods which may invalidate the
    cached length.
    """
    def inner_func(self, *args, **kwargs):
        rv = f(self, *args, **kwargs)
        self._invalidate_cache()
        return rv

    return inner_func


class rrulebase(object):
    def __init__(self, cache=False):
        if cache:
            self._cache = []
            self._cache_lock = _thread.allocate_lock()
            self._invalidate_cache()
        else:
            self._cache = None
            self._cache_complete = False
            self._len = None

    def __iter__(self):
        if self._cache_complete:
            return iter(self._cache)
        elif self._cache is None:
            return self._iter()
        else:
            return self._iter_cached()

    def _invalidate_cache(self):
        if self._cache is not None:
            self._cache = []
            self._cache_complete = False
            self._cache_gen = self._iter()

            if self._cache_lock.locked():
                self._cache_lock.release()

        self._len = None

    def _iter_cached(self):
        i = 0
        gen = self._cache_gen
        cache = self._cache
        acquire = self._cache_lock.acquire
        release = self._cache_lock.release
        while gen:
            if i == len(cache):
                acquire()
                if self._cache_complete:
                    break
                try:
                    for j in range(10):
                        cache.append(advance_iterator(gen))
                except StopIteration:
                    self._cache_gen = gen = None
                    self._cache_complete = True
                    break
                release()
            yield cache[i]
            i += 1
        while i < self._len:
            yield cache[i]
            i += 1

    def __getitem__(self, item):
        if self._cache_complete:
            return self._cache[item]
        elif isinstance(item, slice):
            if item.step and item.step < 0:
                return list(iter(self))[item]
            else:
                return list(itertools.islice(self,
                                             item.start or 0,
                                             item.stop or sys.maxsize,
                                             item.step or 1))
        elif item >= 0:
            gen = iter(self)
            try:
                for i in range(item+1):
                    res = advance_iterator(gen)
            except StopIteration:
                raise IndexError
            return res
        else:
            return list(iter(self))[item]

    def __contains__(self, item):
        if self._cache_complete:
            return item in self._cache
        else:
            for i in self:
                if i == item:
                    return True
                elif i > item:
                    return False
        return False

    # __len__() introduces a large performance penalty.
    def count(self):
        """ Returns the number of recurrences in this set. It will have go
            trough the whole recurrence, if this hasn't been done before. """
        if self._len is None:
            for x in self:
                pass
        return self._len

    def before(self, dt, inc=False):
        """ Returns the last recurrence before the given datetime instance. The
            inc keyword defines what happens if dt is an occurrence. With
            inc=True, if dt itself is an occurrence, it will be returned. """
        if self._cache_complete:
            gen = self._cache
        else:
            gen = self
        last = None
        if inc:
            for i in gen:
                if i > dt:
                    break
                last = i
        else:
            for i in gen:
                if i >= dt:
                    break
                last = i
        return last

    def after(self, dt, inc=False):
        """ Returns the first recurrence after the given datetime instance. The
            inc keyword defines what happens if dt is an occurrence. With
            inc=True, if dt itself is an occurrence, it will be returned.  """
        if self._cache_complete:
            gen = self._cache
        else:
            gen = self
        if inc:
            for i in gen:
                if i >= dt:
                    return i
        else:
            for i in gen:
                if i > dt:
                    return i
        return None

    def xafter(self, dt, count=None, inc=False):
        """
        Generator which yields up to `count` recurrences after the given
        datetime instance, equivalent to `after`.

        :param dt:
            The datetime at which to start generating recurrences.

        :param count:
            The maximum number of recurrences to generate. If `None` (default),
            dates are generated until the recurrence rule is exhausted.

        :param inc:
            If `dt` is an instance of the rule and `inc` is `True`, it is
            included in the output.

        :yields: Yields a sequence of `datetime` objects.
        """

        if self._cache_complete:
            gen = self._cache
        else:
            gen = self

        # Select the comparison function
        if inc:
            comp = lambda dc, dtc: dc >= dtc
        else:
            comp = lambda dc, dtc: dc > dtc

        # Generate dates
        n = 0
        for d in gen:
            if comp(d, dt):
                if count is not None:
                    n += 1
                    if n > count:
                        break

                yield d

    def between(self, after, before, inc=False, count=1):
        """ Returns all the occurrences of the rrule between after and before.
        The inc keyword defines what happens if after and/or before are
        themselves occurrences. With inc=True, they will be included in the
        list, if they are found in the recurrence set. """
        if self._cache_complete:
            gen = self._cache
        else:
            gen = self
        started = False
        l = []
        if inc:
            for i in gen:
                if i > before:
                    break
                elif not started:
                    if i >= after:
                        started = True
                        l.append(i)
                else:
                    l.append(i)
        else:
            for i in gen:
                if i >= before:
                    break
                elif not started:
                    if i > after:
                        started = True
                        l.append(i)
                else:
                    l.append(i)
        return l


class rrule(rrulebase):
    """
    That's the base of the rrule operation. It accepts all the keywords
    defined in the RFC as its constructor parameters (except byday,
    which was renamed to byweekday) and more. The constructor prototype is::

            rrule(freq)

    Where freq must be one of YEARLY, MONTHLY, WEEKLY, DAILY, HOURLY, MINUTELY,
    or SECONDLY.

    .. note::
        Per RFC section 3.3.10, recurrence instances falling on invalid dates
        and times are ignored rather than coerced:

            Recurrence rules may generate recurrence instances with an invalid
            date (e.g., February 30) or nonexistent local time (e.g., 1:30 AM
            on a day where the local time is moved forward by an hour at 1:00
            AM).  Such recurrence instances MUST be ignored and MUST NOT be
            counted as part of the recurrence set.

        This can lead to possibly surprising behavior when, for example, the
        start date occurs at the end of the month:

        >>> from dateutil.rrule import rrule, MONTHLY
        >>> from datetime import datetime
        >>> start_date = datetime(2014, 12, 31)
        >>> list(rrule(freq=MONTHLY, count=4, dtstart=start_date))
        ... # doctest: +NORMALIZE_WHITESPACE
        [datetime.datetime(2014, 12, 31, 0, 0),
         datetime.datetime(2015, 1, 31, 0, 0),
         datetime.datetime(2015, 3, 31, 0, 0),
         datetime.datetime(2015, 5, 31, 0, 0)]

    Additionally, it supports the following keyword arguments:

    :param dtstart:
        The recurrence start. Besides being the base for the recurrence,
        missing parameters in the final recurrence instances will also be
        extracted from this date. If not given, datetime.now() will be used
        instead.
    :param interval:
        The interval between each freq iteration. For example, when using
        YEARLY, an interval of 2 means once every two years, but with HOURLY,
        it means once every two hours. The default interval is 1.
    :param wkst:
        The week start day. Must be one of the MO, TU, WE constants, or an
        integer, specifying the first day of the week. This will affect
        recurrences based on weekly periods. The default week start is got
        from calendar.firstweekday(), and may be modified by
        calendar.setfirstweekday().
    :param count:
        If given, this determines how many occurrences will be generated.

        .. note::
            As of version 2.5.0, the use of the keyword ``until`` in conjunction
            with ``count`` is deprecated, to make sure ``dateutil`` is fully
            compliant with `RFC-5545 Sec. 3.3.10 <https://tools.ietf.org/
            html/rfc5545#section-3.3.10>`_. Therefore, ``until`` and ``count``
            **must not** occur in the same call to ``rrule``.
    :param until:
        If given, this must be a datetime instance specifying the upper-bound
        limit of the recurrence. The last recurrence in the rule is the greatest
        datetime that is less than or equal to the value specified in the
        ``until`` parameter.

        .. note::
            As of version 2.5.0, the use of the keyword ``until`` in conjunction
            with ``count`` is deprecated, to make sure ``dateutil`` is fully
            compliant with `RFC-5545 Sec. 3.3.10 <https://tools.ietf.org/
            html/rfc5545#section-3.3.10>`_. Therefore, ``until`` and ``count``
            **must not** occur in the same call to ``rrule``.
    :param bysetpos:
        If given, it must be either an integer, or a sequence of integers,
        positive or negative. Each given integer will specify an occurrence
        number, corresponding to the nth occurrence of the rule inside the
        frequency period. For example, a bysetpos of -1 if combined with a
        MONTHLY frequency, and a byweekday of (MO, TU, WE, TH, FR), will
        result in the last work day of every month.
    :param bymonth:
        If given, it must be either an integer, or a sequence of integers,
        meaning the months to apply the recurrence to.
    :param bymonthday:
        If given, it must be either an integer, or a sequence of integers,
        meaning the month days to apply the recurrence to.
    :param byyearday:
        If given, it must be either an integer, or a sequence of integers,
        meaning the year days to apply the recurrence to.
    :param byeaster:
        If given, it must be either an integer, or a sequence of integers,
        positive or negative. Each integer will define an offset from the
        Easter Sunday. Passing the offset 0 to byeaster will yield the Easter
        Sunday itself. This is an extension to the RFC specification.
    :param byweekno:
        If given, it must be either an integer, or a sequence of integers,
        meaning the week numbers to apply the recurrence to. Week numbers
        have the meaning described in ISO8601, that is, the first week of
        the year is that containing at least four days of the new year.
    :param byweekday:
        If given, it must be either an integer (0 == MO), a sequence of
        integers, one of the weekday constants (MO, TU, etc), or a sequence
        of these constants. When given, these variables will define the
        weekdays where the recurrence will be applied. It's also possible to
        use an argument n for the weekday instances, which will mean the nth
        occurrence of this weekday in the period. For example, with MONTHLY,
        or with YEARLY and BYMONTH, using FR(+1) in byweekday will specify the
        first friday of the month where the recurrence happens. Notice that in
        the RFC documentation, this is specified as BYDAY, but was renamed to
        avoid the ambiguity of that keyword.
    :param byhour:
        If given, it must be either an integer, or a sequence of integers,
        meaning the hours to apply the recurrence to.
    :param byminute:
        If given, it must be either an integer, or a sequence of integers,
        meaning the minutes to apply the recurrence to.
    :param bysecond:
        If given, it must be either an integer, or a sequence of integers,
        meaning the seconds to apply the recurrence to.
    :param cache:
        If given, it must be a boolean value specifying to enable or disable
        caching of results. If you will use the same rrule instance multiple
        times, enabling caching will improve the performance considerably.
     """
    def __init__(self, freq, dtstart=None,
                 interval=1, wkst=None, count=None, until=None, bysetpos=None,
                 bymonth=None, bymonthday=None, byyearday=None, byeaster=None,
                 byweekno=None, byweekday=None,
                 byhour=None, byminute=None, bysecond=None,
                 cache=False):
        super(rrule, self).__init__(cache)
        global easter
        if not dtstart:
            if until and until.tzinfo:
                dtstart = datetime.datetime.now(tz=until.tzinfo).replace(microsecond=0)
            else:
                dtstart = datetime.datetime.now().replace(microsecond=0)
        elif not isinstance(dtstart, datetime.datetime):
            dtstart = datetime.datetime.fromordinal(dtstart.toordinal())
        else:
            dtstart = dtstart.replace(microsecond=0)
        self._dtstart = dtstart
        self._tzinfo = dtstart.tzinfo
        self._freq = freq
        self._interval = interval
        self._count = count

        # Cache the original byxxx rules, if they are provided, as the _byxxx
        # attributes do not necessarily map to the inputs, and this can be
        # a problem in generating the strings. Only store things if they've
        # been supplied (the string retrieval will just use .get())
        self._original_rule = {}

        if until and not isinstance(until, datetime.datetime):
            until = datetime.datetime.fromordinal(until.toordinal())
        self._until = until

        if self._dtstart and self._until:
            if (self._dtstart.tzinfo is not None) != (self._until.tzinfo is not None):
                # According to RFC5545 Section 3.3.10:
                # https://tools.ietf.org/html/rfc5545#section-3.3.10
                #
                # > If the "DTSTART" property is specified as a date with UTC
                # > time or a date with local time and time zone reference,
                # > then the UNTIL rule part MUST be specified as a date with
                # > UTC time.
                raise ValueError(
                    'RRULE UNTIL values must be specified in UTC when DTSTART '
                    'is timezone-aware'
                )

        if count is not None and until:
            warn("Using both 'count' and 'until' is inconsistent with RFC 5545"
                 " and has been deprecated in dateutil. Future versions will "
                 "raise an error.", DeprecationWarning)

        if wkst is None:
            self._wkst = calendar.firstweekday()
        elif isinstance(wkst, integer_types):
            self._wkst = wkst
        else:
            self._wkst = wkst.weekday

        if bysetpos is None:
            self._bysetpos = None
        elif isinstance(bysetpos, integer_types):
            if bysetpos == 0 or not (-366 <= bysetpos <= 366):
                raise ValueError("bysetpos must be between 1 and 366, "
                                 "or between -366 and -1")
            self._bysetpos = (bysetpos,)
        else:
            self._bysetpos = tuple(bysetpos)
            for pos in self._bysetpos:
                if pos == 0 or not (-366 <= pos <= 366):
                    raise ValueError("bysetpos must be between 1 and 366, "
                                     "or between -366 and -1")

        if self._bysetpos:
            self._original_rule['bysetpos'] = self._bysetpos

        if (byweekno is None and byyearday is None and bymonthday is None and
                byweekday is None and byeaster is None):
            if freq == YEARLY:
                if bymonth is None:
                    bymonth = dtstart.month
                    self._original_rule['bymonth'] = None
                bymonthday = dtstart.day
                self._original_rule['bymonthday'] = None
            elif freq == MONTHLY:
                bymonthday = dtstart.day
                self._original_rule['bymonthday'] = None
            elif freq == WEEKLY:
                byweekday = dtstart.weekday()
                self._original_rule['byweekday'] = None

        # bymonth
        if bymonth is None:
            self._bymonth = None
        else:
            if isinstance(bymonth, integer_types):
                bymonth = (bymonth,)

            self._bymonth = tuple(sorted(set(bymonth)))

            if 'bymonth' not in self._original_rule:
                self._original_rule['bymonth'] = self._bymonth

        # byyearday
        if byyearday is None:
            self._byyearday = None
        else:
            if isinstance(byyearday, integer_types):
                byyearday = (byyearday,)

            self._byyearday = tuple(sorted(set(byyearday)))
            self._original_rule['byyearday'] = self._byyearday

        # byeaster
        if byeaster is not None:
            if not easter:
                from dateutil import easter
            if isinstance(byeaster, integer_types):
                self._byeaster = (byeaster,)
            else:
                self._byeaster = tuple(sorted(byeaster))

            self._original_rule['byeaster'] = self._byeaster
        else:
            self._byeaster = None

        # bymonthday
        if bymonthday is None:
            self._bymonthday = ()
            self._bynmonthday = ()
        else:
            if isinstance(bymonthday, integer_types):
                bymonthday = (bymonthday,)

            bymonthday = set(bymonthday)            # Ensure it's unique

            self._bymonthday = tuple(sorted(x for x in bymonthday if x > 0))
            self._bynmonthday = tuple(sorted(x for x in bymonthday if x < 0))

            # Storing positive numbers first, then negative numbers
            if 'bymonthday' not in self._original_rule:
                self._original_rule['bymonthday'] = tuple(
                    itertools.chain(self._bymonthday, self._bynmonthday))

        # byweekno
        if byweekno is None:
            self._byweekno = None
        else:
            if isinstance(byweekno, integer_types):
                byweekno = (byweekno,)

            self._byweekno = tuple(sorted(set(byweekno)))

            self._original_rule['byweekno'] = self._byweekno

        # byweekday / bynweekday
        if byweekday is None:
            self._byweekday = None
            self._bynweekday = None
        else:
            # If it's one of the valid non-sequence types, convert to a
            # single-element sequence before the iterator that builds the
            # byweekday set.
            if isinstance(byweekday, integer_types) or hasattr(byweekday, "n"):
                byweekday = (byweekday,)

            self._byweekday = set()
            self._bynweekday = set()
            for wday in byweekday:
                if isinstance(wday, integer_types):
                    self._byweekday.add(wday)
                elif not wday.n or freq > MONTHLY:
                    self._byweekday.add(wday.weekday)
                else:
                    self._bynweekday.add((wday.weekday, wday.n))

            if not self._byweekday:
                self._byweekday = None
            elif not self._bynweekday:
                self._bynweekday = None

            if self._byweekday is not None:
                self._byweekday = tuple(sorted(self._byweekday))
                orig_byweekday = [weekday(x) for x in self._byweekday]
            else:
                orig_byweekday = ()

            if self._bynweekday is not None:
                self._bynweekday = tuple(sorted(self._bynweekday))
                orig_bynweekday = [weekday(*x) for x in self._bynweekday]
            else:
                orig_bynweekday = ()

            if 'byweekday' not in self._original_rule:
                self._original_rule['byweekday'] = tuple(itertools.chain(
                    orig_byweekday, orig_bynweekday))

        # byhour
        if byhour is None:
            if freq < HOURLY:
                self._byhour = {dtstart.hour}
            else:
                self._byhour = None
        else:
            if isinstance(byhour, integer_types):
                byhour = (byhour,)

            if freq == HOURLY:
                self._byhour = self.__construct_byset(start=dtstart.hour,
                                                      byxxx=byhour,
                                                      base=24)
            else:
                self._byhour = set(byhour)

            self._byhour = tuple(sorted(self._byhour))
            self._original_rule['byhour'] = self._byhour

        # byminute
        if byminute is None:
            if freq < MINUTELY:
                self._byminute = {dtstart.minute}
            else:
                self._byminute = None
        else:
            if isinstance(byminute, integer_types):
                byminute = (byminute,)

            if freq == MINUTELY:
                self._byminute = self.__construct_byset(start=dtstart.minute,
                                                        byxxx=byminute,
                                                        base=60)
            else:
                self._byminute = set(byminute)

            self._byminute = tuple(sorted(self._byminute))
            self._original_rule['byminute'] = self._byminute

        # bysecond
        if bysecond is None:
            if freq < SECONDLY:
                self._bysecond = ((dtstart.second,))
            else:
                self._bysecond = None
        else:
            if isinstance(bysecond, integer_types):
                bysecond = (bysecond,)

            self._bysecond = set(bysecond)

            if freq == SECONDLY:
                self._bysecond = self.__construct_byset(start=dtstart.second,
                                                        byxxx=bysecond,
                                                        base=60)
            else:
                self._bysecond = set(bysecond)

            self._bysecond = tuple(sorted(self._bysecond))
            self._original_rule['bysecond'] = self._bysecond

        if self._freq >= HOURLY:
            self._timeset = None
        else:
            self._timeset = []
            for hour in self._byhour:
                for minute in self._byminute:
                    for second in self._bysecond:
                        self._timeset.append(
                            datetime.time(hour, minute, second,
                                          tzinfo=self._tzinfo))
            self._timeset.sort()
            self._timeset = tuple(self._timeset)

    def __str__(self):
        """
        Output a string that would generate this RRULE if passed to rrulestr.
        This is mostly compatible with RFC5545, except for the
        dateutil-specific extension BYEASTER.
        """

        output = []
        h, m, s = [None] * 3
        if self._dtstart:
            output.append(self._dtstart.strftime('DTSTART:%Y%m%dT%H%M%S'))
            h, m, s = self._dtstart.timetuple()[3:6]

        parts = ['FREQ=' + FREQNAMES[self._freq]]
        if self._interval != 1:
            parts.append('INTERVAL=' + str(self._interval))

        if self._wkst:
            parts.append('WKST=' + repr(weekday(self._wkst))[0:2])

        if self._count is not None:
            parts.append('COUNT=' + str(self._count))

        if self._until:
            parts.append(self._until.strftime('UNTIL=%Y%m%dT%H%M%S'))

        if self._original_rule.get('byweekday') is not None:
            # The str() method on weekday objects doesn't generate
            # RFC5545-compliant strings, so we should modify that.
            original_rule = dict(self._original_rule)
            wday_strings = []
            for wday in original_rule['byweekday']:
                if wday.n:
                    wday_strings.append('{n:+d}{wday}'.format(
                        n=wday.n,
                        wday=repr(wday)[0:2]))
                else:
                    wday_strings.append(repr(wday))

            original_rule['byweekday'] = wday_strings
        else:
            original_rule = self._original_rule

        partfmt = '{name}={vals}'
        for name, key in [('BYSETPOS', 'bysetpos'),
                          ('BYMONTH', 'bymonth'),
                          ('BYMONTHDAY', 'bymonthday'),
                          ('BYYEARDAY', 'byyearday'),
                          ('BYWEEKNO', 'byweekno'),
                          ('BYDAY', 'byweekday'),
                          ('BYHOUR', 'byhour'),
                          ('BYMINUTE', 'byminute'),
                          ('BYSECOND', 'bysecond'),
                          ('BYEASTER', 'byeaster')]:
            value = original_rule.get(key)
            if value:
                parts.append(partfmt.format(name=name, vals=(','.join(str(v)
                                                             for v in value))))

        output.append('RRULE:' + ';'.join(parts))
        return '\n'.join(output)

    def replace(self, **kwargs):
        """Return new rrule with same attributes except for those attributes given new
           values by whichever keyword arguments are specified."""
        new_kwargs = {"interval": self._interval,
                      "count": self._count,
                      "dtstart": self._dtstart,
                      "freq": self._freq,
                      "until": self._until,
                      "wkst": self._wkst,
                      "cache": False if self._cache is None else True }
        new_kwargs.update(self._original_rule)
        new_kwargs.update(kwargs)
        return rrule(**new_kwargs)

    def _iter(self):
        year, month, day, hour, minute, second, weekday, yearday, _ = \
            self._dtstart.timetuple()

        # Some local variables to speed things up a bit
        freq = self._freq
        interval = self._interval
        wkst = self._wkst
        until = self._until
        bymonth = self._bymonth
        byweekno = self._byweekno
        byyearday = self._byyearday
        byweekday = self._byweekday
        byeaster = self._byeaster
        bymonthday = self._bymonthday
        bynmonthday = self._bynmonthday
        bysetpos = self._bysetpos
        byhour = self._byhour
        byminute = self._byminute
        bysecond = self._bysecond

        ii = _iterinfo(self)
        ii.rebuild(year, month)

        getdayset = {YEARLY: ii.ydayset,
                     MONTHLY: ii.mdayset,
                     WEEKLY: ii.wdayset,
                     DAILY: ii.ddayset,
                     HOURLY: ii.ddayset,
                     MINUTELY: ii.ddayset,
                     SECONDLY: ii.ddayset}[freq]

        if freq < HOURLY:
            timeset = self._timeset
        else:
            gettimeset = {HOURLY: ii.htimeset,
                          MINUTELY: ii.mtimeset,
                          SECONDLY: ii.stimeset}[freq]
            if ((freq >= HOURLY and
                 self._byhour and hour not in self._byhour) or
                (freq >= MINUTELY and
                 self._byminute and minute not in self._byminute) or
                (freq >= SECONDLY and
                 self._bysecond and second not in self._bysecond)):
                timeset = ()
            else:
                timeset = gettimeset(hour, minute, second)

        total = 0
        count = self._count
        while True:
            # Get dayset with the right frequency
            dayset, start, end = getdayset(year, month, day)

            # Do the "hard" work ;-)
            filtered = False
            for i in dayset[start:end]:
                if ((bymonth and ii.mmask[i] not in bymonth) or
                    (byweekno and not ii.wnomask[i]) or
                    (byweekday and ii.wdaymask[i] not in byweekday) or
                    (ii.nwdaymask and not ii.nwdaymask[i]) or
                    (byeaster and not ii.eastermask[i]) or
                    ((bymonthday or bynmonthday) and
                     ii.mdaymask[i] not in bymonthday and
                     ii.nmdaymask[i] not in bynmonthday) or
                    (byyearday and
                     ((i < ii.yearlen and i+1 not in byyearday and
                       -ii.yearlen+i not in byyearday) or
                      (i >= ii.yearlen and i+1-ii.yearlen not in byyearday and
                       -ii.nextyearlen+i-ii.yearlen not in byyearday)))):
                    dayset[i] = None
                    filtered = True

            # Output results
            if bysetpos and timeset:
                poslist = []
                for pos in bysetpos:
                    if pos < 0:
                        daypos, timepos = divmod(pos, len(timeset))
                    else:
                        daypos, timepos = divmod(pos-1, len(timeset))
                    try:
                        i = [x for x in dayset[start:end]
                             if x is not None][daypos]
                        time = timeset[timepos]
                    except IndexError:
                        pass
                    else:
                        date = datetime.date.fromordinal(ii.yearordinal+i)
                        res = datetime.datetime.combine(date, time)
                        if res not in poslist:
                            poslist.append(res)
                poslist.sort()
                for res in poslist:
                    if until and res > until:
                        self._len = total
                        return
                    elif res >= self._dtstart:
                        if count is not None:
                            count -= 1
                            if count < 0:
                                self._len = total
                                return
                        total += 1
                        yield res
            else:
                for i in dayset[start:end]:
                    if i is not None:
                        date = datetime.date.fromordinal(ii.yearordinal + i)
                        for time in timeset:
                            res = datetime.datetime.combine(date, time)
                            if until and res > until:
                                self._len = total
                                return
                            elif res >= self._dtstart:
                                if count is not None:
                                    count -= 1
                                    if count < 0:
                                        self._len = total
                                        return

                                total += 1
                                yield res

            # Handle frequency and interval
            fixday = False
            if freq == YEARLY:
                year += interval
                if year > datetime.MAXYEAR:
                    self._len = total
                    return
                ii.rebuild(year, month)
            elif freq == MONTHLY:
                month += interval
                if month > 12:
                    div, mod = divmod(month, 12)
                    month = mod
                    year += div
                    if month == 0:
                        month = 12
                        year -= 1
                    if year > datetime.MAXYEAR:
                        self._len = total
                        return
                ii.rebuild(year, month)
            elif freq == WEEKLY:
                if wkst > weekday:
                    day += -(weekday+1+(6-wkst))+self._interval*7
                else:
                    day += -(weekday-wkst)+self._interval*7
                weekday = wkst
                fixday = True
            elif freq == DAILY:
                day += interval
                fixday = True
            elif freq == HOURLY:
                if filtered:
                    # Jump to one iteration before next day
                    hour += ((23-hour)//interval)*interval

                if byhour:
                    ndays, hour = self.__mod_distance(value=hour,
                                                      byxxx=self._byhour,
                                                      base=24)
                else:
                    ndays, hour = divmod(hour+interval, 24)

                if ndays:
                    day += ndays
                    fixday = True

                timeset = gettimeset(hour, minute, second)
            elif freq == MINUTELY:
                if filtered:
                    # Jump to one iteration before next day
                    minute += ((1439-(hour*60+minute))//interval)*interval

                valid = False
                rep_rate = (24*60)
                for j in range(rep_rate // gcd(interval, rep_rate)):
                    if byminute:
                        nhours, minute = \
                            self.__mod_distance(value=minute,
                                                byxxx=self._byminute,
                                                base=60)
                    else:
                        nhours, minute = divmod(minute+interval, 60)

                    div, hour = divmod(hour+nhours, 24)
                    if div:
                        day += div
                        fixday = True
                        filtered = False

                    if not byhour or hour in byhour:
                        valid = True
                        break

                if not valid:
                    raise ValueError('Invalid combination of interval and ' +
                                     'byhour resulting in empty rule.')

                timeset = gettimeset(hour, minute, second)
            elif freq == SECONDLY:
                if filtered:
                    # Jump to one iteration before next day
                    second += (((86399 - (hour * 3600 + minute * 60 + second))
                                // interval) * interval)

                rep_rate = (24 * 3600)
                valid = False
                for j in range(0, rep_rate // gcd(interval, rep_rate)):
                    if bysecond:
                        nminutes, second = \
                            self.__mod_distance(value=second,
                                                byxxx=self._bysecond,
                                                base=60)
                    else:
                        nminutes, second = divmod(second+interval, 60)

                    div, minute = divmod(minute+nminutes, 60)
                    if div:
                        hour += div
                        div, hour = divmod(hour, 24)
                        if div:
                            day += div
                            fixday = True

                    if ((not byhour or hour in byhour) and
                            (not byminute or minute in byminute) and
                            (not bysecond or second in bysecond)):
                        valid = True
                        break

                if not valid:
                    raise ValueError('Invalid combination of interval, ' +
                                     'byhour and byminute resulting in empty' +
                                     ' rule.')

                timeset = gettimeset(hour, minute, second)

            if fixday and day > 28:
                daysinmonth = calendar.monthrange(year, month)[1]
                if day > daysinmonth:
                    while day > daysinmonth:
                        day -= daysinmonth
                        month += 1
                        if month == 13:
                            month = 1
                            year += 1
                            if year > datetime.MAXYEAR:
                                self._len = total
                                return
                        daysinmonth = calendar.monthrange(year, month)[1]
                    ii.rebuild(year, month)

    def __construct_byset(self, start, byxxx, base):
        """
        If a `BYXXX` sequence is passed to the constructor at the same level as
        `FREQ` (e.g. `FREQ=HOURLY,BYHOUR={2,4,7},INTERVAL=3`), there are some
        specifications which cannot be reached given some starting conditions.

        This occurs whenever the interval is not coprime with the base of a
        given unit and the difference between the starting position and the
        ending position is not coprime with the greatest common denominator
        between the interval and the base. For example, with a FREQ of hourly
        starting at 17:00 and an interval of 4, the only valid values for
        BYHOUR would be {21, 1, 5, 9, 13, 17}, because 4 and 24 are not
        coprime.

        :param start:
            Specifies the starting position.
        :param byxxx:
            An iterable containing the list of allowed values.
        :param base:
            The largest allowable value for the specified frequency (e.g.
            24 hours, 60 minutes).

        This does not preserve the type of the iterable, returning a set, since
        the values should be unique and the order is irrelevant, this will
        speed up later lookups.

        In the event of an empty set, raises a :exception:`ValueError`, as this
        results in an empty rrule.
        """

        cset = set()

        # Support a single byxxx value.
        if isinstance(byxxx, integer_types):
            byxxx = (byxxx, )

        for num in byxxx:
            i_gcd = gcd(self._interval, base)
            # Use divmod rather than % because we need to wrap negative nums.
            if i_gcd == 1 or divmod(num - start, i_gcd)[1] == 0:
                cset.add(num)

        if len(cset) == 0:
            raise ValueError("Invalid rrule byxxx generates an empty set.")

        return cset

    def __mod_distance(self, value, byxxx, base):
        """
        Calculates the next value in a sequence where the `FREQ` parameter is
        specified along with a `BYXXX` parameter at the same "level"
        (e.g. `HOURLY` specified with `BYHOUR`).

        :param value:
            The old value of the component.
        :param byxxx:
            The `BYXXX` set, which should have been generated by
            `rrule._construct_byset`, or something else which checks that a
            valid rule is present.
        :param base:
            The largest allowable value for the specified frequency (e.g.
            24 hours, 60 minutes).

        If a valid value is not found after `base` iterations (the maximum
        number before the sequence would start to repeat), this raises a
        :exception:`ValueError`, as no valid values were found.

        This returns a tuple of `divmod(n*interval, base)`, where `n` is the
        smallest number of `interval` repetitions until the next specified
        value in `byxxx` is found.
        """
        accumulator = 0
        for ii in range(1, base + 1):
            # Using divmod() over % to account for negative intervals
            div, value = divmod(value + self._interval, base)
            accumulator += div
            if value in byxxx:
                return (accumulator, value)


class _iterinfo(object):
    __slots__ = ["rrule", "lastyear", "lastmonth",
                 "yearlen", "nextyearlen", "yearordinal", "yearweekday",
                 "mmask", "mrange", "mdaymask", "nmdaymask",
                 "wdaymask", "wnomask", "nwdaymask", "eastermask"]

    def __init__(self, rrule):
        for attr in self.__slots__:
            setattr(self, attr, None)
        self.rrule = rrule

    def rebuild(self, year, month):
        # Every mask is 7 days longer to handle cross-year weekly periods.
        rr = self.rrule
        if year != self.lastyear:
            self.yearlen = 365 + calendar.isleap(year)
            self.nextyearlen = 365 + calendar.isleap(year + 1)
            firstyday = datetime.date(year, 1, 1)
            self.yearordinal = firstyday.toordinal()
            self.yearweekday = firstyday.weekday()

            wday = datetime.date(year, 1, 1).weekday()
            if self.yearlen == 365:
                self.mmask = M365MASK
                self.mdaymask = MDAY365MASK
                self.nmdaymask = NMDAY365MASK
                self.wdaymask = WDAYMASK[wday:]
                self.mrange = M365RANGE
            else:
                self.mmask = M366MASK
                self.mdaymask = MDAY366MASK
                self.nmdaymask = NMDAY366MASK
                self.wdaymask = WDAYMASK[wday:]
                self.mrange = M366RANGE

            if not rr._byweekno:
                self.wnomask = None
            else:
                self.wnomask = [0]*(self.yearlen+7)
                # no1wkst = firstwkst = self.wdaymask.index(rr._wkst)
                no1wkst = firstwkst = (7-self.yearweekday+rr._wkst) % 7
                if no1wkst >= 4:
                    no1wkst = 0
                    # Number of days in the year, plus the days we got
                    # from last year.
                    wyearlen = self.yearlen+(self.yearweekday-rr._wkst) % 7
                else:
                    # Number of days in the year, minus the days we
                    # left in last year.
                    wyearlen = self.yearlen-no1wkst
                div, mod = divmod(wyearlen, 7)
                numweeks = div+mod//4
                for n in rr._byweekno:
                    if n < 0:
                        n += numweeks+1
                    if not (0 < n <= numweeks):
                        continue
                    if n > 1:
                        i = no1wkst+(n-1)*7
                        if no1wkst != firstwkst:
                            i -= 7-firstwkst
                    else:
                        i = no1wkst
                    for j in range(7):
                        self.wnomask[i] = 1
                        i += 1
                        if self.wdaymask[i] == rr._wkst:
                            break
                if 1 in rr._byweekno:
                    # Check week number 1 of next year as well
                    # TODO: Check -numweeks for next year.
                    i = no1wkst+numweeks*7
                    if no1wkst != firstwkst:
                        i -= 7-firstwkst
                    if i < self.yearlen:
                        # If week starts in next year, we
                        # don't care about it.
                        for j in range(7):
                            self.wnomask[i] = 1
                            i += 1
                            if self.wdaymask[i] == rr._wkst:
                                break
                if no1wkst:
                    # Check last week number of last year as
                    # well. If no1wkst is 0, either the year
                    # started on week start, or week number 1
                    # got days from last year, so there are no
                    # days from last year's last week number in
                    # this year.
                    if -1 not in rr._byweekno:
                        lyearweekday = datetime.date(year-1, 1, 1).weekday()
                        lno1wkst = (7-lyearweekday+rr._wkst) % 7
                        lyearlen = 365+calendar.isleap(year-1)
                        if lno1wkst >= 4:
                            lno1wkst = 0
                            lnumweeks = 52+(lyearlen +
                                            (lyearweekday-rr._wkst) % 7) % 7//4
                        else:
                            lnumweeks = 52+(self.yearlen-no1wkst) % 7//4
                    else:
                        lnumweeks = -1
                    if lnumweeks in rr._byweekno:
                        for i in range(no1wkst):
                            self.wnomask[i] = 1

        if (rr._bynweekday and (month != self.lastmonth or
                                year != self.lastyear)):
            ranges = []
            if rr._freq == YEARLY:
                if rr._bymonth:
                    for month in rr._bymonth:
                        ranges.append(self.mrange[month-1:month+1])
                else:
                    ranges = [(0, self.yearlen)]
            elif rr._freq == MONTHLY:
                ranges = [self.mrange[month-1:month+1]]
            if ranges:
                # Weekly frequency won't get here, so we may not
                # care about cross-year weekly periods.
                self.nwdaymask = [0]*self.yearlen
                for first, last in ranges:
                    last -= 1
                    for wday, n in rr._bynweekday:
                        if n < 0:
                            i = last+(n+1)*7
                            i -= (self.wdaymask[i]-wday) % 7
                        else:
                            i = first+(n-1)*7
                            i += (7-self.wdaymask[i]+wday) % 7
                        if first <= i <= last:
                            self.nwdaymask[i] = 1

        if rr._byeaster:
            self.eastermask = [0]*(self.yearlen+7)
            eyday = easter.easter(year).toordinal()-self.yearordinal
            for offset in rr._byeaster:
                self.eastermask[eyday+offset] = 1

        self.lastyear = year
        self.lastmonth = month

    def ydayset(self, year, month, day):
        return list(range(self.yearlen)), 0, self.yearlen

    def mdayset(self, year, month, day):
        dset = [None]*self.yearlen
        start, end = self.mrange[month-1:month+1]
        for i in range(start, end):
            dset[i] = i
        return dset, start, end

    def wdayset(self, year, month, day):
        # We need to handle cross-year weeks here.
        dset = [None]*(self.yearlen+7)
        i = datetime.date(year, month, day).toordinal()-self.yearordinal
        start = i
        for j in range(7):
            dset[i] = i
            i += 1
            # if (not (0 <= i < self.yearlen) or
            #    self.wdaymask[i] == self.rrule._wkst):
            # This will cross the year boundary, if necessary.
            if self.wdaymask[i] == self.rrule._wkst:
                break
        return dset, start, i

    def ddayset(self, year, month, day):
        dset = [None] * self.yearlen
        i = datetime.date(year, month, day).toordinal() - self.yearordinal
        dset[i] = i
        return dset, i, i + 1

    def htimeset(self, hour, minute, second):
        tset = []
        rr = self.rrule
        for minute in rr._byminute:
            for second in rr._bysecond:
                tset.append(datetime.time(hour, minute, second,
                                          tzinfo=rr._tzinfo))
        tset.sort()
        return tset

    def mtimeset(self, hour, minute, second):
        tset = []
        rr = self.rrule
        for second in rr._bysecond:
            tset.append(datetime.time(hour, minute, second, tzinfo=rr._tzinfo))
        tset.sort()
        return tset

    def stimeset(self, hour, minute, second):
        return (datetime.time(hour, minute, second,
                tzinfo=self.rrule._tzinfo),)


class rruleset(rrulebase):
    """ The rruleset type allows more complex recurrence setups, mixing
    multiple rules, dates, exclusion rules, and exclusion dates. The type
    constructor takes the following keyword arguments:

    :param cache: If True, caching of results will be enabled, improving
                  performance of multiple queries considerably. """

    class _genitem(object):
        def __init__(self, genlist, gen):
            try:
                self.dt = advance_iterator(gen)
                genlist.append(self)
            except StopIteration:
                pass
            self.genlist = genlist
            self.gen = gen

        def __next__(self):
            try:
                self.dt = advance_iterator(self.gen)
            except StopIteration:
                if self.genlist[0] is self:
                    heapq.heappop(self.genlist)
                else:
                    self.genlist.remove(self)
                    heapq.heapify(self.genlist)

        next = __next__

        def __lt__(self, other):
            return self.dt < other.dt

        def __gt__(self, other):
            return self.dt > other.dt

        def __eq__(self, other):
            return self.dt == other.dt

        def __ne__(self, other):
            return self.dt != other.dt

    def __init__(self, cache=False):
        super(rruleset, self).__init__(cache)
        self._rrule = []
        self._rdate = []
        self._exrule = []
        self._exdate = []

    @_invalidates_cache
    def rrule(self, rrule):
        """ Include the given :py:class:`rrule` instance in the recurrence set
            generation. """
        self._rrule.append(rrule)

    @_invalidates_cache
    def rdate(self, rdate):
        """ Include the given :py:class:`datetime` instance in the recurrence
            set generation. """
        self._rdate.append(rdate)

    @_invalidates_cache
    def exrule(self, exrule):
        """ Include the given rrule instance in the recurrence set exclusion
            list. Dates which are part of the given recurrence rules will not
            be generated, even if some inclusive rrule or rdate matches them.
        """
        self._exrule.append(exrule)

    @_invalidates_cache
    def exdate(self, exdate):
        """ Include the given datetime instance in the recurrence set
            exclusion list. Dates included that way will not be generated,
            even if some inclusive rrule or rdate matches them. """
        self._exdate.append(exdate)

    def _iter(self):
        rlist = []
        self._rdate.sort()
        self._genitem(rlist, iter(self._rdate))
        for gen in [iter(x) for x in self._rrule]:
            self._genitem(rlist, gen)
        exlist = []
        self._exdate.sort()
        self._genitem(exlist, iter(self._exdate))
        for gen in [iter(x) for x in self._exrule]:
            self._genitem(exlist, gen)
        lastdt = None
        total = 0
        heapq.heapify(rlist)
        heapq.heapify(exlist)
        while rlist:
            ritem = rlist[0]
            if not lastdt or lastdt != ritem.dt:
                while exlist and exlist[0] < ritem:
                    exitem = exlist[0]
                    advance_iterator(exitem)
                    if exlist and exlist[0] is exitem:
                        heapq.heapreplace(exlist, exitem)
                if not exlist or ritem != exlist[0]:
                    total += 1
                    yield ritem.dt
                lastdt = ritem.dt
            advance_iterator(ritem)
            if rlist and rlist[0] is ritem:
                heapq.heapreplace(rlist, ritem)
        self._len = total




class _rrulestr(object):
    """ Parses a string representation of a recurrence rule or set of
    recurrence rules.

    :param s:
        Required, a string defining one or more recurrence rules.

    :param dtstart:
        If given, used as the default recurrence start if not specified in the
        rule string.

    :param cache:
        If set ``True`` caching of results will be enabled, improving
        performance of multiple queries considerably.

    :param unfold:
        If set ``True`` indicates that a rule string is split over more
        than one line and should be joined before processing.

    :param forceset:
        If set ``True`` forces a :class:`dateutil.rrule.rruleset` to
        be returned.

    :param compatible:
        If set ``True`` forces ``unfold`` and ``forceset`` to be ``True``.

    :param ignoretz:
        If set ``True``, time zones in parsed strings are ignored and a naive
        :class:`datetime.datetime` object is returned.

    :param tzids:
        If given, a callable or mapping used to retrieve a
        :class:`datetime.tzinfo` from a string representation.
        Defaults to :func:`dateutil.tz.gettz`.

    :param tzinfos:
        Additional time zone names / aliases which may be present in a string
        representation.  See :func:`dateutil.parser.parse` for more
        information.

    :return:
        Returns a :class:`dateutil.rrule.rruleset` or
        :class:`dateutil.rrule.rrule`
    """

    _freq_map = {"YEARLY": YEARLY,
                 "MONTHLY": MONTHLY,
                 "WEEKLY": WEEKLY,
                 "DAILY": DAILY,
                 "HOURLY": HOURLY,
                 "MINUTELY": MINUTELY,
                 "SECONDLY": SECONDLY}

    _weekday_map = {"MO": 0, "TU": 1, "WE": 2, "TH": 3,
                    "FR": 4, "SA": 5, "SU": 6}

    def _handle_int(self, rrkwargs, name, value, **kwargs):
        rrkwargs[name.lower()] = int(value)

    def _handle_int_list(self, rrkwargs, name, value, **kwargs):
        rrkwargs[name.lower()] = [int(x) for x in value.split(',')]

    _handle_INTERVAL = _handle_int
    _handle_COUNT = _handle_int
    _handle_BYSETPOS = _handle_int_list
    _handle_BYMONTH = _handle_int_list
    _handle_BYMONTHDAY = _handle_int_list
    _handle_BYYEARDAY = _handle_int_list
    _handle_BYEASTER = _handle_int_list
    _handle_BYWEEKNO = _handle_int_list
    _handle_BYHOUR = _handle_int_list
    _handle_BYMINUTE = _handle_int_list
    _handle_BYSECOND = _handle_int_list

    def _handle_FREQ(self, rrkwargs, name, value, **kwargs):
        rrkwargs["freq"] = self._freq_map[value]

    def _handle_UNTIL(self, rrkwargs, name, value, **kwargs):
        global parser
        if not parser:
            from dateutil import parser
        try:
            rrkwargs["until"] = parser.parse(value,
                                             ignoretz=kwargs.get("ignoretz"),
                                             tzinfos=kwargs.get("tzinfos"))
        except ValueError:
            raise ValueError("invalid until date")

    def _handle_WKST(self, rrkwargs, name, value, **kwargs):
        rrkwargs["wkst"] = self._weekday_map[value]

    def _handle_BYWEEKDAY(self, rrkwargs, name, value, **kwargs):
        """
        Two ways to specify this: +1MO or MO(+1)
        """
        l = []
        for wday in value.split(','):
            if '(' in wday:
                # If it's of the form TH(+1), etc.
                splt = wday.split('(')
                w = splt[0]
                n = int(splt[1][:-1])
            elif len(wday):
                # If it's of the form +1MO
                for i in range(len(wday)):
                    if wday[i] not in '+-0123456789':
                        break
                n = wday[:i] or None
                w = wday[i:]
                if n:
                    n = int(n)
            else:
                raise ValueError("Invalid (empty) BYDAY specification.")

            l.append(weekdays[self._weekday_map[w]](n))
        rrkwargs["byweekday"] = l

    _handle_BYDAY = _handle_BYWEEKDAY

    def _parse_rfc_rrule(self, line,
                         dtstart=None,
                         cache=False,
                         ignoretz=False,
                         tzinfos=None):
        if line.find(':') != -1:
            name, value = line.split(':')
            if name != "RRULE":
                raise ValueError("unknown parameter name")
        else:
            value = line
        rrkwargs = {}
        for pair in value.split(';'):
            name, value = pair.split('=')
            name = name.upper()
            value = value.upper()
            try:
                getattr(self, "_handle_"+name)(rrkwargs, name, value,
                                               ignoretz=ignoretz,
                                               tzinfos=tzinfos)
            except AttributeError:
                raise ValueError("unknown parameter '%s'" % name)
            except (KeyError, ValueError):
                raise ValueError("invalid '%s': %s" % (name, value))
        return rrule(dtstart=dtstart, cache=cache, **rrkwargs)

    def _parse_date_value(self, date_value, parms, rule_tzids,
                          ignoretz, tzids, tzinfos):
        global parser
        if not parser:
            from dateutil import parser

        datevals = []
        value_found = False
        TZID = None

        for parm in parms:
            if parm.startswith("TZID="):
                try:
                    tzkey = rule_tzids[parm.split('TZID=')[-1]]
                except KeyError:
                    continue
                if tzids is None:
                    from . import tz
                    tzlookup = tz.gettz
                elif callable(tzids):
                    tzlookup = tzids
                else:
                    tzlookup = getattr(tzids, 'get', None)
                    if tzlookup is None:
                        msg = ('tzids must be a callable, mapping, or None, '
                               'not %s' % tzids)
                        raise ValueError(msg)

                TZID = tzlookup(tzkey)
                continue

            # RFC 5445 3.8.2.4: The VALUE parameter is optional, but may be found
            # only once.
            if parm not in {"VALUE=DATE-TIME", "VALUE=DATE"}:
                raise ValueError("unsupported parm: " + parm)
            else:
                if value_found:
                    msg = ("Duplicate value parameter found in: " + parm)
                    raise ValueError(msg)
                value_found = True

        for datestr in date_value.split(','):
            date = parser.parse(datestr, ignoretz=ignoretz, tzinfos=tzinfos)
            if TZID is not None:
                if date.tzinfo is None:
                    date = date.replace(tzinfo=TZID)
                else:
                    raise ValueError('DTSTART/EXDATE specifies multiple timezone')
            datevals.append(date)

        return datevals

    def _parse_rfc(self, s,
                   dtstart=None,
                   cache=False,
                   unfold=False,
                   forceset=False,
                   compatible=False,
                   ignoretz=False,
                   tzids=None,
                   tzinfos=None):
        global parser
        if compatible:
            forceset = True
            unfold = True

        TZID_NAMES = dict(map(
            lambda x: (x.upper(), x),
            re.findall('TZID=(?P<name>[^:]+):', s)
        ))
        s = s.upper()
        if not s.strip():
            raise ValueError("empty string")
        if unfold:
            lines = s.splitlines()
            i = 0
            while i < len(lines):
                line = lines[i].rstrip()
                if not line:
                    del lines[i]
                elif i > 0 and line[0] == " ":
                    lines[i-1] += line[1:]
                    del lines[i]
                else:
                    i += 1
        else:
            lines = s.split()
        if (not forceset and len(lines) == 1 and (s.find(':') == -1 or
                                                  s.startswith('RRULE:'))):
            return self._parse_rfc_rrule(lines[0], cache=cache,
                                         dtstart=dtstart, ignoretz=ignoretz,
                                         tzinfos=tzinfos)
        else:
            rrulevals = []
            rdatevals = []
            exrulevals = []
            exdatevals = []
            for line in lines:
                if not line:
                    continue
                if line.find(':') == -1:
                    name = "RRULE"
                    value = line
                else:
                    name, value = line.split(':', 1)
                parms = name.split(';')
                if not parms:
                    raise ValueError("empty property name")
                name = parms[0]
                parms = parms[1:]
                if name == "RRULE":
                    for parm in parms:
                        raise ValueError("unsupported RRULE parm: "+parm)
                    rrulevals.append(value)
                elif name == "RDATE":
                    for parm in parms:
                        if parm != "VALUE=DATE-TIME":
                            raise ValueError("unsupported RDATE parm: "+parm)
                    rdatevals.append(value)
                elif name == "EXRULE":
                    for parm in parms:
                        raise ValueError("unsupported EXRULE parm: "+parm)
                    exrulevals.append(value)
                elif name == "EXDATE":
                    exdatevals.extend(
                        self._parse_date_value(value, parms,
                                               TZID_NAMES, ignoretz,
                                               tzids, tzinfos)
                    )
                elif name == "DTSTART":
                    dtvals = self._parse_date_value(value, parms, TZID_NAMES,
                                                    ignoretz, tzids, tzinfos)
                    if len(dtvals) != 1:
                        raise ValueError("Multiple DTSTART values specified:" +
                                         value)
                    dtstart = dtvals[0]
                else:
                    raise ValueError("unsupported property: "+name)
            if (forceset or len(rrulevals) > 1 or rdatevals
                    or exrulevals or exdatevals):
                if not parser and (rdatevals or exdatevals):
                    from dateutil import parser
                rset = rruleset(cache=cache)
                for value in rrulevals:
                    rset.rrule(self._parse_rfc_rrule(value, dtstart=dtstart,
                                                     ignoretz=ignoretz,
                                                     tzinfos=tzinfos))
                for value in rdatevals:
                    for datestr in value.split(','):
                        rset.rdate(parser.parse(datestr,
                                                ignoretz=ignoretz,
                                                tzinfos=tzinfos))
                for value in exrulevals:
                    rset.exrule(self._parse_rfc_rrule(value, dtstart=dtstart,
                                                      ignoretz=ignoretz,
                                                      tzinfos=tzinfos))
                for value in exdatevals:
                    rset.exdate(value)
                if compatible and dtstart:
                    rset.rdate(dtstart)
                return rset
            else:
                return self._parse_rfc_rrule(rrulevals[0],
                                             dtstart=dtstart,
                                             cache=cache,
                                             ignoretz=ignoretz,
                                             tzinfos=tzinfos)

    def __call__(self, s, **kwargs):
        return self._parse_rfc(s, **kwargs)


rrulestr = _rrulestr()

# vim:ts=4:sw=4:et




############################################################
### File: sbcharsetprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from collections import namedtuple

from .charsetprober import CharSetProber
from .enums import CharacterCategory, ProbingState, SequenceLikelihood


SingleByteCharSetModel = namedtuple('SingleByteCharSetModel',
                                    ['charset_name',
                                     'language',
                                     'char_to_order_map',
                                     'language_model',
                                     'typical_positive_ratio',
                                     'keep_ascii_letters',
                                     'alphabet'])


class SingleByteCharSetProber(CharSetProber):
    SAMPLE_SIZE = 64
    SB_ENOUGH_REL_THRESHOLD = 1024  #  0.25 * SAMPLE_SIZE^2
    POSITIVE_SHORTCUT_THRESHOLD = 0.95
    NEGATIVE_SHORTCUT_THRESHOLD = 0.05

    def __init__(self, model, reversed=False, name_prober=None):
        super(SingleByteCharSetProber, self).__init__()
        self._model = model
        # TRUE if we need to reverse every pair in the model lookup
        self._reversed = reversed
        # Optional auxiliary prober for name decision
        self._name_prober = name_prober
        self._last_order = None
        self._seq_counters = None
        self._total_seqs = None
        self._total_char = None
        self._freq_char = None
        self.reset()

    def reset(self):
        super(SingleByteCharSetProber, self).reset()
        # char order of last character
        self._last_order = 255
        self._seq_counters = [0] * SequenceLikelihood.get_num_categories()
        self._total_seqs = 0
        self._total_char = 0
        # characters that fall in our sampling range
        self._freq_char = 0

    @property
    def charset_name(self):
        if self._name_prober:
            return self._name_prober.charset_name
        else:
            return self._model.charset_name

    @property
    def language(self):
        if self._name_prober:
            return self._name_prober.language
        else:
            return self._model.language

    def feed(self, byte_str):
        # TODO: Make filter_international_words keep things in self.alphabet
        if not self._model.keep_ascii_letters:
            byte_str = self.filter_international_words(byte_str)
        if not byte_str:
            return self.state
        char_to_order_map = self._model.char_to_order_map
        language_model = self._model.language_model
        for char in byte_str:
            order = char_to_order_map.get(char, CharacterCategory.UNDEFINED)
            # XXX: This was SYMBOL_CAT_ORDER before, with a value of 250, but
            #      CharacterCategory.SYMBOL is actually 253, so we use CONTROL
            #      to make it closer to the original intent. The only difference
            #      is whether or not we count digits and control characters for
            #      _total_char purposes.
            if order < CharacterCategory.CONTROL:
                self._total_char += 1
            # TODO: Follow uchardet's lead and discount confidence for frequent
            #       control characters.
            #       See https://github.com/BYVoid/uchardet/commit/55b4f23971db61
            if order < self.SAMPLE_SIZE:
                self._freq_char += 1
                if self._last_order < self.SAMPLE_SIZE:
                    self._total_seqs += 1
                    if not self._reversed:
                        lm_cat = language_model[self._last_order][order]
                    else:
                        lm_cat = language_model[order][self._last_order]
                    self._seq_counters[lm_cat] += 1
            self._last_order = order

        charset_name = self._model.charset_name
        if self.state == ProbingState.DETECTING:
            if self._total_seqs > self.SB_ENOUGH_REL_THRESHOLD:
                confidence = self.get_confidence()
                if confidence > self.POSITIVE_SHORTCUT_THRESHOLD:
                    self.logger.debug('%s confidence = %s, we have a winner',
                                      charset_name, confidence)
                    self._state = ProbingState.FOUND_IT
                elif confidence < self.NEGATIVE_SHORTCUT_THRESHOLD:
                    self.logger.debug('%s confidence = %s, below negative '
                                      'shortcut threshhold %s', charset_name,
                                      confidence,
                                      self.NEGATIVE_SHORTCUT_THRESHOLD)
                    self._state = ProbingState.NOT_ME

        return self.state

    def get_confidence(self):
        r = 0.01
        if self._total_seqs > 0:
            r = ((1.0 * self._seq_counters[SequenceLikelihood.POSITIVE]) /
                 self._total_seqs / self._model.typical_positive_ratio)
            r = r * self._freq_char / self._total_char
            if r >= 1.0:
                r = 0.99
        return r




############################################################
### File: sbcsgroupprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetgroupprober import CharSetGroupProber
from .hebrewprober import HebrewProber
from .langbulgarianmodel import (ISO_8859_5_BULGARIAN_MODEL,
                                 WINDOWS_1251_BULGARIAN_MODEL)
from .langgreekmodel import ISO_8859_7_GREEK_MODEL, WINDOWS_1253_GREEK_MODEL
from .langhebrewmodel import WINDOWS_1255_HEBREW_MODEL
# from .langhungarianmodel import (ISO_8859_2_HUNGARIAN_MODEL,
#                                  WINDOWS_1250_HUNGARIAN_MODEL)
from .langrussianmodel import (IBM855_RUSSIAN_MODEL, IBM866_RUSSIAN_MODEL,
                               ISO_8859_5_RUSSIAN_MODEL, KOI8_R_RUSSIAN_MODEL,
                               MACCYRILLIC_RUSSIAN_MODEL,
                               WINDOWS_1251_RUSSIAN_MODEL)
from .langthaimodel import TIS_620_THAI_MODEL
from .langturkishmodel import ISO_8859_9_TURKISH_MODEL
from .sbcharsetprober import SingleByteCharSetProber


class SBCSGroupProber(CharSetGroupProber):
    def __init__(self):
        super(SBCSGroupProber, self).__init__()
        hebrew_prober = HebrewProber()
        logical_hebrew_prober = SingleByteCharSetProber(WINDOWS_1255_HEBREW_MODEL,
                                                        False, hebrew_prober)
        # TODO: See if using ISO-8859-8 Hebrew model works better here, since
        #       it's actually the visual one
        visual_hebrew_prober = SingleByteCharSetProber(WINDOWS_1255_HEBREW_MODEL,
                                                       True, hebrew_prober)
        hebrew_prober.set_model_probers(logical_hebrew_prober,
                                        visual_hebrew_prober)
        # TODO: ORDER MATTERS HERE. I changed the order vs what was in master
        #       and several tests failed that did not before. Some thought
        #       should be put into the ordering, and we should consider making
        #       order not matter here, because that is very counter-intuitive.
        self.probers = [
            SingleByteCharSetProber(WINDOWS_1251_RUSSIAN_MODEL),
            SingleByteCharSetProber(KOI8_R_RUSSIAN_MODEL),
            SingleByteCharSetProber(ISO_8859_5_RUSSIAN_MODEL),
            SingleByteCharSetProber(MACCYRILLIC_RUSSIAN_MODEL),
            SingleByteCharSetProber(IBM866_RUSSIAN_MODEL),
            SingleByteCharSetProber(IBM855_RUSSIAN_MODEL),
            SingleByteCharSetProber(ISO_8859_7_GREEK_MODEL),
            SingleByteCharSetProber(WINDOWS_1253_GREEK_MODEL),
            SingleByteCharSetProber(ISO_8859_5_BULGARIAN_MODEL),
            SingleByteCharSetProber(WINDOWS_1251_BULGARIAN_MODEL),
            # TODO: Restore Hungarian encodings (iso-8859-2 and windows-1250)
            #       after we retrain model.
            # SingleByteCharSetProber(ISO_8859_2_HUNGARIAN_MODEL),
            # SingleByteCharSetProber(WINDOWS_1250_HUNGARIAN_MODEL),
            SingleByteCharSetProber(TIS_620_THAI_MODEL),
            SingleByteCharSetProber(ISO_8859_9_TURKISH_MODEL),
            hebrew_prober,
            logical_hebrew_prober,
            visual_hebrew_prober,
        ]
        self.reset()




############################################################
### File: sessions.py
############################################################
# -*- coding: utf-8 -*-

"""
requests.sessions
~~~~~~~~~~~~~~~~~

This module provides a Session object to manage and persist settings across
requests (cookies, auth, proxies).
"""
import os
import sys
import time
from datetime import timedelta
from collections import OrderedDict

from .auth import _basic_auth_str
from .compat import cookielib, is_py3, urljoin, urlparse, Mapping
from .cookies import (
    cookiejar_from_dict, extract_cookies_to_jar, RequestsCookieJar, merge_cookies)
from .models import Request, PreparedRequest, DEFAULT_REDIRECT_LIMIT
from .hooks import default_hooks, dispatch_hook
from ._internal_utils import to_native_string
from .utils import to_key_val_list, default_headers, DEFAULT_PORTS
from .exceptions import (
    TooManyRedirects, InvalidSchema, ChunkedEncodingError, ContentDecodingError)

from .structures import CaseInsensitiveDict
from .adapters import HTTPAdapter

from .utils import (
    requote_uri, get_environ_proxies, get_netrc_auth, should_bypass_proxies,
    get_auth_from_url, rewind_body, resolve_proxies
)

from .status_codes import codes

# formerly defined here, reexposed here for backward compatibility
from .models import REDIRECT_STATI

# Preferred clock, based on which one is more accurate on a given system.
if sys.platform == 'win32':
    try:  # Python 3.4+
        preferred_clock = time.perf_counter
    except AttributeError:  # Earlier than Python 3.
        preferred_clock = time.clock
else:
    preferred_clock = time.time


def merge_setting(request_setting, session_setting, dict_class=OrderedDict):
    """Determines appropriate setting for a given request, taking into account
    the explicit setting on that request, and the setting in the session. If a
    setting is a dictionary, they will be merged together using `dict_class`
    """

    if session_setting is None:
        return request_setting

    if request_setting is None:
        return session_setting

    # Bypass if not a dictionary (e.g. verify)
    if not (
            isinstance(session_setting, Mapping) and
            isinstance(request_setting, Mapping)
    ):
        return request_setting

    merged_setting = dict_class(to_key_val_list(session_setting))
    merged_setting.update(to_key_val_list(request_setting))

    # Remove keys that are set to None. Extract keys first to avoid altering
    # the dictionary during iteration.
    none_keys = [k for (k, v) in merged_setting.items() if v is None]
    for key in none_keys:
        del merged_setting[key]

    return merged_setting


def merge_hooks(request_hooks, session_hooks, dict_class=OrderedDict):
    """Properly merges both requests and session hooks.

    This is necessary because when request_hooks == {'response': []}, the
    merge breaks Session hooks entirely.
    """
    if session_hooks is None or session_hooks.get('response') == []:
        return request_hooks

    if request_hooks is None or request_hooks.get('response') == []:
        return session_hooks

    return merge_setting(request_hooks, session_hooks, dict_class)


class SessionRedirectMixin(object):

    def get_redirect_target(self, resp):
        """Receives a Response. Returns a redirect URI or ``None``"""
        # Due to the nature of how requests processes redirects this method will
        # be called at least once upon the original response and at least twice
        # on each subsequent redirect response (if any).
        # If a custom mixin is used to handle this logic, it may be advantageous
        # to cache the redirect location onto the response object as a private
        # attribute.
        if resp.is_redirect:
            location = resp.headers['location']
            # Currently the underlying http module on py3 decode headers
            # in latin1, but empirical evidence suggests that latin1 is very
            # rarely used with non-ASCII characters in HTTP headers.
            # It is more likely to get UTF8 header rather than latin1.
            # This causes incorrect handling of UTF8 encoded location headers.
            # To solve this, we re-encode the location in latin1.
            if is_py3:
                location = location.encode('latin1')
            return to_native_string(location, 'utf8')
        return None

    def should_strip_auth(self, old_url, new_url):
        """Decide whether Authorization header should be removed when redirecting"""
        old_parsed = urlparse(old_url)
        new_parsed = urlparse(new_url)
        if old_parsed.hostname != new_parsed.hostname:
            return True
        # Special case: allow http -> https redirect when using the standard
        # ports. This isn't specified by RFC 7235, but is kept to avoid
        # breaking backwards compatibility with older versions of requests
        # that allowed any redirects on the same host.
        if (old_parsed.scheme == 'http' and old_parsed.port in (80, None)
                and new_parsed.scheme == 'https' and new_parsed.port in (443, None)):
            return False

        # Handle default port usage corresponding to scheme.
        changed_port = old_parsed.port != new_parsed.port
        changed_scheme = old_parsed.scheme != new_parsed.scheme
        default_port = (DEFAULT_PORTS.get(old_parsed.scheme, None), None)
        if (not changed_scheme and old_parsed.port in default_port
                and new_parsed.port in default_port):
            return False

        # Standard case: root URI must match
        return changed_port or changed_scheme

    def resolve_redirects(self, resp, req, stream=False, timeout=None,
                          verify=True, cert=None, proxies=None, yield_requests=False, **adapter_kwargs):
        """Receives a Response. Returns a generator of Responses or Requests."""

        hist = []  # keep track of history

        url = self.get_redirect_target(resp)
        previous_fragment = urlparse(req.url).fragment
        while url:
            prepared_request = req.copy()

            # Update history and keep track of redirects.
            # resp.history must ignore the original request in this loop
            hist.append(resp)
            resp.history = hist[1:]

            try:
                resp.content  # Consume socket so it can be released
            except (ChunkedEncodingError, ContentDecodingError, RuntimeError):
                resp.raw.read(decode_content=False)

            if len(resp.history) >= self.max_redirects:
                raise TooManyRedirects('Exceeded {} redirects.'.format(self.max_redirects), response=resp)

            # Release the connection back into the pool.
            resp.close()

            # Handle redirection without scheme (see: RFC 1808 Section 4)
            if url.startswith('//'):
                parsed_rurl = urlparse(resp.url)
                url = ':'.join([to_native_string(parsed_rurl.scheme), url])

            # Normalize url case and attach previous fragment if needed (RFC 7231 7.1.2)
            parsed = urlparse(url)
            if parsed.fragment == '' and previous_fragment:
                parsed = parsed._replace(fragment=previous_fragment)
            elif parsed.fragment:
                previous_fragment = parsed.fragment
            url = parsed.geturl()

            # Facilitate relative 'location' headers, as allowed by RFC 7231.
            # (e.g. '/path/to/resource' instead of 'http://domain.tld/path/to/resource')
            # Compliant with RFC3986, we percent encode the url.
            if not parsed.netloc:
                url = urljoin(resp.url, requote_uri(url))
            else:
                url = requote_uri(url)

            prepared_request.url = to_native_string(url)

            self.rebuild_method(prepared_request, resp)

            # https://github.com/psf/requests/issues/1084
            if resp.status_code not in (codes.temporary_redirect, codes.permanent_redirect):
                # https://github.com/psf/requests/issues/3490
                purged_headers = ('Content-Length', 'Content-Type', 'Transfer-Encoding')
                for header in purged_headers:
                    prepared_request.headers.pop(header, None)
                prepared_request.body = None

            headers = prepared_request.headers
            headers.pop('Cookie', None)

            # Extract any cookies sent on the response to the cookiejar
            # in the new request. Because we've mutated our copied prepared
            # request, use the old one that we haven't yet touched.
            extract_cookies_to_jar(prepared_request._cookies, req, resp.raw)
            merge_cookies(prepared_request._cookies, self.cookies)
            prepared_request.prepare_cookies(prepared_request._cookies)

            # Rebuild auth and proxy information.
            proxies = self.rebuild_proxies(prepared_request, proxies)
            self.rebuild_auth(prepared_request, resp)

            # A failed tell() sets `_body_position` to `object()`. This non-None
            # value ensures `rewindable` will be True, allowing us to raise an
            # UnrewindableBodyError, instead of hanging the connection.
            rewindable = (
                prepared_request._body_position is not None and
                ('Content-Length' in headers or 'Transfer-Encoding' in headers)
            )

            # Attempt to rewind consumed file-like object.
            if rewindable:
                rewind_body(prepared_request)

            # Override the original request.
            req = prepared_request

            if yield_requests:
                yield req
            else:

                resp = self.send(
                    req,
                    stream=stream,
                    timeout=timeout,
                    verify=verify,
                    cert=cert,
                    proxies=proxies,
                    allow_redirects=False,
                    **adapter_kwargs
                )

                extract_cookies_to_jar(self.cookies, prepared_request, resp.raw)

                # extract redirect url, if any, for the next loop
                url = self.get_redirect_target(resp)
                yield resp

    def rebuild_auth(self, prepared_request, response):
        """When being redirected we may want to strip authentication from the
        request to avoid leaking credentials. This method intelligently removes
        and reapplies authentication where possible to avoid credential loss.
        """
        headers = prepared_request.headers
        url = prepared_request.url

        if 'Authorization' in headers and self.should_strip_auth(response.request.url, url):
            # If we get redirected to a new host, we should strip out any
            # authentication headers.
            del headers['Authorization']

        # .netrc might have more auth for us on our new host.
        new_auth = get_netrc_auth(url) if self.trust_env else None
        if new_auth is not None:
            prepared_request.prepare_auth(new_auth)

    def rebuild_proxies(self, prepared_request, proxies):
        """This method re-evaluates the proxy configuration by considering the
        environment variables. If we are redirected to a URL covered by
        NO_PROXY, we strip the proxy configuration. Otherwise, we set missing
        proxy keys for this URL (in case they were stripped by a previous
        redirect).

        This method also replaces the Proxy-Authorization header where
        necessary.

        :rtype: dict
        """
        headers = prepared_request.headers
        scheme = urlparse(prepared_request.url).scheme
        new_proxies = resolve_proxies(prepared_request, proxies, self.trust_env)

        if 'Proxy-Authorization' in headers:
            del headers['Proxy-Authorization']

        try:
            username, password = get_auth_from_url(new_proxies[scheme])
        except KeyError:
            username, password = None, None

        if username and password:
            headers['Proxy-Authorization'] = _basic_auth_str(username, password)

        return new_proxies

    def rebuild_method(self, prepared_request, response):
        """When being redirected we may want to change the method of the request
        based on certain specs or browser behavior.
        """
        method = prepared_request.method

        # https://tools.ietf.org/html/rfc7231#section-6.4.4
        if response.status_code == codes.see_other and method != 'HEAD':
            method = 'GET'

        # Do what the browsers do, despite standards...
        # First, turn 302s into GETs.
        if response.status_code == codes.found and method != 'HEAD':
            method = 'GET'

        # Second, if a POST is responded to with a 301, turn it into a GET.
        # This bizarre behaviour is explained in Issue 1704.
        if response.status_code == codes.moved and method == 'POST':
            method = 'GET'

        prepared_request.method = method


class Session(SessionRedirectMixin):
    """A Requests session.

    Provides cookie persistence, connection-pooling, and configuration.

    Basic Usage::

      >>> import requests
      >>> s = requests.Session()
      >>> s.get('https://httpbin.org/get')
      <Response [200]>

    Or as a context manager::

      >>> with requests.Session() as s:
      ...     s.get('https://httpbin.org/get')
      <Response [200]>
    """

    __attrs__ = [
        'headers', 'cookies', 'auth', 'proxies', 'hooks', 'params', 'verify',
        'cert', 'adapters', 'stream', 'trust_env',
        'max_redirects',
    ]

    def __init__(self):

        #: A case-insensitive dictionary of headers to be sent on each
        #: :class:`Request <Request>` sent from this
        #: :class:`Session <Session>`.
        self.headers = default_headers()

        #: Default Authentication tuple or object to attach to
        #: :class:`Request <Request>`.
        self.auth = None

        #: Dictionary mapping protocol or protocol and host to the URL of the proxy
        #: (e.g. {'http': 'foo.bar:3128', 'http://host.name': 'foo.bar:4012'}) to
        #: be used on each :class:`Request <Request>`.
        self.proxies = {}

        #: Event-handling hooks.
        self.hooks = default_hooks()

        #: Dictionary of querystring data to attach to each
        #: :class:`Request <Request>`. The dictionary values may be lists for
        #: representing multivalued query parameters.
        self.params = {}

        #: Stream response content default.
        self.stream = False

        #: SSL Verification default.
        #: Defaults to `True`, requiring requests to verify the TLS certificate at the
        #: remote end.
        #: If verify is set to `False`, requests will accept any TLS certificate
        #: presented by the server, and will ignore hostname mismatches and/or
        #: expired certificates, which will make your application vulnerable to
        #: man-in-the-middle (MitM) attacks.
        #: Only set this to `False` for testing.
        self.verify = True

        #: SSL client certificate default, if String, path to ssl client
        #: cert file (.pem). If Tuple, ('cert', 'key') pair.
        self.cert = None

        #: Maximum number of redirects allowed. If the request exceeds this
        #: limit, a :class:`TooManyRedirects` exception is raised.
        #: This defaults to requests.models.DEFAULT_REDIRECT_LIMIT, which is
        #: 30.
        self.max_redirects = DEFAULT_REDIRECT_LIMIT

        #: Trust environment settings for proxy configuration, default
        #: authentication and similar.
        self.trust_env = True

        #: A CookieJar containing all currently outstanding cookies set on this
        #: session. By default it is a
        #: :class:`RequestsCookieJar <requests.cookies.RequestsCookieJar>`, but
        #: may be any other ``cookielib.CookieJar`` compatible object.
        self.cookies = cookiejar_from_dict({})

        # Default connection adapters.
        self.adapters = OrderedDict()
        self.mount('https://', HTTPAdapter())
        self.mount('http://', HTTPAdapter())

    def __enter__(self):
        return self

    def __exit__(self, *args):
        self.close()

    def prepare_request(self, request):
        """Constructs a :class:`PreparedRequest <PreparedRequest>` for
        transmission and returns it. The :class:`PreparedRequest` has settings
        merged from the :class:`Request <Request>` instance and those of the
        :class:`Session`.

        :param request: :class:`Request` instance to prepare with this
            session's settings.
        :rtype: requests.PreparedRequest
        """
        cookies = request.cookies or {}

        # Bootstrap CookieJar.
        if not isinstance(cookies, cookielib.CookieJar):
            cookies = cookiejar_from_dict(cookies)

        # Merge with session cookies
        merged_cookies = merge_cookies(
            merge_cookies(RequestsCookieJar(), self.cookies), cookies)

        # Set environment's basic authentication if not explicitly set.
        auth = request.auth
        if self.trust_env and not auth and not self.auth:
            auth = get_netrc_auth(request.url)

        p = PreparedRequest()
        p.prepare(
            method=request.method.upper(),
            url=request.url,
            files=request.files,
            data=request.data,
            json=request.json,
            headers=merge_setting(request.headers, self.headers, dict_class=CaseInsensitiveDict),
            params=merge_setting(request.params, self.params),
            auth=merge_setting(auth, self.auth),
            cookies=merged_cookies,
            hooks=merge_hooks(request.hooks, self.hooks),
        )
        return p

    def request(self, method, url,
            params=None, data=None, headers=None, cookies=None, files=None,
            auth=None, timeout=None, allow_redirects=True, proxies=None,
            hooks=None, stream=None, verify=None, cert=None, json=None):
        """Constructs a :class:`Request <Request>`, prepares it and sends it.
        Returns :class:`Response <Response>` object.

        :param method: method for the new :class:`Request` object.
        :param url: URL for the new :class:`Request` object.
        :param params: (optional) Dictionary or bytes to be sent in the query
            string for the :class:`Request`.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the
            :class:`Request`.
        :param headers: (optional) Dictionary of HTTP Headers to send with the
            :class:`Request`.
        :param cookies: (optional) Dict or CookieJar object to send with the
            :class:`Request`.
        :param files: (optional) Dictionary of ``'filename': file-like-objects``
            for multipart encoding upload.
        :param auth: (optional) Auth tuple or callable to enable
            Basic/Digest/Custom HTTP Auth.
        :param timeout: (optional) How long to wait for the server to send
            data before giving up, as a float, or a :ref:`(connect timeout,
            read timeout) <timeouts>` tuple.
        :type timeout: float or tuple
        :param allow_redirects: (optional) Set to True by default.
        :type allow_redirects: bool
        :param proxies: (optional) Dictionary mapping protocol or protocol and
            hostname to the URL of the proxy.
        :param stream: (optional) whether to immediately download the response
            content. Defaults to ``False``.
        :param verify: (optional) Either a boolean, in which case it controls whether we verify
            the server's TLS certificate, or a string, in which case it must be a path
            to a CA bundle to use. Defaults to ``True``. When set to
            ``False``, requests will accept any TLS certificate presented by
            the server, and will ignore hostname mismatches and/or expired
            certificates, which will make your application vulnerable to
            man-in-the-middle (MitM) attacks. Setting verify to ``False`` 
            may be useful during local development or testing.
        :param cert: (optional) if String, path to ssl client cert file (.pem).
            If Tuple, ('cert', 'key') pair.
        :rtype: requests.Response
        """
        # Create the Request.
        req = Request(
            method=method.upper(),
            url=url,
            headers=headers,
            files=files,
            data=data or {},
            json=json,
            params=params or {},
            auth=auth,
            cookies=cookies,
            hooks=hooks,
        )
        prep = self.prepare_request(req)

        proxies = proxies or {}

        settings = self.merge_environment_settings(
            prep.url, proxies, stream, verify, cert
        )

        # Send the request.
        send_kwargs = {
            'timeout': timeout,
            'allow_redirects': allow_redirects,
        }
        send_kwargs.update(settings)
        resp = self.send(prep, **send_kwargs)

        return resp

    def get(self, url, **kwargs):
        r"""Sends a GET request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        """

        kwargs.setdefault('allow_redirects', True)
        return self.request('GET', url, **kwargs)

    def options(self, url, **kwargs):
        r"""Sends a OPTIONS request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        """

        kwargs.setdefault('allow_redirects', True)
        return self.request('OPTIONS', url, **kwargs)

    def head(self, url, **kwargs):
        r"""Sends a HEAD request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        """

        kwargs.setdefault('allow_redirects', False)
        return self.request('HEAD', url, **kwargs)

    def post(self, url, data=None, json=None, **kwargs):
        r"""Sends a POST request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param json: (optional) json to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        """

        return self.request('POST', url, data=data, json=json, **kwargs)

    def put(self, url, data=None, **kwargs):
        r"""Sends a PUT request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        """

        return self.request('PUT', url, data=data, **kwargs)

    def patch(self, url, data=None, **kwargs):
        r"""Sends a PATCH request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param data: (optional) Dictionary, list of tuples, bytes, or file-like
            object to send in the body of the :class:`Request`.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        """

        return self.request('PATCH', url, data=data, **kwargs)

    def delete(self, url, **kwargs):
        r"""Sends a DELETE request. Returns :class:`Response` object.

        :param url: URL for the new :class:`Request` object.
        :param \*\*kwargs: Optional arguments that ``request`` takes.
        :rtype: requests.Response
        """

        return self.request('DELETE', url, **kwargs)

    def send(self, request, **kwargs):
        """Send a given PreparedRequest.

        :rtype: requests.Response
        """
        # Set defaults that the hooks can utilize to ensure they always have
        # the correct parameters to reproduce the previous request.
        kwargs.setdefault('stream', self.stream)
        kwargs.setdefault('verify', self.verify)
        kwargs.setdefault('cert', self.cert)
        if 'proxies' not in kwargs:
            kwargs['proxies'] = resolve_proxies(
                request, self.proxies, self.trust_env
            )

        # It's possible that users might accidentally send a Request object.
        # Guard against that specific failure case.
        if isinstance(request, Request):
            raise ValueError('You can only send PreparedRequests.')

        # Set up variables needed for resolve_redirects and dispatching of hooks
        allow_redirects = kwargs.pop('allow_redirects', True)
        stream = kwargs.get('stream')
        hooks = request.hooks

        # Get the appropriate adapter to use
        adapter = self.get_adapter(url=request.url)

        # Start time (approximately) of the request
        start = preferred_clock()

        # Send the request
        r = adapter.send(request, **kwargs)

        # Total elapsed time of the request (approximately)
        elapsed = preferred_clock() - start
        r.elapsed = timedelta(seconds=elapsed)

        # Response manipulation hooks
        r = dispatch_hook('response', hooks, r, **kwargs)

        # Persist cookies
        if r.history:

            # If the hooks create history then we want those cookies too
            for resp in r.history:
                extract_cookies_to_jar(self.cookies, resp.request, resp.raw)

        extract_cookies_to_jar(self.cookies, request, r.raw)

        # Resolve redirects if allowed.
        if allow_redirects:
            # Redirect resolving generator.
            gen = self.resolve_redirects(r, request, **kwargs)
            history = [resp for resp in gen]
        else:
            history = []

        # Shuffle things around if there's history.
        if history:
            # Insert the first (original) request at the start
            history.insert(0, r)
            # Get the last request made
            r = history.pop()
            r.history = history

        # If redirects aren't being followed, store the response on the Request for Response.next().
        if not allow_redirects:
            try:
                r._next = next(self.resolve_redirects(r, request, yield_requests=True, **kwargs))
            except StopIteration:
                pass

        if not stream:
            r.content

        return r

    def merge_environment_settings(self, url, proxies, stream, verify, cert):
        """
        Check the environment and merge it with some settings.

        :rtype: dict
        """
        # Gather clues from the surrounding environment.
        if self.trust_env:
            # Set environment's proxies.
            no_proxy = proxies.get('no_proxy') if proxies is not None else None
            env_proxies = get_environ_proxies(url, no_proxy=no_proxy)
            for (k, v) in env_proxies.items():
                proxies.setdefault(k, v)

            # Look for requests environment configuration and be compatible
            # with cURL.
            if verify is True or verify is None:
                verify = (os.environ.get('REQUESTS_CA_BUNDLE') or
                          os.environ.get('CURL_CA_BUNDLE'))

        # Merge all the kwargs.
        proxies = merge_setting(proxies, self.proxies)
        stream = merge_setting(stream, self.stream)
        verify = merge_setting(verify, self.verify)
        cert = merge_setting(cert, self.cert)

        return {'verify': verify, 'proxies': proxies, 'stream': stream,
                'cert': cert}

    def get_adapter(self, url):
        """
        Returns the appropriate connection adapter for the given URL.

        :rtype: requests.adapters.BaseAdapter
        """
        for (prefix, adapter) in self.adapters.items():

            if url.lower().startswith(prefix.lower()):
                return adapter

        # Nothing matches :-/
        raise InvalidSchema("No connection adapters were found for {!r}".format(url))

    def close(self):
        """Closes all adapters and as such the session"""
        for v in self.adapters.values():
            v.close()

    def mount(self, prefix, adapter):
        """Registers a connection adapter to a prefix.

        Adapters are sorted in descending order by prefix length.
        """
        self.adapters[prefix] = adapter
        keys_to_move = [k for k in self.adapters if len(k) < len(prefix)]

        for key in keys_to_move:
            self.adapters[key] = self.adapters.pop(key)

    def __getstate__(self):
        state = {attr: getattr(self, attr, None) for attr in self.__attrs__}
        return state

    def __setstate__(self, state):
        for attr, value in state.items():
            setattr(self, attr, value)


def session():
    """
    Returns a :class:`Session` for context-management.

    .. deprecated:: 1.0.0

        This method has been deprecated since version 1.0.0 and is only kept for
        backwards compatibility. New code should use :class:`~requests.sessions.Session`
        to create a session. This may be removed at a future date.

    :rtype: Session
    """
    return Session()




############################################################
### File: set.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

class Set(object):

    """A simple set class.

    This class was originally used to deal with sets being missing in
    ancient versions of python, but dnspython will continue to use it
    as these sets are based on lists and are thus indexable, and this
    ability is widely used in dnspython applications.
    """

    __slots__ = ['items']

    def __init__(self, items=None):
        """Initialize the set.

        *items*, an iterable or ``None``, the initial set of items.
        """

        self.items = []
        if items is not None:
            for item in items:
                self.add(item)

    def __repr__(self):
        return "dns.simpleset.Set(%s)" % repr(self.items)

    def add(self, item):
        """Add an item to the set.
        """

        if item not in self.items:
            self.items.append(item)

    def remove(self, item):
        """Remove an item from the set.
        """

        self.items.remove(item)

    def discard(self, item):
        """Remove an item from the set if present.
        """

        try:
            self.items.remove(item)
        except ValueError:
            pass

    def _clone(self):
        """Make a (shallow) copy of the set.

        There is a 'clone protocol' that subclasses of this class
        should use.  To make a copy, first call your super's _clone()
        method, and use the object returned as the new instance.  Then
        make shallow copies of the attributes defined in the subclass.

        This protocol allows us to write the set algorithms that
        return new instances (e.g. union) once, and keep using them in
        subclasses.
        """

        cls = self.__class__
        obj = cls.__new__(cls)
        obj.items = list(self.items)
        return obj

    def __copy__(self):
        """Make a (shallow) copy of the set.
        """

        return self._clone()

    def copy(self):
        """Make a (shallow) copy of the set.
        """

        return self._clone()

    def union_update(self, other):
        """Update the set, adding any elements from other which are not
        already in the set.
        """

        if not isinstance(other, Set):
            raise ValueError('other must be a Set instance')
        if self is other:
            return
        for item in other.items:
            self.add(item)

    def intersection_update(self, other):
        """Update the set, removing any elements from other which are not
        in both sets.
        """

        if not isinstance(other, Set):
            raise ValueError('other must be a Set instance')
        if self is other:
            return
        # we make a copy of the list so that we can remove items from
        # the list without breaking the iterator.
        for item in list(self.items):
            if item not in other.items:
                self.items.remove(item)

    def difference_update(self, other):
        """Update the set, removing any elements from other which are in
        the set.
        """

        if not isinstance(other, Set):
            raise ValueError('other must be a Set instance')
        if self is other:
            self.items = []
        else:
            for item in other.items:
                self.discard(item)

    def union(self, other):
        """Return a new set which is the union of ``self`` and ``other``.

        Returns the same Set type as this set.
        """

        obj = self._clone()
        obj.union_update(other)
        return obj

    def intersection(self, other):
        """Return a new set which is the intersection of ``self`` and
        ``other``.

        Returns the same Set type as this set.
        """

        obj = self._clone()
        obj.intersection_update(other)
        return obj

    def difference(self, other):
        """Return a new set which ``self`` - ``other``, i.e. the items
        in ``self`` which are not also in ``other``.

        Returns the same Set type as this set.
        """

        obj = self._clone()
        obj.difference_update(other)
        return obj

    def __or__(self, other):
        return self.union(other)

    def __and__(self, other):
        return self.intersection(other)

    def __add__(self, other):
        return self.union(other)

    def __sub__(self, other):
        return self.difference(other)

    def __ior__(self, other):
        self.union_update(other)
        return self

    def __iand__(self, other):
        self.intersection_update(other)
        return self

    def __iadd__(self, other):
        self.union_update(other)
        return self

    def __isub__(self, other):
        self.difference_update(other)
        return self

    def update(self, other):
        """Update the set, adding any elements from other which are not
        already in the set.

        *other*, the collection of items with which to update the set, which
        may be any iterable type.
        """

        for item in other:
            self.add(item)

    def clear(self):
        """Make the set empty."""
        self.items = []

    def __eq__(self, other):
        # Yes, this is inefficient but the sets we're dealing with are
        # usually quite small, so it shouldn't hurt too much.
        for item in self.items:
            if item not in other.items:
                return False
        for item in other.items:
            if item not in self.items:
                return False
        return True

    def __ne__(self, other):
        return not self.__eq__(other)

    def __len__(self):
        return len(self.items)

    def __iter__(self):
        return iter(self.items)

    def __getitem__(self, i):
        return self.items[i]

    def __delitem__(self, i):
        del self.items[i]

    def issubset(self, other):
        """Is this set a subset of *other*?

        Returns a ``bool``.
        """

        if not isinstance(other, Set):
            raise ValueError('other must be a Set instance')
        for item in self.items:
            if item not in other.items:
                return False
        return True

    def issuperset(self, other):
        """Is this set a superset of *other*?

        Returns a ``bool``.
        """

        if not isinstance(other, Set):
            raise ValueError('other must be a Set instance')
        for item in other.items:
            if item not in self.items:
                return False
        return True




############################################################
### File: settings.py
############################################################
from slyguy.settings import CommonSettings
from slyguy.settings.types import Bool, Text
from slyguy.constants import *

from .language import _


class Settings(CommonSettings):
    FLATTEN_SINGLE_SEASON = Bool('flatten_single_season', _.FLATTEN_SINGLE_SEASON, default=True)
    HIDE_SUGGESTED = Bool('hide_suggested', _.HIDE_SUGGESTED, default=False)
    HIDE_CLIPS = Bool('hide_clips', _.HIDE_CLIPS, default=False)
    LAT_LONG = Text('lat_long', _.LAT_LONG)


settings = Settings()




############################################################
### File: six.py
############################################################
# Copyright (c) 2010-2020 Benjamin Peterson
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

"""Utilities for writing code that runs on Python 2 and 3"""

from __future__ import absolute_import

import functools
import itertools
import operator
import sys
import types

__author__ = "Benjamin Peterson <benjamin@python.org>"
__version__ = "1.16.0"


# Useful for very coarse version differentiation.
PY2 = sys.version_info[0] == 2
PY3 = sys.version_info[0] == 3
PY34 = sys.version_info[0:2] >= (3, 4)

if PY3:
    string_types = str,
    integer_types = int,
    class_types = type,
    text_type = str
    binary_type = bytes

    MAXSIZE = sys.maxsize
else:
    string_types = basestring,
    integer_types = (int, long)
    class_types = (type, types.ClassType)
    text_type = unicode
    binary_type = str

    if sys.platform.startswith("java"):
        # Jython always uses 32 bits.
        MAXSIZE = int((1 << 31) - 1)
    else:
        # It's possible to have sizeof(long) != sizeof(Py_ssize_t).
        class X(object):

            def __len__(self):
                return 1 << 31
        try:
            len(X())
        except OverflowError:
            # 32-bit
            MAXSIZE = int((1 << 31) - 1)
        else:
            # 64-bit
            MAXSIZE = int((1 << 63) - 1)
        del X

if PY34:
    from importlib.util import spec_from_loader
else:
    spec_from_loader = None


def _add_doc(func, doc):
    """Add documentation to a function."""
    func.__doc__ = doc


def _import_module(name):
    """Import module, returning the module after the last dot."""
    __import__(name)
    return sys.modules[name]


class _LazyDescr(object):

    def __init__(self, name):
        self.name = name

    def __get__(self, obj, tp):
        result = self._resolve()
        setattr(obj, self.name, result)  # Invokes __set__.
        try:
            # This is a bit ugly, but it avoids running this again by
            # removing this descriptor.
            delattr(obj.__class__, self.name)
        except AttributeError:
            pass
        return result


class MovedModule(_LazyDescr):

    def __init__(self, name, old, new=None):
        super(MovedModule, self).__init__(name)
        if PY3:
            if new is None:
                new = name
            self.mod = new
        else:
            self.mod = old

    def _resolve(self):
        return _import_module(self.mod)

    def __getattr__(self, attr):
        _module = self._resolve()
        value = getattr(_module, attr)
        setattr(self, attr, value)
        return value


class _LazyModule(types.ModuleType):

    def __init__(self, name):
        super(_LazyModule, self).__init__(name)
        self.__doc__ = self.__class__.__doc__

    def __dir__(self):
        attrs = ["__doc__", "__name__"]
        attrs += [attr.name for attr in self._moved_attributes]
        return attrs

    # Subclasses should override this
    _moved_attributes = []


class MovedAttribute(_LazyDescr):

    def __init__(self, name, old_mod, new_mod, old_attr=None, new_attr=None):
        super(MovedAttribute, self).__init__(name)
        if PY3:
            if new_mod is None:
                new_mod = name
            self.mod = new_mod
            if new_attr is None:
                if old_attr is None:
                    new_attr = name
                else:
                    new_attr = old_attr
            self.attr = new_attr
        else:
            self.mod = old_mod
            if old_attr is None:
                old_attr = name
            self.attr = old_attr

    def _resolve(self):
        module = _import_module(self.mod)
        return getattr(module, self.attr)


class _SixMetaPathImporter(object):

    """
    A meta path importer to import six.moves and its submodules.

    This class implements a PEP302 finder and loader. It should be compatible
    with Python 2.5 and all existing versions of Python3
    """

    def __init__(self, six_module_name):
        self.name = six_module_name
        self.known_modules = {}

    def _add_module(self, mod, *fullnames):
        for fullname in fullnames:
            self.known_modules[self.name + "." + fullname] = mod

    def _get_module(self, fullname):
        return self.known_modules[self.name + "." + fullname]

    def find_module(self, fullname, path=None):
        if fullname in self.known_modules:
            return self
        return None

    def find_spec(self, fullname, path, target=None):
        if fullname in self.known_modules:
            return spec_from_loader(fullname, self)
        return None

    def __get_module(self, fullname):
        try:
            return self.known_modules[fullname]
        except KeyError:
            raise ImportError("This loader does not know module " + fullname)

    def load_module(self, fullname):
        try:
            # in case of a reload
            return sys.modules[fullname]
        except KeyError:
            pass
        mod = self.__get_module(fullname)
        if isinstance(mod, MovedModule):
            mod = mod._resolve()
        else:
            mod.__loader__ = self
        sys.modules[fullname] = mod
        return mod

    def is_package(self, fullname):
        """
        Return true, if the named module is a package.

        We need this method to get correct spec objects with
        Python 3.4 (see PEP451)
        """
        return hasattr(self.__get_module(fullname), "__path__")

    def get_code(self, fullname):
        """Return None

        Required, if is_package is implemented"""
        self.__get_module(fullname)  # eventually raises ImportError
        return None
    get_source = get_code  # same as get_code

    def create_module(self, spec):
        return self.load_module(spec.name)

    def exec_module(self, module):
        pass

_importer = _SixMetaPathImporter(__name__)


class _MovedItems(_LazyModule):

    """Lazy loading of moved objects"""
    __path__ = []  # mark as package


_moved_attributes = [
    MovedAttribute("cStringIO", "cStringIO", "io", "StringIO"),
    MovedAttribute("filter", "itertools", "builtins", "ifilter", "filter"),
    MovedAttribute("filterfalse", "itertools", "itertools", "ifilterfalse", "filterfalse"),
    MovedAttribute("input", "__builtin__", "builtins", "raw_input", "input"),
    MovedAttribute("intern", "__builtin__", "sys"),
    MovedAttribute("map", "itertools", "builtins", "imap", "map"),
    MovedAttribute("getcwd", "os", "os", "getcwdu", "getcwd"),
    MovedAttribute("getcwdb", "os", "os", "getcwd", "getcwdb"),
    MovedAttribute("getoutput", "commands", "subprocess"),
    MovedAttribute("range", "__builtin__", "builtins", "xrange", "range"),
    MovedAttribute("reload_module", "__builtin__", "importlib" if PY34 else "imp", "reload"),
    MovedAttribute("reduce", "__builtin__", "functools"),
    MovedAttribute("shlex_quote", "pipes", "shlex", "quote"),
    MovedAttribute("StringIO", "StringIO", "io"),
    MovedAttribute("UserDict", "UserDict", "collections"),
    MovedAttribute("UserList", "UserList", "collections"),
    MovedAttribute("UserString", "UserString", "collections"),
    MovedAttribute("xrange", "__builtin__", "builtins", "xrange", "range"),
    MovedAttribute("zip", "itertools", "builtins", "izip", "zip"),
    MovedAttribute("zip_longest", "itertools", "itertools", "izip_longest", "zip_longest"),
    MovedModule("builtins", "__builtin__"),
    MovedModule("configparser", "ConfigParser"),
    MovedModule("collections_abc", "collections", "collections.abc" if sys.version_info >= (3, 3) else "collections"),
    MovedModule("copyreg", "copy_reg"),
    MovedModule("dbm_gnu", "gdbm", "dbm.gnu"),
    MovedModule("dbm_ndbm", "dbm", "dbm.ndbm"),
    MovedModule("_dummy_thread", "dummy_thread", "_dummy_thread" if sys.version_info < (3, 9) else "_thread"),
    MovedModule("http_cookiejar", "cookielib", "http.cookiejar"),
    MovedModule("http_cookies", "Cookie", "http.cookies"),
    MovedModule("html_entities", "htmlentitydefs", "html.entities"),
    MovedModule("html_parser", "HTMLParser", "html.parser"),
    MovedModule("http_client", "httplib", "http.client"),
    MovedModule("email_mime_base", "email.MIMEBase", "email.mime.base"),
    MovedModule("email_mime_image", "email.MIMEImage", "email.mime.image"),
    MovedModule("email_mime_multipart", "email.MIMEMultipart", "email.mime.multipart"),
    MovedModule("email_mime_nonmultipart", "email.MIMENonMultipart", "email.mime.nonmultipart"),
    MovedModule("email_mime_text", "email.MIMEText", "email.mime.text"),
    MovedModule("BaseHTTPServer", "BaseHTTPServer", "http.server"),
    MovedModule("CGIHTTPServer", "CGIHTTPServer", "http.server"),
    MovedModule("SimpleHTTPServer", "SimpleHTTPServer", "http.server"),
    MovedModule("cPickle", "cPickle", "pickle"),
    MovedModule("queue", "Queue"),
    MovedModule("reprlib", "repr"),
    MovedModule("socketserver", "SocketServer"),
    MovedModule("_thread", "thread", "_thread"),
    MovedModule("tkinter", "Tkinter"),
    MovedModule("tkinter_dialog", "Dialog", "tkinter.dialog"),
    MovedModule("tkinter_filedialog", "FileDialog", "tkinter.filedialog"),
    MovedModule("tkinter_scrolledtext", "ScrolledText", "tkinter.scrolledtext"),
    MovedModule("tkinter_simpledialog", "SimpleDialog", "tkinter.simpledialog"),
    MovedModule("tkinter_tix", "Tix", "tkinter.tix"),
    MovedModule("tkinter_ttk", "ttk", "tkinter.ttk"),
    MovedModule("tkinter_constants", "Tkconstants", "tkinter.constants"),
    MovedModule("tkinter_dnd", "Tkdnd", "tkinter.dnd"),
    MovedModule("tkinter_colorchooser", "tkColorChooser",
                "tkinter.colorchooser"),
    MovedModule("tkinter_commondialog", "tkCommonDialog",
                "tkinter.commondialog"),
    MovedModule("tkinter_tkfiledialog", "tkFileDialog", "tkinter.filedialog"),
    MovedModule("tkinter_font", "tkFont", "tkinter.font"),
    MovedModule("tkinter_messagebox", "tkMessageBox", "tkinter.messagebox"),
    MovedModule("tkinter_tksimpledialog", "tkSimpleDialog",
                "tkinter.simpledialog"),
    MovedModule("urllib_parse", __name__ + ".moves.urllib_parse", "urllib.parse"),
    MovedModule("urllib_error", __name__ + ".moves.urllib_error", "urllib.error"),
    MovedModule("urllib", __name__ + ".moves.urllib", __name__ + ".moves.urllib"),
    MovedModule("urllib_robotparser", "robotparser", "urllib.robotparser"),
    MovedModule("xmlrpc_client", "xmlrpclib", "xmlrpc.client"),
    MovedModule("xmlrpc_server", "SimpleXMLRPCServer", "xmlrpc.server"),
]
# Add windows specific modules.
if sys.platform == "win32":
    _moved_attributes += [
        MovedModule("winreg", "_winreg"),
    ]

for attr in _moved_attributes:
    setattr(_MovedItems, attr.name, attr)
    if isinstance(attr, MovedModule):
        _importer._add_module(attr, "moves." + attr.name)
del attr

_MovedItems._moved_attributes = _moved_attributes

moves = _MovedItems(__name__ + ".moves")
_importer._add_module(moves, "moves")


class Module_six_moves_urllib_parse(_LazyModule):

    """Lazy loading of moved objects in six.moves.urllib_parse"""


_urllib_parse_moved_attributes = [
    MovedAttribute("ParseResult", "urlparse", "urllib.parse"),
    MovedAttribute("SplitResult", "urlparse", "urllib.parse"),
    MovedAttribute("parse_qs", "urlparse", "urllib.parse"),
    MovedAttribute("parse_qsl", "urlparse", "urllib.parse"),
    MovedAttribute("urldefrag", "urlparse", "urllib.parse"),
    MovedAttribute("urljoin", "urlparse", "urllib.parse"),
    MovedAttribute("urlparse", "urlparse", "urllib.parse"),
    MovedAttribute("urlsplit", "urlparse", "urllib.parse"),
    MovedAttribute("urlunparse", "urlparse", "urllib.parse"),
    MovedAttribute("urlunsplit", "urlparse", "urllib.parse"),
    MovedAttribute("quote", "urllib", "urllib.parse"),
    MovedAttribute("quote_plus", "urllib", "urllib.parse"),
    MovedAttribute("unquote", "urllib", "urllib.parse"),
    MovedAttribute("unquote_plus", "urllib", "urllib.parse"),
    MovedAttribute("unquote_to_bytes", "urllib", "urllib.parse", "unquote", "unquote_to_bytes"),
    MovedAttribute("urlencode", "urllib", "urllib.parse"),
    MovedAttribute("splitquery", "urllib", "urllib.parse"),
    MovedAttribute("splittag", "urllib", "urllib.parse"),
    MovedAttribute("splituser", "urllib", "urllib.parse"),
    MovedAttribute("splitvalue", "urllib", "urllib.parse"),
    MovedAttribute("uses_fragment", "urlparse", "urllib.parse"),
    MovedAttribute("uses_netloc", "urlparse", "urllib.parse"),
    MovedAttribute("uses_params", "urlparse", "urllib.parse"),
    MovedAttribute("uses_query", "urlparse", "urllib.parse"),
    MovedAttribute("uses_relative", "urlparse", "urllib.parse"),
]
for attr in _urllib_parse_moved_attributes:
    setattr(Module_six_moves_urllib_parse, attr.name, attr)
del attr

Module_six_moves_urllib_parse._moved_attributes = _urllib_parse_moved_attributes

_importer._add_module(Module_six_moves_urllib_parse(__name__ + ".moves.urllib_parse"),
                      "moves.urllib_parse", "moves.urllib.parse")


class Module_six_moves_urllib_error(_LazyModule):

    """Lazy loading of moved objects in six.moves.urllib_error"""


_urllib_error_moved_attributes = [
    MovedAttribute("URLError", "urllib2", "urllib.error"),
    MovedAttribute("HTTPError", "urllib2", "urllib.error"),
    MovedAttribute("ContentTooShortError", "urllib", "urllib.error"),
]
for attr in _urllib_error_moved_attributes:
    setattr(Module_six_moves_urllib_error, attr.name, attr)
del attr

Module_six_moves_urllib_error._moved_attributes = _urllib_error_moved_attributes

_importer._add_module(Module_six_moves_urllib_error(__name__ + ".moves.urllib.error"),
                      "moves.urllib_error", "moves.urllib.error")


class Module_six_moves_urllib_request(_LazyModule):

    """Lazy loading of moved objects in six.moves.urllib_request"""


_urllib_request_moved_attributes = [
    MovedAttribute("urlopen", "urllib2", "urllib.request"),
    MovedAttribute("install_opener", "urllib2", "urllib.request"),
    MovedAttribute("build_opener", "urllib2", "urllib.request"),
    MovedAttribute("pathname2url", "urllib", "urllib.request"),
    MovedAttribute("url2pathname", "urllib", "urllib.request"),
    MovedAttribute("getproxies", "urllib", "urllib.request"),
    MovedAttribute("Request", "urllib2", "urllib.request"),
    MovedAttribute("OpenerDirector", "urllib2", "urllib.request"),
    MovedAttribute("HTTPDefaultErrorHandler", "urllib2", "urllib.request"),
    MovedAttribute("HTTPRedirectHandler", "urllib2", "urllib.request"),
    MovedAttribute("HTTPCookieProcessor", "urllib2", "urllib.request"),
    MovedAttribute("ProxyHandler", "urllib2", "urllib.request"),
    MovedAttribute("BaseHandler", "urllib2", "urllib.request"),
    MovedAttribute("HTTPPasswordMgr", "urllib2", "urllib.request"),
    MovedAttribute("HTTPPasswordMgrWithDefaultRealm", "urllib2", "urllib.request"),
    MovedAttribute("AbstractBasicAuthHandler", "urllib2", "urllib.request"),
    MovedAttribute("HTTPBasicAuthHandler", "urllib2", "urllib.request"),
    MovedAttribute("ProxyBasicAuthHandler", "urllib2", "urllib.request"),
    MovedAttribute("AbstractDigestAuthHandler", "urllib2", "urllib.request"),
    MovedAttribute("HTTPDigestAuthHandler", "urllib2", "urllib.request"),
    MovedAttribute("ProxyDigestAuthHandler", "urllib2", "urllib.request"),
    MovedAttribute("HTTPHandler", "urllib2", "urllib.request"),
    MovedAttribute("HTTPSHandler", "urllib2", "urllib.request"),
    MovedAttribute("FileHandler", "urllib2", "urllib.request"),
    MovedAttribute("FTPHandler", "urllib2", "urllib.request"),
    MovedAttribute("CacheFTPHandler", "urllib2", "urllib.request"),
    MovedAttribute("UnknownHandler", "urllib2", "urllib.request"),
    MovedAttribute("HTTPErrorProcessor", "urllib2", "urllib.request"),
    MovedAttribute("urlretrieve", "urllib", "urllib.request"),
    MovedAttribute("urlcleanup", "urllib", "urllib.request"),
    MovedAttribute("URLopener", "urllib", "urllib.request"),
    MovedAttribute("FancyURLopener", "urllib", "urllib.request"),
    MovedAttribute("proxy_bypass", "urllib", "urllib.request"),
    MovedAttribute("parse_http_list", "urllib2", "urllib.request"),
    MovedAttribute("parse_keqv_list", "urllib2", "urllib.request"),
]
for attr in _urllib_request_moved_attributes:
    setattr(Module_six_moves_urllib_request, attr.name, attr)
del attr

Module_six_moves_urllib_request._moved_attributes = _urllib_request_moved_attributes

_importer._add_module(Module_six_moves_urllib_request(__name__ + ".moves.urllib.request"),
                      "moves.urllib_request", "moves.urllib.request")


class Module_six_moves_urllib_response(_LazyModule):

    """Lazy loading of moved objects in six.moves.urllib_response"""


_urllib_response_moved_attributes = [
    MovedAttribute("addbase", "urllib", "urllib.response"),
    MovedAttribute("addclosehook", "urllib", "urllib.response"),
    MovedAttribute("addinfo", "urllib", "urllib.response"),
    MovedAttribute("addinfourl", "urllib", "urllib.response"),
]
for attr in _urllib_response_moved_attributes:
    setattr(Module_six_moves_urllib_response, attr.name, attr)
del attr

Module_six_moves_urllib_response._moved_attributes = _urllib_response_moved_attributes

_importer._add_module(Module_six_moves_urllib_response(__name__ + ".moves.urllib.response"),
                      "moves.urllib_response", "moves.urllib.response")


class Module_six_moves_urllib_robotparser(_LazyModule):

    """Lazy loading of moved objects in six.moves.urllib_robotparser"""


_urllib_robotparser_moved_attributes = [
    MovedAttribute("RobotFileParser", "robotparser", "urllib.robotparser"),
]
for attr in _urllib_robotparser_moved_attributes:
    setattr(Module_six_moves_urllib_robotparser, attr.name, attr)
del attr

Module_six_moves_urllib_robotparser._moved_attributes = _urllib_robotparser_moved_attributes

_importer._add_module(Module_six_moves_urllib_robotparser(__name__ + ".moves.urllib.robotparser"),
                      "moves.urllib_robotparser", "moves.urllib.robotparser")


class Module_six_moves_urllib(types.ModuleType):

    """Create a six.moves.urllib namespace that resembles the Python 3 namespace"""
    __path__ = []  # mark as package
    parse = _importer._get_module("moves.urllib_parse")
    error = _importer._get_module("moves.urllib_error")
    request = _importer._get_module("moves.urllib_request")
    response = _importer._get_module("moves.urllib_response")
    robotparser = _importer._get_module("moves.urllib_robotparser")

    def __dir__(self):
        return ['parse', 'error', 'request', 'response', 'robotparser']

_importer._add_module(Module_six_moves_urllib(__name__ + ".moves.urllib"),
                      "moves.urllib")


def add_move(move):
    """Add an item to six.moves."""
    setattr(_MovedItems, move.name, move)


def remove_move(name):
    """Remove item from six.moves."""
    try:
        delattr(_MovedItems, name)
    except AttributeError:
        try:
            del moves.__dict__[name]
        except KeyError:
            raise AttributeError("no such move, %r" % (name,))


if PY3:
    _meth_func = "__func__"
    _meth_self = "__self__"

    _func_closure = "__closure__"
    _func_code = "__code__"
    _func_defaults = "__defaults__"
    _func_globals = "__globals__"
else:
    _meth_func = "im_func"
    _meth_self = "im_self"

    _func_closure = "func_closure"
    _func_code = "func_code"
    _func_defaults = "func_defaults"
    _func_globals = "func_globals"


try:
    advance_iterator = next
except NameError:
    def advance_iterator(it):
        return it.next()
next = advance_iterator


try:
    callable = callable
except NameError:
    def callable(obj):
        return any("__call__" in klass.__dict__ for klass in type(obj).__mro__)


if PY3:
    def get_unbound_function(unbound):
        return unbound

    create_bound_method = types.MethodType

    def create_unbound_method(func, cls):
        return func

    Iterator = object
else:
    def get_unbound_function(unbound):
        return unbound.im_func

    def create_bound_method(func, obj):
        return types.MethodType(func, obj, obj.__class__)

    def create_unbound_method(func, cls):
        return types.MethodType(func, None, cls)

    class Iterator(object):

        def next(self):
            return type(self).__next__(self)

    callable = callable
_add_doc(get_unbound_function,
         """Get the function out of a possibly unbound function""")


get_method_function = operator.attrgetter(_meth_func)
get_method_self = operator.attrgetter(_meth_self)
get_function_closure = operator.attrgetter(_func_closure)
get_function_code = operator.attrgetter(_func_code)
get_function_defaults = operator.attrgetter(_func_defaults)
get_function_globals = operator.attrgetter(_func_globals)


if PY3:
    def iterkeys(d, **kw):
        return iter(d.keys(**kw))

    def itervalues(d, **kw):
        return iter(d.values(**kw))

    def iteritems(d, **kw):
        return iter(d.items(**kw))

    def iterlists(d, **kw):
        return iter(d.lists(**kw))

    viewkeys = operator.methodcaller("keys")

    viewvalues = operator.methodcaller("values")

    viewitems = operator.methodcaller("items")
else:
    def iterkeys(d, **kw):
        return d.iterkeys(**kw)

    def itervalues(d, **kw):
        return d.itervalues(**kw)

    def iteritems(d, **kw):
        return d.iteritems(**kw)

    def iterlists(d, **kw):
        return d.iterlists(**kw)

    viewkeys = operator.methodcaller("viewkeys")

    viewvalues = operator.methodcaller("viewvalues")

    viewitems = operator.methodcaller("viewitems")

_add_doc(iterkeys, "Return an iterator over the keys of a dictionary.")
_add_doc(itervalues, "Return an iterator over the values of a dictionary.")
_add_doc(iteritems,
         "Return an iterator over the (key, value) pairs of a dictionary.")
_add_doc(iterlists,
         "Return an iterator over the (key, [values]) pairs of a dictionary.")


if PY3:
    def b(s):
        return s.encode("latin-1")

    def u(s):
        return s
    unichr = chr
    import struct
    int2byte = struct.Struct(">B").pack
    del struct
    byte2int = operator.itemgetter(0)
    indexbytes = operator.getitem
    iterbytes = iter
    import io
    StringIO = io.StringIO
    BytesIO = io.BytesIO
    del io
    _assertCountEqual = "assertCountEqual"
    if sys.version_info[1] <= 1:
        _assertRaisesRegex = "assertRaisesRegexp"
        _assertRegex = "assertRegexpMatches"
        _assertNotRegex = "assertNotRegexpMatches"
    else:
        _assertRaisesRegex = "assertRaisesRegex"
        _assertRegex = "assertRegex"
        _assertNotRegex = "assertNotRegex"
else:
    def b(s):
        return s
    # Workaround for standalone backslash

    def u(s):
        return unicode(s.replace(r'\\', r'\\\\'), "unicode_escape")
    unichr = unichr
    int2byte = chr

    def byte2int(bs):
        return ord(bs[0])

    def indexbytes(buf, i):
        return ord(buf[i])
    iterbytes = functools.partial(itertools.imap, ord)
    import StringIO
    StringIO = BytesIO = StringIO.StringIO
    _assertCountEqual = "assertItemsEqual"
    _assertRaisesRegex = "assertRaisesRegexp"
    _assertRegex = "assertRegexpMatches"
    _assertNotRegex = "assertNotRegexpMatches"
_add_doc(b, """Byte literal""")
_add_doc(u, """Text literal""")


def assertCountEqual(self, *args, **kwargs):
    return getattr(self, _assertCountEqual)(*args, **kwargs)


def assertRaisesRegex(self, *args, **kwargs):
    return getattr(self, _assertRaisesRegex)(*args, **kwargs)


def assertRegex(self, *args, **kwargs):
    return getattr(self, _assertRegex)(*args, **kwargs)


def assertNotRegex(self, *args, **kwargs):
    return getattr(self, _assertNotRegex)(*args, **kwargs)


if PY3:
    exec_ = getattr(moves.builtins, "exec")

    def reraise(tp, value, tb=None):
        try:
            if value is None:
                value = tp()
            if value.__traceback__ is not tb:
                raise value.with_traceback(tb)
            raise value
        finally:
            value = None
            tb = None

else:
    def exec_(_code_, _globs_=None, _locs_=None):
        """Execute code in a namespace."""
        if _globs_ is None:
            frame = sys._getframe(1)
            _globs_ = frame.f_globals
            if _locs_ is None:
                _locs_ = frame.f_locals
            del frame
        elif _locs_ is None:
            _locs_ = _globs_
        exec("""exec _code_ in _globs_, _locs_""")

    exec_("""def reraise(tp, value, tb=None):
    try:
        raise tp, value, tb
    finally:
        tb = None
""")


if sys.version_info[:2] > (3,):
    exec_("""def raise_from(value, from_value):
    try:
        raise value from from_value
    finally:
        value = None
""")
else:
    def raise_from(value, from_value):
        raise value


print_ = getattr(moves.builtins, "print", None)
if print_ is None:
    def print_(*args, **kwargs):
        """The new-style print function for Python 2.4 and 2.5."""
        fp = kwargs.pop("file", sys.stdout)
        if fp is None:
            return

        def write(data):
            if not isinstance(data, basestring):
                data = str(data)
            # If the file has an encoding, encode unicode with it.
            if (isinstance(fp, file) and
                    isinstance(data, unicode) and
                    fp.encoding is not None):
                errors = getattr(fp, "errors", None)
                if errors is None:
                    errors = "strict"
                data = data.encode(fp.encoding, errors)
            fp.write(data)
        want_unicode = False
        sep = kwargs.pop("sep", None)
        if sep is not None:
            if isinstance(sep, unicode):
                want_unicode = True
            elif not isinstance(sep, str):
                raise TypeError("sep must be None or a string")
        end = kwargs.pop("end", None)
        if end is not None:
            if isinstance(end, unicode):
                want_unicode = True
            elif not isinstance(end, str):
                raise TypeError("end must be None or a string")
        if kwargs:
            raise TypeError("invalid keyword arguments to print()")
        if not want_unicode:
            for arg in args:
                if isinstance(arg, unicode):
                    want_unicode = True
                    break
        if want_unicode:
            newline = unicode("\n")
            space = unicode(" ")
        else:
            newline = "\n"
            space = " "
        if sep is None:
            sep = space
        if end is None:
            end = newline
        for i, arg in enumerate(args):
            if i:
                write(sep)
            write(arg)
        write(end)
if sys.version_info[:2] < (3, 3):
    _print = print_

    def print_(*args, **kwargs):
        fp = kwargs.get("file", sys.stdout)
        flush = kwargs.pop("flush", False)
        _print(*args, **kwargs)
        if flush and fp is not None:
            fp.flush()

_add_doc(reraise, """Reraise an exception.""")

if sys.version_info[0:2] < (3, 4):
    # This does exactly the same what the :func:`py3:functools.update_wrapper`
    # function does on Python versions after 3.2. It sets the ``__wrapped__``
    # attribute on ``wrapper`` object and it doesn't raise an error if any of
    # the attributes mentioned in ``assigned`` and ``updated`` are missing on
    # ``wrapped`` object.
    def _update_wrapper(wrapper, wrapped,
                        assigned=functools.WRAPPER_ASSIGNMENTS,
                        updated=functools.WRAPPER_UPDATES):
        for attr in assigned:
            try:
                value = getattr(wrapped, attr)
            except AttributeError:
                continue
            else:
                setattr(wrapper, attr, value)
        for attr in updated:
            getattr(wrapper, attr).update(getattr(wrapped, attr, {}))
        wrapper.__wrapped__ = wrapped
        return wrapper
    _update_wrapper.__doc__ = functools.update_wrapper.__doc__

    def wraps(wrapped, assigned=functools.WRAPPER_ASSIGNMENTS,
              updated=functools.WRAPPER_UPDATES):
        return functools.partial(_update_wrapper, wrapped=wrapped,
                                 assigned=assigned, updated=updated)
    wraps.__doc__ = functools.wraps.__doc__

else:
    wraps = functools.wraps


def with_metaclass(meta, *bases):
    """Create a base class with a metaclass."""
    # This requires a bit of explanation: the basic idea is to make a dummy
    # metaclass for one level of class instantiation that replaces itself with
    # the actual metaclass.
    class metaclass(type):

        def __new__(cls, name, this_bases, d):
            if sys.version_info[:2] >= (3, 7):
                # This version introduced PEP 560 that requires a bit
                # of extra care (we mimic what is done by __build_class__).
                resolved_bases = types.resolve_bases(bases)
                if resolved_bases is not bases:
                    d['__orig_bases__'] = bases
            else:
                resolved_bases = bases
            return meta(name, resolved_bases, d)

        @classmethod
        def __prepare__(cls, name, this_bases):
            return meta.__prepare__(name, bases)
    return type.__new__(metaclass, 'temporary_class', (), {})


def add_metaclass(metaclass):
    """Class decorator for creating a class with a metaclass."""
    def wrapper(cls):
        orig_vars = cls.__dict__.copy()
        slots = orig_vars.get('__slots__')
        if slots is not None:
            if isinstance(slots, str):
                slots = [slots]
            for slots_var in slots:
                orig_vars.pop(slots_var)
        orig_vars.pop('__dict__', None)
        orig_vars.pop('__weakref__', None)
        if hasattr(cls, '__qualname__'):
            orig_vars['__qualname__'] = cls.__qualname__
        return metaclass(cls.__name__, cls.__bases__, orig_vars)
    return wrapper


def ensure_binary(s, encoding='utf-8', errors='strict'):
    """Coerce **s** to six.binary_type.

    For Python 2:
      - `unicode` -> encoded to `str`
      - `str` -> `str`

    For Python 3:
      - `str` -> encoded to `bytes`
      - `bytes` -> `bytes`
    """
    if isinstance(s, binary_type):
        return s
    if isinstance(s, text_type):
        return s.encode(encoding, errors)
    raise TypeError("not expecting type '%s'" % type(s))


def ensure_str(s, encoding='utf-8', errors='strict'):
    """Coerce *s* to `str`.

    For Python 2:
      - `unicode` -> encoded to `str`
      - `str` -> `str`

    For Python 3:
      - `str` -> `str`
      - `bytes` -> decoded to `str`
    """
    # Optimization: Fast return for the common case.
    if type(s) is str:
        return s
    if PY2 and isinstance(s, text_type):
        return s.encode(encoding, errors)
    elif PY3 and isinstance(s, binary_type):
        return s.decode(encoding, errors)
    elif not isinstance(s, (text_type, binary_type)):
        raise TypeError("not expecting type '%s'" % type(s))
    return s


def ensure_text(s, encoding='utf-8', errors='strict'):
    """Coerce *s* to six.text_type.

    For Python 2:
      - `unicode` -> `unicode`
      - `str` -> `unicode`

    For Python 3:
      - `str` -> `str`
      - `bytes` -> decoded to `str`
    """
    if isinstance(s, binary_type):
        return s.decode(encoding, errors)
    elif isinstance(s, text_type):
        return s
    else:
        raise TypeError("not expecting type '%s'" % type(s))


def python_2_unicode_compatible(klass):
    """
    A class decorator that defines __unicode__ and __str__ methods under Python 2.
    Under Python 3 it does nothing.

    To support Python 2 and 3 with a single code base, define a __str__ method
    returning text and apply this decorator to the class.
    """
    if PY2:
        if '__str__' not in klass.__dict__:
            raise ValueError("@python_2_unicode_compatible cannot be applied "
                             "to %s because it doesn't define __str__()." %
                             klass.__name__)
        klass.__unicode__ = klass.__str__
        klass.__str__ = lambda self: self.__unicode__().encode('utf-8')
    return klass


# Complete the moves implementation.
# This code is at the end of this module to speed up module loading.
# Turn this module into a package.
__path__ = []  # required for PEP 302 and PEP 451
__package__ = __name__  # see PEP 366 @ReservedAssignment
if globals().get("__spec__") is not None:
    __spec__.submodule_search_locations = []  # PEP 451 @UndefinedVariable
# Remove other six meta path importers, since they cause problems. This can
# happen if six is removed from sys.modules and then reloaded. (Setuptools does
# this for some reason.)
if sys.meta_path:
    for i, importer in enumerate(sys.meta_path):
        # Here's some real nastiness: Another "instance" of the six module might
        # be floating around. Therefore, we can't use isinstance() to check for
        # the six meta path importer, since the other six instance will have
        # inserted an importer with different class.
        if (type(importer).__name__ == "_SixMetaPathImporter" and
                importer.name == __name__):
            del sys.meta_path[i]
            break
    del i, importer
# Finally, add the importer to the meta path import hook.
sys.meta_path.append(_importer)




############################################################
### File: sjisprober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .mbcharsetprober import MultiByteCharSetProber
from .codingstatemachine import CodingStateMachine
from .chardistribution import SJISDistributionAnalysis
from .jpcntx import SJISContextAnalysis
from .mbcssm import SJIS_SM_MODEL
from .enums import ProbingState, MachineState


class SJISProber(MultiByteCharSetProber):
    def __init__(self):
        super(SJISProber, self).__init__()
        self.coding_sm = CodingStateMachine(SJIS_SM_MODEL)
        self.distribution_analyzer = SJISDistributionAnalysis()
        self.context_analyzer = SJISContextAnalysis()
        self.reset()

    def reset(self):
        super(SJISProber, self).reset()
        self.context_analyzer.reset()

    @property
    def charset_name(self):
        return self.context_analyzer.charset_name

    @property
    def language(self):
        return "Japanese"

    def feed(self, byte_str):
        for i in range(len(byte_str)):
            coding_state = self.coding_sm.next_state(byte_str[i])
            if coding_state == MachineState.ERROR:
                self.logger.debug('%s %s prober hit error at byte %s',
                                  self.charset_name, self.language, i)
                self._state = ProbingState.NOT_ME
                break
            elif coding_state == MachineState.ITS_ME:
                self._state = ProbingState.FOUND_IT
                break
            elif coding_state == MachineState.START:
                char_len = self.coding_sm.get_current_charlen()
                if i == 0:
                    self._last_char[1] = byte_str[0]
                    self.context_analyzer.feed(self._last_char[2 - char_len:],
                                               char_len)
                    self.distribution_analyzer.feed(self._last_char, char_len)
                else:
                    self.context_analyzer.feed(byte_str[i + 1 - char_len:i + 3
                                                        - char_len], char_len)
                    self.distribution_analyzer.feed(byte_str[i - 1:i + 1],
                                                    char_len)

        self._last_char[0] = byte_str[-1]

        if self.state == ProbingState.DETECTING:
            if (self.context_analyzer.got_enough_data() and
               (self.get_confidence() > self.SHORTCUT_THRESHOLD)):
                self._state = ProbingState.FOUND_IT

        return self.state

    def get_confidence(self):
        context_conf = self.context_analyzer.get_confidence()
        distrib_conf = self.distribution_analyzer.get_confidence()
        return max(context_conf, distrib_conf)




############################################################
### File: socks.py
############################################################
from base64 import b64encode
try:
    from collections.abc import Callable
except ImportError:
    from collections import Callable
from errno import EOPNOTSUPP, EINVAL, EAGAIN
import functools
from io import BytesIO
import logging
import os
from os import SEEK_CUR
import socket
import struct
import sys

__version__ = "1.7.1"


if os.name == "nt" and sys.version_info < (3, 0):
    try:
        import win_inet_pton
    except ImportError:
        raise ImportError(
            "To run PySocks on Windows you must install win_inet_pton")

log = logging.getLogger(__name__)

PROXY_TYPE_SOCKS4 = SOCKS4 = 1
PROXY_TYPE_SOCKS5 = SOCKS5 = 2
PROXY_TYPE_HTTP = HTTP = 3

PROXY_TYPES = {"SOCKS4": SOCKS4, "SOCKS5": SOCKS5, "HTTP": HTTP}
PRINTABLE_PROXY_TYPES = dict(zip(PROXY_TYPES.values(), PROXY_TYPES.keys()))

_orgsocket = _orig_socket = socket.socket


def set_self_blocking(function):

    @functools.wraps(function)
    def wrapper(*args, **kwargs):
        self = args[0]
        try:
            _is_blocking = self.gettimeout()
            if _is_blocking == 0:
                self.setblocking(True)
            return function(*args, **kwargs)
        except Exception as e:
            raise
        finally:
            # set orgin blocking
            if _is_blocking == 0:
                self.setblocking(False)
    return wrapper


class ProxyError(IOError):
    """Socket_err contains original socket.error exception."""
    def __init__(self, msg, socket_err=None):
        self.msg = msg
        self.socket_err = socket_err

        if socket_err:
            self.msg += ": {}".format(socket_err)

    def __str__(self):
        return self.msg


class GeneralProxyError(ProxyError):
    pass


class ProxyConnectionError(ProxyError):
    pass


class SOCKS5AuthError(ProxyError):
    pass


class SOCKS5Error(ProxyError):
    pass


class SOCKS4Error(ProxyError):
    pass


class HTTPError(ProxyError):
    pass

SOCKS4_ERRORS = {
    0x5B: "Request rejected or failed",
    0x5C: ("Request rejected because SOCKS server cannot connect to identd on"
           " the client"),
    0x5D: ("Request rejected because the client program and identd report"
           " different user-ids")
}

SOCKS5_ERRORS = {
    0x01: "General SOCKS server failure",
    0x02: "Connection not allowed by ruleset",
    0x03: "Network unreachable",
    0x04: "Host unreachable",
    0x05: "Connection refused",
    0x06: "TTL expired",
    0x07: "Command not supported, or protocol error",
    0x08: "Address type not supported"
}

DEFAULT_PORTS = {SOCKS4: 1080, SOCKS5: 1080, HTTP: 8080}


def set_default_proxy(proxy_type=None, addr=None, port=None, rdns=True,
                      username=None, password=None):
    """Sets a default proxy.

    All further socksocket objects will use the default unless explicitly
    changed. All parameters are as for socket.set_proxy()."""
    socksocket.default_proxy = (proxy_type, addr, port, rdns,
                                username.encode() if username else None,
                                password.encode() if password else None)


def setdefaultproxy(*args, **kwargs):
    if "proxytype" in kwargs:
        kwargs["proxy_type"] = kwargs.pop("proxytype")
    return set_default_proxy(*args, **kwargs)


def get_default_proxy():
    """Returns the default proxy, set by set_default_proxy."""
    return socksocket.default_proxy

getdefaultproxy = get_default_proxy


def wrap_module(module):
    """Attempts to replace a module's socket library with a SOCKS socket.

    Must set a default proxy using set_default_proxy(...) first. This will
    only work on modules that import socket directly into the namespace;
    most of the Python Standard Library falls into this category."""
    if socksocket.default_proxy:
        module.socket.socket = socksocket
    else:
        raise GeneralProxyError("No default proxy specified")

wrapmodule = wrap_module


def create_connection(dest_pair,
                      timeout=None, source_address=None,
                      proxy_type=None, proxy_addr=None,
                      proxy_port=None, proxy_rdns=True,
                      proxy_username=None, proxy_password=None,
                      socket_options=None,
                      getaddrinfo = socket.getaddrinfo):
    """create_connection(dest_pair, *[, timeout], **proxy_args) -> socket object

    Like socket.create_connection(), but connects to proxy
    before returning the socket object.

    dest_pair - 2-tuple of (IP/hostname, port).
    **proxy_args - Same args passed to socksocket.set_proxy() if present.
    timeout - Optional socket timeout value, in seconds.
    source_address - tuple (host, port) for the socket to bind to as its source
    address before connecting (only for compatibility)
    """
    # Remove IPv6 brackets on the remote address and proxy address.
    remote_host, remote_port = dest_pair
    if remote_host.startswith("["):
        remote_host = remote_host.strip("[]")
    if proxy_addr and proxy_addr.startswith("["):
        proxy_addr = proxy_addr.strip("[]")

    err = None

    # Allow the SOCKS proxy to be on IPv4 or IPv6 addresses.
    for r in getaddrinfo(proxy_addr, proxy_port, 0, socket.SOCK_STREAM):
        family, socket_type, proto, canonname, sa = r
        sock = None
        try:
            sock = socksocket(family, socket_type, proto)

            if socket_options:
                for opt in socket_options:
                    sock.setsockopt(*opt)

            if isinstance(timeout, (int, float)):
                sock.settimeout(timeout)

            if proxy_type:
                sock.set_proxy(proxy_type, proxy_addr, proxy_port, proxy_rdns,
                               proxy_username, proxy_password)
            if source_address:
                sock.bind(source_address)

            sock.connect((remote_host, remote_port))
            return sock

        except (socket.error, ProxyError) as e:
            err = e
            if sock:
                sock.close()
                sock = None

    if err:
        raise err

    raise socket.error("gai returned empty list.")


class _BaseSocket(socket.socket):
    """Allows Python 2 delegated methods such as send() to be overridden."""
    def __init__(self, *pos, **kw):
        _orig_socket.__init__(self, *pos, **kw)

        self._savedmethods = dict()
        for name in self._savenames:
            self._savedmethods[name] = getattr(self, name)
            delattr(self, name)  # Allows normal overriding mechanism to work

    _savenames = list()


def _makemethod(name):
    return lambda self, *pos, **kw: self._savedmethods[name](*pos, **kw)
for name in ("sendto", "send", "recvfrom", "recv"):
    method = getattr(_BaseSocket, name, None)

    # Determine if the method is not defined the usual way
    # as a function in the class.
    # Python 2 uses __slots__, so there are descriptors for each method,
    # but they are not functions.
    if not isinstance(method, Callable):
        _BaseSocket._savenames.append(name)
        setattr(_BaseSocket, name, _makemethod(name))


class socksocket(_BaseSocket):
    """socksocket([family[, type[, proto]]]) -> socket object

    Open a SOCKS enabled socket. The parameters are the same as
    those of the standard socket init. In order for SOCKS to work,
    you must specify family=AF_INET and proto=0.
    The "type" argument must be either SOCK_STREAM or SOCK_DGRAM.
    """

    default_proxy = None

    def __init__(self, family=socket.AF_INET, type=socket.SOCK_STREAM,
                 proto=0, *args, **kwargs):
        if type not in (socket.SOCK_STREAM, socket.SOCK_DGRAM):
            msg = "Socket type must be stream or datagram, not {!r}"
            raise ValueError(msg.format(type))

        super(socksocket, self).__init__(family, type, proto, *args, **kwargs)
        self._proxyconn = None  # TCP connection to keep UDP relay alive

        if self.default_proxy:
            self.proxy = self.default_proxy
        else:
            self.proxy = (None, None, None, None, None, None)
        self.proxy_sockname = None
        self.proxy_peername = None

        self._timeout = None

    def _readall(self, file, count):
        """Receive EXACTLY the number of bytes requested from the file object.

        Blocks until the required number of bytes have been received."""
        data = b""
        while len(data) < count:
            d = file.read(count - len(data))
            if not d:
                raise GeneralProxyError("Connection closed unexpectedly")
            data += d
        return data

    def settimeout(self, timeout):
        self._timeout = timeout
        try:
            # test if we're connected, if so apply timeout
            peer = self.get_proxy_peername()
            super(socksocket, self).settimeout(self._timeout)
        except socket.error:
            pass

    def gettimeout(self):
        return self._timeout

    def setblocking(self, v):
        if v:
            self.settimeout(None)
        else:
            self.settimeout(0.0)

    def set_proxy(self, proxy_type=None, addr=None, port=None, rdns=True,
                  username=None, password=None):
        """ Sets the proxy to be used.

        proxy_type -  The type of the proxy to be used. Three types
                        are supported: PROXY_TYPE_SOCKS4 (including socks4a),
                        PROXY_TYPE_SOCKS5 and PROXY_TYPE_HTTP
        addr -        The address of the server (IP or DNS).
        port -        The port of the server. Defaults to 1080 for SOCKS
                        servers and 8080 for HTTP proxy servers.
        rdns -        Should DNS queries be performed on the remote side
                       (rather than the local side). The default is True.
                       Note: This has no effect with SOCKS4 servers.
        username -    Username to authenticate with to the server.
                       The default is no authentication.
        password -    Password to authenticate with to the server.
                       Only relevant when username is also provided."""
        self.proxy = (proxy_type, addr, port, rdns,
                      username.encode() if username else None,
                      password.encode() if password else None)

    def setproxy(self, *args, **kwargs):
        if "proxytype" in kwargs:
            kwargs["proxy_type"] = kwargs.pop("proxytype")
        return self.set_proxy(*args, **kwargs)

    def bind(self, *pos, **kw):
        """Implements proxy connection for UDP sockets.

        Happens during the bind() phase."""
        (proxy_type, proxy_addr, proxy_port, rdns, username,
         password) = self.proxy
        if not proxy_type or self.type != socket.SOCK_DGRAM:
            return _orig_socket.bind(self, *pos, **kw)

        if self._proxyconn:
            raise socket.error(EINVAL, "Socket already bound to an address")
        if proxy_type != SOCKS5:
            msg = "UDP only supported by SOCKS5 proxy type"
            raise socket.error(EOPNOTSUPP, msg)
        super(socksocket, self).bind(*pos, **kw)

        # Need to specify actual local port because
        # some relays drop packets if a port of zero is specified.
        # Avoid specifying host address in case of NAT though.
        _, port = self.getsockname()
        dst = ("0", port)

        self._proxyconn = _orig_socket()
        proxy = self._proxy_addr()
        self._proxyconn.connect(proxy)

        UDP_ASSOCIATE = b"\x03"
        _, relay = self._SOCKS5_request(self._proxyconn, UDP_ASSOCIATE, dst)

        # The relay is most likely on the same host as the SOCKS proxy,
        # but some proxies return a private IP address (10.x.y.z)
        host, _ = proxy
        _, port = relay
        super(socksocket, self).connect((host, port))
        super(socksocket, self).settimeout(self._timeout)
        self.proxy_sockname = ("0.0.0.0", 0)  # Unknown

    def sendto(self, bytes, *args, **kwargs):
        if self.type != socket.SOCK_DGRAM:
            return super(socksocket, self).sendto(bytes, *args, **kwargs)
        if not self._proxyconn:
            self.bind(("", 0))

        address = args[-1]
        flags = args[:-1]

        header = BytesIO()
        RSV = b"\x00\x00"
        header.write(RSV)
        STANDALONE = b"\x00"
        header.write(STANDALONE)
        self._write_SOCKS5_address(address, header)

        sent = super(socksocket, self).send(header.getvalue() + bytes, *flags,
                                            **kwargs)
        return sent - header.tell()

    def send(self, bytes, flags=0, **kwargs):
        if self.type == socket.SOCK_DGRAM:
            return self.sendto(bytes, flags, self.proxy_peername, **kwargs)
        else:
            return super(socksocket, self).send(bytes, flags, **kwargs)

    def recvfrom(self, bufsize, flags=0):
        if self.type != socket.SOCK_DGRAM:
            return super(socksocket, self).recvfrom(bufsize, flags)
        if not self._proxyconn:
            self.bind(("", 0))

        buf = BytesIO(super(socksocket, self).recv(bufsize + 1024, flags))
        buf.seek(2, SEEK_CUR)
        frag = buf.read(1)
        if ord(frag):
            raise NotImplementedError("Received UDP packet fragment")
        fromhost, fromport = self._read_SOCKS5_address(buf)

        if self.proxy_peername:
            peerhost, peerport = self.proxy_peername
            if fromhost != peerhost or peerport not in (0, fromport):
                raise socket.error(EAGAIN, "Packet filtered")

        return (buf.read(bufsize), (fromhost, fromport))

    def recv(self, *pos, **kw):
        bytes, _ = self.recvfrom(*pos, **kw)
        return bytes

    def close(self):
        if self._proxyconn:
            self._proxyconn.close()
        return super(socksocket, self).close()

    def get_proxy_sockname(self):
        """Returns the bound IP address and port number at the proxy."""
        return self.proxy_sockname

    getproxysockname = get_proxy_sockname

    def get_proxy_peername(self):
        """
        Returns the IP and port number of the proxy.
        """
        return self.getpeername()

    getproxypeername = get_proxy_peername

    def get_peername(self):
        """Returns the IP address and port number of the destination machine.

        Note: get_proxy_peername returns the proxy."""
        return self.proxy_peername

    getpeername = get_peername

    def _negotiate_SOCKS5(self, *dest_addr):
        """Negotiates a stream connection through a SOCKS5 server."""
        CONNECT = b"\x01"
        self.proxy_peername, self.proxy_sockname = self._SOCKS5_request(
            self, CONNECT, dest_addr)

    def _SOCKS5_request(self, conn, cmd, dst):
        """
        Send SOCKS5 request with given command (CMD field) and
        address (DST field). Returns resolved DST address that was used.
        """
        proxy_type, addr, port, rdns, username, password = self.proxy

        writer = conn.makefile("wb")
        reader = conn.makefile("rb", 0)  # buffering=0 renamed in Python 3
        try:
            # First we'll send the authentication packages we support.
            if username and password:
                # The username/password details were supplied to the
                # set_proxy method so we support the USERNAME/PASSWORD
                # authentication (in addition to the standard none).
                writer.write(b"\x05\x02\x00\x02")
            else:
                # No username/password were entered, therefore we
                # only support connections with no authentication.
                writer.write(b"\x05\x01\x00")

            # We'll receive the server's response to determine which
            # method was selected
            writer.flush()
            chosen_auth = self._readall(reader, 2)

            if chosen_auth[0:1] != b"\x05":
                # Note: string[i:i+1] is used because indexing of a bytestring
                # via bytestring[i] yields an integer in Python 3
                raise GeneralProxyError(
                    "SOCKS5 proxy server sent invalid data")

            # Check the chosen authentication method

            if chosen_auth[1:2] == b"\x02":
                # Okay, we need to perform a basic username/password
                # authentication.
                if not (username and password):
                    # Although we said we don't support authentication, the
                    # server may still request basic username/password
                    # authentication
                    raise SOCKS5AuthError("No username/password supplied. "
                                          "Server requested username/password"
                                          " authentication")

                writer.write(b"\x01" + chr(len(username)).encode()
                             + username
                             + chr(len(password)).encode()
                             + password)
                writer.flush()
                auth_status = self._readall(reader, 2)
                if auth_status[0:1] != b"\x01":
                    # Bad response
                    raise GeneralProxyError(
                        "SOCKS5 proxy server sent invalid data")
                if auth_status[1:2] != b"\x00":
                    # Authentication failed
                    raise SOCKS5AuthError("SOCKS5 authentication failed")

                # Otherwise, authentication succeeded

            # No authentication is required if 0x00
            elif chosen_auth[1:2] != b"\x00":
                # Reaching here is always bad
                if chosen_auth[1:2] == b"\xFF":
                    raise SOCKS5AuthError(
                        "All offered SOCKS5 authentication methods were"
                        " rejected")
                else:
                    raise GeneralProxyError(
                        "SOCKS5 proxy server sent invalid data")

            # Now we can request the actual connection
            writer.write(b"\x05" + cmd + b"\x00")
            resolved = self._write_SOCKS5_address(dst, writer)
            writer.flush()

            # Get the response
            resp = self._readall(reader, 3)
            if resp[0:1] != b"\x05":
                raise GeneralProxyError(
                    "SOCKS5 proxy server sent invalid data")

            status = ord(resp[1:2])
            if status != 0x00:
                # Connection failed: server returned an error
                error = SOCKS5_ERRORS.get(status, "Unknown error")
                raise SOCKS5Error("{:#04x}: {}".format(status, error))

            # Get the bound address/port
            bnd = self._read_SOCKS5_address(reader)

            super(socksocket, self).settimeout(self._timeout)
            return (resolved, bnd)
        finally:
            reader.close()
            writer.close()

    def _write_SOCKS5_address(self, addr, file):
        """
        Return the host and port packed for the SOCKS5 protocol,
        and the resolved address as a tuple object.
        """
        host, port = addr
        proxy_type, _, _, rdns, username, password = self.proxy
        family_to_byte = {socket.AF_INET: b"\x01", socket.AF_INET6: b"\x04"}

        # If the given destination address is an IP address, we'll
        # use the IP address request even if remote resolving was specified.
        # Detect whether the address is IPv4/6 directly.
        for family in (socket.AF_INET, socket.AF_INET6):
            try:
                addr_bytes = socket.inet_pton(family, host)
                file.write(family_to_byte[family] + addr_bytes)
                host = socket.inet_ntop(family, addr_bytes)
                file.write(struct.pack(">H", port))
                return host, port
            except socket.error:
                continue

        # Well it's not an IP number, so it's probably a DNS name.
        if rdns:
            # Resolve remotely
            host_bytes = host.encode("idna")
            file.write(b"\x03" + chr(len(host_bytes)).encode() + host_bytes)
        else:
            # Resolve locally
            addresses = socket.getaddrinfo(host, port, socket.AF_UNSPEC,
                                           socket.SOCK_STREAM,
                                           socket.IPPROTO_TCP,
                                           socket.AI_ADDRCONFIG)
            # We can't really work out what IP is reachable, so just pick the
            # first.
            target_addr = addresses[0]
            family = target_addr[0]
            host = target_addr[4][0]

            addr_bytes = socket.inet_pton(family, host)
            file.write(family_to_byte[family] + addr_bytes)
            host = socket.inet_ntop(family, addr_bytes)
        file.write(struct.pack(">H", port))
        return host, port

    def _read_SOCKS5_address(self, file):
        atyp = self._readall(file, 1)
        if atyp == b"\x01":
            addr = socket.inet_ntoa(self._readall(file, 4))
        elif atyp == b"\x03":
            length = self._readall(file, 1)
            addr = self._readall(file, ord(length))
        elif atyp == b"\x04":
            addr = socket.inet_ntop(socket.AF_INET6, self._readall(file, 16))
        else:
            raise GeneralProxyError("SOCKS5 proxy server sent invalid data")

        port = struct.unpack(">H", self._readall(file, 2))[0]
        return addr, port

    def _negotiate_SOCKS4(self, dest_addr, dest_port):
        """Negotiates a connection through a SOCKS4 server."""
        proxy_type, addr, port, rdns, username, password = self.proxy

        writer = self.makefile("wb")
        reader = self.makefile("rb", 0)  # buffering=0 renamed in Python 3
        try:
            # Check if the destination address provided is an IP address
            remote_resolve = False
            try:
                addr_bytes = socket.inet_aton(dest_addr)
            except socket.error:
                # It's a DNS name. Check where it should be resolved.
                if rdns:
                    addr_bytes = b"\x00\x00\x00\x01"
                    remote_resolve = True
                else:
                    addr_bytes = socket.inet_aton(
                        socket.gethostbyname(dest_addr))

            # Construct the request packet
            writer.write(struct.pack(">BBH", 0x04, 0x01, dest_port))
            writer.write(addr_bytes)

            # The username parameter is considered userid for SOCKS4
            if username:
                writer.write(username)
            writer.write(b"\x00")

            # DNS name if remote resolving is required
            # NOTE: This is actually an extension to the SOCKS4 protocol
            # called SOCKS4A and may not be supported in all cases.
            if remote_resolve:
                writer.write(dest_addr.encode("idna") + b"\x00")
            writer.flush()

            # Get the response from the server
            resp = self._readall(reader, 8)
            if resp[0:1] != b"\x00":
                # Bad data
                raise GeneralProxyError(
                    "SOCKS4 proxy server sent invalid data")

            status = ord(resp[1:2])
            if status != 0x5A:
                # Connection failed: server returned an error
                error = SOCKS4_ERRORS.get(status, "Unknown error")
                raise SOCKS4Error("{:#04x}: {}".format(status, error))

            # Get the bound address/port
            self.proxy_sockname = (socket.inet_ntoa(resp[4:]),
                                   struct.unpack(">H", resp[2:4])[0])
            if remote_resolve:
                self.proxy_peername = socket.inet_ntoa(addr_bytes), dest_port
            else:
                self.proxy_peername = dest_addr, dest_port
        finally:
            reader.close()
            writer.close()

    def _negotiate_HTTP(self, dest_addr, dest_port):
        """Negotiates a connection through an HTTP server.

        NOTE: This currently only supports HTTP CONNECT-style proxies."""
        proxy_type, addr, port, rdns, username, password = self.proxy

        # If we need to resolve locally, we do this now
        addr = dest_addr if rdns else socket.gethostbyname(dest_addr)

        http_headers = [
            (b"CONNECT " + addr.encode("idna") + b":"
             + str(dest_port).encode() + b" HTTP/1.1"),
            b"Host: " + dest_addr.encode("idna")
        ]

        if username and password:
            http_headers.append(b"Proxy-Authorization: basic "
                                + b64encode(username + b":" + password))

        http_headers.append(b"\r\n")

        self.sendall(b"\r\n".join(http_headers))

        # We just need the first line to check if the connection was successful
        fobj = self.makefile()
        status_line = fobj.readline()
        fobj.close()

        if not status_line:
            raise GeneralProxyError("Connection closed unexpectedly")

        try:
            proto, status_code, status_msg = status_line.split(" ", 2)
        except ValueError:
            raise GeneralProxyError("HTTP proxy server sent invalid response")

        if not proto.startswith("HTTP/"):
            raise GeneralProxyError(
                "Proxy server does not appear to be an HTTP proxy")

        try:
            status_code = int(status_code)
        except ValueError:
            raise HTTPError(
                "HTTP proxy server did not return a valid HTTP status")

        if status_code != 200:
            error = "{}: {}".format(status_code, status_msg)
            if status_code in (400, 403, 405):
                # It's likely that the HTTP proxy server does not support the
                # CONNECT tunneling method
                error += ("\n[*] Note: The HTTP proxy server may not be"
                          " supported by PySocks (must be a CONNECT tunnel"
                          " proxy)")
            raise HTTPError(error)

        self.proxy_sockname = (b"0.0.0.0", 0)
        self.proxy_peername = addr, dest_port

    _proxy_negotiators = {
                           SOCKS4: _negotiate_SOCKS4,
                           SOCKS5: _negotiate_SOCKS5,
                           HTTP: _negotiate_HTTP
                         }

    @set_self_blocking
    def connect(self, dest_pair, catch_errors=None):
        """
        Connects to the specified destination through a proxy.
        Uses the same API as socket's connect().
        To select the proxy server, use set_proxy().

        dest_pair - 2-tuple of (IP/hostname, port).
        """
        if len(dest_pair) != 2 or dest_pair[0].startswith("["):
            # Probably IPv6, not supported -- raise an error, and hope
            # Happy Eyeballs (RFC6555) makes sure at least the IPv4
            # connection works...
            raise socket.error("PySocks doesn't support IPv6: %s"
                               % str(dest_pair))

        dest_addr, dest_port = dest_pair

        if self.type == socket.SOCK_DGRAM:
            if not self._proxyconn:
                self.bind(("", 0))
            dest_addr = socket.gethostbyname(dest_addr)

            # If the host address is INADDR_ANY or similar, reset the peer
            # address so that packets are received from any peer
            if dest_addr == "0.0.0.0" and not dest_port:
                self.proxy_peername = None
            else:
                self.proxy_peername = (dest_addr, dest_port)
            return

        (proxy_type, proxy_addr, proxy_port, rdns, username,
         password) = self.proxy

        # Do a minimal input check first
        if (not isinstance(dest_pair, (list, tuple))
                or len(dest_pair) != 2
                or not dest_addr
                or not isinstance(dest_port, int)):
            # Inputs failed, raise an error
            raise GeneralProxyError(
                "Invalid destination-connection (host, port) pair")

        # We set the timeout here so that we don't hang in connection or during
        # negotiation.
        super(socksocket, self).settimeout(self._timeout)

        if proxy_type is None:
            # Treat like regular socket object
            self.proxy_peername = dest_pair
            super(socksocket, self).settimeout(self._timeout)
            super(socksocket, self).connect((dest_addr, dest_port))
            return

        proxy_addr = self._proxy_addr()

        try:
            # Initial connection to proxy server.
            super(socksocket, self).connect(proxy_addr)

        except socket.error as error:
            # Error while connecting to proxy
            self.close()
            if not catch_errors:
                proxy_addr, proxy_port = proxy_addr
                proxy_server = "{}:{}".format(proxy_addr, proxy_port)
                printable_type = PRINTABLE_PROXY_TYPES[proxy_type]

                msg = "Error connecting to {} proxy {}".format(printable_type,
                                                                    proxy_server)
                log.debug("%s due to: %s", msg, error)
                raise ProxyConnectionError(msg, error)
            else:
                raise error

        else:
            # Connected to proxy server, now negotiate
            try:
                # Calls negotiate_{SOCKS4, SOCKS5, HTTP}
                negotiate = self._proxy_negotiators[proxy_type]
                negotiate(self, dest_addr, dest_port)
            except socket.error as error:
                if not catch_errors:
                    # Wrap socket errors
                    self.close()
                    raise GeneralProxyError("Socket error", error)
                else:
                    raise error
            except ProxyError:
                # Protocol error while negotiating with proxy
                self.close()
                raise

    @set_self_blocking
    def connect_ex(self, dest_pair):
        """ https://docs.python.org/3/library/socket.html#socket.socket.connect_ex
        Like connect(address), but return an error indicator instead of raising an exception for errors returned by the C-level connect() call (other problems, such as "host not found" can still raise exceptions).
        """
        try:
            self.connect(dest_pair, catch_errors=True)
            return 0
        except OSError as e:
            # If the error is numeric (socket errors are numeric), then return number as
            # connect_ex expects. Otherwise raise the error again (socket timeout for example)
            if e.errno:
                return e.errno
            else:
                raise

    def _proxy_addr(self):
        """
        Return proxy address to connect to as tuple object
        """
        (proxy_type, proxy_addr, proxy_port, rdns, username,
         password) = self.proxy
        proxy_port = proxy_port or DEFAULT_PORTS.get(proxy_type)
        if not proxy_port:
            raise GeneralProxyError("Invalid proxy type")
        return proxy_addr, proxy_port




############################################################
### File: sockshandler.py
############################################################
#!/usr/bin/env python
"""
SocksiPy + urllib2 handler

version: 0.3
author: e<e@tr0ll.in>

This module provides a Handler which you can use with urllib2 to allow it to tunnel your connection through a socks.sockssocket socket, with out monkey patching the original socket...
"""
import socket
import ssl

try:
    import urllib2
    import httplib
except ImportError: # Python 3
    import urllib.request as urllib2
    import http.client as httplib

import socks # $ pip install PySocks

def merge_dict(a, b):
    d = a.copy()
    d.update(b)
    return d

def is_ip(s):
    try:
        if ':' in s:
            socket.inet_pton(socket.AF_INET6, s)
        elif '.' in s:
            socket.inet_aton(s)
        else:
            return False
    except:
        return False
    else:
        return True

socks4_no_rdns = set()

class SocksiPyConnection(httplib.HTTPConnection):
    def __init__(self, proxytype, proxyaddr, proxyport=None, rdns=True, username=None, password=None, *args, **kwargs):
        self.proxyargs = (proxytype, proxyaddr, proxyport, rdns, username, password)
        httplib.HTTPConnection.__init__(self, *args, **kwargs)

    def connect(self):
        (proxytype, proxyaddr, proxyport, rdns, username, password) = self.proxyargs
        rdns = rdns and proxyaddr not in socks4_no_rdns
        while True:
            try:
                sock = socks.create_connection(
                    (self.host, self.port), self.timeout, None,
                    proxytype, proxyaddr, proxyport, rdns, username, password,
                    ((socket.IPPROTO_TCP, socket.TCP_NODELAY, 1),))
                break
            except socks.SOCKS4Error as e:
                if rdns and "0x5b" in str(e) and not is_ip(self.host):
                    # Maybe a SOCKS4 server that doesn't support remote resolving
                    # Let's try again
                    rdns = False
                    socks4_no_rdns.add(proxyaddr)
                else:
                    raise
        self.sock = sock

class SocksiPyConnectionS(httplib.HTTPSConnection):
    def __init__(self, proxytype, proxyaddr, proxyport=None, rdns=True, username=None, password=None, *args, **kwargs):
        self.proxyargs = (proxytype, proxyaddr, proxyport, rdns, username, password)
        httplib.HTTPSConnection.__init__(self, *args, **kwargs)

    def connect(self):
        SocksiPyConnection.connect(self)
        self.sock = self._context.wrap_socket(self.sock, server_hostname=self.host)
        if not self._context.check_hostname and self._check_hostname:
            try:
                ssl.match_hostname(self.sock.getpeercert(), self.host)
            except Exception:
                self.sock.shutdown(socket.SHUT_RDWR)
                self.sock.close()
                raise

class SocksiPyHandler(urllib2.HTTPHandler, urllib2.HTTPSHandler):
    def __init__(self, *args, **kwargs):
        self.args = args
        self.kw = kwargs
        urllib2.HTTPHandler.__init__(self)

    def http_open(self, req):
        def build(host, port=None, timeout=0, **kwargs):
            kw = merge_dict(self.kw, kwargs)
            conn = SocksiPyConnection(*self.args, host=host, port=port, timeout=timeout, **kw)
            return conn
        return self.do_open(build, req)

    def https_open(self, req):
        def build(host, port=None, timeout=0, **kwargs):
            kw = merge_dict(self.kw, kwargs)
            conn = SocksiPyConnectionS(*self.args, host=host, port=port, timeout=timeout, **kw)
            return conn
        return self.do_open(build, req)

if __name__ == "__main__":
    import sys
    try:
        port = int(sys.argv[1])
    except (ValueError, IndexError):
        port = 9050
    opener = urllib2.build_opener(SocksiPyHandler(socks.PROXY_TYPE_SOCKS5, "localhost", port))
    print("HTTP: " + opener.open("http://httpbin.org/ip").read().decode())
    print("HTTPS: " + opener.open("https://httpbin.org/ip").read().decode())




############################################################
### File: srt.py
############################################################
from copy import deepcopy
import six

from .base import (
    BaseReader, BaseWriter, CaptionSet, CaptionList, Caption, CaptionNode)
from .exceptions import CaptionReadNoCaptions, InvalidInputError


class SRTReader(BaseReader):
    def detect(self, content):
        lines = content.splitlines()
        if lines[0].isdigit() and '-->' in lines[1]:
            return True
        else:
            return False

    def read(self, content, lang='en-US'):
        if type(content) != six.text_type:
            raise InvalidInputError('The content is not a unicode string.')

        lines = content.splitlines()
        start_line = 0
        captions = CaptionList()

        while start_line < len(lines):
            if not lines[start_line].isdigit():
                break

            end_line = self._find_text_line(start_line, lines)

            timing = lines[start_line + 1].split('-->')
            start = self._srttomicro(timing[0].strip(' \r\n'))
            end = self._srttomicro(timing[1].strip(' \r\n'))

            nodes = []

            for line in lines[start_line + 2:end_line - 1]:
                # skip extra blank lines
                if not nodes or line != '':
                    nodes.append(CaptionNode.create_text(line))
                    nodes.append(CaptionNode.create_break())

            if len(nodes):
                # remove last line break from end of caption list
                nodes.pop()
                caption = Caption(start, end, nodes)
                captions.append(caption)

            start_line = end_line

        caption_set = CaptionSet({lang: captions})

        if caption_set.is_empty():
            raise CaptionReadNoCaptions("empty caption file")

        return caption_set

    def _srttomicro(self, stamp):
        timesplit = stamp.split(':')
        if ',' not in timesplit[2]:
            timesplit[2] += ',000'
        secsplit = timesplit[2].split(',')
        microseconds = (int(timesplit[0]) * 3600000000 +
                        int(timesplit[1]) * 60000000 +
                        int(secsplit[0]) * 1000000 +
                        int(secsplit[1]) * 1000)

        return microseconds

    def _find_text_line(self, start_line, lines):
        end_line = start_line

        found = False
        while end_line < len(lines):
            if lines[end_line].strip() == "":
                found = True
            elif found is True:
                end_line -= 1
                break
            end_line += 1

        return end_line + 1


class SRTWriter(BaseWriter):
    def write(self, caption_set):
        caption_set = deepcopy(caption_set)

        srt_captions = []

        for lang in caption_set.get_languages():
            srt_captions.append(
                self._recreate_lang(caption_set.get_captions(lang))
            )

        caption_content = 'MULTI-LANGUAGE SRT\n'.join(srt_captions)
        return caption_content

    def _recreate_lang(self, captions):
        srt = ''
        count = 1

        for caption in captions:
            srt += '%s\n' % count

            start = caption.format_start(msec_separator=',')
            end = caption.format_end(msec_separator=',')
            timestamp = '%s --> %s\n' % (start[:12], end[:12])

            srt += timestamp.replace('.', ',')

            new_content = ''
            for node in caption.nodes:
                new_content = self._recreate_line(new_content, node)

            # Eliminate excessive line breaks
            new_content = new_content.strip()
            while '\n\n' in new_content:
                new_content = new_content.replace('\n\n', '\n')

            srt += "%s%s" % (new_content, '\n\n')
            count += 1

        return srt[:-1]  # remove unwanted newline at end of file

    def _recreate_line(self, srt, line):
        if line.type_ == CaptionNode.TEXT:
            return srt + '%s ' % line.content
        elif line.type_ == CaptionNode.BREAK:
            return srt + '\n'
        else:
            return srt




############################################################
### File: status_codes.py
############################################################
# -*- coding: utf-8 -*-

r"""
The ``codes`` object defines a mapping from common names for HTTP statuses
to their numerical codes, accessible either as attributes or as dictionary
items.

Example::

    >>> import requests
    >>> requests.codes['temporary_redirect']
    307
    >>> requests.codes.teapot
    418
    >>> requests.codes['\o/']
    200

Some codes have multiple names, and both upper- and lower-case versions of
the names are allowed. For example, ``codes.ok``, ``codes.OK``, and
``codes.okay`` all correspond to the HTTP status code 200.
"""

from .structures import LookupDict

_codes = {

    # Informational.
    100: ('continue',),
    101: ('switching_protocols',),
    102: ('processing',),
    103: ('checkpoint',),
    122: ('uri_too_long', 'request_uri_too_long'),
    200: ('ok', 'okay', 'all_ok', 'all_okay', 'all_good', '\\o/', ''),
    201: ('created',),
    202: ('accepted',),
    203: ('non_authoritative_info', 'non_authoritative_information'),
    204: ('no_content',),
    205: ('reset_content', 'reset'),
    206: ('partial_content', 'partial'),
    207: ('multi_status', 'multiple_status', 'multi_stati', 'multiple_stati'),
    208: ('already_reported',),
    226: ('im_used',),

    # Redirection.
    300: ('multiple_choices',),
    301: ('moved_permanently', 'moved', '\\o-'),
    302: ('found',),
    303: ('see_other', 'other'),
    304: ('not_modified',),
    305: ('use_proxy',),
    306: ('switch_proxy',),
    307: ('temporary_redirect', 'temporary_moved', 'temporary'),
    308: ('permanent_redirect',
          'resume_incomplete', 'resume',),  # These 2 to be removed in 3.0

    # Client Error.
    400: ('bad_request', 'bad'),
    401: ('unauthorized',),
    402: ('payment_required', 'payment'),
    403: ('forbidden',),
    404: ('not_found', '-o-'),
    405: ('method_not_allowed', 'not_allowed'),
    406: ('not_acceptable',),
    407: ('proxy_authentication_required', 'proxy_auth', 'proxy_authentication'),
    408: ('request_timeout', 'timeout'),
    409: ('conflict',),
    410: ('gone',),
    411: ('length_required',),
    412: ('precondition_failed', 'precondition'),
    413: ('request_entity_too_large',),
    414: ('request_uri_too_large',),
    415: ('unsupported_media_type', 'unsupported_media', 'media_type'),
    416: ('requested_range_not_satisfiable', 'requested_range', 'range_not_satisfiable'),
    417: ('expectation_failed',),
    418: ('im_a_teapot', 'teapot', 'i_am_a_teapot'),
    421: ('misdirected_request',),
    422: ('unprocessable_entity', 'unprocessable'),
    423: ('locked',),
    424: ('failed_dependency', 'dependency'),
    425: ('unordered_collection', 'unordered'),
    426: ('upgrade_required', 'upgrade'),
    428: ('precondition_required', 'precondition'),
    429: ('too_many_requests', 'too_many'),
    431: ('header_fields_too_large', 'fields_too_large'),
    444: ('no_response', 'none'),
    449: ('retry_with', 'retry'),
    450: ('blocked_by_windows_parental_controls', 'parental_controls'),
    451: ('unavailable_for_legal_reasons', 'legal_reasons'),
    499: ('client_closed_request',),

    # Server Error.
    500: ('internal_server_error', 'server_error', '/o\\', ''),
    501: ('not_implemented',),
    502: ('bad_gateway',),
    503: ('service_unavailable', 'unavailable'),
    504: ('gateway_timeout',),
    505: ('http_version_not_supported', 'http_version'),
    506: ('variant_also_negotiates',),
    507: ('insufficient_storage',),
    509: ('bandwidth_limit_exceeded', 'bandwidth'),
    510: ('not_extended',),
    511: ('network_authentication_required', 'network_auth', 'network_authentication'),
}

codes = LookupDict(name='status_codes')

def _init():
    for code, titles in _codes.items():
        for title in titles:
            setattr(codes, title, code)
            if not title.startswith(('\\', '/')):
                setattr(codes, title.upper(), code)

    def doc(code):
        names = ', '.join('``%s``' % n for n in _codes[code])
        return '* %d: %s' % (code, names)

    global __doc__
    __doc__ = (__doc__ + '\n' +
               '\n'.join(doc(code) for code in sorted(_codes))
               if __doc__ is not None else None)

_init()




############################################################
### File: std_nodes.py
############################################################
from .pyjsparserdata import *


class Ecma51NotSupported(Exception):
    def __init__(self, feature):
        super(Ecma51NotSupported,
              self).__init__("%s is not supported by ECMA 5.1." % feature)
        self.feature = feature

    def get_feature(self):
        return self.feature


class BaseNode:
    def finish(self):
        pass

    def finishArrayExpression(self, elements):
        self.type = Syntax.ArrayExpression
        self.elements = elements
        self.finish()
        return self

    def finishArrayPattern(self, elements):
        self.type = Syntax.ArrayPattern
        self.elements = elements
        self.finish()
        return self

    def finishAssignmentExpression(self, operator, left, right):
        self.type = Syntax.AssignmentExpression
        self.operator = operator
        self.left = left
        self.right = right
        self.finish()
        return self

    def finishAssignmentPattern(self, left, right):
        self.type = Syntax.AssignmentPattern
        self.left = left
        self.right = right
        self.finish()
        return self

    def finishBinaryExpression(self, operator, left, right):
        self.type = Syntax.LogicalExpression if (
            operator == '||' or operator == '&&') else Syntax.BinaryExpression
        self.operator = operator
        self.left = left
        self.right = right
        self.finish()
        return self

    def finishBlockStatement(self, body):
        self.type = Syntax.BlockStatement
        self.body = body
        self.finish()
        return self

    def finishBreakStatement(self, label):
        self.type = Syntax.BreakStatement
        self.label = label
        self.finish()
        return self

    def finishCallExpression(self, callee, args):
        self.type = Syntax.CallExpression
        self.callee = callee
        self.arguments = args
        self.finish()
        return self

    def finishCatchClause(self, param, body):
        self.type = Syntax.CatchClause
        self.param = param
        self.body = body
        self.finish()
        return self

    def finishConditionalExpression(self, test, consequent, alternate):
        self.type = Syntax.ConditionalExpression
        self.test = test
        self.consequent = consequent
        self.alternate = alternate
        self.finish()
        return self

    def finishContinueStatement(self, label):
        self.type = Syntax.ContinueStatement
        self.label = label
        self.finish()
        return self

    def finishDebuggerStatement(self, ):
        self.type = Syntax.DebuggerStatement
        self.finish()
        return self

    def finishDoWhileStatement(self, body, test):
        self.type = Syntax.DoWhileStatement
        self.body = body
        self.test = test
        self.finish()
        return self

    def finishEmptyStatement(self, ):
        self.type = Syntax.EmptyStatement
        self.finish()
        return self

    def finishExpressionStatement(self, expression):
        self.type = Syntax.ExpressionStatement
        self.expression = expression
        self.finish()
        return self

    def finishForStatement(self, init, test, update, body):
        self.type = Syntax.ForStatement
        self.init = init
        self.test = test
        self.update = update
        self.body = body
        self.finish()
        return self

    def finishForInStatement(self, left, right, body):
        self.type = Syntax.ForInStatement
        self.left = left
        self.right = right
        self.body = body
        self.each = False
        self.finish()
        return self

    def finishFunctionDeclaration(self, id, params, defaults, body):
        self.type = Syntax.FunctionDeclaration
        self.id = id
        self.params = params
        self.defaults = defaults
        self.body = body
        self.generator = False
        self.expression = False
        self.finish()
        return self

    def finishFunctionExpression(self, id, params, defaults, body):
        self.type = Syntax.FunctionExpression
        self.id = id
        self.params = params
        self.defaults = defaults
        self.body = body
        self.generator = False
        self.expression = False
        self.finish()
        return self

    def finishIdentifier(self, name):
        self.type = Syntax.Identifier
        self.name = name
        self.finish()
        return self

    def finishIfStatement(self, test, consequent, alternate):
        self.type = Syntax.IfStatement
        self.test = test
        self.consequent = consequent
        self.alternate = alternate
        self.finish()
        return self

    def finishLabeledStatement(self, label, body):
        self.type = Syntax.LabeledStatement
        self.label = label
        self.body = body
        self.finish()
        return self

    def finishLiteral(self, token):
        self.type = Syntax.Literal
        self.value = token['value']
        self.raw = token['raw']
        if token.get('regex'):
            self.regex = token['regex']
        self.finish()
        return self

    def finishMemberExpression(self, accessor, object, property):
        self.type = Syntax.MemberExpression
        self.computed = accessor == '['
        self.object = object
        self.property = property
        self.finish()
        return self

    def finishNewExpression(self, callee, args):
        self.type = Syntax.NewExpression
        self.callee = callee
        self.arguments = args
        self.finish()
        return self

    def finishObjectExpression(self, properties):
        self.type = Syntax.ObjectExpression
        self.properties = properties
        self.finish()
        return self

    def finishObjectPattern(self, properties):
        self.type = Syntax.ObjectPattern
        self.properties = properties
        self.finish()
        return self

    def finishPostfixExpression(self, operator, argument):
        self.type = Syntax.UpdateExpression
        self.operator = operator
        self.argument = argument
        self.prefix = False
        self.finish()
        return self

    def finishProgram(self, body):
        self.type = Syntax.Program
        self.body = body
        self.finish()
        return self

    def finishPyimport(self, imp):
        self.type = 'PyimportStatement'
        self.imp = imp
        self.finish()
        return self

    def finishProperty(self, kind, key, computed, value, method, shorthand):
        self.type = Syntax.Property
        self.key = key
        self.computed = computed
        self.value = value
        self.kind = kind
        self.method = method
        self.shorthand = shorthand
        self.finish()
        return self

    def finishReturnStatement(self, argument):
        self.type = Syntax.ReturnStatement
        self.argument = argument
        self.finish()
        return self

    def finishSequenceExpression(self, expressions):
        self.type = Syntax.SequenceExpression
        self.expressions = expressions
        self.finish()
        return self

    def finishSwitchCase(self, test, consequent):
        self.type = Syntax.SwitchCase
        self.test = test
        self.consequent = consequent
        self.finish()
        return self

    def finishSwitchStatement(self, discriminant, cases):
        self.type = Syntax.SwitchStatement
        self.discriminant = discriminant
        self.cases = cases
        self.finish()
        return self

    def finishThisExpression(self, ):
        self.type = Syntax.ThisExpression
        self.finish()
        return self

    def finishThrowStatement(self, argument):
        self.type = Syntax.ThrowStatement
        self.argument = argument
        self.finish()
        return self

    def finishTryStatement(self, block, handler, finalizer):
        self.type = Syntax.TryStatement
        self.block = block
        self.guardedHandlers = []
        self.handlers = [handler] if handler else []
        self.handler = handler
        self.finalizer = finalizer
        self.finish()
        return self

    def finishUnaryExpression(self, operator, argument):
        self.type = Syntax.UpdateExpression if (
            operator == '++' or operator == '--') else Syntax.UnaryExpression
        self.operator = operator
        self.argument = argument
        self.prefix = True
        self.finish()
        return self

    def finishVariableDeclaration(self, declarations):
        self.type = Syntax.VariableDeclaration
        self.declarations = declarations
        self.kind = 'var'
        self.finish()
        return self

    def finishLexicalDeclaration(self, declarations, kind):
        self.type = Syntax.VariableDeclaration
        self.declarations = declarations
        self.kind = kind
        self.finish()
        return self

    def finishVariableDeclarator(self, id, init):
        self.type = Syntax.VariableDeclarator
        self.id = id
        self.init = init
        self.finish()
        return self

    def finishWhileStatement(self, test, body):
        self.type = Syntax.WhileStatement
        self.test = test
        self.body = body
        self.finish()
        return self

    def finishWithStatement(self, object, body):
        self.type = Syntax.WithStatement
        self.object = object
        self.body = body
        self.finish()
        return self

    def __getattr__(self, item):
        if item in self.__dict__:
            return self.__dict__[item]
        if item.startswith('finish'):
            feature = item[6:]
            raise Ecma51NotSupported(feature)
        else:
            raise AttributeError(item)

    def __getitem__(self, item):
        return getattr(self, item)

    def __setitem__(self, key, value):
        setattr(self, key, value)

    def to_dict(self):
        return node_to_dict(self)


class Node(BaseNode):
    pass


class WrappingNode(BaseNode):
    def __init__(self, startToken=None):
        pass


def node_to_dict(node):  # extremely important for translation speed
    if isinstance(node, list):
        return [node_to_dict(e) for e in node]
    elif isinstance(node, dict):
        return dict((k, node_to_dict(v)) for k, v in node.items())
    elif not isinstance(node, BaseNode):
        return node
    return dict((k, node_to_dict(v)) for k, v in node.__dict__.items())




############################################################
### File: structures.py
############################################################
# -*- coding: utf-8 -*-

"""
requests.structures
~~~~~~~~~~~~~~~~~~~

Data structures that power Requests.
"""

from collections import OrderedDict

from .compat import Mapping, MutableMapping


class CaseInsensitiveDict(MutableMapping):
    """A case-insensitive ``dict``-like object.

    Implements all methods and operations of
    ``MutableMapping`` as well as dict's ``copy``. Also
    provides ``lower_items``.

    All keys are expected to be strings. The structure remembers the
    case of the last key to be set, and ``iter(instance)``,
    ``keys()``, ``items()``, ``iterkeys()``, and ``iteritems()``
    will contain case-sensitive keys. However, querying and contains
    testing is case insensitive::

        cid = CaseInsensitiveDict()
        cid['Accept'] = 'application/json'
        cid['aCCEPT'] == 'application/json'  # True
        list(cid) == ['Accept']  # True

    For example, ``headers['content-encoding']`` will return the
    value of a ``'Content-Encoding'`` response header, regardless
    of how the header name was originally stored.

    If the constructor, ``.update``, or equality comparison
    operations are given keys that have equal ``.lower()``s, the
    behavior is undefined.
    """

    def __init__(self, data=None, **kwargs):
        self._store = OrderedDict()
        if data is None:
            data = {}
        self.update(data, **kwargs)

    def __setitem__(self, key, value):
        # Use the lowercased key for lookups, but store the actual
        # key alongside the value.
        self._store[key.lower()] = (key, value)

    def __getitem__(self, key):
        return self._store[key.lower()][1]

    def __delitem__(self, key):
        del self._store[key.lower()]

    def __iter__(self):
        return (casedkey for casedkey, mappedvalue in self._store.values())

    def __len__(self):
        return len(self._store)

    def lower_items(self):
        """Like iteritems(), but with all lowercase keys."""
        return (
            (lowerkey, keyval[1])
            for (lowerkey, keyval)
            in self._store.items()
        )

    def __eq__(self, other):
        if isinstance(other, Mapping):
            other = CaseInsensitiveDict(other)
        else:
            return NotImplemented
        # Compare insensitively
        return dict(self.lower_items()) == dict(other.lower_items())

    # Copy is required
    def copy(self):
        return CaseInsensitiveDict(self._store.values())

    def __repr__(self):
        return str(dict(self.items()))


class LookupDict(dict):
    """Dictionary lookup object."""

    def __init__(self, name=None):
        self.name = name
        super(LookupDict, self).__init__()

    def __repr__(self):
        return '<lookup \'%s\'>' % (self.name)

    def __getitem__(self, key):
        # We allow fall-through here, so values default to None

        return self.__dict__.get(key, None)

    def get(self, key, default=None):
        return self.__dict__.get(key, default)




############################################################
### File: tokenizer.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""Tokenize DNS master file format"""

from io import StringIO
import sys

import dns.exception
import dns.name
import dns.ttl
from ._compat import long, text_type, binary_type

_DELIMITERS = {
    ' ': True,
    '\t': True,
    '\n': True,
    ';': True,
    '(': True,
    ')': True,
    '"': True}

_QUOTING_DELIMITERS = {'"': True}

EOF = 0
EOL = 1
WHITESPACE = 2
IDENTIFIER = 3
QUOTED_STRING = 4
COMMENT = 5
DELIMITER = 6


class UngetBufferFull(dns.exception.DNSException):
    """An attempt was made to unget a token when the unget buffer was full."""


class Token(object):
    """A DNS master file format token.

    ttype: The token type
    value: The token value
    has_escape: Does the token value contain escapes?
    """

    def __init__(self, ttype, value='', has_escape=False):
        """Initialize a token instance."""

        self.ttype = ttype
        self.value = value
        self.has_escape = has_escape

    def is_eof(self):
        return self.ttype == EOF

    def is_eol(self):
        return self.ttype == EOL

    def is_whitespace(self):
        return self.ttype == WHITESPACE

    def is_identifier(self):
        return self.ttype == IDENTIFIER

    def is_quoted_string(self):
        return self.ttype == QUOTED_STRING

    def is_comment(self):
        return self.ttype == COMMENT

    def is_delimiter(self):
        return self.ttype == DELIMITER

    def is_eol_or_eof(self):
        return self.ttype == EOL or self.ttype == EOF

    def __eq__(self, other):
        if not isinstance(other, Token):
            return False
        return (self.ttype == other.ttype and
                self.value == other.value)

    def __ne__(self, other):
        if not isinstance(other, Token):
            return True
        return (self.ttype != other.ttype or
                self.value != other.value)

    def __str__(self):
        return '%d "%s"' % (self.ttype, self.value)

    def unescape(self):
        if not self.has_escape:
            return self
        unescaped = ''
        l = len(self.value)
        i = 0
        while i < l:
            c = self.value[i]
            i += 1
            if c == '\\':
                if i >= l:
                    raise dns.exception.UnexpectedEnd
                c = self.value[i]
                i += 1
                if c.isdigit():
                    if i >= l:
                        raise dns.exception.UnexpectedEnd
                    c2 = self.value[i]
                    i += 1
                    if i >= l:
                        raise dns.exception.UnexpectedEnd
                    c3 = self.value[i]
                    i += 1
                    if not (c2.isdigit() and c3.isdigit()):
                        raise dns.exception.SyntaxError
                    c = chr(int(c) * 100 + int(c2) * 10 + int(c3))
            unescaped += c
        return Token(self.ttype, unescaped)

    # compatibility for old-style tuple tokens

    def __len__(self):
        return 2

    def __iter__(self):
        return iter((self.ttype, self.value))

    def __getitem__(self, i):
        if i == 0:
            return self.ttype
        elif i == 1:
            return self.value
        else:
            raise IndexError


class Tokenizer(object):
    """A DNS master file format tokenizer.

    A token object is basically a (type, value) tuple.  The valid
    types are EOF, EOL, WHITESPACE, IDENTIFIER, QUOTED_STRING,
    COMMENT, and DELIMITER.

    file: The file to tokenize

    ungotten_char: The most recently ungotten character, or None.

    ungotten_token: The most recently ungotten token, or None.

    multiline: The current multiline level.  This value is increased
    by one every time a '(' delimiter is read, and decreased by one every time
    a ')' delimiter is read.

    quoting: This variable is true if the tokenizer is currently
    reading a quoted string.

    eof: This variable is true if the tokenizer has encountered EOF.

    delimiters: The current delimiter dictionary.

    line_number: The current line number

    filename: A filename that will be returned by the where() method.
    """

    def __init__(self, f=sys.stdin, filename=None):
        """Initialize a tokenizer instance.

        f: The file to tokenize.  The default is sys.stdin.
        This parameter may also be a string, in which case the tokenizer
        will take its input from the contents of the string.

        filename: the name of the filename that the where() method
        will return.
        """

        if isinstance(f, text_type):
            f = StringIO(f)
            if filename is None:
                filename = '<string>'
        elif isinstance(f, binary_type):
            f = StringIO(f.decode())
            if filename is None:
                filename = '<string>'
        else:
            if filename is None:
                if f is sys.stdin:
                    filename = '<stdin>'
                else:
                    filename = '<file>'
        self.file = f
        self.ungotten_char = None
        self.ungotten_token = None
        self.multiline = 0
        self.quoting = False
        self.eof = False
        self.delimiters = _DELIMITERS
        self.line_number = 1
        self.filename = filename

    def _get_char(self):
        """Read a character from input.
        """

        if self.ungotten_char is None:
            if self.eof:
                c = ''
            else:
                c = self.file.read(1)
                if c == '':
                    self.eof = True
                elif c == '\n':
                    self.line_number += 1
        else:
            c = self.ungotten_char
            self.ungotten_char = None
        return c

    def where(self):
        """Return the current location in the input.

        Returns a (string, int) tuple.  The first item is the filename of
        the input, the second is the current line number.
        """

        return (self.filename, self.line_number)

    def _unget_char(self, c):
        """Unget a character.

        The unget buffer for characters is only one character large; it is
        an error to try to unget a character when the unget buffer is not
        empty.

        c: the character to unget
        raises UngetBufferFull: there is already an ungotten char
        """

        if self.ungotten_char is not None:
            raise UngetBufferFull
        self.ungotten_char = c

    def skip_whitespace(self):
        """Consume input until a non-whitespace character is encountered.

        The non-whitespace character is then ungotten, and the number of
        whitespace characters consumed is returned.

        If the tokenizer is in multiline mode, then newlines are whitespace.

        Returns the number of characters skipped.
        """

        skipped = 0
        while True:
            c = self._get_char()
            if c != ' ' and c != '\t':
                if (c != '\n') or not self.multiline:
                    self._unget_char(c)
                    return skipped
            skipped += 1

    def get(self, want_leading=False, want_comment=False):
        """Get the next token.

        want_leading: If True, return a WHITESPACE token if the
        first character read is whitespace.  The default is False.

        want_comment: If True, return a COMMENT token if the
        first token read is a comment.  The default is False.

        Raises dns.exception.UnexpectedEnd: input ended prematurely

        Raises dns.exception.SyntaxError: input was badly formed

        Returns a Token.
        """

        if self.ungotten_token is not None:
            token = self.ungotten_token
            self.ungotten_token = None
            if token.is_whitespace():
                if want_leading:
                    return token
            elif token.is_comment():
                if want_comment:
                    return token
            else:
                return token
        skipped = self.skip_whitespace()
        if want_leading and skipped > 0:
            return Token(WHITESPACE, ' ')
        token = ''
        ttype = IDENTIFIER
        has_escape = False
        while True:
            c = self._get_char()
            if c == '' or c in self.delimiters:
                if c == '' and self.quoting:
                    raise dns.exception.UnexpectedEnd
                if token == '' and ttype != QUOTED_STRING:
                    if c == '(':
                        self.multiline += 1
                        self.skip_whitespace()
                        continue
                    elif c == ')':
                        if self.multiline <= 0:
                            raise dns.exception.SyntaxError
                        self.multiline -= 1
                        self.skip_whitespace()
                        continue
                    elif c == '"':
                        if not self.quoting:
                            self.quoting = True
                            self.delimiters = _QUOTING_DELIMITERS
                            ttype = QUOTED_STRING
                            continue
                        else:
                            self.quoting = False
                            self.delimiters = _DELIMITERS
                            self.skip_whitespace()
                            continue
                    elif c == '\n':
                        return Token(EOL, '\n')
                    elif c == ';':
                        while 1:
                            c = self._get_char()
                            if c == '\n' or c == '':
                                break
                            token += c
                        if want_comment:
                            self._unget_char(c)
                            return Token(COMMENT, token)
                        elif c == '':
                            if self.multiline:
                                raise dns.exception.SyntaxError(
                                    'unbalanced parentheses')
                            return Token(EOF)
                        elif self.multiline:
                            self.skip_whitespace()
                            token = ''
                            continue
                        else:
                            return Token(EOL, '\n')
                    else:
                        # This code exists in case we ever want a
                        # delimiter to be returned.  It never produces
                        # a token currently.
                        token = c
                        ttype = DELIMITER
                else:
                    self._unget_char(c)
                break
            elif self.quoting:
                if c == '\\':
                    c = self._get_char()
                    if c == '':
                        raise dns.exception.UnexpectedEnd
                    if c.isdigit():
                        c2 = self._get_char()
                        if c2 == '':
                            raise dns.exception.UnexpectedEnd
                        c3 = self._get_char()
                        if c == '':
                            raise dns.exception.UnexpectedEnd
                        if not (c2.isdigit() and c3.isdigit()):
                            raise dns.exception.SyntaxError
                        c = chr(int(c) * 100 + int(c2) * 10 + int(c3))
                elif c == '\n':
                    raise dns.exception.SyntaxError('newline in quoted string')
            elif c == '\\':
                #
                # It's an escape.  Put it and the next character into
                # the token; it will be checked later for goodness.
                #
                token += c
                has_escape = True
                c = self._get_char()
                if c == '' or c == '\n':
                    raise dns.exception.UnexpectedEnd
            token += c
        if token == '' and ttype != QUOTED_STRING:
            if self.multiline:
                raise dns.exception.SyntaxError('unbalanced parentheses')
            ttype = EOF
        return Token(ttype, token, has_escape)

    def unget(self, token):
        """Unget a token.

        The unget buffer for tokens is only one token large; it is
        an error to try to unget a token when the unget buffer is not
        empty.

        token: the token to unget

        Raises UngetBufferFull: there is already an ungotten token
        """

        if self.ungotten_token is not None:
            raise UngetBufferFull
        self.ungotten_token = token

    def next(self):
        """Return the next item in an iteration.

        Returns a Token.
        """

        token = self.get()
        if token.is_eof():
            raise StopIteration
        return token

    __next__ = next

    def __iter__(self):
        return self

    # Helpers

    def get_int(self, base=10):
        """Read the next token and interpret it as an integer.

        Raises dns.exception.SyntaxError if not an integer.

        Returns an int.
        """

        token = self.get().unescape()
        if not token.is_identifier():
            raise dns.exception.SyntaxError('expecting an identifier')
        if not token.value.isdigit():
            raise dns.exception.SyntaxError('expecting an integer')
        return int(token.value, base)

    def get_uint8(self):
        """Read the next token and interpret it as an 8-bit unsigned
        integer.

        Raises dns.exception.SyntaxError if not an 8-bit unsigned integer.

        Returns an int.
        """

        value = self.get_int()
        if value < 0 or value > 255:
            raise dns.exception.SyntaxError(
                '%d is not an unsigned 8-bit integer' % value)
        return value

    def get_uint16(self, base=10):
        """Read the next token and interpret it as a 16-bit unsigned
        integer.

        Raises dns.exception.SyntaxError if not a 16-bit unsigned integer.

        Returns an int.
        """

        value = self.get_int(base=base)
        if value < 0 or value > 65535:
            if base == 8:
                raise dns.exception.SyntaxError(
                    '%o is not an octal unsigned 16-bit integer' % value)
            else:
                raise dns.exception.SyntaxError(
                    '%d is not an unsigned 16-bit integer' % value)
        return value

    def get_uint32(self):
        """Read the next token and interpret it as a 32-bit unsigned
        integer.

        Raises dns.exception.SyntaxError if not a 32-bit unsigned integer.

        Returns an int.
        """

        token = self.get().unescape()
        if not token.is_identifier():
            raise dns.exception.SyntaxError('expecting an identifier')
        if not token.value.isdigit():
            raise dns.exception.SyntaxError('expecting an integer')
        value = long(token.value)
        if value < 0 or value > long(4294967296):
            raise dns.exception.SyntaxError(
                '%d is not an unsigned 32-bit integer' % value)
        return value

    def get_string(self, origin=None):
        """Read the next token and interpret it as a string.

        Raises dns.exception.SyntaxError if not a string.

        Returns a string.
        """

        token = self.get().unescape()
        if not (token.is_identifier() or token.is_quoted_string()):
            raise dns.exception.SyntaxError('expecting a string')
        return token.value

    def get_identifier(self, origin=None):
        """Read the next token, which should be an identifier.

        Raises dns.exception.SyntaxError if not an identifier.

        Returns a string.
        """

        token = self.get().unescape()
        if not token.is_identifier():
            raise dns.exception.SyntaxError('expecting an identifier')
        return token.value

    def get_name(self, origin=None):
        """Read the next token and interpret it as a DNS name.

        Raises dns.exception.SyntaxError if not a name.

        Returns a dns.name.Name.
        """

        token = self.get()
        if not token.is_identifier():
            raise dns.exception.SyntaxError('expecting an identifier')
        return dns.name.from_text(token.value, origin)

    def get_eol(self):
        """Read the next token and raise an exception if it isn't EOL or
        EOF.

        Returns a string.
        """

        token = self.get()
        if not token.is_eol_or_eof():
            raise dns.exception.SyntaxError(
                'expected EOL or EOF, got %d "%s"' % (token.ttype,
                                                      token.value))
        return token.value

    def get_ttl(self):
        """Read the next token and interpret it as a DNS TTL.

        Raises dns.exception.SyntaxError or dns.ttl.BadTTL if not an
        identifier or badly formed.

        Returns an int.
        """

        token = self.get().unescape()
        if not token.is_identifier():
            raise dns.exception.SyntaxError('expecting an identifier')
        return dns.ttl.from_text(token.value)




############################################################
### File: tsig.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2001-2007, 2009-2011 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS TSIG support."""

import hashlib
import hmac
import struct

import dns.exception
import dns.rdataclass
import dns.name
from ._compat import long, string_types, text_type

class BadTime(dns.exception.DNSException):

    """The current time is not within the TSIG's validity time."""


class BadSignature(dns.exception.DNSException):

    """The TSIG signature fails to verify."""


class PeerError(dns.exception.DNSException):

    """Base class for all TSIG errors generated by the remote peer"""


class PeerBadKey(PeerError):

    """The peer didn't know the key we used"""


class PeerBadSignature(PeerError):

    """The peer didn't like the signature we sent"""


class PeerBadTime(PeerError):

    """The peer didn't like the time we sent"""


class PeerBadTruncation(PeerError):

    """The peer didn't like amount of truncation in the TSIG we sent"""

# TSIG Algorithms

HMAC_MD5 = dns.name.from_text("HMAC-MD5.SIG-ALG.REG.INT")
HMAC_SHA1 = dns.name.from_text("hmac-sha1")
HMAC_SHA224 = dns.name.from_text("hmac-sha224")
HMAC_SHA256 = dns.name.from_text("hmac-sha256")
HMAC_SHA384 = dns.name.from_text("hmac-sha384")
HMAC_SHA512 = dns.name.from_text("hmac-sha512")

_hashes = {
    HMAC_SHA224: hashlib.sha224,
    HMAC_SHA256: hashlib.sha256,
    HMAC_SHA384: hashlib.sha384,
    HMAC_SHA512: hashlib.sha512,
    HMAC_SHA1: hashlib.sha1,
    HMAC_MD5: hashlib.md5,
}

default_algorithm = HMAC_MD5

BADSIG = 16
BADKEY = 17
BADTIME = 18
BADTRUNC = 22


def sign(wire, keyname, secret, time, fudge, original_id, error,
         other_data, request_mac, ctx=None, multi=False, first=True,
         algorithm=default_algorithm):
    """Return a (tsig_rdata, mac, ctx) tuple containing the HMAC TSIG rdata
    for the input parameters, the HMAC MAC calculated by applying the
    TSIG signature algorithm, and the TSIG digest context.
    @rtype: (string, string, hmac.HMAC object)
    @raises ValueError: I{other_data} is too long
    @raises NotImplementedError: I{algorithm} is not supported
    """

    if isinstance(other_data, text_type):
        other_data = other_data.encode()
    (algorithm_name, digestmod) = get_algorithm(algorithm)
    if first:
        ctx = hmac.new(secret, digestmod=digestmod)
        ml = len(request_mac)
        if ml > 0:
            ctx.update(struct.pack('!H', ml))
            ctx.update(request_mac)
    id = struct.pack('!H', original_id)
    ctx.update(id)
    ctx.update(wire[2:])
    if first:
        ctx.update(keyname.to_digestable())
        ctx.update(struct.pack('!H', dns.rdataclass.ANY))
        ctx.update(struct.pack('!I', 0))
    long_time = time + long(0)
    upper_time = (long_time >> 32) & long(0xffff)
    lower_time = long_time & long(0xffffffff)
    time_mac = struct.pack('!HIH', upper_time, lower_time, fudge)
    pre_mac = algorithm_name + time_mac
    ol = len(other_data)
    if ol > 65535:
        raise ValueError('TSIG Other Data is > 65535 bytes')
    post_mac = struct.pack('!HH', error, ol) + other_data
    if first:
        ctx.update(pre_mac)
        ctx.update(post_mac)
    else:
        ctx.update(time_mac)
    mac = ctx.digest()
    mpack = struct.pack('!H', len(mac))
    tsig_rdata = pre_mac + mpack + mac + id + post_mac
    if multi:
        ctx = hmac.new(secret, digestmod=digestmod)
        ml = len(mac)
        ctx.update(struct.pack('!H', ml))
        ctx.update(mac)
    else:
        ctx = None
    return (tsig_rdata, mac, ctx)


def hmac_md5(wire, keyname, secret, time, fudge, original_id, error,
             other_data, request_mac, ctx=None, multi=False, first=True,
             algorithm=default_algorithm):
    return sign(wire, keyname, secret, time, fudge, original_id, error,
                other_data, request_mac, ctx, multi, first, algorithm)


def validate(wire, keyname, secret, now, request_mac, tsig_start, tsig_rdata,
             tsig_rdlen, ctx=None, multi=False, first=True):
    """Validate the specified TSIG rdata against the other input parameters.

    @raises FormError: The TSIG is badly formed.
    @raises BadTime: There is too much time skew between the client and the
    server.
    @raises BadSignature: The TSIG signature did not validate
    @rtype: hmac.HMAC object"""

    (adcount,) = struct.unpack("!H", wire[10:12])
    if adcount == 0:
        raise dns.exception.FormError
    adcount -= 1
    new_wire = wire[0:10] + struct.pack("!H", adcount) + wire[12:tsig_start]
    current = tsig_rdata
    (aname, used) = dns.name.from_wire(wire, current)
    current = current + used
    (upper_time, lower_time, fudge, mac_size) = \
        struct.unpack("!HIHH", wire[current:current + 10])
    time = ((upper_time + long(0)) << 32) + (lower_time + long(0))
    current += 10
    mac = wire[current:current + mac_size]
    current += mac_size
    (original_id, error, other_size) = \
        struct.unpack("!HHH", wire[current:current + 6])
    current += 6
    other_data = wire[current:current + other_size]
    current += other_size
    if current != tsig_rdata + tsig_rdlen:
        raise dns.exception.FormError
    if error != 0:
        if error == BADSIG:
            raise PeerBadSignature
        elif error == BADKEY:
            raise PeerBadKey
        elif error == BADTIME:
            raise PeerBadTime
        elif error == BADTRUNC:
            raise PeerBadTruncation
        else:
            raise PeerError('unknown TSIG error code %d' % error)
    time_low = time - fudge
    time_high = time + fudge
    if now < time_low or now > time_high:
        raise BadTime
    (junk, our_mac, ctx) = sign(new_wire, keyname, secret, time, fudge,
                                original_id, error, other_data,
                                request_mac, ctx, multi, first, aname)
    if our_mac != mac:
        raise BadSignature
    return ctx


def get_algorithm(algorithm):
    """Returns the wire format string and the hash module to use for the
    specified TSIG algorithm

    @rtype: (string, hash constructor)
    @raises NotImplementedError: I{algorithm} is not supported
    """

    if isinstance(algorithm, string_types):
        algorithm = dns.name.from_text(algorithm)

    try:
        return (algorithm.to_digestable(), _hashes[algorithm])
    except KeyError:
        raise NotImplementedError("TSIG algorithm " + str(algorithm) +
                                  " is not supported")


def get_algorithm_and_mac(wire, tsig_rdata, tsig_rdlen):
    """Return the tsig algorithm for the specified tsig_rdata
    @raises FormError: The TSIG is badly formed.
    """
    current = tsig_rdata
    (aname, used) = dns.name.from_wire(wire, current)
    current = current + used
    (upper_time, lower_time, fudge, mac_size) = \
        struct.unpack("!HIHH", wire[current:current + 10])
    current += 10
    mac = wire[current:current + mac_size]
    current += mac_size
    if current > tsig_rdata + tsig_rdlen:
        raise dns.exception.FormError
    return (aname, mac)




############################################################
### File: tsigkeyring.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2007, 2009-2011 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""A place to store TSIG keys."""

from dns._compat import maybe_decode, maybe_encode

import base64

import dns.name


def from_text(textring):
    """Convert a dictionary containing (textual DNS name, base64 secret) pairs
    into a binary keyring which has (dns.name.Name, binary secret) pairs.
    @rtype: dict"""

    keyring = {}
    for keytext in textring:
        keyname = dns.name.from_text(keytext)
        secret = base64.decodestring(maybe_encode(textring[keytext]))
        keyring[keyname] = secret
    return keyring


def to_text(keyring):
    """Convert a dictionary containing (dns.name.Name, binary secret) pairs
    into a text keyring which has (textual DNS name, base64 secret) pairs.
    @rtype: dict"""

    textring = {}
    for keyname in keyring:
        keytext = maybe_decode(keyname.to_text())
        secret = maybe_decode(base64.encodestring(keyring[keyname]))
        textring[keytext] = secret
    return textring




############################################################
### File: tt.py
############################################################
import re
import six
import sys
from xml.etree import ElementTree

from .base import (
    BaseReader, BaseWriter, CaptionSet, CaptionList, Caption, CaptionNode
)

from .geometry import Layout

from .exceptions import (
    CaptionReadError, CaptionReadSyntaxError, CaptionReadNoCaptions,
    InvalidInputError
)

class TTReader(BaseReader):
    def __init__(self, rich_formatting=True, *args, **kwargs):
        """
        :param ignore_timing_errors: Whether to ignore timing checks
        """
        self.rich_formatting = rich_formatting

    def detect(self, content):
        return 'WEBVTT' in content

    def read(self, content, lang='en-US'):
        if type(content) != six.text_type:
            raise InvalidInputError('The content is not a unicode string.')

        caption_set = CaptionSet({lang: self._parse(content)})

        if caption_set.is_empty():
            raise CaptionReadNoCaptions("empty caption file")

        return caption_set

    def __parse_style(self, element):
        style = {}
        for k, v in list(element.items()):
            if k == '{tts}color':
                if re.match(r'#\d{6}\d{2}?', v):
                    style['color'] = v[0:7]
                else:
                    rgb_color = re.match(r'rgb\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)', v.strip())
                    if rgb_color:
                        style['color'] = '#%02x%02x%02x' % (int(rgb_color.group(1)), int(rgb_color.group(2)), int(rgb_color.group(3)))
                    else:
                        c = self.__named_colors.get(v)
                        if c:
                            style['color'] = c
            elif k == '{tts}fontStyle':
                style['italic'] = v == 'italic'
            elif k == '{tts}fontWeight':
                style['bold'] = v == 'bold'
            elif k == '{tts}textDecoration':
                style['underline'] = v == 'underline'
        return style

    def __process_time(self, text):
        coefs = [3600, 60, 1]
        time = 0.0

        offset_match = re.match(r'(\d+)(:?\.\d+)?(h|m|s|ms|f|t)', text)
        if offset_match:
            return float(offset_match.group(1)) * {
                'h': 3600.0,
                'm': 60.0,
                's': 1.0,
                'ms': 0.001,
                'f': 1.0/(self.frameRate * self.frameRateMultiplier),
                't': 1.0/self.tickRate
            }.get(offset_match.group(2), 1.0)
        params = text.split(':')
        if len(params) == 1:
            return float(text)
        elif len(params) in (3, 4):
            if len(params) == 4:
                frames = params[3].split('.', 2)
                if len(frames) == 1:
                    params[2] = float(params[2]) + float(params[3]) / (self.frameRate * self.frameRateMultiplier)
                else:
                    params[2] = float(params[2]) + (
                        float(frames[0]) / self.frameRate +
                        float(frames[1]) / (self.frameRate * self.subFrameRate)
                    ) * self.frameRateMultiplier
                del params[3]
            for c, v in zip(coefs, params):
                time += c*float(v)
            return time
        return 0.0

    def _parse(self, content):
        # Normalize namespaces to a single alias. The draft namespace are still used in some file which makes searching for tags cumbersome
        namespace_clean = {
            'http://www.w3.org/2006/10/ttaf1': 'tt',
            'http://www.w3.org/2006/04/ttaf1': 'tt',
            'http://www.w3.org/ns/ttml': 'tt',
            'http://www.w3.org/2006/10/ttaf1#styling': 'tts',
            'http://www.w3.org/2006/04/ttaf1#styling': 'tts',
            'http://www.w3.org/ns/ttml#styling': 'tts',
            'http://www.w3.org/2006/10/ttaf1#parameter': 'ttp',
            'http://www.w3.org/2006/04/ttaf1#parameter': 'ttp',
            'http://www.w3.org/ns/ttml#parameter': 'ttp',
        }
        def normalize_qname(name):
            if name[0] == '{':
                (ns, name) = name[1:].split('}', 1)
                ns = namespace_clean.get(ns, ns)
                return '{%s}%s' % (ns, name)
            return name

        xml = ElementTree.fromstring(content)
        for element in xml.getiterator():
            element.tag = normalize_qname(element.tag)
            for k, v in list(element.items()):
                new_k = normalize_qname(k)
                if k != new_k:
                    del element.attrib[k]
                    element.attrib[new_k] = v

        # Define style aliases
        styles = {}
        regions = {}

        root = list(xml.getiterator())[0]
        if int(root.get('{ttp}tickRate', 0)) > 0:
            self.tickRate = int(root.get('{ttp}tickRate'))
        if int(root.get('{ttp}frameRate', 0)) > 0:
            self.frameRate = int(root.get('{ttp}frameRate'))
        if int(root.get('{ttp}subFrameRate', 0)) > 0:
            self.subFrameRate = int(root.get('{ttp}subFrameRate'))
        if root.get('{ttp}frameRateMultiplier'):
            num, denom = root.get('{ttp}frameRateMultiplier').split(' ')
            self.frameRateMultiplier = float(num) / float(denom)
        if not self.tickRate:
            self.tickRate = self.frameRate * self.subFrameRate * self.frameRateMultiplier

        # Build a cache for the default styles
        for style_tag in xml.findall('{tt}head/{tt}styling/{tt}style'):
            style = self.__parse_style(style_tag)
            styles[style_tag.get('{http://www.w3.org/XML/1998/namespace}id')] = style

        # Build a cache for the default style of the regions
        for region_tag in xml.findall('{tt}head/{tt}layout/{tt}region'):
            region = self.__parse_style(region_tag)
            regions[region_tag.get('{http://www.w3.org/XML/1998/namespace}id')] = region

        def compute_style_tree(element):
            style_ref = element.get('style')
            region_ref = element.get('region')

            style = {}
            if region_ref:
                style.update(regions[region_ref])
            if style_ref:
                style.update(styles[style_ref])
            style.update(self.__parse_style(element))

            return style

        def styleToHtml(tag, value):
            return {
                'bold': ('b', '<b>'),
                'italic': ('i', '<i>'),
                'underline': ('u', '<u>'),
                'color': ('font', '<font color="%s">' % value),
            }[tag]

        def openTags(output, style_pairs):
            (before, after) = style_pairs
            for tag in sorted(after.keys()):
                new_value = after[tag]
                old_value = before.get(tag, None)
                if old_value == None and new_value:
                    html = styleToHtml(tag, new_value)
                    output.openTag(html[0], html[1])
                elif old_value != new_value:
                    if new_value:
                        html = styleToHtml(tag, new_value)
                        output.openTag(html[0], html[1])
                    else:
                        output.closeTag(styleToHtml(tag, new_value)[0])

        def closeTags(output, style_pairs):
            (before, after) = style_pairs
            for tag in sorted(list(after.keys()), reverse=True):
                new_value = after[tag]
                old_value = before.get(tag, None)
                if old_value == None and new_value:
                    output.closeTag(styleToHtml(tag, new_value)[0])
                elif old_value != new_value:
                    if new_value:
                        output.closeTag(styleToHtml(tag, new_value)[0])
                    else:
                        html = styleToHtml(tag, before[tag])
                        output.openTag(html[0], html[1])

        # Store the subs in a list
        self.subs = []
        prev_sub = None
        content = None
        sub_grouping = False
        for sub in xml.findall('{tt}body/{tt}div/{tt}p'):
            begin = self.__process_time(sub.get('begin'))
            if not sub.get('end'):
                end = begin + self.__process_time(sub.get('dur'))
            else:
                end = self.__process_time(sub.get('end'))

            style_stack = [{'color': '#ffffff'}] # default color

            if not prev_sub or begin != prev_sub[0] or end != prev_sub[1]:
                content = RichText(self.rich_formatting)
                sub_grouping = False
            else:
                content.write("\n")
                sub_grouping = True

            def parseChildTree(element_list):
                for child in element_list:
                    style_stack.append(compute_style_tree(child))
                    openTags(content, style_stack[-2:])
                    if child.text and child.text.strip():
                        content.write(child.text.strip())
                    if child.tag == '{tt}br':
                        content.write("\n")
                    parseChildTree(list(child))
                    if child.tail and child.tail.strip():
                        content.write(child.tail.strip())
                    closeTags(content, style_stack[-2:])
                    style_stack.pop()

            parseChildTree([sub])

            # try to regroup subtitles if possible
            if sub_grouping:
                self.subs[-1][2] = six.text_type(content)
            else:
                prev_sub = [begin, end, six.text_type(content)]
                self.subs.append(prev_sub)

    # def _parse(self, lines):
    #     captions = CaptionList()
    #     start = None
    #     end = None
    #     nodes = []
    #     layout_info = None
    #     found_timing = False

    #     for i, line in enumerate(lines):

    #         if '-->' in line:
    #             found_timing = True
    #             timing_line = i
    #             last_start_time = captions[-1].start if captions else 0
    #             try:
    #                 start, end, layout_info = self._parse_timing_line(
    #                     line, last_start_time)
    #             except CaptionReadError as e:
    #                 new_message = '%s (line %d)' % (e.args[0], timing_line)
    #                 six.reraise(type(e), type(e)(new_message), sys.exc_info()[2])

    #         elif '' == line:
    #             if found_timing:
    #                 if not nodes:
    #                     raise CaptionReadSyntaxError(
    #                         'Cue without content. (line %d)' % timing_line)
    #                 else:
    #                     found_timing = False
    #                     caption = Caption(
    #                         start, end, nodes, layout_info=layout_info)
    #                     captions.append(caption)
    #                     nodes = []
    #         else:
    #             if found_timing:
    #                 if nodes:
    #                     nodes.append(CaptionNode.create_break())
    #                 nodes.append(CaptionNode.create_text(
    #                     self._decode(line)))
    #             else:
    #                 # it's a comment or some metadata; ignore it
    #                 pass

    #     # Add a last caption if there are remaining nodes
    #     if nodes:
    #         caption = Caption(start, end, nodes, layout_info=layout_info)
    #         captions.append(caption)

    #     return captions

class RichText:
    def __init__(self, use_html_tags):
        self.tag_stack = []
        self.opened_tags = set()
        self.output = []
        self.add_html_tags = use_html_tags

    def write(self, string):
        self.output.append(string)

    def openTag(self, tag_name, tag_html=None):
        if not tag_html:
            tag_html = '<%s>' % tag_name
        if tag_name not in self.opened_tags:
            self.tag_stack.append((tag_name, tag_html))
            self.opened_tags.add(tag_name)
            if not self.add_html_tags:
                self.output.append(' ')
            else:
                self.output.append(tag_html)

    def closeTag(self, tag):
        if not self.add_html_tags:
            return
        tag_html = '</%s>' % tag
        if tag in self.opened_tags:
            reopen_stack = []
            while self.tag_stack:
                tag_to_close = self.tag_stack.pop()
                if tag_to_close[0] == tag:
                    self.output.append(tag_html)
                    self.opened_tags.remove(tag)
                    break
                else:
                    reopen_stack += tag_to_close
            for tag_to_reopen in reopen_stack:
                self.output.append(tag_to_reopen[1])
                self.tag_stack.append(tag_to_reopen)

    def __str__(self):
        if not self.add_html_tags:
            return ''.join(self.output)

        closing_tags = []
        # Close all the tags still open
        for tag in self.tag_stack[::-1]:
            closing_tags.append('</%s>' % tag[0])
        return ''.join(self.output + closing_tags)



############################################################
### File: ttl.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS TTL conversion."""

import dns.exception
from ._compat import long


class BadTTL(dns.exception.SyntaxError):
    """DNS TTL value is not well-formed."""


def from_text(text):
    """Convert the text form of a TTL to an integer.

    The BIND 8 units syntax for TTLs (e.g. '1w6d4h3m10s') is supported.

    *text*, a ``text``, the textual TTL.

    Raises ``dns.ttl.BadTTL`` if the TTL is not well-formed.

    Returns an ``int``.
    """

    if text.isdigit():
        total = long(text)
    else:
        if not text[0].isdigit():
            raise BadTTL
        total = long(0)
        current = long(0)
        for c in text:
            if c.isdigit():
                current *= 10
                current += long(c)
            else:
                c = c.lower()
                if c == 'w':
                    total += current * long(604800)
                elif c == 'd':
                    total += current * long(86400)
                elif c == 'h':
                    total += current * long(3600)
                elif c == 'm':
                    total += current * long(60)
                elif c == 's':
                    total += current
                else:
                    raise BadTTL("unknown unit '%s'" % c)
                current = 0
        if not current == 0:
            raise BadTTL("trailing integer")
    if total < long(0) or total > long(2147483647):
        raise BadTTL("TTL should be between 0 and 2^31 - 1 (inclusive)")
    return total




############################################################
### File: tzfile.py
############################################################
'''
$Id: tzfile.py,v 1.8 2004/06/03 00:15:24 zenzen Exp $
'''

from datetime import datetime
from struct import unpack, calcsize

from pytz.tzinfo import StaticTzInfo, DstTzInfo, memorized_ttinfo
from pytz.tzinfo import memorized_datetime, memorized_timedelta


def _byte_string(s):
    """Cast a string or byte string to an ASCII byte string."""
    return s.encode('ASCII')

_NULL = _byte_string('\0')


def _std_string(s):
    """Cast a string or byte string to an ASCII string."""
    return str(s.decode('ASCII'))


def build_tzinfo(zone, fp):
    head_fmt = '>4s c 15x 6l'
    head_size = calcsize(head_fmt)
    (magic, format, ttisgmtcnt, ttisstdcnt, leapcnt, timecnt,
        typecnt, charcnt) = unpack(head_fmt, fp.read(head_size))

    # Make sure it is a tzfile(5) file
    assert magic == _byte_string('TZif'), 'Got magic %s' % repr(magic)

    # Read out the transition times, localtime indices and ttinfo structures.
    data_fmt = '>%(timecnt)dl %(timecnt)dB %(ttinfo)s %(charcnt)ds' % dict(
        timecnt=timecnt, ttinfo='lBB' * typecnt, charcnt=charcnt)
    data_size = calcsize(data_fmt)
    data = unpack(data_fmt, fp.read(data_size))

    # make sure we unpacked the right number of values
    assert len(data) == 2 * timecnt + 3 * typecnt + 1
    transitions = [memorized_datetime(trans)
                   for trans in data[:timecnt]]
    lindexes = list(data[timecnt:2 * timecnt])
    ttinfo_raw = data[2 * timecnt:-1]
    tznames_raw = data[-1]
    del data

    # Process ttinfo into separate structs
    ttinfo = []
    tznames = {}
    i = 0
    while i < len(ttinfo_raw):
        # have we looked up this timezone name yet?
        tzname_offset = ttinfo_raw[i + 2]
        if tzname_offset not in tznames:
            nul = tznames_raw.find(_NULL, tzname_offset)
            if nul < 0:
                nul = len(tznames_raw)
            tznames[tzname_offset] = _std_string(
                tznames_raw[tzname_offset:nul])
        ttinfo.append((ttinfo_raw[i],
                       bool(ttinfo_raw[i + 1]),
                       tznames[tzname_offset]))
        i += 3

    # Now build the timezone object
    if len(ttinfo) == 1 or len(transitions) == 0:
        ttinfo[0][0], ttinfo[0][2]
        cls = type(zone, (StaticTzInfo,), dict(
            zone=zone,
            _utcoffset=memorized_timedelta(ttinfo[0][0]),
            _tzname=ttinfo[0][2]))
    else:
        # Early dates use the first standard time ttinfo
        i = 0
        while ttinfo[i][1]:
            i += 1
        if ttinfo[i] == ttinfo[lindexes[0]]:
            transitions[0] = datetime.min
        else:
            transitions.insert(0, datetime.min)
            lindexes.insert(0, i)

        # calculate transition info
        transition_info = []
        for i in range(len(transitions)):
            inf = ttinfo[lindexes[i]]
            utcoffset = inf[0]
            if not inf[1]:
                dst = 0
            else:
                for j in range(i - 1, -1, -1):
                    prev_inf = ttinfo[lindexes[j]]
                    if not prev_inf[1]:
                        break
                dst = inf[0] - prev_inf[0]  # dst offset

                # Bad dst? Look further. DST > 24 hours happens when
                # a timzone has moved across the international dateline.
                if dst <= 0 or dst > 3600 * 3:
                    for j in range(i + 1, len(transitions)):
                        stdinf = ttinfo[lindexes[j]]
                        if not stdinf[1]:
                            dst = inf[0] - stdinf[0]
                            if dst > 0:
                                break  # Found a useful std time.

            tzname = inf[2]

            # Round utcoffset and dst to the nearest minute or the
            # datetime library will complain. Conversions to these timezones
            # might be up to plus or minus 30 seconds out, but it is
            # the best we can do.
            utcoffset = int((utcoffset + 30) // 60) * 60
            dst = int((dst + 30) // 60) * 60
            transition_info.append(memorized_ttinfo(utcoffset, dst, tzname))

        cls = type(zone, (DstTzInfo,), dict(
            zone=zone,
            _utc_transition_times=transitions,
            _transition_info=transition_info))

    return cls()

if __name__ == '__main__':
    import os.path
    from pprint import pprint
    base = os.path.join(os.path.dirname(__file__), 'zoneinfo')
    tz = build_tzinfo('Australia/Melbourne',
                      open(os.path.join(base, 'Australia', 'Melbourne'), 'rb'))
    tz = build_tzinfo('US/Eastern',
                      open(os.path.join(base, 'US', 'Eastern'), 'rb'))
    pprint(tz._utc_transition_times)




############################################################
### File: tzinfo.py
############################################################
'''Base classes and helpers for building zone specific tzinfo classes'''

from datetime import datetime, timedelta, tzinfo
from bisect import bisect_right
try:
    set
except NameError:
    from sets import Set as set

import pytz
from pytz.exceptions import AmbiguousTimeError, NonExistentTimeError

__all__ = []

_timedelta_cache = {}


def memorized_timedelta(seconds):
    '''Create only one instance of each distinct timedelta'''
    try:
        return _timedelta_cache[seconds]
    except KeyError:
        delta = timedelta(seconds=seconds)
        _timedelta_cache[seconds] = delta
        return delta

_epoch = datetime.utcfromtimestamp(0)
_datetime_cache = {0: _epoch}


def memorized_datetime(seconds):
    '''Create only one instance of each distinct datetime'''
    try:
        return _datetime_cache[seconds]
    except KeyError:
        # NB. We can't just do datetime.utcfromtimestamp(seconds) as this
        # fails with negative values under Windows (Bug #90096)
        dt = _epoch + timedelta(seconds=seconds)
        _datetime_cache[seconds] = dt
        return dt

_ttinfo_cache = {}


def memorized_ttinfo(*args):
    '''Create only one instance of each distinct tuple'''
    try:
        return _ttinfo_cache[args]
    except KeyError:
        ttinfo = (
            memorized_timedelta(args[0]),
            memorized_timedelta(args[1]),
            args[2]
        )
        _ttinfo_cache[args] = ttinfo
        return ttinfo

_notime = memorized_timedelta(0)


def _to_seconds(td):
    '''Convert a timedelta to seconds'''
    return td.seconds + td.days * 24 * 60 * 60


class BaseTzInfo(tzinfo):
    # Overridden in subclass
    _utcoffset = None
    _tzname = None
    zone = None

    def __str__(self):
        return self.zone


class StaticTzInfo(BaseTzInfo):
    '''A timezone that has a constant offset from UTC

    These timezones are rare, as most locations have changed their
    offset at some point in their history
    '''
    def fromutc(self, dt):
        '''See datetime.tzinfo.fromutc'''
        if dt.tzinfo is not None and dt.tzinfo is not self:
            raise ValueError('fromutc: dt.tzinfo is not self')
        return (dt + self._utcoffset).replace(tzinfo=self)

    def utcoffset(self, dt, is_dst=None):
        '''See datetime.tzinfo.utcoffset

        is_dst is ignored for StaticTzInfo, and exists only to
        retain compatibility with DstTzInfo.
        '''
        return self._utcoffset

    def dst(self, dt, is_dst=None):
        '''See datetime.tzinfo.dst

        is_dst is ignored for StaticTzInfo, and exists only to
        retain compatibility with DstTzInfo.
        '''
        return _notime

    def tzname(self, dt, is_dst=None):
        '''See datetime.tzinfo.tzname

        is_dst is ignored for StaticTzInfo, and exists only to
        retain compatibility with DstTzInfo.
        '''
        return self._tzname

    def localize(self, dt, is_dst=False):
        '''Convert naive time to local time'''
        if dt.tzinfo is not None:
            raise ValueError('Not naive datetime (tzinfo is already set)')
        return dt.replace(tzinfo=self)

    def normalize(self, dt, is_dst=False):
        '''Correct the timezone information on the given datetime.

        This is normally a no-op, as StaticTzInfo timezones never have
        ambiguous cases to correct:

        >>> from pytz import timezone
        >>> gmt = timezone('GMT')
        >>> isinstance(gmt, StaticTzInfo)
        True
        >>> dt = datetime(2011, 5, 8, 1, 2, 3, tzinfo=gmt)
        >>> gmt.normalize(dt) is dt
        True

        The supported method of converting between timezones is to use
        datetime.astimezone(). Currently normalize() also works:

        >>> la = timezone('America/Los_Angeles')
        >>> dt = la.localize(datetime(2011, 5, 7, 1, 2, 3))
        >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'
        >>> gmt.normalize(dt).strftime(fmt)
        '2011-05-07 08:02:03 GMT (+0000)'
        '''
        if dt.tzinfo is self:
            return dt
        if dt.tzinfo is None:
            raise ValueError('Naive time - no tzinfo set')
        return dt.astimezone(self)

    def __repr__(self):
        return '<StaticTzInfo %r>' % (self.zone,)

    def __reduce__(self):
        # Special pickle to zone remains a singleton and to cope with
        # database changes.
        return pytz._p, (self.zone,)


class DstTzInfo(BaseTzInfo):
    '''A timezone that has a variable offset from UTC

    The offset might change if daylight saving time comes into effect,
    or at a point in history when the region decides to change their
    timezone definition.
    '''
    # Overridden in subclass

    # Sorted list of DST transition times, UTC
    _utc_transition_times = None

    # [(utcoffset, dstoffset, tzname)] corresponding to
    # _utc_transition_times entries
    _transition_info = None

    zone = None

    # Set in __init__

    _tzinfos = None
    _dst = None  # DST offset

    def __init__(self, _inf=None, _tzinfos=None):
        if _inf:
            self._tzinfos = _tzinfos
            self._utcoffset, self._dst, self._tzname = _inf
        else:
            _tzinfos = {}
            self._tzinfos = _tzinfos
            self._utcoffset, self._dst, self._tzname = (
                self._transition_info[0])
            _tzinfos[self._transition_info[0]] = self
            for inf in self._transition_info[1:]:
                if inf not in _tzinfos:
                    _tzinfos[inf] = self.__class__(inf, _tzinfos)

    def fromutc(self, dt):
        '''See datetime.tzinfo.fromutc'''
        if (dt.tzinfo is not None and
                getattr(dt.tzinfo, '_tzinfos', None) is not self._tzinfos):
            raise ValueError('fromutc: dt.tzinfo is not self')
        dt = dt.replace(tzinfo=None)
        idx = max(0, bisect_right(self._utc_transition_times, dt) - 1)
        inf = self._transition_info[idx]
        return (dt + inf[0]).replace(tzinfo=self._tzinfos[inf])

    def normalize(self, dt):
        '''Correct the timezone information on the given datetime

        If date arithmetic crosses DST boundaries, the tzinfo
        is not magically adjusted. This method normalizes the
        tzinfo to the correct one.

        To test, first we need to do some setup

        >>> from pytz import timezone
        >>> utc = timezone('UTC')
        >>> eastern = timezone('US/Eastern')
        >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'

        We next create a datetime right on an end-of-DST transition point,
        the instant when the wallclocks are wound back one hour.

        >>> utc_dt = datetime(2002, 10, 27, 6, 0, 0, tzinfo=utc)
        >>> loc_dt = utc_dt.astimezone(eastern)
        >>> loc_dt.strftime(fmt)
        '2002-10-27 01:00:00 EST (-0500)'

        Now, if we subtract a few minutes from it, note that the timezone
        information has not changed.

        >>> before = loc_dt - timedelta(minutes=10)
        >>> before.strftime(fmt)
        '2002-10-27 00:50:00 EST (-0500)'

        But we can fix that by calling the normalize method

        >>> before = eastern.normalize(before)
        >>> before.strftime(fmt)
        '2002-10-27 01:50:00 EDT (-0400)'

        The supported method of converting between timezones is to use
        datetime.astimezone(). Currently, normalize() also works:

        >>> th = timezone('Asia/Bangkok')
        >>> am = timezone('Europe/Amsterdam')
        >>> dt = th.localize(datetime(2011, 5, 7, 1, 2, 3))
        >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'
        >>> am.normalize(dt).strftime(fmt)
        '2011-05-06 20:02:03 CEST (+0200)'
        '''
        if dt.tzinfo is None:
            raise ValueError('Naive time - no tzinfo set')

        # Convert dt in localtime to UTC
        offset = dt.tzinfo._utcoffset
        dt = dt.replace(tzinfo=None)
        dt = dt - offset
        # convert it back, and return it
        return self.fromutc(dt)

    def localize(self, dt, is_dst=False):
        '''Convert naive time to local time.

        This method should be used to construct localtimes, rather
        than passing a tzinfo argument to a datetime constructor.

        is_dst is used to determine the correct timezone in the ambigous
        period at the end of daylight saving time.

        >>> from pytz import timezone
        >>> fmt = '%Y-%m-%d %H:%M:%S %Z (%z)'
        >>> amdam = timezone('Europe/Amsterdam')
        >>> dt  = datetime(2004, 10, 31, 2, 0, 0)
        >>> loc_dt1 = amdam.localize(dt, is_dst=True)
        >>> loc_dt2 = amdam.localize(dt, is_dst=False)
        >>> loc_dt1.strftime(fmt)
        '2004-10-31 02:00:00 CEST (+0200)'
        >>> loc_dt2.strftime(fmt)
        '2004-10-31 02:00:00 CET (+0100)'
        >>> str(loc_dt2 - loc_dt1)
        '1:00:00'

        Use is_dst=None to raise an AmbiguousTimeError for ambiguous
        times at the end of daylight saving time

        >>> try:
        ...     loc_dt1 = amdam.localize(dt, is_dst=None)
        ... except AmbiguousTimeError:
        ...     print('Ambiguous')
        Ambiguous

        is_dst defaults to False

        >>> amdam.localize(dt) == amdam.localize(dt, False)
        True

        is_dst is also used to determine the correct timezone in the
        wallclock times jumped over at the start of daylight saving time.

        >>> pacific = timezone('US/Pacific')
        >>> dt = datetime(2008, 3, 9, 2, 0, 0)
        >>> ploc_dt1 = pacific.localize(dt, is_dst=True)
        >>> ploc_dt2 = pacific.localize(dt, is_dst=False)
        >>> ploc_dt1.strftime(fmt)
        '2008-03-09 02:00:00 PDT (-0700)'
        >>> ploc_dt2.strftime(fmt)
        '2008-03-09 02:00:00 PST (-0800)'
        >>> str(ploc_dt2 - ploc_dt1)
        '1:00:00'

        Use is_dst=None to raise a NonExistentTimeError for these skipped
        times.

        >>> try:
        ...     loc_dt1 = pacific.localize(dt, is_dst=None)
        ... except NonExistentTimeError:
        ...     print('Non-existent')
        Non-existent
        '''
        if dt.tzinfo is not None:
            raise ValueError('Not naive datetime (tzinfo is already set)')

        # Find the two best possibilities.
        possible_loc_dt = set()
        for delta in [timedelta(days=-1), timedelta(days=1)]:
            loc_dt = dt + delta
            idx = max(0, bisect_right(
                self._utc_transition_times, loc_dt) - 1)
            inf = self._transition_info[idx]
            tzinfo = self._tzinfos[inf]
            loc_dt = tzinfo.normalize(dt.replace(tzinfo=tzinfo))
            if loc_dt.replace(tzinfo=None) == dt:
                possible_loc_dt.add(loc_dt)

        if len(possible_loc_dt) == 1:
            return possible_loc_dt.pop()

        # If there are no possibly correct timezones, we are attempting
        # to convert a time that never happened - the time period jumped
        # during the start-of-DST transition period.
        if len(possible_loc_dt) == 0:
            # If we refuse to guess, raise an exception.
            if is_dst is None:
                raise NonExistentTimeError(dt)

            # If we are forcing the pre-DST side of the DST transition, we
            # obtain the correct timezone by winding the clock forward a few
            # hours.
            elif is_dst:
                return self.localize(
                    dt + timedelta(hours=6), is_dst=True) - timedelta(hours=6)

            # If we are forcing the post-DST side of the DST transition, we
            # obtain the correct timezone by winding the clock back.
            else:
                return self.localize(
                    dt - timedelta(hours=6),
                    is_dst=False) + timedelta(hours=6)

        # If we get this far, we have multiple possible timezones - this
        # is an ambiguous case occuring during the end-of-DST transition.

        # If told to be strict, raise an exception since we have an
        # ambiguous case
        if is_dst is None:
            raise AmbiguousTimeError(dt)

        # Filter out the possiblilities that don't match the requested
        # is_dst
        filtered_possible_loc_dt = [
            p for p in possible_loc_dt if bool(p.tzinfo._dst) == is_dst
        ]

        # Hopefully we only have one possibility left. Return it.
        if len(filtered_possible_loc_dt) == 1:
            return filtered_possible_loc_dt[0]

        if len(filtered_possible_loc_dt) == 0:
            filtered_possible_loc_dt = list(possible_loc_dt)

        # If we get this far, we have in a wierd timezone transition
        # where the clocks have been wound back but is_dst is the same
        # in both (eg. Europe/Warsaw 1915 when they switched to CET).
        # At this point, we just have to guess unless we allow more
        # hints to be passed in (such as the UTC offset or abbreviation),
        # but that is just getting silly.
        #
        # Choose the earliest (by UTC) applicable timezone if is_dst=True
        # Choose the latest (by UTC) applicable timezone if is_dst=False
        # i.e., behave like end-of-DST transition
        dates = {}  # utc -> local
        for local_dt in filtered_possible_loc_dt:
            utc_time = (
                local_dt.replace(tzinfo=None) - local_dt.tzinfo._utcoffset)
            assert utc_time not in dates
            dates[utc_time] = local_dt
        return dates[[min, max][not is_dst](dates)]

    def utcoffset(self, dt, is_dst=None):
        '''See datetime.tzinfo.utcoffset

        The is_dst parameter may be used to remove ambiguity during DST
        transitions.

        >>> from pytz import timezone
        >>> tz = timezone('America/St_Johns')
        >>> ambiguous = datetime(2009, 10, 31, 23, 30)

        >>> str(tz.utcoffset(ambiguous, is_dst=False))
        '-1 day, 20:30:00'

        >>> str(tz.utcoffset(ambiguous, is_dst=True))
        '-1 day, 21:30:00'

        >>> try:
        ...     tz.utcoffset(ambiguous)
        ... except AmbiguousTimeError:
        ...     print('Ambiguous')
        Ambiguous

        '''
        if dt is None:
            return None
        elif dt.tzinfo is not self:
            dt = self.localize(dt, is_dst)
            return dt.tzinfo._utcoffset
        else:
            return self._utcoffset

    def dst(self, dt, is_dst=None):
        '''See datetime.tzinfo.dst

        The is_dst parameter may be used to remove ambiguity during DST
        transitions.

        >>> from pytz import timezone
        >>> tz = timezone('America/St_Johns')

        >>> normal = datetime(2009, 9, 1)

        >>> str(tz.dst(normal))
        '1:00:00'
        >>> str(tz.dst(normal, is_dst=False))
        '1:00:00'
        >>> str(tz.dst(normal, is_dst=True))
        '1:00:00'

        >>> ambiguous = datetime(2009, 10, 31, 23, 30)

        >>> str(tz.dst(ambiguous, is_dst=False))
        '0:00:00'
        >>> str(tz.dst(ambiguous, is_dst=True))
        '1:00:00'
        >>> try:
        ...     tz.dst(ambiguous)
        ... except AmbiguousTimeError:
        ...     print('Ambiguous')
        Ambiguous

        '''
        if dt is None:
            return None
        elif dt.tzinfo is not self:
            dt = self.localize(dt, is_dst)
            return dt.tzinfo._dst
        else:
            return self._dst

    def tzname(self, dt, is_dst=None):
        '''See datetime.tzinfo.tzname

        The is_dst parameter may be used to remove ambiguity during DST
        transitions.

        >>> from pytz import timezone
        >>> tz = timezone('America/St_Johns')

        >>> normal = datetime(2009, 9, 1)

        >>> tz.tzname(normal)
        'NDT'
        >>> tz.tzname(normal, is_dst=False)
        'NDT'
        >>> tz.tzname(normal, is_dst=True)
        'NDT'

        >>> ambiguous = datetime(2009, 10, 31, 23, 30)

        >>> tz.tzname(ambiguous, is_dst=False)
        'NST'
        >>> tz.tzname(ambiguous, is_dst=True)
        'NDT'
        >>> try:
        ...     tz.tzname(ambiguous)
        ... except AmbiguousTimeError:
        ...     print('Ambiguous')
        Ambiguous
        '''
        if dt is None:
            return self.zone
        elif dt.tzinfo is not self:
            dt = self.localize(dt, is_dst)
            return dt.tzinfo._tzname
        else:
            return self._tzname

    def __repr__(self):
        if self._dst:
            dst = 'DST'
        else:
            dst = 'STD'
        if self._utcoffset > _notime:
            return '<DstTzInfo %r %s+%s %s>' % (
                self.zone, self._tzname, self._utcoffset, dst
            )
        else:
            return '<DstTzInfo %r %s%s %s>' % (
                self.zone, self._tzname, self._utcoffset, dst
            )

    def __reduce__(self):
        # Special pickle to zone remains a singleton and to cope with
        # database changes.
        return pytz._p, (
            self.zone,
            _to_seconds(self._utcoffset),
            _to_seconds(self._dst),
            self._tzname
        )


def unpickler(zone, utcoffset=None, dstoffset=None, tzname=None):
    """Factory function for unpickling pytz tzinfo instances.

    This is shared for both StaticTzInfo and DstTzInfo instances, because
    database changes could cause a zones implementation to switch between
    these two base classes and we can't break pickles on a pytz version
    upgrade.
    """
    # Raises a KeyError if zone no longer exists, which should never happen
    # and would be a bug.
    tz = pytz.timezone(zone)

    # A StaticTzInfo - just return it
    if utcoffset is None:
        return tz

    # This pickle was created from a DstTzInfo. We need to
    # determine which of the list of tzinfo instances for this zone
    # to use in order to restore the state of any datetime instances using
    # it correctly.
    utcoffset = memorized_timedelta(utcoffset)
    dstoffset = memorized_timedelta(dstoffset)
    try:
        return tz._tzinfos[(utcoffset, dstoffset, tzname)]
    except KeyError:
        # The particular state requested in this timezone no longer exists.
        # This indicates a corrupt pickle, or the timezone database has been
        # corrected violently enough to make this particular
        # (utcoffset,dstoffset) no longer exist in the zone, or the
        # abbreviation has been changed.
        pass

    # See if we can find an entry differing only by tzname. Abbreviations
    # get changed from the initial guess by the database maintainers to
    # match reality when this information is discovered.
    for localized_tz in tz._tzinfos.values():
        if (localized_tz._utcoffset == utcoffset and
                localized_tz._dst == dstoffset):
            return localized_tz

    # This (utcoffset, dstoffset) information has been removed from the
    # zone. Add it back. This might occur when the database maintainers have
    # corrected incorrect information. datetime instances using this
    # incorrect information will continue to do so, exactly as they were
    # before being pickled. This is purely an overly paranoid safety net - I
    # doubt this will ever been needed in real life.
    inf = (utcoffset, dstoffset, tzname)
    tz._tzinfos[inf] = tz.__class__(inf, tz._tzinfos)
    return tz._tzinfos[inf]




############################################################
### File: tzwin.py
############################################################
# tzwin has moved to dateutil.tz.win
from .tz.win import *




############################################################
### File: universaldetector.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is Mozilla Universal charset detector code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 2001
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#   Shy Shalom - original C code
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################
"""
Module containing the UniversalDetector detector class, which is the primary
class a user of ``chardet`` should use.

:author: Mark Pilgrim (initial port to Python)
:author: Shy Shalom (original C code)
:author: Dan Blanchard (major refactoring for 3.0)
:author: Ian Cordasco
"""


import codecs
import logging
import re

from .charsetgroupprober import CharSetGroupProber
from .enums import InputState, LanguageFilter, ProbingState
from .escprober import EscCharSetProber
from .latin1prober import Latin1Prober
from .mbcsgroupprober import MBCSGroupProber
from .sbcsgroupprober import SBCSGroupProber


class UniversalDetector(object):
    """
    The ``UniversalDetector`` class underlies the ``chardet.detect`` function
    and coordinates all of the different charset probers.

    To get a ``dict`` containing an encoding and its confidence, you can simply
    run:

    .. code::

            u = UniversalDetector()
            u.feed(some_bytes)
            u.close()
            detected = u.result

    """

    MINIMUM_THRESHOLD = 0.20
    HIGH_BYTE_DETECTOR = re.compile(b'[\x80-\xFF]')
    ESC_DETECTOR = re.compile(b'(\033|~{)')
    WIN_BYTE_DETECTOR = re.compile(b'[\x80-\x9F]')
    ISO_WIN_MAP = {'iso-8859-1': 'Windows-1252',
                   'iso-8859-2': 'Windows-1250',
                   'iso-8859-5': 'Windows-1251',
                   'iso-8859-6': 'Windows-1256',
                   'iso-8859-7': 'Windows-1253',
                   'iso-8859-8': 'Windows-1255',
                   'iso-8859-9': 'Windows-1254',
                   'iso-8859-13': 'Windows-1257'}

    def __init__(self, lang_filter=LanguageFilter.ALL):
        self._esc_charset_prober = None
        self._charset_probers = []
        self.result = None
        self.done = None
        self._got_data = None
        self._input_state = None
        self._last_char = None
        self.lang_filter = lang_filter
        self.logger = logging.getLogger(__name__)
        self._has_win_bytes = None
        self.reset()

    def reset(self):
        """
        Reset the UniversalDetector and all of its probers back to their
        initial states.  This is called by ``__init__``, so you only need to
        call this directly in between analyses of different documents.
        """
        self.result = {'encoding': None, 'confidence': 0.0, 'language': None}
        self.done = False
        self._got_data = False
        self._has_win_bytes = False
        self._input_state = InputState.PURE_ASCII
        self._last_char = b''
        if self._esc_charset_prober:
            self._esc_charset_prober.reset()
        for prober in self._charset_probers:
            prober.reset()

    def feed(self, byte_str):
        """
        Takes a chunk of a document and feeds it through all of the relevant
        charset probers.

        After calling ``feed``, you can check the value of the ``done``
        attribute to see if you need to continue feeding the
        ``UniversalDetector`` more data, or if it has made a prediction
        (in the ``result`` attribute).

        .. note::
           You should always call ``close`` when you're done feeding in your
           document if ``done`` is not already ``True``.
        """
        if self.done:
            return

        if not len(byte_str):
            return

        if not isinstance(byte_str, bytearray):
            byte_str = bytearray(byte_str)

        # First check for known BOMs, since these are guaranteed to be correct
        if not self._got_data:
            # If the data starts with BOM, we know it is UTF
            if byte_str.startswith(codecs.BOM_UTF8):
                # EF BB BF  UTF-8 with BOM
                self.result = {'encoding': "UTF-8-SIG",
                               'confidence': 1.0,
                               'language': ''}
            elif byte_str.startswith((codecs.BOM_UTF32_LE,
                                      codecs.BOM_UTF32_BE)):
                # FF FE 00 00  UTF-32, little-endian BOM
                # 00 00 FE FF  UTF-32, big-endian BOM
                self.result = {'encoding': "UTF-32",
                               'confidence': 1.0,
                               'language': ''}
            elif byte_str.startswith(b'\xFE\xFF\x00\x00'):
                # FE FF 00 00  UCS-4, unusual octet order BOM (3412)
                self.result = {'encoding': "X-ISO-10646-UCS-4-3412",
                               'confidence': 1.0,
                               'language': ''}
            elif byte_str.startswith(b'\x00\x00\xFF\xFE'):
                # 00 00 FF FE  UCS-4, unusual octet order BOM (2143)
                self.result = {'encoding': "X-ISO-10646-UCS-4-2143",
                               'confidence': 1.0,
                               'language': ''}
            elif byte_str.startswith((codecs.BOM_LE, codecs.BOM_BE)):
                # FF FE  UTF-16, little endian BOM
                # FE FF  UTF-16, big endian BOM
                self.result = {'encoding': "UTF-16",
                               'confidence': 1.0,
                               'language': ''}

            self._got_data = True
            if self.result['encoding'] is not None:
                self.done = True
                return

        # If none of those matched and we've only see ASCII so far, check
        # for high bytes and escape sequences
        if self._input_state == InputState.PURE_ASCII:
            if self.HIGH_BYTE_DETECTOR.search(byte_str):
                self._input_state = InputState.HIGH_BYTE
            elif self._input_state == InputState.PURE_ASCII and \
                    self.ESC_DETECTOR.search(self._last_char + byte_str):
                self._input_state = InputState.ESC_ASCII

        self._last_char = byte_str[-1:]

        # If we've seen escape sequences, use the EscCharSetProber, which
        # uses a simple state machine to check for known escape sequences in
        # HZ and ISO-2022 encodings, since those are the only encodings that
        # use such sequences.
        if self._input_state == InputState.ESC_ASCII:
            if not self._esc_charset_prober:
                self._esc_charset_prober = EscCharSetProber(self.lang_filter)
            if self._esc_charset_prober.feed(byte_str) == ProbingState.FOUND_IT:
                self.result = {'encoding':
                               self._esc_charset_prober.charset_name,
                               'confidence':
                               self._esc_charset_prober.get_confidence(),
                               'language':
                               self._esc_charset_prober.language}
                self.done = True
        # If we've seen high bytes (i.e., those with values greater than 127),
        # we need to do more complicated checks using all our multi-byte and
        # single-byte probers that are left.  The single-byte probers
        # use character bigram distributions to determine the encoding, whereas
        # the multi-byte probers use a combination of character unigram and
        # bigram distributions.
        elif self._input_state == InputState.HIGH_BYTE:
            if not self._charset_probers:
                self._charset_probers = [MBCSGroupProber(self.lang_filter)]
                # If we're checking non-CJK encodings, use single-byte prober
                if self.lang_filter & LanguageFilter.NON_CJK:
                    self._charset_probers.append(SBCSGroupProber())
                self._charset_probers.append(Latin1Prober())
            for prober in self._charset_probers:
                if prober.feed(byte_str) == ProbingState.FOUND_IT:
                    self.result = {'encoding': prober.charset_name,
                                   'confidence': prober.get_confidence(),
                                   'language': prober.language}
                    self.done = True
                    break
            if self.WIN_BYTE_DETECTOR.search(byte_str):
                self._has_win_bytes = True

    def close(self):
        """
        Stop analyzing the current document and come up with a final
        prediction.

        :returns:  The ``result`` attribute, a ``dict`` with the keys
                   `encoding`, `confidence`, and `language`.
        """
        # Don't bother with checks if we're already done
        if self.done:
            return self.result
        self.done = True

        if not self._got_data:
            self.logger.debug('no data received!')

        # Default to ASCII if it is all we've seen so far
        elif self._input_state == InputState.PURE_ASCII:
            self.result = {'encoding': 'ascii',
                           'confidence': 1.0,
                           'language': ''}

        # If we have seen non-ASCII, return the best that met MINIMUM_THRESHOLD
        elif self._input_state == InputState.HIGH_BYTE:
            prober_confidence = None
            max_prober_confidence = 0.0
            max_prober = None
            for prober in self._charset_probers:
                if not prober:
                    continue
                prober_confidence = prober.get_confidence()
                if prober_confidence > max_prober_confidence:
                    max_prober_confidence = prober_confidence
                    max_prober = prober
            if max_prober and (max_prober_confidence > self.MINIMUM_THRESHOLD):
                charset_name = max_prober.charset_name
                lower_charset_name = max_prober.charset_name.lower()
                confidence = max_prober.get_confidence()
                # Use Windows encoding name instead of ISO-8859 if we saw any
                # extra Windows-specific bytes
                if lower_charset_name.startswith('iso-8859'):
                    if self._has_win_bytes:
                        charset_name = self.ISO_WIN_MAP.get(lower_charset_name,
                                                            charset_name)
                self.result = {'encoding': charset_name,
                               'confidence': confidence,
                               'language': max_prober.language}

        # Log all prober confidences if none met MINIMUM_THRESHOLD
        if self.logger.getEffectiveLevel() <= logging.DEBUG:
            if self.result['encoding'] is None:
                self.logger.debug('no probers hit minimum threshold')
                for group_prober in self._charset_probers:
                    if not group_prober:
                        continue
                    if isinstance(group_prober, CharSetGroupProber):
                        for prober in group_prober.probers:
                            self.logger.debug('%s %s confidence = %s',
                                              prober.charset_name,
                                              prober.language,
                                              prober.get_confidence())
                    else:
                        self.logger.debug('%s %s confidence = %s',
                                          group_prober.charset_name,
                                          group_prober.language,
                                          group_prober.get_confidence())
        return self.result




############################################################
### File: unix.py
############################################################
import os
import pytz
import re
import warnings

from tzlocal import utils

_cache_tz = None


def _tz_from_env(tzenv):
    if tzenv[0] == ':':
        tzenv = tzenv[1:]

    # TZ specifies a file
    if os.path.isabs(tzenv) and os.path.exists(tzenv):
        with open(tzenv, 'rb') as tzfile:
            return pytz.tzfile.build_tzinfo('local', tzfile)

    # TZ specifies a zoneinfo zone.
    try:
        tz = pytz.timezone(tzenv)
        # That worked, so we return this:
        return tz
    except pytz.UnknownTimeZoneError:
        raise pytz.UnknownTimeZoneError(
            "tzlocal() does not support non-zoneinfo timezones like %s. \n"
            "Please use a timezone in the form of Continent/City")


def _try_tz_from_env():
    tzenv = os.environ.get('TZ')
    if tzenv:
        try:
            return _tz_from_env(tzenv)
        except pytz.UnknownTimeZoneError:
            pass


def _get_localzone(_root='/'):
    """Tries to find the local timezone configuration.

    This method prefers finding the timezone name and passing that to pytz,
    over passing in the localtime file, as in the later case the zoneinfo
    name is unknown.

    The parameter _root makes the function look for files like /etc/localtime
    beneath the _root directory. This is primarily used by the tests.
    In normal usage you call the function without parameters."""

    tzenv = _try_tz_from_env()
    if tzenv:
        return tzenv

    # Are we under Termux on Android?
    if os.path.exists('/system/bin/getprop'):
        import subprocess
        androidtz = subprocess.check_output(['getprop', 'persist.sys.timezone']).strip().decode()
        return pytz.timezone(androidtz)

    # Now look for distribution specific configuration files
    # that contain the timezone name.
    for configfile in ('etc/timezone', 'var/db/zoneinfo'):
        tzpath = os.path.join(_root, configfile)
        try:
            with open(tzpath, 'rb') as tzfile:
                data = tzfile.read()

                # Issue #3 was that /etc/timezone was a zoneinfo file.
                # That's a misconfiguration, but we need to handle it gracefully:
                if data[:5] == b'TZif2':
                    continue

                etctz = data.strip().decode()
                if not etctz:
                    # Empty file, skip
                    continue
                for etctz in data.decode().splitlines():
                    # Get rid of host definitions and comments:
                    if ' ' in etctz:
                        etctz, dummy = etctz.split(' ', 1)
                    if '#' in etctz:
                        etctz, dummy = etctz.split('#', 1)
                    if not etctz:
                        continue
                    tz = pytz.timezone(etctz.replace(' ', '_'))
                    if _root == '/':
                        # We are using a file in etc to name the timezone.
                        # Verify that the timezone specified there is actually used:
                        utils.assert_tz_offset(tz)
                    return tz

        except IOError:
            # File doesn't exist or is a directory
            continue

    # CentOS has a ZONE setting in /etc/sysconfig/clock,
    # OpenSUSE has a TIMEZONE setting in /etc/sysconfig/clock and
    # Gentoo has a TIMEZONE setting in /etc/conf.d/clock
    # We look through these files for a timezone:

    zone_re = re.compile(r'\s*ZONE\s*=\s*\"')
    timezone_re = re.compile(r'\s*TIMEZONE\s*=\s*\"')
    end_re = re.compile('\"')

    for filename in ('etc/sysconfig/clock', 'etc/conf.d/clock'):
        tzpath = os.path.join(_root, filename)
        try:
            with open(tzpath, 'rt') as tzfile:
                data = tzfile.readlines()

            for line in data:
                # Look for the ZONE= setting.
                match = zone_re.match(line)
                if match is None:
                    # No ZONE= setting. Look for the TIMEZONE= setting.
                    match = timezone_re.match(line)
                if match is not None:
                    # Some setting existed
                    line = line[match.end():]
                    etctz = line[:end_re.search(line).start()]

                    # We found a timezone
                    tz = pytz.timezone(etctz.replace(' ', '_'))
                    if _root == '/':
                        # We are using a file in etc to name the timezone.
                        # Verify that the timezone specified there is actually used:
                        utils.assert_tz_offset(tz)
                    return tz

        except IOError:
            # File doesn't exist or is a directory
            continue

    # systemd distributions use symlinks that include the zone name,
    # see manpage of localtime(5) and timedatectl(1)
    tzpath = os.path.join(_root, 'etc/localtime')
    if os.path.exists(tzpath) and os.path.islink(tzpath):
        tzpath = os.path.realpath(tzpath)
        start = tzpath.find("/")+1
        while start != 0:
            tzpath = tzpath[start:]
            try:
                return pytz.timezone(tzpath)
            except pytz.UnknownTimeZoneError:
                pass
            start = tzpath.find("/")+1

    # No explicit setting existed. Use localtime
    for filename in ('etc/localtime', 'usr/local/etc/localtime'):
        tzpath = os.path.join(_root, filename)

        if not os.path.exists(tzpath):
            continue
        with open(tzpath, 'rb') as tzfile:
            return pytz.tzfile.build_tzinfo('local', tzfile)

    warnings.warn('Can not find any timezone configuration, defaulting to UTC.')
    return pytz.utc

def get_localzone():
    """Get the computers configured local timezone, if any."""
    global _cache_tz
    if _cache_tz is None:
        _cache_tz = _get_localzone()

    return _cache_tz


def reload_localzone():
    """Reload the cached localzone. You need to call this if the timezone has changed."""
    global _cache_tz
    _cache_tz = _get_localzone()
    return _cache_tz




############################################################
### File: update.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2007, 2009-2011 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Dynamic Update Support"""


import dns.message
import dns.name
import dns.opcode
import dns.rdata
import dns.rdataclass
import dns.rdataset
import dns.tsig
from ._compat import string_types


class Update(dns.message.Message):

    def __init__(self, zone, rdclass=dns.rdataclass.IN, keyring=None,
                 keyname=None, keyalgorithm=dns.tsig.default_algorithm):
        """Initialize a new DNS Update object.

        See the documentation of the Message class for a complete
        description of the keyring dictionary.

        *zone*, a ``dns.name.Name`` or ``text``, the zone which is being
        updated.

        *rdclass*, an ``int`` or ``text``, the class of the zone.

        *keyring*, a ``dict``, the TSIG keyring to use.  If a
        *keyring* is specified but a *keyname* is not, then the key
        used will be the first key in the *keyring*.  Note that the
        order of keys in a dictionary is not defined, so applications
        should supply a keyname when a keyring is used, unless they
        know the keyring contains only one key.

        *keyname*, a ``dns.name.Name`` or ``None``, the name of the TSIG key
        to use; defaults to ``None``. The key must be defined in the keyring.

        *keyalgorithm*, a ``dns.name.Name``, the TSIG algorithm to use.
        """
        super(Update, self).__init__()
        self.flags |= dns.opcode.to_flags(dns.opcode.UPDATE)
        if isinstance(zone, string_types):
            zone = dns.name.from_text(zone)
        self.origin = zone
        if isinstance(rdclass, string_types):
            rdclass = dns.rdataclass.from_text(rdclass)
        self.zone_rdclass = rdclass
        self.find_rrset(self.question, self.origin, rdclass, dns.rdatatype.SOA,
                        create=True, force_unique=True)
        if keyring is not None:
            self.use_tsig(keyring, keyname, algorithm=keyalgorithm)

    def _add_rr(self, name, ttl, rd, deleting=None, section=None):
        """Add a single RR to the update section."""

        if section is None:
            section = self.authority
        covers = rd.covers()
        rrset = self.find_rrset(section, name, self.zone_rdclass, rd.rdtype,
                                covers, deleting, True, True)
        rrset.add(rd, ttl)

    def _add(self, replace, section, name, *args):
        """Add records.

        *replace* is the replacement mode.  If ``False``,
        RRs are added to an existing RRset; if ``True``, the RRset
        is replaced with the specified contents.  The second
        argument is the section to add to.  The third argument
        is always a name.  The other arguments can be:

                - rdataset...

                - ttl, rdata...

                - ttl, rdtype, string...
        """

        if isinstance(name, string_types):
            name = dns.name.from_text(name, None)
        if isinstance(args[0], dns.rdataset.Rdataset):
            for rds in args:
                if replace:
                    self.delete(name, rds.rdtype)
                for rd in rds:
                    self._add_rr(name, rds.ttl, rd, section=section)
        else:
            args = list(args)
            ttl = int(args.pop(0))
            if isinstance(args[0], dns.rdata.Rdata):
                if replace:
                    self.delete(name, args[0].rdtype)
                for rd in args:
                    self._add_rr(name, ttl, rd, section=section)
            else:
                rdtype = args.pop(0)
                if isinstance(rdtype, string_types):
                    rdtype = dns.rdatatype.from_text(rdtype)
                if replace:
                    self.delete(name, rdtype)
                for s in args:
                    rd = dns.rdata.from_text(self.zone_rdclass, rdtype, s,
                                             self.origin)
                    self._add_rr(name, ttl, rd, section=section)

    def add(self, name, *args):
        """Add records.

        The first argument is always a name.  The other
        arguments can be:

                - rdataset...

                - ttl, rdata...

                - ttl, rdtype, string...
        """

        self._add(False, self.authority, name, *args)

    def delete(self, name, *args):
        """Delete records.

        The first argument is always a name.  The other
        arguments can be:

                - *empty*

                - rdataset...

                - rdata...

                - rdtype, [string...]
        """

        if isinstance(name, string_types):
            name = dns.name.from_text(name, None)
        if len(args) == 0:
            self.find_rrset(self.authority, name, dns.rdataclass.ANY,
                            dns.rdatatype.ANY, dns.rdatatype.NONE,
                            dns.rdatatype.ANY, True, True)
        elif isinstance(args[0], dns.rdataset.Rdataset):
            for rds in args:
                for rd in rds:
                    self._add_rr(name, 0, rd, dns.rdataclass.NONE)
        else:
            args = list(args)
            if isinstance(args[0], dns.rdata.Rdata):
                for rd in args:
                    self._add_rr(name, 0, rd, dns.rdataclass.NONE)
            else:
                rdtype = args.pop(0)
                if isinstance(rdtype, string_types):
                    rdtype = dns.rdatatype.from_text(rdtype)
                if len(args) == 0:
                    self.find_rrset(self.authority, name,
                                    self.zone_rdclass, rdtype,
                                    dns.rdatatype.NONE,
                                    dns.rdataclass.ANY,
                                    True, True)
                else:
                    for s in args:
                        rd = dns.rdata.from_text(self.zone_rdclass, rdtype, s,
                                                 self.origin)
                        self._add_rr(name, 0, rd, dns.rdataclass.NONE)

    def replace(self, name, *args):
        """Replace records.

        The first argument is always a name.  The other
        arguments can be:

                - rdataset...

                - ttl, rdata...

                - ttl, rdtype, string...

        Note that if you want to replace the entire node, you should do
        a delete of the name followed by one or more calls to add.
        """

        self._add(True, self.authority, name, *args)

    def present(self, name, *args):
        """Require that an owner name (and optionally an rdata type,
        or specific rdataset) exists as a prerequisite to the
        execution of the update.

        The first argument is always a name.
        The other arguments can be:

                - rdataset...

                - rdata...

                - rdtype, string...
        """

        if isinstance(name, string_types):
            name = dns.name.from_text(name, None)
        if len(args) == 0:
            self.find_rrset(self.answer, name,
                            dns.rdataclass.ANY, dns.rdatatype.ANY,
                            dns.rdatatype.NONE, None,
                            True, True)
        elif isinstance(args[0], dns.rdataset.Rdataset) or \
            isinstance(args[0], dns.rdata.Rdata) or \
                len(args) > 1:
            if not isinstance(args[0], dns.rdataset.Rdataset):
                # Add a 0 TTL
                args = list(args)
                args.insert(0, 0)
            self._add(False, self.answer, name, *args)
        else:
            rdtype = args[0]
            if isinstance(rdtype, string_types):
                rdtype = dns.rdatatype.from_text(rdtype)
            self.find_rrset(self.answer, name,
                            dns.rdataclass.ANY, rdtype,
                            dns.rdatatype.NONE, None,
                            True, True)

    def absent(self, name, rdtype=None):
        """Require that an owner name (and optionally an rdata type) does
        not exist as a prerequisite to the execution of the update."""

        if isinstance(name, string_types):
            name = dns.name.from_text(name, None)
        if rdtype is None:
            self.find_rrset(self.answer, name,
                            dns.rdataclass.NONE, dns.rdatatype.ANY,
                            dns.rdatatype.NONE, None,
                            True, True)
        else:
            if isinstance(rdtype, string_types):
                rdtype = dns.rdatatype.from_text(rdtype)
            self.find_rrset(self.answer, name,
                            dns.rdataclass.NONE, rdtype,
                            dns.rdatatype.NONE, None,
                            True, True)

    def to_wire(self, origin=None, max_size=65535):
        """Return a string containing the update in DNS compressed wire
        format.

        *origin*, a ``dns.name.Name`` or ``None``, the origin to be
        appended to any relative names.  If *origin* is ``None``, then
        the origin of the ``dns.update.Update`` message object is used
        (i.e. the *zone* parameter passed when the Update object was
        created).

        *max_size*, an ``int``, the maximum size of the wire format
        output; default is 0, which means "the message's request
        payload, if nonzero, or 65535".

        Returns a ``binary``.
        """

        if origin is None:
            origin = self.origin
        return super(Update, self).to_wire(origin, max_size)




############################################################
### File: urls.py
############################################################
# -*- coding: utf-8 -*-
"""
Predefined URLs used to make google translate requests.
"""
BASE = 'https://translate.google.com'
TRANSLATE = 'https://{host}/translate_a/single'
TRANSLATE_RPC = 'https://{host}/_/TranslateWebserverUi/data/batchexecute'




############################################################
### File: utf8prober.py
############################################################
######################## BEGIN LICENSE BLOCK ########################
# The Original Code is mozilla.org code.
#
# The Initial Developer of the Original Code is
# Netscape Communications Corporation.
# Portions created by the Initial Developer are Copyright (C) 1998
# the Initial Developer. All Rights Reserved.
#
# Contributor(s):
#   Mark Pilgrim - port to Python
#
# This library is free software; you can redistribute it and/or
# modify it under the terms of the GNU Lesser General Public
# License as published by the Free Software Foundation; either
# version 2.1 of the License, or (at your option) any later version.
#
# This library is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
# Lesser General Public License for more details.
#
# You should have received a copy of the GNU Lesser General Public
# License along with this library; if not, write to the Free Software
# Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA
# 02110-1301  USA
######################### END LICENSE BLOCK #########################

from .charsetprober import CharSetProber
from .enums import ProbingState, MachineState
from .codingstatemachine import CodingStateMachine
from .mbcssm import UTF8_SM_MODEL



class UTF8Prober(CharSetProber):
    ONE_CHAR_PROB = 0.5

    def __init__(self):
        super(UTF8Prober, self).__init__()
        self.coding_sm = CodingStateMachine(UTF8_SM_MODEL)
        self._num_mb_chars = None
        self.reset()

    def reset(self):
        super(UTF8Prober, self).reset()
        self.coding_sm.reset()
        self._num_mb_chars = 0

    @property
    def charset_name(self):
        return "utf-8"

    @property
    def language(self):
        return ""

    def feed(self, byte_str):
        for c in byte_str:
            coding_state = self.coding_sm.next_state(c)
            if coding_state == MachineState.ERROR:
                self._state = ProbingState.NOT_ME
                break
            elif coding_state == MachineState.ITS_ME:
                self._state = ProbingState.FOUND_IT
                break
            elif coding_state == MachineState.START:
                if self.coding_sm.get_current_charlen() >= 2:
                    self._num_mb_chars += 1

        if self.state == ProbingState.DETECTING:
            if self.get_confidence() > self.SHORTCUT_THRESHOLD:
                self._state = ProbingState.FOUND_IT

        return self.state

    def get_confidence(self):
        unlike = 0.99
        if self._num_mb_chars < 6:
            unlike *= self.ONE_CHAR_PROB ** self._num_mb_chars
            return 1.0 - unlike
        else:
            return unlike




############################################################
### File: util.py
############################################################
# The MIT License (MIT)
#
# Copyright (c) 2014 Richard Moore
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
# THE SOFTWARE.

# Why to_bufferable?
# Python 3 is very different from Python 2.x when it comes to strings of text
# and strings of bytes; in Python 3, strings of bytes do not exist, instead to
# represent arbitrary binary data, we must use the "bytes" object. This method
# ensures the object behaves as we need it to.

def to_bufferable(binary):
    return binary

def _get_byte(c):
    return ord(c)

try:
    xrange
except:

    def to_bufferable(binary):
        if isinstance(binary, bytes):
            return binary
        return bytes(ord(b) for b in binary)

    def _get_byte(c):
        return c

def append_PKCS7_padding(data):
    pad = 16 - (len(data) % 16)
    return data + to_bufferable(chr(pad) * pad)

def strip_PKCS7_padding(data):
    if len(data) % 16 != 0:
        raise ValueError("invalid length")

    pad = _get_byte(data[-1])

    if pad > 16:
        raise ValueError("invalid padding byte")

    return data[:-pad]




############################################################
### File: utils.py
############################################################
# -*- coding: utf-8 -*-
import time
import datetime
import calendar


def get_system_offset():
    """Get system's timezone offset using built-in library time.

    For the Timezone constants (altzone, daylight, timezone, and tzname), the
    value is determined by the timezone rules in effect at module load time or
    the last time tzset() is called and may be incorrect for times in the past.

    To keep compatibility with Windows, we're always importing time module here.
    """

    localtime = calendar.timegm(time.localtime())
    gmtime = calendar.timegm(time.gmtime())
    offset = gmtime - localtime
    # We could get the localtime and gmtime on either side of a second switch
    # so we check that the difference is less than one minute, because nobody
    # has that small DST differences.
    if abs(offset - time.altzone) < 60:
        return -time.altzone
    else:
        return -time.timezone


def get_tz_offset(tz):
    """Get timezone's offset using built-in function datetime.utcoffset()."""
    return int(datetime.datetime.now(tz).utcoffset().total_seconds())


def assert_tz_offset(tz):
    """Assert that system's timezone offset equals to the timezone offset found.

    If they don't match, we probably have a misconfiguration, for example, an
    incorrect timezone set in /etc/timezone file in systemd distributions."""
    tz_offset = get_tz_offset(tz)
    system_offset = get_system_offset()
    if tz_offset != system_offset:
        msg = ('Timezone offset does not match system offset: {0} != {1}. '
               'Please, check your config files.').format(
                   tz_offset, system_offset
               )
        raise ValueError(msg)




############################################################
### File: uts46data.py
############################################################
# This file is automatically generated by tools/idna-data
# vim: set fileencoding=utf-8 :

"""IDNA Mapping Table from UTS46."""


__version__ = "13.0.0"
def _seg_0():
    return [
    (0x0, '3'),
    (0x1, '3'),
    (0x2, '3'),
    (0x3, '3'),
    (0x4, '3'),
    (0x5, '3'),
    (0x6, '3'),
    (0x7, '3'),
    (0x8, '3'),
    (0x9, '3'),
    (0xA, '3'),
    (0xB, '3'),
    (0xC, '3'),
    (0xD, '3'),
    (0xE, '3'),
    (0xF, '3'),
    (0x10, '3'),
    (0x11, '3'),
    (0x12, '3'),
    (0x13, '3'),
    (0x14, '3'),
    (0x15, '3'),
    (0x16, '3'),
    (0x17, '3'),
    (0x18, '3'),
    (0x19, '3'),
    (0x1A, '3'),
    (0x1B, '3'),
    (0x1C, '3'),
    (0x1D, '3'),
    (0x1E, '3'),
    (0x1F, '3'),
    (0x20, '3'),
    (0x21, '3'),
    (0x22, '3'),
    (0x23, '3'),
    (0x24, '3'),
    (0x25, '3'),
    (0x26, '3'),
    (0x27, '3'),
    (0x28, '3'),
    (0x29, '3'),
    (0x2A, '3'),
    (0x2B, '3'),
    (0x2C, '3'),
    (0x2D, 'V'),
    (0x2E, 'V'),
    (0x2F, '3'),
    (0x30, 'V'),
    (0x31, 'V'),
    (0x32, 'V'),
    (0x33, 'V'),
    (0x34, 'V'),
    (0x35, 'V'),
    (0x36, 'V'),
    (0x37, 'V'),
    (0x38, 'V'),
    (0x39, 'V'),
    (0x3A, '3'),
    (0x3B, '3'),
    (0x3C, '3'),
    (0x3D, '3'),
    (0x3E, '3'),
    (0x3F, '3'),
    (0x40, '3'),
    (0x41, 'M', u'a'),
    (0x42, 'M', u'b'),
    (0x43, 'M', u'c'),
    (0x44, 'M', u'd'),
    (0x45, 'M', u'e'),
    (0x46, 'M', u'f'),
    (0x47, 'M', u'g'),
    (0x48, 'M', u'h'),
    (0x49, 'M', u'i'),
    (0x4A, 'M', u'j'),
    (0x4B, 'M', u'k'),
    (0x4C, 'M', u'l'),
    (0x4D, 'M', u'm'),
    (0x4E, 'M', u'n'),
    (0x4F, 'M', u'o'),
    (0x50, 'M', u'p'),
    (0x51, 'M', u'q'),
    (0x52, 'M', u'r'),
    (0x53, 'M', u's'),
    (0x54, 'M', u't'),
    (0x55, 'M', u'u'),
    (0x56, 'M', u'v'),
    (0x57, 'M', u'w'),
    (0x58, 'M', u'x'),
    (0x59, 'M', u'y'),
    (0x5A, 'M', u'z'),
    (0x5B, '3'),
    (0x5C, '3'),
    (0x5D, '3'),
    (0x5E, '3'),
    (0x5F, '3'),
    (0x60, '3'),
    (0x61, 'V'),
    (0x62, 'V'),
    (0x63, 'V'),
    ]

def _seg_1():
    return [
    (0x64, 'V'),
    (0x65, 'V'),
    (0x66, 'V'),
    (0x67, 'V'),
    (0x68, 'V'),
    (0x69, 'V'),
    (0x6A, 'V'),
    (0x6B, 'V'),
    (0x6C, 'V'),
    (0x6D, 'V'),
    (0x6E, 'V'),
    (0x6F, 'V'),
    (0x70, 'V'),
    (0x71, 'V'),
    (0x72, 'V'),
    (0x73, 'V'),
    (0x74, 'V'),
    (0x75, 'V'),
    (0x76, 'V'),
    (0x77, 'V'),
    (0x78, 'V'),
    (0x79, 'V'),
    (0x7A, 'V'),
    (0x7B, '3'),
    (0x7C, '3'),
    (0x7D, '3'),
    (0x7E, '3'),
    (0x7F, '3'),
    (0x80, 'X'),
    (0x81, 'X'),
    (0x82, 'X'),
    (0x83, 'X'),
    (0x84, 'X'),
    (0x85, 'X'),
    (0x86, 'X'),
    (0x87, 'X'),
    (0x88, 'X'),
    (0x89, 'X'),
    (0x8A, 'X'),
    (0x8B, 'X'),
    (0x8C, 'X'),
    (0x8D, 'X'),
    (0x8E, 'X'),
    (0x8F, 'X'),
    (0x90, 'X'),
    (0x91, 'X'),
    (0x92, 'X'),
    (0x93, 'X'),
    (0x94, 'X'),
    (0x95, 'X'),
    (0x96, 'X'),
    (0x97, 'X'),
    (0x98, 'X'),
    (0x99, 'X'),
    (0x9A, 'X'),
    (0x9B, 'X'),
    (0x9C, 'X'),
    (0x9D, 'X'),
    (0x9E, 'X'),
    (0x9F, 'X'),
    (0xA0, '3', u' '),
    (0xA1, 'V'),
    (0xA2, 'V'),
    (0xA3, 'V'),
    (0xA4, 'V'),
    (0xA5, 'V'),
    (0xA6, 'V'),
    (0xA7, 'V'),
    (0xA8, '3', u' '),
    (0xA9, 'V'),
    (0xAA, 'M', u'a'),
    (0xAB, 'V'),
    (0xAC, 'V'),
    (0xAD, 'I'),
    (0xAE, 'V'),
    (0xAF, '3', u' '),
    (0xB0, 'V'),
    (0xB1, 'V'),
    (0xB2, 'M', u'2'),
    (0xB3, 'M', u'3'),
    (0xB4, '3', u' '),
    (0xB5, 'M', u''),
    (0xB6, 'V'),
    (0xB7, 'V'),
    (0xB8, '3', u' '),
    (0xB9, 'M', u'1'),
    (0xBA, 'M', u'o'),
    (0xBB, 'V'),
    (0xBC, 'M', u'14'),
    (0xBD, 'M', u'12'),
    (0xBE, 'M', u'34'),
    (0xBF, 'V'),
    (0xC0, 'M', u''),
    (0xC1, 'M', u''),
    (0xC2, 'M', u''),
    (0xC3, 'M', u''),
    (0xC4, 'M', u''),
    (0xC5, 'M', u''),
    (0xC6, 'M', u''),
    (0xC7, 'M', u''),
    ]

def _seg_2():
    return [
    (0xC8, 'M', u''),
    (0xC9, 'M', u''),
    (0xCA, 'M', u''),
    (0xCB, 'M', u''),
    (0xCC, 'M', u''),
    (0xCD, 'M', u''),
    (0xCE, 'M', u''),
    (0xCF, 'M', u''),
    (0xD0, 'M', u''),
    (0xD1, 'M', u''),
    (0xD2, 'M', u''),
    (0xD3, 'M', u''),
    (0xD4, 'M', u''),
    (0xD5, 'M', u''),
    (0xD6, 'M', u''),
    (0xD7, 'V'),
    (0xD8, 'M', u''),
    (0xD9, 'M', u''),
    (0xDA, 'M', u''),
    (0xDB, 'M', u''),
    (0xDC, 'M', u''),
    (0xDD, 'M', u''),
    (0xDE, 'M', u''),
    (0xDF, 'D', u'ss'),
    (0xE0, 'V'),
    (0xE1, 'V'),
    (0xE2, 'V'),
    (0xE3, 'V'),
    (0xE4, 'V'),
    (0xE5, 'V'),
    (0xE6, 'V'),
    (0xE7, 'V'),
    (0xE8, 'V'),
    (0xE9, 'V'),
    (0xEA, 'V'),
    (0xEB, 'V'),
    (0xEC, 'V'),
    (0xED, 'V'),
    (0xEE, 'V'),
    (0xEF, 'V'),
    (0xF0, 'V'),
    (0xF1, 'V'),
    (0xF2, 'V'),
    (0xF3, 'V'),
    (0xF4, 'V'),
    (0xF5, 'V'),
    (0xF6, 'V'),
    (0xF7, 'V'),
    (0xF8, 'V'),
    (0xF9, 'V'),
    (0xFA, 'V'),
    (0xFB, 'V'),
    (0xFC, 'V'),
    (0xFD, 'V'),
    (0xFE, 'V'),
    (0xFF, 'V'),
    (0x100, 'M', u''),
    (0x101, 'V'),
    (0x102, 'M', u''),
    (0x103, 'V'),
    (0x104, 'M', u''),
    (0x105, 'V'),
    (0x106, 'M', u''),
    (0x107, 'V'),
    (0x108, 'M', u''),
    (0x109, 'V'),
    (0x10A, 'M', u''),
    (0x10B, 'V'),
    (0x10C, 'M', u''),
    (0x10D, 'V'),
    (0x10E, 'M', u''),
    (0x10F, 'V'),
    (0x110, 'M', u''),
    (0x111, 'V'),
    (0x112, 'M', u''),
    (0x113, 'V'),
    (0x114, 'M', u''),
    (0x115, 'V'),
    (0x116, 'M', u''),
    (0x117, 'V'),
    (0x118, 'M', u''),
    (0x119, 'V'),
    (0x11A, 'M', u''),
    (0x11B, 'V'),
    (0x11C, 'M', u''),
    (0x11D, 'V'),
    (0x11E, 'M', u''),
    (0x11F, 'V'),
    (0x120, 'M', u''),
    (0x121, 'V'),
    (0x122, 'M', u''),
    (0x123, 'V'),
    (0x124, 'M', u''),
    (0x125, 'V'),
    (0x126, 'M', u''),
    (0x127, 'V'),
    (0x128, 'M', u''),
    (0x129, 'V'),
    (0x12A, 'M', u''),
    (0x12B, 'V'),
    ]

def _seg_3():
    return [
    (0x12C, 'M', u''),
    (0x12D, 'V'),
    (0x12E, 'M', u''),
    (0x12F, 'V'),
    (0x130, 'M', u'i'),
    (0x131, 'V'),
    (0x132, 'M', u'ij'),
    (0x134, 'M', u''),
    (0x135, 'V'),
    (0x136, 'M', u''),
    (0x137, 'V'),
    (0x139, 'M', u''),
    (0x13A, 'V'),
    (0x13B, 'M', u''),
    (0x13C, 'V'),
    (0x13D, 'M', u''),
    (0x13E, 'V'),
    (0x13F, 'M', u'l'),
    (0x141, 'M', u''),
    (0x142, 'V'),
    (0x143, 'M', u''),
    (0x144, 'V'),
    (0x145, 'M', u''),
    (0x146, 'V'),
    (0x147, 'M', u''),
    (0x148, 'V'),
    (0x149, 'M', u'n'),
    (0x14A, 'M', u''),
    (0x14B, 'V'),
    (0x14C, 'M', u''),
    (0x14D, 'V'),
    (0x14E, 'M', u''),
    (0x14F, 'V'),
    (0x150, 'M', u''),
    (0x151, 'V'),
    (0x152, 'M', u''),
    (0x153, 'V'),
    (0x154, 'M', u''),
    (0x155, 'V'),
    (0x156, 'M', u''),
    (0x157, 'V'),
    (0x158, 'M', u''),
    (0x159, 'V'),
    (0x15A, 'M', u''),
    (0x15B, 'V'),
    (0x15C, 'M', u''),
    (0x15D, 'V'),
    (0x15E, 'M', u''),
    (0x15F, 'V'),
    (0x160, 'M', u''),
    (0x161, 'V'),
    (0x162, 'M', u''),
    (0x163, 'V'),
    (0x164, 'M', u''),
    (0x165, 'V'),
    (0x166, 'M', u''),
    (0x167, 'V'),
    (0x168, 'M', u''),
    (0x169, 'V'),
    (0x16A, 'M', u''),
    (0x16B, 'V'),
    (0x16C, 'M', u''),
    (0x16D, 'V'),
    (0x16E, 'M', u''),
    (0x16F, 'V'),
    (0x170, 'M', u''),
    (0x171, 'V'),
    (0x172, 'M', u''),
    (0x173, 'V'),
    (0x174, 'M', u''),
    (0x175, 'V'),
    (0x176, 'M', u''),
    (0x177, 'V'),
    (0x178, 'M', u''),
    (0x179, 'M', u''),
    (0x17A, 'V'),
    (0x17B, 'M', u''),
    (0x17C, 'V'),
    (0x17D, 'M', u''),
    (0x17E, 'V'),
    (0x17F, 'M', u's'),
    (0x180, 'V'),
    (0x181, 'M', u''),
    (0x182, 'M', u''),
    (0x183, 'V'),
    (0x184, 'M', u''),
    (0x185, 'V'),
    (0x186, 'M', u''),
    (0x187, 'M', u''),
    (0x188, 'V'),
    (0x189, 'M', u''),
    (0x18A, 'M', u''),
    (0x18B, 'M', u''),
    (0x18C, 'V'),
    (0x18E, 'M', u''),
    (0x18F, 'M', u''),
    (0x190, 'M', u''),
    (0x191, 'M', u''),
    (0x192, 'V'),
    (0x193, 'M', u''),
    ]

def _seg_4():
    return [
    (0x194, 'M', u''),
    (0x195, 'V'),
    (0x196, 'M', u''),
    (0x197, 'M', u''),
    (0x198, 'M', u''),
    (0x199, 'V'),
    (0x19C, 'M', u''),
    (0x19D, 'M', u''),
    (0x19E, 'V'),
    (0x19F, 'M', u''),
    (0x1A0, 'M', u''),
    (0x1A1, 'V'),
    (0x1A2, 'M', u''),
    (0x1A3, 'V'),
    (0x1A4, 'M', u''),
    (0x1A5, 'V'),
    (0x1A6, 'M', u''),
    (0x1A7, 'M', u''),
    (0x1A8, 'V'),
    (0x1A9, 'M', u''),
    (0x1AA, 'V'),
    (0x1AC, 'M', u''),
    (0x1AD, 'V'),
    (0x1AE, 'M', u''),
    (0x1AF, 'M', u''),
    (0x1B0, 'V'),
    (0x1B1, 'M', u''),
    (0x1B2, 'M', u''),
    (0x1B3, 'M', u''),
    (0x1B4, 'V'),
    (0x1B5, 'M', u''),
    (0x1B6, 'V'),
    (0x1B7, 'M', u''),
    (0x1B8, 'M', u''),
    (0x1B9, 'V'),
    (0x1BC, 'M', u''),
    (0x1BD, 'V'),
    (0x1C4, 'M', u'd'),
    (0x1C7, 'M', u'lj'),
    (0x1CA, 'M', u'nj'),
    (0x1CD, 'M', u''),
    (0x1CE, 'V'),
    (0x1CF, 'M', u''),
    (0x1D0, 'V'),
    (0x1D1, 'M', u''),
    (0x1D2, 'V'),
    (0x1D3, 'M', u''),
    (0x1D4, 'V'),
    (0x1D5, 'M', u''),
    (0x1D6, 'V'),
    (0x1D7, 'M', u''),
    (0x1D8, 'V'),
    (0x1D9, 'M', u''),
    (0x1DA, 'V'),
    (0x1DB, 'M', u''),
    (0x1DC, 'V'),
    (0x1DE, 'M', u''),
    (0x1DF, 'V'),
    (0x1E0, 'M', u''),
    (0x1E1, 'V'),
    (0x1E2, 'M', u''),
    (0x1E3, 'V'),
    (0x1E4, 'M', u''),
    (0x1E5, 'V'),
    (0x1E6, 'M', u''),
    (0x1E7, 'V'),
    (0x1E8, 'M', u''),
    (0x1E9, 'V'),
    (0x1EA, 'M', u''),
    (0x1EB, 'V'),
    (0x1EC, 'M', u''),
    (0x1ED, 'V'),
    (0x1EE, 'M', u''),
    (0x1EF, 'V'),
    (0x1F1, 'M', u'dz'),
    (0x1F4, 'M', u''),
    (0x1F5, 'V'),
    (0x1F6, 'M', u''),
    (0x1F7, 'M', u''),
    (0x1F8, 'M', u''),
    (0x1F9, 'V'),
    (0x1FA, 'M', u''),
    (0x1FB, 'V'),
    (0x1FC, 'M', u''),
    (0x1FD, 'V'),
    (0x1FE, 'M', u''),
    (0x1FF, 'V'),
    (0x200, 'M', u''),
    (0x201, 'V'),
    (0x202, 'M', u''),
    (0x203, 'V'),
    (0x204, 'M', u''),
    (0x205, 'V'),
    (0x206, 'M', u''),
    (0x207, 'V'),
    (0x208, 'M', u''),
    (0x209, 'V'),
    (0x20A, 'M', u''),
    (0x20B, 'V'),
    (0x20C, 'M', u''),
    ]

def _seg_5():
    return [
    (0x20D, 'V'),
    (0x20E, 'M', u''),
    (0x20F, 'V'),
    (0x210, 'M', u''),
    (0x211, 'V'),
    (0x212, 'M', u''),
    (0x213, 'V'),
    (0x214, 'M', u''),
    (0x215, 'V'),
    (0x216, 'M', u''),
    (0x217, 'V'),
    (0x218, 'M', u''),
    (0x219, 'V'),
    (0x21A, 'M', u''),
    (0x21B, 'V'),
    (0x21C, 'M', u''),
    (0x21D, 'V'),
    (0x21E, 'M', u''),
    (0x21F, 'V'),
    (0x220, 'M', u''),
    (0x221, 'V'),
    (0x222, 'M', u''),
    (0x223, 'V'),
    (0x224, 'M', u''),
    (0x225, 'V'),
    (0x226, 'M', u''),
    (0x227, 'V'),
    (0x228, 'M', u''),
    (0x229, 'V'),
    (0x22A, 'M', u''),
    (0x22B, 'V'),
    (0x22C, 'M', u''),
    (0x22D, 'V'),
    (0x22E, 'M', u''),
    (0x22F, 'V'),
    (0x230, 'M', u''),
    (0x231, 'V'),
    (0x232, 'M', u''),
    (0x233, 'V'),
    (0x23A, 'M', u''),
    (0x23B, 'M', u''),
    (0x23C, 'V'),
    (0x23D, 'M', u''),
    (0x23E, 'M', u''),
    (0x23F, 'V'),
    (0x241, 'M', u''),
    (0x242, 'V'),
    (0x243, 'M', u''),
    (0x244, 'M', u''),
    (0x245, 'M', u''),
    (0x246, 'M', u''),
    (0x247, 'V'),
    (0x248, 'M', u''),
    (0x249, 'V'),
    (0x24A, 'M', u''),
    (0x24B, 'V'),
    (0x24C, 'M', u''),
    (0x24D, 'V'),
    (0x24E, 'M', u''),
    (0x24F, 'V'),
    (0x2B0, 'M', u'h'),
    (0x2B1, 'M', u''),
    (0x2B2, 'M', u'j'),
    (0x2B3, 'M', u'r'),
    (0x2B4, 'M', u''),
    (0x2B5, 'M', u''),
    (0x2B6, 'M', u''),
    (0x2B7, 'M', u'w'),
    (0x2B8, 'M', u'y'),
    (0x2B9, 'V'),
    (0x2D8, '3', u' '),
    (0x2D9, '3', u' '),
    (0x2DA, '3', u' '),
    (0x2DB, '3', u' '),
    (0x2DC, '3', u' '),
    (0x2DD, '3', u' '),
    (0x2DE, 'V'),
    (0x2E0, 'M', u''),
    (0x2E1, 'M', u'l'),
    (0x2E2, 'M', u's'),
    (0x2E3, 'M', u'x'),
    (0x2E4, 'M', u''),
    (0x2E5, 'V'),
    (0x340, 'M', u''),
    (0x341, 'M', u''),
    (0x342, 'V'),
    (0x343, 'M', u''),
    (0x344, 'M', u''),
    (0x345, 'M', u''),
    (0x346, 'V'),
    (0x34F, 'I'),
    (0x350, 'V'),
    (0x370, 'M', u''),
    (0x371, 'V'),
    (0x372, 'M', u''),
    (0x373, 'V'),
    (0x374, 'M', u''),
    (0x375, 'V'),
    (0x376, 'M', u''),
    (0x377, 'V'),
    ]

def _seg_6():
    return [
    (0x378, 'X'),
    (0x37A, '3', u' '),
    (0x37B, 'V'),
    (0x37E, '3', u';'),
    (0x37F, 'M', u''),
    (0x380, 'X'),
    (0x384, '3', u' '),
    (0x385, '3', u' '),
    (0x386, 'M', u''),
    (0x387, 'M', u''),
    (0x388, 'M', u''),
    (0x389, 'M', u''),
    (0x38A, 'M', u''),
    (0x38B, 'X'),
    (0x38C, 'M', u''),
    (0x38D, 'X'),
    (0x38E, 'M', u''),
    (0x38F, 'M', u''),
    (0x390, 'V'),
    (0x391, 'M', u''),
    (0x392, 'M', u''),
    (0x393, 'M', u''),
    (0x394, 'M', u''),
    (0x395, 'M', u''),
    (0x396, 'M', u''),
    (0x397, 'M', u''),
    (0x398, 'M', u''),
    (0x399, 'M', u''),
    (0x39A, 'M', u''),
    (0x39B, 'M', u''),
    (0x39C, 'M', u''),
    (0x39D, 'M', u''),
    (0x39E, 'M', u''),
    (0x39F, 'M', u''),
    (0x3A0, 'M', u''),
    (0x3A1, 'M', u''),
    (0x3A2, 'X'),
    (0x3A3, 'M', u''),
    (0x3A4, 'M', u''),
    (0x3A5, 'M', u''),
    (0x3A6, 'M', u''),
    (0x3A7, 'M', u''),
    (0x3A8, 'M', u''),
    (0x3A9, 'M', u''),
    (0x3AA, 'M', u''),
    (0x3AB, 'M', u''),
    (0x3AC, 'V'),
    (0x3C2, 'D', u''),
    (0x3C3, 'V'),
    (0x3CF, 'M', u''),
    (0x3D0, 'M', u''),
    (0x3D1, 'M', u''),
    (0x3D2, 'M', u''),
    (0x3D3, 'M', u''),
    (0x3D4, 'M', u''),
    (0x3D5, 'M', u''),
    (0x3D6, 'M', u''),
    (0x3D7, 'V'),
    (0x3D8, 'M', u''),
    (0x3D9, 'V'),
    (0x3DA, 'M', u''),
    (0x3DB, 'V'),
    (0x3DC, 'M', u''),
    (0x3DD, 'V'),
    (0x3DE, 'M', u''),
    (0x3DF, 'V'),
    (0x3E0, 'M', u''),
    (0x3E1, 'V'),
    (0x3E2, 'M', u''),
    (0x3E3, 'V'),
    (0x3E4, 'M', u''),
    (0x3E5, 'V'),
    (0x3E6, 'M', u''),
    (0x3E7, 'V'),
    (0x3E8, 'M', u''),
    (0x3E9, 'V'),
    (0x3EA, 'M', u''),
    (0x3EB, 'V'),
    (0x3EC, 'M', u''),
    (0x3ED, 'V'),
    (0x3EE, 'M', u''),
    (0x3EF, 'V'),
    (0x3F0, 'M', u''),
    (0x3F1, 'M', u''),
    (0x3F2, 'M', u''),
    (0x3F3, 'V'),
    (0x3F4, 'M', u''),
    (0x3F5, 'M', u''),
    (0x3F6, 'V'),
    (0x3F7, 'M', u''),
    (0x3F8, 'V'),
    (0x3F9, 'M', u''),
    (0x3FA, 'M', u''),
    (0x3FB, 'V'),
    (0x3FD, 'M', u''),
    (0x3FE, 'M', u''),
    (0x3FF, 'M', u''),
    (0x400, 'M', u''),
    (0x401, 'M', u''),
    (0x402, 'M', u''),
    ]

def _seg_7():
    return [
    (0x403, 'M', u''),
    (0x404, 'M', u''),
    (0x405, 'M', u''),
    (0x406, 'M', u''),
    (0x407, 'M', u''),
    (0x408, 'M', u''),
    (0x409, 'M', u''),
    (0x40A, 'M', u''),
    (0x40B, 'M', u''),
    (0x40C, 'M', u''),
    (0x40D, 'M', u''),
    (0x40E, 'M', u''),
    (0x40F, 'M', u''),
    (0x410, 'M', u''),
    (0x411, 'M', u''),
    (0x412, 'M', u''),
    (0x413, 'M', u''),
    (0x414, 'M', u''),
    (0x415, 'M', u''),
    (0x416, 'M', u''),
    (0x417, 'M', u''),
    (0x418, 'M', u''),
    (0x419, 'M', u''),
    (0x41A, 'M', u''),
    (0x41B, 'M', u''),
    (0x41C, 'M', u''),
    (0x41D, 'M', u''),
    (0x41E, 'M', u''),
    (0x41F, 'M', u''),
    (0x420, 'M', u''),
    (0x421, 'M', u''),
    (0x422, 'M', u''),
    (0x423, 'M', u''),
    (0x424, 'M', u''),
    (0x425, 'M', u''),
    (0x426, 'M', u''),
    (0x427, 'M', u''),
    (0x428, 'M', u''),
    (0x429, 'M', u''),
    (0x42A, 'M', u''),
    (0x42B, 'M', u''),
    (0x42C, 'M', u''),
    (0x42D, 'M', u''),
    (0x42E, 'M', u''),
    (0x42F, 'M', u''),
    (0x430, 'V'),
    (0x460, 'M', u''),
    (0x461, 'V'),
    (0x462, 'M', u''),
    (0x463, 'V'),
    (0x464, 'M', u''),
    (0x465, 'V'),
    (0x466, 'M', u''),
    (0x467, 'V'),
    (0x468, 'M', u''),
    (0x469, 'V'),
    (0x46A, 'M', u''),
    (0x46B, 'V'),
    (0x46C, 'M', u''),
    (0x46D, 'V'),
    (0x46E, 'M', u''),
    (0x46F, 'V'),
    (0x470, 'M', u''),
    (0x471, 'V'),
    (0x472, 'M', u''),
    (0x473, 'V'),
    (0x474, 'M', u''),
    (0x475, 'V'),
    (0x476, 'M', u''),
    (0x477, 'V'),
    (0x478, 'M', u''),
    (0x479, 'V'),
    (0x47A, 'M', u''),
    (0x47B, 'V'),
    (0x47C, 'M', u''),
    (0x47D, 'V'),
    (0x47E, 'M', u''),
    (0x47F, 'V'),
    (0x480, 'M', u''),
    (0x481, 'V'),
    (0x48A, 'M', u''),
    (0x48B, 'V'),
    (0x48C, 'M', u''),
    (0x48D, 'V'),
    (0x48E, 'M', u''),
    (0x48F, 'V'),
    (0x490, 'M', u''),
    (0x491, 'V'),
    (0x492, 'M', u''),
    (0x493, 'V'),
    (0x494, 'M', u''),
    (0x495, 'V'),
    (0x496, 'M', u''),
    (0x497, 'V'),
    (0x498, 'M', u''),
    (0x499, 'V'),
    (0x49A, 'M', u''),
    (0x49B, 'V'),
    (0x49C, 'M', u''),
    (0x49D, 'V'),
    ]

def _seg_8():
    return [
    (0x49E, 'M', u''),
    (0x49F, 'V'),
    (0x4A0, 'M', u''),
    (0x4A1, 'V'),
    (0x4A2, 'M', u''),
    (0x4A3, 'V'),
    (0x4A4, 'M', u''),
    (0x4A5, 'V'),
    (0x4A6, 'M', u''),
    (0x4A7, 'V'),
    (0x4A8, 'M', u''),
    (0x4A9, 'V'),
    (0x4AA, 'M', u''),
    (0x4AB, 'V'),
    (0x4AC, 'M', u''),
    (0x4AD, 'V'),
    (0x4AE, 'M', u''),
    (0x4AF, 'V'),
    (0x4B0, 'M', u''),
    (0x4B1, 'V'),
    (0x4B2, 'M', u''),
    (0x4B3, 'V'),
    (0x4B4, 'M', u''),
    (0x4B5, 'V'),
    (0x4B6, 'M', u''),
    (0x4B7, 'V'),
    (0x4B8, 'M', u''),
    (0x4B9, 'V'),
    (0x4BA, 'M', u''),
    (0x4BB, 'V'),
    (0x4BC, 'M', u''),
    (0x4BD, 'V'),
    (0x4BE, 'M', u''),
    (0x4BF, 'V'),
    (0x4C0, 'X'),
    (0x4C1, 'M', u''),
    (0x4C2, 'V'),
    (0x4C3, 'M', u''),
    (0x4C4, 'V'),
    (0x4C5, 'M', u''),
    (0x4C6, 'V'),
    (0x4C7, 'M', u''),
    (0x4C8, 'V'),
    (0x4C9, 'M', u''),
    (0x4CA, 'V'),
    (0x4CB, 'M', u''),
    (0x4CC, 'V'),
    (0x4CD, 'M', u''),
    (0x4CE, 'V'),
    (0x4D0, 'M', u''),
    (0x4D1, 'V'),
    (0x4D2, 'M', u''),
    (0x4D3, 'V'),
    (0x4D4, 'M', u''),
    (0x4D5, 'V'),
    (0x4D6, 'M', u''),
    (0x4D7, 'V'),
    (0x4D8, 'M', u''),
    (0x4D9, 'V'),
    (0x4DA, 'M', u''),
    (0x4DB, 'V'),
    (0x4DC, 'M', u''),
    (0x4DD, 'V'),
    (0x4DE, 'M', u''),
    (0x4DF, 'V'),
    (0x4E0, 'M', u''),
    (0x4E1, 'V'),
    (0x4E2, 'M', u''),
    (0x4E3, 'V'),
    (0x4E4, 'M', u''),
    (0x4E5, 'V'),
    (0x4E6, 'M', u''),
    (0x4E7, 'V'),
    (0x4E8, 'M', u''),
    (0x4E9, 'V'),
    (0x4EA, 'M', u''),
    (0x4EB, 'V'),
    (0x4EC, 'M', u''),
    (0x4ED, 'V'),
    (0x4EE, 'M', u''),
    (0x4EF, 'V'),
    (0x4F0, 'M', u''),
    (0x4F1, 'V'),
    (0x4F2, 'M', u''),
    (0x4F3, 'V'),
    (0x4F4, 'M', u''),
    (0x4F5, 'V'),
    (0x4F6, 'M', u''),
    (0x4F7, 'V'),
    (0x4F8, 'M', u''),
    (0x4F9, 'V'),
    (0x4FA, 'M', u''),
    (0x4FB, 'V'),
    (0x4FC, 'M', u''),
    (0x4FD, 'V'),
    (0x4FE, 'M', u''),
    (0x4FF, 'V'),
    (0x500, 'M', u''),
    (0x501, 'V'),
    (0x502, 'M', u''),
    ]

def _seg_9():
    return [
    (0x503, 'V'),
    (0x504, 'M', u''),
    (0x505, 'V'),
    (0x506, 'M', u''),
    (0x507, 'V'),
    (0x508, 'M', u''),
    (0x509, 'V'),
    (0x50A, 'M', u''),
    (0x50B, 'V'),
    (0x50C, 'M', u''),
    (0x50D, 'V'),
    (0x50E, 'M', u''),
    (0x50F, 'V'),
    (0x510, 'M', u''),
    (0x511, 'V'),
    (0x512, 'M', u''),
    (0x513, 'V'),
    (0x514, 'M', u''),
    (0x515, 'V'),
    (0x516, 'M', u''),
    (0x517, 'V'),
    (0x518, 'M', u''),
    (0x519, 'V'),
    (0x51A, 'M', u''),
    (0x51B, 'V'),
    (0x51C, 'M', u''),
    (0x51D, 'V'),
    (0x51E, 'M', u''),
    (0x51F, 'V'),
    (0x520, 'M', u''),
    (0x521, 'V'),
    (0x522, 'M', u''),
    (0x523, 'V'),
    (0x524, 'M', u''),
    (0x525, 'V'),
    (0x526, 'M', u''),
    (0x527, 'V'),
    (0x528, 'M', u''),
    (0x529, 'V'),
    (0x52A, 'M', u''),
    (0x52B, 'V'),
    (0x52C, 'M', u''),
    (0x52D, 'V'),
    (0x52E, 'M', u''),
    (0x52F, 'V'),
    (0x530, 'X'),
    (0x531, 'M', u''),
    (0x532, 'M', u''),
    (0x533, 'M', u''),
    (0x534, 'M', u''),
    (0x535, 'M', u''),
    (0x536, 'M', u''),
    (0x537, 'M', u''),
    (0x538, 'M', u''),
    (0x539, 'M', u''),
    (0x53A, 'M', u''),
    (0x53B, 'M', u''),
    (0x53C, 'M', u''),
    (0x53D, 'M', u''),
    (0x53E, 'M', u''),
    (0x53F, 'M', u''),
    (0x540, 'M', u''),
    (0x541, 'M', u''),
    (0x542, 'M', u''),
    (0x543, 'M', u''),
    (0x544, 'M', u''),
    (0x545, 'M', u''),
    (0x546, 'M', u''),
    (0x547, 'M', u''),
    (0x548, 'M', u''),
    (0x549, 'M', u''),
    (0x54A, 'M', u''),
    (0x54B, 'M', u''),
    (0x54C, 'M', u''),
    (0x54D, 'M', u''),
    (0x54E, 'M', u''),
    (0x54F, 'M', u''),
    (0x550, 'M', u''),
    (0x551, 'M', u''),
    (0x552, 'M', u''),
    (0x553, 'M', u''),
    (0x554, 'M', u''),
    (0x555, 'M', u''),
    (0x556, 'M', u''),
    (0x557, 'X'),
    (0x559, 'V'),
    (0x587, 'M', u''),
    (0x588, 'V'),
    (0x58B, 'X'),
    (0x58D, 'V'),
    (0x590, 'X'),
    (0x591, 'V'),
    (0x5C8, 'X'),
    (0x5D0, 'V'),
    (0x5EB, 'X'),
    (0x5EF, 'V'),
    (0x5F5, 'X'),
    (0x606, 'V'),
    (0x61C, 'X'),
    (0x61E, 'V'),
    ]

def _seg_10():
    return [
    (0x675, 'M', u''),
    (0x676, 'M', u''),
    (0x677, 'M', u''),
    (0x678, 'M', u''),
    (0x679, 'V'),
    (0x6DD, 'X'),
    (0x6DE, 'V'),
    (0x70E, 'X'),
    (0x710, 'V'),
    (0x74B, 'X'),
    (0x74D, 'V'),
    (0x7B2, 'X'),
    (0x7C0, 'V'),
    (0x7FB, 'X'),
    (0x7FD, 'V'),
    (0x82E, 'X'),
    (0x830, 'V'),
    (0x83F, 'X'),
    (0x840, 'V'),
    (0x85C, 'X'),
    (0x85E, 'V'),
    (0x85F, 'X'),
    (0x860, 'V'),
    (0x86B, 'X'),
    (0x8A0, 'V'),
    (0x8B5, 'X'),
    (0x8B6, 'V'),
    (0x8C8, 'X'),
    (0x8D3, 'V'),
    (0x8E2, 'X'),
    (0x8E3, 'V'),
    (0x958, 'M', u''),
    (0x959, 'M', u''),
    (0x95A, 'M', u''),
    (0x95B, 'M', u''),
    (0x95C, 'M', u''),
    (0x95D, 'M', u''),
    (0x95E, 'M', u''),
    (0x95F, 'M', u''),
    (0x960, 'V'),
    (0x984, 'X'),
    (0x985, 'V'),
    (0x98D, 'X'),
    (0x98F, 'V'),
    (0x991, 'X'),
    (0x993, 'V'),
    (0x9A9, 'X'),
    (0x9AA, 'V'),
    (0x9B1, 'X'),
    (0x9B2, 'V'),
    (0x9B3, 'X'),
    (0x9B6, 'V'),
    (0x9BA, 'X'),
    (0x9BC, 'V'),
    (0x9C5, 'X'),
    (0x9C7, 'V'),
    (0x9C9, 'X'),
    (0x9CB, 'V'),
    (0x9CF, 'X'),
    (0x9D7, 'V'),
    (0x9D8, 'X'),
    (0x9DC, 'M', u''),
    (0x9DD, 'M', u''),
    (0x9DE, 'X'),
    (0x9DF, 'M', u''),
    (0x9E0, 'V'),
    (0x9E4, 'X'),
    (0x9E6, 'V'),
    (0x9FF, 'X'),
    (0xA01, 'V'),
    (0xA04, 'X'),
    (0xA05, 'V'),
    (0xA0B, 'X'),
    (0xA0F, 'V'),
    (0xA11, 'X'),
    (0xA13, 'V'),
    (0xA29, 'X'),
    (0xA2A, 'V'),
    (0xA31, 'X'),
    (0xA32, 'V'),
    (0xA33, 'M', u''),
    (0xA34, 'X'),
    (0xA35, 'V'),
    (0xA36, 'M', u''),
    (0xA37, 'X'),
    (0xA38, 'V'),
    (0xA3A, 'X'),
    (0xA3C, 'V'),
    (0xA3D, 'X'),
    (0xA3E, 'V'),
    (0xA43, 'X'),
    (0xA47, 'V'),
    (0xA49, 'X'),
    (0xA4B, 'V'),
    (0xA4E, 'X'),
    (0xA51, 'V'),
    (0xA52, 'X'),
    (0xA59, 'M', u''),
    (0xA5A, 'M', u''),
    (0xA5B, 'M', u''),
    ]

def _seg_11():
    return [
    (0xA5C, 'V'),
    (0xA5D, 'X'),
    (0xA5E, 'M', u''),
    (0xA5F, 'X'),
    (0xA66, 'V'),
    (0xA77, 'X'),
    (0xA81, 'V'),
    (0xA84, 'X'),
    (0xA85, 'V'),
    (0xA8E, 'X'),
    (0xA8F, 'V'),
    (0xA92, 'X'),
    (0xA93, 'V'),
    (0xAA9, 'X'),
    (0xAAA, 'V'),
    (0xAB1, 'X'),
    (0xAB2, 'V'),
    (0xAB4, 'X'),
    (0xAB5, 'V'),
    (0xABA, 'X'),
    (0xABC, 'V'),
    (0xAC6, 'X'),
    (0xAC7, 'V'),
    (0xACA, 'X'),
    (0xACB, 'V'),
    (0xACE, 'X'),
    (0xAD0, 'V'),
    (0xAD1, 'X'),
    (0xAE0, 'V'),
    (0xAE4, 'X'),
    (0xAE6, 'V'),
    (0xAF2, 'X'),
    (0xAF9, 'V'),
    (0xB00, 'X'),
    (0xB01, 'V'),
    (0xB04, 'X'),
    (0xB05, 'V'),
    (0xB0D, 'X'),
    (0xB0F, 'V'),
    (0xB11, 'X'),
    (0xB13, 'V'),
    (0xB29, 'X'),
    (0xB2A, 'V'),
    (0xB31, 'X'),
    (0xB32, 'V'),
    (0xB34, 'X'),
    (0xB35, 'V'),
    (0xB3A, 'X'),
    (0xB3C, 'V'),
    (0xB45, 'X'),
    (0xB47, 'V'),
    (0xB49, 'X'),
    (0xB4B, 'V'),
    (0xB4E, 'X'),
    (0xB55, 'V'),
    (0xB58, 'X'),
    (0xB5C, 'M', u''),
    (0xB5D, 'M', u''),
    (0xB5E, 'X'),
    (0xB5F, 'V'),
    (0xB64, 'X'),
    (0xB66, 'V'),
    (0xB78, 'X'),
    (0xB82, 'V'),
    (0xB84, 'X'),
    (0xB85, 'V'),
    (0xB8B, 'X'),
    (0xB8E, 'V'),
    (0xB91, 'X'),
    (0xB92, 'V'),
    (0xB96, 'X'),
    (0xB99, 'V'),
    (0xB9B, 'X'),
    (0xB9C, 'V'),
    (0xB9D, 'X'),
    (0xB9E, 'V'),
    (0xBA0, 'X'),
    (0xBA3, 'V'),
    (0xBA5, 'X'),
    (0xBA8, 'V'),
    (0xBAB, 'X'),
    (0xBAE, 'V'),
    (0xBBA, 'X'),
    (0xBBE, 'V'),
    (0xBC3, 'X'),
    (0xBC6, 'V'),
    (0xBC9, 'X'),
    (0xBCA, 'V'),
    (0xBCE, 'X'),
    (0xBD0, 'V'),
    (0xBD1, 'X'),
    (0xBD7, 'V'),
    (0xBD8, 'X'),
    (0xBE6, 'V'),
    (0xBFB, 'X'),
    (0xC00, 'V'),
    (0xC0D, 'X'),
    (0xC0E, 'V'),
    (0xC11, 'X'),
    (0xC12, 'V'),
    ]

def _seg_12():
    return [
    (0xC29, 'X'),
    (0xC2A, 'V'),
    (0xC3A, 'X'),
    (0xC3D, 'V'),
    (0xC45, 'X'),
    (0xC46, 'V'),
    (0xC49, 'X'),
    (0xC4A, 'V'),
    (0xC4E, 'X'),
    (0xC55, 'V'),
    (0xC57, 'X'),
    (0xC58, 'V'),
    (0xC5B, 'X'),
    (0xC60, 'V'),
    (0xC64, 'X'),
    (0xC66, 'V'),
    (0xC70, 'X'),
    (0xC77, 'V'),
    (0xC8D, 'X'),
    (0xC8E, 'V'),
    (0xC91, 'X'),
    (0xC92, 'V'),
    (0xCA9, 'X'),
    (0xCAA, 'V'),
    (0xCB4, 'X'),
    (0xCB5, 'V'),
    (0xCBA, 'X'),
    (0xCBC, 'V'),
    (0xCC5, 'X'),
    (0xCC6, 'V'),
    (0xCC9, 'X'),
    (0xCCA, 'V'),
    (0xCCE, 'X'),
    (0xCD5, 'V'),
    (0xCD7, 'X'),
    (0xCDE, 'V'),
    (0xCDF, 'X'),
    (0xCE0, 'V'),
    (0xCE4, 'X'),
    (0xCE6, 'V'),
    (0xCF0, 'X'),
    (0xCF1, 'V'),
    (0xCF3, 'X'),
    (0xD00, 'V'),
    (0xD0D, 'X'),
    (0xD0E, 'V'),
    (0xD11, 'X'),
    (0xD12, 'V'),
    (0xD45, 'X'),
    (0xD46, 'V'),
    (0xD49, 'X'),
    (0xD4A, 'V'),
    (0xD50, 'X'),
    (0xD54, 'V'),
    (0xD64, 'X'),
    (0xD66, 'V'),
    (0xD80, 'X'),
    (0xD81, 'V'),
    (0xD84, 'X'),
    (0xD85, 'V'),
    (0xD97, 'X'),
    (0xD9A, 'V'),
    (0xDB2, 'X'),
    (0xDB3, 'V'),
    (0xDBC, 'X'),
    (0xDBD, 'V'),
    (0xDBE, 'X'),
    (0xDC0, 'V'),
    (0xDC7, 'X'),
    (0xDCA, 'V'),
    (0xDCB, 'X'),
    (0xDCF, 'V'),
    (0xDD5, 'X'),
    (0xDD6, 'V'),
    (0xDD7, 'X'),
    (0xDD8, 'V'),
    (0xDE0, 'X'),
    (0xDE6, 'V'),
    (0xDF0, 'X'),
    (0xDF2, 'V'),
    (0xDF5, 'X'),
    (0xE01, 'V'),
    (0xE33, 'M', u''),
    (0xE34, 'V'),
    (0xE3B, 'X'),
    (0xE3F, 'V'),
    (0xE5C, 'X'),
    (0xE81, 'V'),
    (0xE83, 'X'),
    (0xE84, 'V'),
    (0xE85, 'X'),
    (0xE86, 'V'),
    (0xE8B, 'X'),
    (0xE8C, 'V'),
    (0xEA4, 'X'),
    (0xEA5, 'V'),
    (0xEA6, 'X'),
    (0xEA7, 'V'),
    (0xEB3, 'M', u''),
    (0xEB4, 'V'),
    ]

def _seg_13():
    return [
    (0xEBE, 'X'),
    (0xEC0, 'V'),
    (0xEC5, 'X'),
    (0xEC6, 'V'),
    (0xEC7, 'X'),
    (0xEC8, 'V'),
    (0xECE, 'X'),
    (0xED0, 'V'),
    (0xEDA, 'X'),
    (0xEDC, 'M', u''),
    (0xEDD, 'M', u''),
    (0xEDE, 'V'),
    (0xEE0, 'X'),
    (0xF00, 'V'),
    (0xF0C, 'M', u''),
    (0xF0D, 'V'),
    (0xF43, 'M', u''),
    (0xF44, 'V'),
    (0xF48, 'X'),
    (0xF49, 'V'),
    (0xF4D, 'M', u''),
    (0xF4E, 'V'),
    (0xF52, 'M', u''),
    (0xF53, 'V'),
    (0xF57, 'M', u''),
    (0xF58, 'V'),
    (0xF5C, 'M', u''),
    (0xF5D, 'V'),
    (0xF69, 'M', u''),
    (0xF6A, 'V'),
    (0xF6D, 'X'),
    (0xF71, 'V'),
    (0xF73, 'M', u''),
    (0xF74, 'V'),
    (0xF75, 'M', u''),
    (0xF76, 'M', u''),
    (0xF77, 'M', u''),
    (0xF78, 'M', u''),
    (0xF79, 'M', u''),
    (0xF7A, 'V'),
    (0xF81, 'M', u''),
    (0xF82, 'V'),
    (0xF93, 'M', u''),
    (0xF94, 'V'),
    (0xF98, 'X'),
    (0xF99, 'V'),
    (0xF9D, 'M', u''),
    (0xF9E, 'V'),
    (0xFA2, 'M', u''),
    (0xFA3, 'V'),
    (0xFA7, 'M', u''),
    (0xFA8, 'V'),
    (0xFAC, 'M', u''),
    (0xFAD, 'V'),
    (0xFB9, 'M', u''),
    (0xFBA, 'V'),
    (0xFBD, 'X'),
    (0xFBE, 'V'),
    (0xFCD, 'X'),
    (0xFCE, 'V'),
    (0xFDB, 'X'),
    (0x1000, 'V'),
    (0x10A0, 'X'),
    (0x10C7, 'M', u''),
    (0x10C8, 'X'),
    (0x10CD, 'M', u''),
    (0x10CE, 'X'),
    (0x10D0, 'V'),
    (0x10FC, 'M', u''),
    (0x10FD, 'V'),
    (0x115F, 'X'),
    (0x1161, 'V'),
    (0x1249, 'X'),
    (0x124A, 'V'),
    (0x124E, 'X'),
    (0x1250, 'V'),
    (0x1257, 'X'),
    (0x1258, 'V'),
    (0x1259, 'X'),
    (0x125A, 'V'),
    (0x125E, 'X'),
    (0x1260, 'V'),
    (0x1289, 'X'),
    (0x128A, 'V'),
    (0x128E, 'X'),
    (0x1290, 'V'),
    (0x12B1, 'X'),
    (0x12B2, 'V'),
    (0x12B6, 'X'),
    (0x12B8, 'V'),
    (0x12BF, 'X'),
    (0x12C0, 'V'),
    (0x12C1, 'X'),
    (0x12C2, 'V'),
    (0x12C6, 'X'),
    (0x12C8, 'V'),
    (0x12D7, 'X'),
    (0x12D8, 'V'),
    (0x1311, 'X'),
    (0x1312, 'V'),
    ]

def _seg_14():
    return [
    (0x1316, 'X'),
    (0x1318, 'V'),
    (0x135B, 'X'),
    (0x135D, 'V'),
    (0x137D, 'X'),
    (0x1380, 'V'),
    (0x139A, 'X'),
    (0x13A0, 'V'),
    (0x13F6, 'X'),
    (0x13F8, 'M', u''),
    (0x13F9, 'M', u''),
    (0x13FA, 'M', u''),
    (0x13FB, 'M', u''),
    (0x13FC, 'M', u''),
    (0x13FD, 'M', u''),
    (0x13FE, 'X'),
    (0x1400, 'V'),
    (0x1680, 'X'),
    (0x1681, 'V'),
    (0x169D, 'X'),
    (0x16A0, 'V'),
    (0x16F9, 'X'),
    (0x1700, 'V'),
    (0x170D, 'X'),
    (0x170E, 'V'),
    (0x1715, 'X'),
    (0x1720, 'V'),
    (0x1737, 'X'),
    (0x1740, 'V'),
    (0x1754, 'X'),
    (0x1760, 'V'),
    (0x176D, 'X'),
    (0x176E, 'V'),
    (0x1771, 'X'),
    (0x1772, 'V'),
    (0x1774, 'X'),
    (0x1780, 'V'),
    (0x17B4, 'X'),
    (0x17B6, 'V'),
    (0x17DE, 'X'),
    (0x17E0, 'V'),
    (0x17EA, 'X'),
    (0x17F0, 'V'),
    (0x17FA, 'X'),
    (0x1800, 'V'),
    (0x1806, 'X'),
    (0x1807, 'V'),
    (0x180B, 'I'),
    (0x180E, 'X'),
    (0x1810, 'V'),
    (0x181A, 'X'),
    (0x1820, 'V'),
    (0x1879, 'X'),
    (0x1880, 'V'),
    (0x18AB, 'X'),
    (0x18B0, 'V'),
    (0x18F6, 'X'),
    (0x1900, 'V'),
    (0x191F, 'X'),
    (0x1920, 'V'),
    (0x192C, 'X'),
    (0x1930, 'V'),
    (0x193C, 'X'),
    (0x1940, 'V'),
    (0x1941, 'X'),
    (0x1944, 'V'),
    (0x196E, 'X'),
    (0x1970, 'V'),
    (0x1975, 'X'),
    (0x1980, 'V'),
    (0x19AC, 'X'),
    (0x19B0, 'V'),
    (0x19CA, 'X'),
    (0x19D0, 'V'),
    (0x19DB, 'X'),
    (0x19DE, 'V'),
    (0x1A1C, 'X'),
    (0x1A1E, 'V'),
    (0x1A5F, 'X'),
    (0x1A60, 'V'),
    (0x1A7D, 'X'),
    (0x1A7F, 'V'),
    (0x1A8A, 'X'),
    (0x1A90, 'V'),
    (0x1A9A, 'X'),
    (0x1AA0, 'V'),
    (0x1AAE, 'X'),
    (0x1AB0, 'V'),
    (0x1AC1, 'X'),
    (0x1B00, 'V'),
    (0x1B4C, 'X'),
    (0x1B50, 'V'),
    (0x1B7D, 'X'),
    (0x1B80, 'V'),
    (0x1BF4, 'X'),
    (0x1BFC, 'V'),
    (0x1C38, 'X'),
    (0x1C3B, 'V'),
    (0x1C4A, 'X'),
    (0x1C4D, 'V'),
    ]

def _seg_15():
    return [
    (0x1C80, 'M', u''),
    (0x1C81, 'M', u''),
    (0x1C82, 'M', u''),
    (0x1C83, 'M', u''),
    (0x1C84, 'M', u''),
    (0x1C86, 'M', u''),
    (0x1C87, 'M', u''),
    (0x1C88, 'M', u''),
    (0x1C89, 'X'),
    (0x1C90, 'M', u''),
    (0x1C91, 'M', u''),
    (0x1C92, 'M', u''),
    (0x1C93, 'M', u''),
    (0x1C94, 'M', u''),
    (0x1C95, 'M', u''),
    (0x1C96, 'M', u''),
    (0x1C97, 'M', u''),
    (0x1C98, 'M', u''),
    (0x1C99, 'M', u''),
    (0x1C9A, 'M', u''),
    (0x1C9B, 'M', u''),
    (0x1C9C, 'M', u''),
    (0x1C9D, 'M', u''),
    (0x1C9E, 'M', u''),
    (0x1C9F, 'M', u''),
    (0x1CA0, 'M', u''),
    (0x1CA1, 'M', u''),
    (0x1CA2, 'M', u''),
    (0x1CA3, 'M', u''),
    (0x1CA4, 'M', u''),
    (0x1CA5, 'M', u''),
    (0x1CA6, 'M', u''),
    (0x1CA7, 'M', u''),
    (0x1CA8, 'M', u''),
    (0x1CA9, 'M', u''),
    (0x1CAA, 'M', u''),
    (0x1CAB, 'M', u''),
    (0x1CAC, 'M', u''),
    (0x1CAD, 'M', u''),
    (0x1CAE, 'M', u''),
    (0x1CAF, 'M', u''),
    (0x1CB0, 'M', u''),
    (0x1CB1, 'M', u''),
    (0x1CB2, 'M', u''),
    (0x1CB3, 'M', u''),
    (0x1CB4, 'M', u''),
    (0x1CB5, 'M', u''),
    (0x1CB6, 'M', u''),
    (0x1CB7, 'M', u''),
    (0x1CB8, 'M', u''),
    (0x1CB9, 'M', u''),
    (0x1CBA, 'M', u''),
    (0x1CBB, 'X'),
    (0x1CBD, 'M', u''),
    (0x1CBE, 'M', u''),
    (0x1CBF, 'M', u''),
    (0x1CC0, 'V'),
    (0x1CC8, 'X'),
    (0x1CD0, 'V'),
    (0x1CFB, 'X'),
    (0x1D00, 'V'),
    (0x1D2C, 'M', u'a'),
    (0x1D2D, 'M', u''),
    (0x1D2E, 'M', u'b'),
    (0x1D2F, 'V'),
    (0x1D30, 'M', u'd'),
    (0x1D31, 'M', u'e'),
    (0x1D32, 'M', u''),
    (0x1D33, 'M', u'g'),
    (0x1D34, 'M', u'h'),
    (0x1D35, 'M', u'i'),
    (0x1D36, 'M', u'j'),
    (0x1D37, 'M', u'k'),
    (0x1D38, 'M', u'l'),
    (0x1D39, 'M', u'm'),
    (0x1D3A, 'M', u'n'),
    (0x1D3B, 'V'),
    (0x1D3C, 'M', u'o'),
    (0x1D3D, 'M', u''),
    (0x1D3E, 'M', u'p'),
    (0x1D3F, 'M', u'r'),
    (0x1D40, 'M', u't'),
    (0x1D41, 'M', u'u'),
    (0x1D42, 'M', u'w'),
    (0x1D43, 'M', u'a'),
    (0x1D44, 'M', u''),
    (0x1D45, 'M', u''),
    (0x1D46, 'M', u''),
    (0x1D47, 'M', u'b'),
    (0x1D48, 'M', u'd'),
    (0x1D49, 'M', u'e'),
    (0x1D4A, 'M', u''),
    (0x1D4B, 'M', u''),
    (0x1D4C, 'M', u''),
    (0x1D4D, 'M', u'g'),
    (0x1D4E, 'V'),
    (0x1D4F, 'M', u'k'),
    (0x1D50, 'M', u'm'),
    (0x1D51, 'M', u''),
    (0x1D52, 'M', u'o'),
    ]

def _seg_16():
    return [
    (0x1D53, 'M', u''),
    (0x1D54, 'M', u''),
    (0x1D55, 'M', u''),
    (0x1D56, 'M', u'p'),
    (0x1D57, 'M', u't'),
    (0x1D58, 'M', u'u'),
    (0x1D59, 'M', u''),
    (0x1D5A, 'M', u''),
    (0x1D5B, 'M', u'v'),
    (0x1D5C, 'M', u''),
    (0x1D5D, 'M', u''),
    (0x1D5E, 'M', u''),
    (0x1D5F, 'M', u''),
    (0x1D60, 'M', u''),
    (0x1D61, 'M', u''),
    (0x1D62, 'M', u'i'),
    (0x1D63, 'M', u'r'),
    (0x1D64, 'M', u'u'),
    (0x1D65, 'M', u'v'),
    (0x1D66, 'M', u''),
    (0x1D67, 'M', u''),
    (0x1D68, 'M', u''),
    (0x1D69, 'M', u''),
    (0x1D6A, 'M', u''),
    (0x1D6B, 'V'),
    (0x1D78, 'M', u''),
    (0x1D79, 'V'),
    (0x1D9B, 'M', u''),
    (0x1D9C, 'M', u'c'),
    (0x1D9D, 'M', u''),
    (0x1D9E, 'M', u''),
    (0x1D9F, 'M', u''),
    (0x1DA0, 'M', u'f'),
    (0x1DA1, 'M', u''),
    (0x1DA2, 'M', u''),
    (0x1DA3, 'M', u''),
    (0x1DA4, 'M', u''),
    (0x1DA5, 'M', u''),
    (0x1DA6, 'M', u''),
    (0x1DA7, 'M', u''),
    (0x1DA8, 'M', u''),
    (0x1DA9, 'M', u''),
    (0x1DAA, 'M', u''),
    (0x1DAB, 'M', u''),
    (0x1DAC, 'M', u''),
    (0x1DAD, 'M', u''),
    (0x1DAE, 'M', u''),
    (0x1DAF, 'M', u''),
    (0x1DB0, 'M', u''),
    (0x1DB1, 'M', u''),
    (0x1DB2, 'M', u''),
    (0x1DB3, 'M', u''),
    (0x1DB4, 'M', u''),
    (0x1DB5, 'M', u''),
    (0x1DB6, 'M', u''),
    (0x1DB7, 'M', u''),
    (0x1DB8, 'M', u''),
    (0x1DB9, 'M', u''),
    (0x1DBA, 'M', u''),
    (0x1DBB, 'M', u'z'),
    (0x1DBC, 'M', u''),
    (0x1DBD, 'M', u''),
    (0x1DBE, 'M', u''),
    (0x1DBF, 'M', u''),
    (0x1DC0, 'V'),
    (0x1DFA, 'X'),
    (0x1DFB, 'V'),
    (0x1E00, 'M', u''),
    (0x1E01, 'V'),
    (0x1E02, 'M', u''),
    (0x1E03, 'V'),
    (0x1E04, 'M', u''),
    (0x1E05, 'V'),
    (0x1E06, 'M', u''),
    (0x1E07, 'V'),
    (0x1E08, 'M', u''),
    (0x1E09, 'V'),
    (0x1E0A, 'M', u''),
    (0x1E0B, 'V'),
    (0x1E0C, 'M', u''),
    (0x1E0D, 'V'),
    (0x1E0E, 'M', u''),
    (0x1E0F, 'V'),
    (0x1E10, 'M', u''),
    (0x1E11, 'V'),
    (0x1E12, 'M', u''),
    (0x1E13, 'V'),
    (0x1E14, 'M', u''),
    (0x1E15, 'V'),
    (0x1E16, 'M', u''),
    (0x1E17, 'V'),
    (0x1E18, 'M', u''),
    (0x1E19, 'V'),
    (0x1E1A, 'M', u''),
    (0x1E1B, 'V'),
    (0x1E1C, 'M', u''),
    (0x1E1D, 'V'),
    (0x1E1E, 'M', u''),
    (0x1E1F, 'V'),
    (0x1E20, 'M', u''),
    ]

def _seg_17():
    return [
    (0x1E21, 'V'),
    (0x1E22, 'M', u''),
    (0x1E23, 'V'),
    (0x1E24, 'M', u''),
    (0x1E25, 'V'),
    (0x1E26, 'M', u''),
    (0x1E27, 'V'),
    (0x1E28, 'M', u''),
    (0x1E29, 'V'),
    (0x1E2A, 'M', u''),
    (0x1E2B, 'V'),
    (0x1E2C, 'M', u''),
    (0x1E2D, 'V'),
    (0x1E2E, 'M', u''),
    (0x1E2F, 'V'),
    (0x1E30, 'M', u''),
    (0x1E31, 'V'),
    (0x1E32, 'M', u''),
    (0x1E33, 'V'),
    (0x1E34, 'M', u''),
    (0x1E35, 'V'),
    (0x1E36, 'M', u''),
    (0x1E37, 'V'),
    (0x1E38, 'M', u''),
    (0x1E39, 'V'),
    (0x1E3A, 'M', u''),
    (0x1E3B, 'V'),
    (0x1E3C, 'M', u''),
    (0x1E3D, 'V'),
    (0x1E3E, 'M', u''),
    (0x1E3F, 'V'),
    (0x1E40, 'M', u''),
    (0x1E41, 'V'),
    (0x1E42, 'M', u''),
    (0x1E43, 'V'),
    (0x1E44, 'M', u''),
    (0x1E45, 'V'),
    (0x1E46, 'M', u''),
    (0x1E47, 'V'),
    (0x1E48, 'M', u''),
    (0x1E49, 'V'),
    (0x1E4A, 'M', u''),
    (0x1E4B, 'V'),
    (0x1E4C, 'M', u''),
    (0x1E4D, 'V'),
    (0x1E4E, 'M', u''),
    (0x1E4F, 'V'),
    (0x1E50, 'M', u''),
    (0x1E51, 'V'),
    (0x1E52, 'M', u''),
    (0x1E53, 'V'),
    (0x1E54, 'M', u''),
    (0x1E55, 'V'),
    (0x1E56, 'M', u''),
    (0x1E57, 'V'),
    (0x1E58, 'M', u''),
    (0x1E59, 'V'),
    (0x1E5A, 'M', u''),
    (0x1E5B, 'V'),
    (0x1E5C, 'M', u''),
    (0x1E5D, 'V'),
    (0x1E5E, 'M', u''),
    (0x1E5F, 'V'),
    (0x1E60, 'M', u''),
    (0x1E61, 'V'),
    (0x1E62, 'M', u''),
    (0x1E63, 'V'),
    (0x1E64, 'M', u''),
    (0x1E65, 'V'),
    (0x1E66, 'M', u''),
    (0x1E67, 'V'),
    (0x1E68, 'M', u''),
    (0x1E69, 'V'),
    (0x1E6A, 'M', u''),
    (0x1E6B, 'V'),
    (0x1E6C, 'M', u''),
    (0x1E6D, 'V'),
    (0x1E6E, 'M', u''),
    (0x1E6F, 'V'),
    (0x1E70, 'M', u''),
    (0x1E71, 'V'),
    (0x1E72, 'M', u''),
    (0x1E73, 'V'),
    (0x1E74, 'M', u''),
    (0x1E75, 'V'),
    (0x1E76, 'M', u''),
    (0x1E77, 'V'),
    (0x1E78, 'M', u''),
    (0x1E79, 'V'),
    (0x1E7A, 'M', u''),
    (0x1E7B, 'V'),
    (0x1E7C, 'M', u''),
    (0x1E7D, 'V'),
    (0x1E7E, 'M', u''),
    (0x1E7F, 'V'),
    (0x1E80, 'M', u''),
    (0x1E81, 'V'),
    (0x1E82, 'M', u''),
    (0x1E83, 'V'),
    (0x1E84, 'M', u''),
    ]

def _seg_18():
    return [
    (0x1E85, 'V'),
    (0x1E86, 'M', u''),
    (0x1E87, 'V'),
    (0x1E88, 'M', u''),
    (0x1E89, 'V'),
    (0x1E8A, 'M', u''),
    (0x1E8B, 'V'),
    (0x1E8C, 'M', u''),
    (0x1E8D, 'V'),
    (0x1E8E, 'M', u''),
    (0x1E8F, 'V'),
    (0x1E90, 'M', u''),
    (0x1E91, 'V'),
    (0x1E92, 'M', u''),
    (0x1E93, 'V'),
    (0x1E94, 'M', u''),
    (0x1E95, 'V'),
    (0x1E9A, 'M', u'a'),
    (0x1E9B, 'M', u''),
    (0x1E9C, 'V'),
    (0x1E9E, 'M', u'ss'),
    (0x1E9F, 'V'),
    (0x1EA0, 'M', u''),
    (0x1EA1, 'V'),
    (0x1EA2, 'M', u''),
    (0x1EA3, 'V'),
    (0x1EA4, 'M', u''),
    (0x1EA5, 'V'),
    (0x1EA6, 'M', u''),
    (0x1EA7, 'V'),
    (0x1EA8, 'M', u''),
    (0x1EA9, 'V'),
    (0x1EAA, 'M', u''),
    (0x1EAB, 'V'),
    (0x1EAC, 'M', u''),
    (0x1EAD, 'V'),
    (0x1EAE, 'M', u''),
    (0x1EAF, 'V'),
    (0x1EB0, 'M', u''),
    (0x1EB1, 'V'),
    (0x1EB2, 'M', u''),
    (0x1EB3, 'V'),
    (0x1EB4, 'M', u''),
    (0x1EB5, 'V'),
    (0x1EB6, 'M', u''),
    (0x1EB7, 'V'),
    (0x1EB8, 'M', u''),
    (0x1EB9, 'V'),
    (0x1EBA, 'M', u''),
    (0x1EBB, 'V'),
    (0x1EBC, 'M', u''),
    (0x1EBD, 'V'),
    (0x1EBE, 'M', u''),
    (0x1EBF, 'V'),
    (0x1EC0, 'M', u''),
    (0x1EC1, 'V'),
    (0x1EC2, 'M', u''),
    (0x1EC3, 'V'),
    (0x1EC4, 'M', u''),
    (0x1EC5, 'V'),
    (0x1EC6, 'M', u''),
    (0x1EC7, 'V'),
    (0x1EC8, 'M', u''),
    (0x1EC9, 'V'),
    (0x1ECA, 'M', u''),
    (0x1ECB, 'V'),
    (0x1ECC, 'M', u''),
    (0x1ECD, 'V'),
    (0x1ECE, 'M', u''),
    (0x1ECF, 'V'),
    (0x1ED0, 'M', u''),
    (0x1ED1, 'V'),
    (0x1ED2, 'M', u''),
    (0x1ED3, 'V'),
    (0x1ED4, 'M', u''),
    (0x1ED5, 'V'),
    (0x1ED6, 'M', u''),
    (0x1ED7, 'V'),
    (0x1ED8, 'M', u''),
    (0x1ED9, 'V'),
    (0x1EDA, 'M', u''),
    (0x1EDB, 'V'),
    (0x1EDC, 'M', u''),
    (0x1EDD, 'V'),
    (0x1EDE, 'M', u''),
    (0x1EDF, 'V'),
    (0x1EE0, 'M', u''),
    (0x1EE1, 'V'),
    (0x1EE2, 'M', u''),
    (0x1EE3, 'V'),
    (0x1EE4, 'M', u''),
    (0x1EE5, 'V'),
    (0x1EE6, 'M', u''),
    (0x1EE7, 'V'),
    (0x1EE8, 'M', u''),
    (0x1EE9, 'V'),
    (0x1EEA, 'M', u''),
    (0x1EEB, 'V'),
    (0x1EEC, 'M', u''),
    (0x1EED, 'V'),
    ]

def _seg_19():
    return [
    (0x1EEE, 'M', u''),
    (0x1EEF, 'V'),
    (0x1EF0, 'M', u''),
    (0x1EF1, 'V'),
    (0x1EF2, 'M', u''),
    (0x1EF3, 'V'),
    (0x1EF4, 'M', u''),
    (0x1EF5, 'V'),
    (0x1EF6, 'M', u''),
    (0x1EF7, 'V'),
    (0x1EF8, 'M', u''),
    (0x1EF9, 'V'),
    (0x1EFA, 'M', u''),
    (0x1EFB, 'V'),
    (0x1EFC, 'M', u''),
    (0x1EFD, 'V'),
    (0x1EFE, 'M', u''),
    (0x1EFF, 'V'),
    (0x1F08, 'M', u''),
    (0x1F09, 'M', u''),
    (0x1F0A, 'M', u''),
    (0x1F0B, 'M', u''),
    (0x1F0C, 'M', u''),
    (0x1F0D, 'M', u''),
    (0x1F0E, 'M', u''),
    (0x1F0F, 'M', u''),
    (0x1F10, 'V'),
    (0x1F16, 'X'),
    (0x1F18, 'M', u''),
    (0x1F19, 'M', u''),
    (0x1F1A, 'M', u''),
    (0x1F1B, 'M', u''),
    (0x1F1C, 'M', u''),
    (0x1F1D, 'M', u''),
    (0x1F1E, 'X'),
    (0x1F20, 'V'),
    (0x1F28, 'M', u''),
    (0x1F29, 'M', u''),
    (0x1F2A, 'M', u''),
    (0x1F2B, 'M', u''),
    (0x1F2C, 'M', u''),
    (0x1F2D, 'M', u''),
    (0x1F2E, 'M', u''),
    (0x1F2F, 'M', u''),
    (0x1F30, 'V'),
    (0x1F38, 'M', u''),
    (0x1F39, 'M', u''),
    (0x1F3A, 'M', u''),
    (0x1F3B, 'M', u''),
    (0x1F3C, 'M', u''),
    (0x1F3D, 'M', u''),
    (0x1F3E, 'M', u''),
    (0x1F3F, 'M', u''),
    (0x1F40, 'V'),
    (0x1F46, 'X'),
    (0x1F48, 'M', u''),
    (0x1F49, 'M', u''),
    (0x1F4A, 'M', u''),
    (0x1F4B, 'M', u''),
    (0x1F4C, 'M', u''),
    (0x1F4D, 'M', u''),
    (0x1F4E, 'X'),
    (0x1F50, 'V'),
    (0x1F58, 'X'),
    (0x1F59, 'M', u''),
    (0x1F5A, 'X'),
    (0x1F5B, 'M', u''),
    (0x1F5C, 'X'),
    (0x1F5D, 'M', u''),
    (0x1F5E, 'X'),
    (0x1F5F, 'M', u''),
    (0x1F60, 'V'),
    (0x1F68, 'M', u''),
    (0x1F69, 'M', u''),
    (0x1F6A, 'M', u''),
    (0x1F6B, 'M', u''),
    (0x1F6C, 'M', u''),
    (0x1F6D, 'M', u''),
    (0x1F6E, 'M', u''),
    (0x1F6F, 'M', u''),
    (0x1F70, 'V'),
    (0x1F71, 'M', u''),
    (0x1F72, 'V'),
    (0x1F73, 'M', u''),
    (0x1F74, 'V'),
    (0x1F75, 'M', u''),
    (0x1F76, 'V'),
    (0x1F77, 'M', u''),
    (0x1F78, 'V'),
    (0x1F79, 'M', u''),
    (0x1F7A, 'V'),
    (0x1F7B, 'M', u''),
    (0x1F7C, 'V'),
    (0x1F7D, 'M', u''),
    (0x1F7E, 'X'),
    (0x1F80, 'M', u''),
    (0x1F81, 'M', u''),
    (0x1F82, 'M', u''),
    (0x1F83, 'M', u''),
    (0x1F84, 'M', u''),
    ]

def _seg_20():
    return [
    (0x1F85, 'M', u''),
    (0x1F86, 'M', u''),
    (0x1F87, 'M', u''),
    (0x1F88, 'M', u''),
    (0x1F89, 'M', u''),
    (0x1F8A, 'M', u''),
    (0x1F8B, 'M', u''),
    (0x1F8C, 'M', u''),
    (0x1F8D, 'M', u''),
    (0x1F8E, 'M', u''),
    (0x1F8F, 'M', u''),
    (0x1F90, 'M', u''),
    (0x1F91, 'M', u''),
    (0x1F92, 'M', u''),
    (0x1F93, 'M', u''),
    (0x1F94, 'M', u''),
    (0x1F95, 'M', u''),
    (0x1F96, 'M', u''),
    (0x1F97, 'M', u''),
    (0x1F98, 'M', u''),
    (0x1F99, 'M', u''),
    (0x1F9A, 'M', u''),
    (0x1F9B, 'M', u''),
    (0x1F9C, 'M', u''),
    (0x1F9D, 'M', u''),
    (0x1F9E, 'M', u''),
    (0x1F9F, 'M', u''),
    (0x1FA0, 'M', u''),
    (0x1FA1, 'M', u''),
    (0x1FA2, 'M', u''),
    (0x1FA3, 'M', u''),
    (0x1FA4, 'M', u''),
    (0x1FA5, 'M', u''),
    (0x1FA6, 'M', u''),
    (0x1FA7, 'M', u''),
    (0x1FA8, 'M', u''),
    (0x1FA9, 'M', u''),
    (0x1FAA, 'M', u''),
    (0x1FAB, 'M', u''),
    (0x1FAC, 'M', u''),
    (0x1FAD, 'M', u''),
    (0x1FAE, 'M', u''),
    (0x1FAF, 'M', u''),
    (0x1FB0, 'V'),
    (0x1FB2, 'M', u''),
    (0x1FB3, 'M', u''),
    (0x1FB4, 'M', u''),
    (0x1FB5, 'X'),
    (0x1FB6, 'V'),
    (0x1FB7, 'M', u''),
    (0x1FB8, 'M', u''),
    (0x1FB9, 'M', u''),
    (0x1FBA, 'M', u''),
    (0x1FBB, 'M', u''),
    (0x1FBC, 'M', u''),
    (0x1FBD, '3', u' '),
    (0x1FBE, 'M', u''),
    (0x1FBF, '3', u' '),
    (0x1FC0, '3', u' '),
    (0x1FC1, '3', u' '),
    (0x1FC2, 'M', u''),
    (0x1FC3, 'M', u''),
    (0x1FC4, 'M', u''),
    (0x1FC5, 'X'),
    (0x1FC6, 'V'),
    (0x1FC7, 'M', u''),
    (0x1FC8, 'M', u''),
    (0x1FC9, 'M', u''),
    (0x1FCA, 'M', u''),
    (0x1FCB, 'M', u''),
    (0x1FCC, 'M', u''),
    (0x1FCD, '3', u' '),
    (0x1FCE, '3', u' '),
    (0x1FCF, '3', u' '),
    (0x1FD0, 'V'),
    (0x1FD3, 'M', u''),
    (0x1FD4, 'X'),
    (0x1FD6, 'V'),
    (0x1FD8, 'M', u''),
    (0x1FD9, 'M', u''),
    (0x1FDA, 'M', u''),
    (0x1FDB, 'M', u''),
    (0x1FDC, 'X'),
    (0x1FDD, '3', u' '),
    (0x1FDE, '3', u' '),
    (0x1FDF, '3', u' '),
    (0x1FE0, 'V'),
    (0x1FE3, 'M', u''),
    (0x1FE4, 'V'),
    (0x1FE8, 'M', u''),
    (0x1FE9, 'M', u''),
    (0x1FEA, 'M', u''),
    (0x1FEB, 'M', u''),
    (0x1FEC, 'M', u''),
    (0x1FED, '3', u' '),
    (0x1FEE, '3', u' '),
    (0x1FEF, '3', u'`'),
    (0x1FF0, 'X'),
    (0x1FF2, 'M', u''),
    (0x1FF3, 'M', u''),
    ]

def _seg_21():
    return [
    (0x1FF4, 'M', u''),
    (0x1FF5, 'X'),
    (0x1FF6, 'V'),
    (0x1FF7, 'M', u''),
    (0x1FF8, 'M', u''),
    (0x1FF9, 'M', u''),
    (0x1FFA, 'M', u''),
    (0x1FFB, 'M', u''),
    (0x1FFC, 'M', u''),
    (0x1FFD, '3', u' '),
    (0x1FFE, '3', u' '),
    (0x1FFF, 'X'),
    (0x2000, '3', u' '),
    (0x200B, 'I'),
    (0x200C, 'D', u''),
    (0x200E, 'X'),
    (0x2010, 'V'),
    (0x2011, 'M', u''),
    (0x2012, 'V'),
    (0x2017, '3', u' '),
    (0x2018, 'V'),
    (0x2024, 'X'),
    (0x2027, 'V'),
    (0x2028, 'X'),
    (0x202F, '3', u' '),
    (0x2030, 'V'),
    (0x2033, 'M', u''),
    (0x2034, 'M', u''),
    (0x2035, 'V'),
    (0x2036, 'M', u''),
    (0x2037, 'M', u''),
    (0x2038, 'V'),
    (0x203C, '3', u'!!'),
    (0x203D, 'V'),
    (0x203E, '3', u' '),
    (0x203F, 'V'),
    (0x2047, '3', u'??'),
    (0x2048, '3', u'?!'),
    (0x2049, '3', u'!?'),
    (0x204A, 'V'),
    (0x2057, 'M', u''),
    (0x2058, 'V'),
    (0x205F, '3', u' '),
    (0x2060, 'I'),
    (0x2061, 'X'),
    (0x2064, 'I'),
    (0x2065, 'X'),
    (0x2070, 'M', u'0'),
    (0x2071, 'M', u'i'),
    (0x2072, 'X'),
    (0x2074, 'M', u'4'),
    (0x2075, 'M', u'5'),
    (0x2076, 'M', u'6'),
    (0x2077, 'M', u'7'),
    (0x2078, 'M', u'8'),
    (0x2079, 'M', u'9'),
    (0x207A, '3', u'+'),
    (0x207B, 'M', u''),
    (0x207C, '3', u'='),
    (0x207D, '3', u'('),
    (0x207E, '3', u')'),
    (0x207F, 'M', u'n'),
    (0x2080, 'M', u'0'),
    (0x2081, 'M', u'1'),
    (0x2082, 'M', u'2'),
    (0x2083, 'M', u'3'),
    (0x2084, 'M', u'4'),
    (0x2085, 'M', u'5'),
    (0x2086, 'M', u'6'),
    (0x2087, 'M', u'7'),
    (0x2088, 'M', u'8'),
    (0x2089, 'M', u'9'),
    (0x208A, '3', u'+'),
    (0x208B, 'M', u''),
    (0x208C, '3', u'='),
    (0x208D, '3', u'('),
    (0x208E, '3', u')'),
    (0x208F, 'X'),
    (0x2090, 'M', u'a'),
    (0x2091, 'M', u'e'),
    (0x2092, 'M', u'o'),
    (0x2093, 'M', u'x'),
    (0x2094, 'M', u''),
    (0x2095, 'M', u'h'),
    (0x2096, 'M', u'k'),
    (0x2097, 'M', u'l'),
    (0x2098, 'M', u'm'),
    (0x2099, 'M', u'n'),
    (0x209A, 'M', u'p'),
    (0x209B, 'M', u's'),
    (0x209C, 'M', u't'),
    (0x209D, 'X'),
    (0x20A0, 'V'),
    (0x20A8, 'M', u'rs'),
    (0x20A9, 'V'),
    (0x20C0, 'X'),
    (0x20D0, 'V'),
    (0x20F1, 'X'),
    (0x2100, '3', u'a/c'),
    (0x2101, '3', u'a/s'),
    ]

def _seg_22():
    return [
    (0x2102, 'M', u'c'),
    (0x2103, 'M', u'c'),
    (0x2104, 'V'),
    (0x2105, '3', u'c/o'),
    (0x2106, '3', u'c/u'),
    (0x2107, 'M', u''),
    (0x2108, 'V'),
    (0x2109, 'M', u'f'),
    (0x210A, 'M', u'g'),
    (0x210B, 'M', u'h'),
    (0x210F, 'M', u''),
    (0x2110, 'M', u'i'),
    (0x2112, 'M', u'l'),
    (0x2114, 'V'),
    (0x2115, 'M', u'n'),
    (0x2116, 'M', u'no'),
    (0x2117, 'V'),
    (0x2119, 'M', u'p'),
    (0x211A, 'M', u'q'),
    (0x211B, 'M', u'r'),
    (0x211E, 'V'),
    (0x2120, 'M', u'sm'),
    (0x2121, 'M', u'tel'),
    (0x2122, 'M', u'tm'),
    (0x2123, 'V'),
    (0x2124, 'M', u'z'),
    (0x2125, 'V'),
    (0x2126, 'M', u''),
    (0x2127, 'V'),
    (0x2128, 'M', u'z'),
    (0x2129, 'V'),
    (0x212A, 'M', u'k'),
    (0x212B, 'M', u''),
    (0x212C, 'M', u'b'),
    (0x212D, 'M', u'c'),
    (0x212E, 'V'),
    (0x212F, 'M', u'e'),
    (0x2131, 'M', u'f'),
    (0x2132, 'X'),
    (0x2133, 'M', u'm'),
    (0x2134, 'M', u'o'),
    (0x2135, 'M', u''),
    (0x2136, 'M', u''),
    (0x2137, 'M', u''),
    (0x2138, 'M', u''),
    (0x2139, 'M', u'i'),
    (0x213A, 'V'),
    (0x213B, 'M', u'fax'),
    (0x213C, 'M', u''),
    (0x213D, 'M', u''),
    (0x213F, 'M', u''),
    (0x2140, 'M', u''),
    (0x2141, 'V'),
    (0x2145, 'M', u'd'),
    (0x2147, 'M', u'e'),
    (0x2148, 'M', u'i'),
    (0x2149, 'M', u'j'),
    (0x214A, 'V'),
    (0x2150, 'M', u'17'),
    (0x2151, 'M', u'19'),
    (0x2152, 'M', u'110'),
    (0x2153, 'M', u'13'),
    (0x2154, 'M', u'23'),
    (0x2155, 'M', u'15'),
    (0x2156, 'M', u'25'),
    (0x2157, 'M', u'35'),
    (0x2158, 'M', u'45'),
    (0x2159, 'M', u'16'),
    (0x215A, 'M', u'56'),
    (0x215B, 'M', u'18'),
    (0x215C, 'M', u'38'),
    (0x215D, 'M', u'58'),
    (0x215E, 'M', u'78'),
    (0x215F, 'M', u'1'),
    (0x2160, 'M', u'i'),
    (0x2161, 'M', u'ii'),
    (0x2162, 'M', u'iii'),
    (0x2163, 'M', u'iv'),
    (0x2164, 'M', u'v'),
    (0x2165, 'M', u'vi'),
    (0x2166, 'M', u'vii'),
    (0x2167, 'M', u'viii'),
    (0x2168, 'M', u'ix'),
    (0x2169, 'M', u'x'),
    (0x216A, 'M', u'xi'),
    (0x216B, 'M', u'xii'),
    (0x216C, 'M', u'l'),
    (0x216D, 'M', u'c'),
    (0x216E, 'M', u'd'),
    (0x216F, 'M', u'm'),
    (0x2170, 'M', u'i'),
    (0x2171, 'M', u'ii'),
    (0x2172, 'M', u'iii'),
    (0x2173, 'M', u'iv'),
    (0x2174, 'M', u'v'),
    (0x2175, 'M', u'vi'),
    (0x2176, 'M', u'vii'),
    (0x2177, 'M', u'viii'),
    (0x2178, 'M', u'ix'),
    (0x2179, 'M', u'x'),
    ]

def _seg_23():
    return [
    (0x217A, 'M', u'xi'),
    (0x217B, 'M', u'xii'),
    (0x217C, 'M', u'l'),
    (0x217D, 'M', u'c'),
    (0x217E, 'M', u'd'),
    (0x217F, 'M', u'm'),
    (0x2180, 'V'),
    (0x2183, 'X'),
    (0x2184, 'V'),
    (0x2189, 'M', u'03'),
    (0x218A, 'V'),
    (0x218C, 'X'),
    (0x2190, 'V'),
    (0x222C, 'M', u''),
    (0x222D, 'M', u''),
    (0x222E, 'V'),
    (0x222F, 'M', u''),
    (0x2230, 'M', u''),
    (0x2231, 'V'),
    (0x2260, '3'),
    (0x2261, 'V'),
    (0x226E, '3'),
    (0x2270, 'V'),
    (0x2329, 'M', u''),
    (0x232A, 'M', u''),
    (0x232B, 'V'),
    (0x2427, 'X'),
    (0x2440, 'V'),
    (0x244B, 'X'),
    (0x2460, 'M', u'1'),
    (0x2461, 'M', u'2'),
    (0x2462, 'M', u'3'),
    (0x2463, 'M', u'4'),
    (0x2464, 'M', u'5'),
    (0x2465, 'M', u'6'),
    (0x2466, 'M', u'7'),
    (0x2467, 'M', u'8'),
    (0x2468, 'M', u'9'),
    (0x2469, 'M', u'10'),
    (0x246A, 'M', u'11'),
    (0x246B, 'M', u'12'),
    (0x246C, 'M', u'13'),
    (0x246D, 'M', u'14'),
    (0x246E, 'M', u'15'),
    (0x246F, 'M', u'16'),
    (0x2470, 'M', u'17'),
    (0x2471, 'M', u'18'),
    (0x2472, 'M', u'19'),
    (0x2473, 'M', u'20'),
    (0x2474, '3', u'(1)'),
    (0x2475, '3', u'(2)'),
    (0x2476, '3', u'(3)'),
    (0x2477, '3', u'(4)'),
    (0x2478, '3', u'(5)'),
    (0x2479, '3', u'(6)'),
    (0x247A, '3', u'(7)'),
    (0x247B, '3', u'(8)'),
    (0x247C, '3', u'(9)'),
    (0x247D, '3', u'(10)'),
    (0x247E, '3', u'(11)'),
    (0x247F, '3', u'(12)'),
    (0x2480, '3', u'(13)'),
    (0x2481, '3', u'(14)'),
    (0x2482, '3', u'(15)'),
    (0x2483, '3', u'(16)'),
    (0x2484, '3', u'(17)'),
    (0x2485, '3', u'(18)'),
    (0x2486, '3', u'(19)'),
    (0x2487, '3', u'(20)'),
    (0x2488, 'X'),
    (0x249C, '3', u'(a)'),
    (0x249D, '3', u'(b)'),
    (0x249E, '3', u'(c)'),
    (0x249F, '3', u'(d)'),
    (0x24A0, '3', u'(e)'),
    (0x24A1, '3', u'(f)'),
    (0x24A2, '3', u'(g)'),
    (0x24A3, '3', u'(h)'),
    (0x24A4, '3', u'(i)'),
    (0x24A5, '3', u'(j)'),
    (0x24A6, '3', u'(k)'),
    (0x24A7, '3', u'(l)'),
    (0x24A8, '3', u'(m)'),
    (0x24A9, '3', u'(n)'),
    (0x24AA, '3', u'(o)'),
    (0x24AB, '3', u'(p)'),
    (0x24AC, '3', u'(q)'),
    (0x24AD, '3', u'(r)'),
    (0x24AE, '3', u'(s)'),
    (0x24AF, '3', u'(t)'),
    (0x24B0, '3', u'(u)'),
    (0x24B1, '3', u'(v)'),
    (0x24B2, '3', u'(w)'),
    (0x24B3, '3', u'(x)'),
    (0x24B4, '3', u'(y)'),
    (0x24B5, '3', u'(z)'),
    (0x24B6, 'M', u'a'),
    (0x24B7, 'M', u'b'),
    (0x24B8, 'M', u'c'),
    (0x24B9, 'M', u'd'),
    ]

def _seg_24():
    return [
    (0x24BA, 'M', u'e'),
    (0x24BB, 'M', u'f'),
    (0x24BC, 'M', u'g'),
    (0x24BD, 'M', u'h'),
    (0x24BE, 'M', u'i'),
    (0x24BF, 'M', u'j'),
    (0x24C0, 'M', u'k'),
    (0x24C1, 'M', u'l'),
    (0x24C2, 'M', u'm'),
    (0x24C3, 'M', u'n'),
    (0x24C4, 'M', u'o'),
    (0x24C5, 'M', u'p'),
    (0x24C6, 'M', u'q'),
    (0x24C7, 'M', u'r'),
    (0x24C8, 'M', u's'),
    (0x24C9, 'M', u't'),
    (0x24CA, 'M', u'u'),
    (0x24CB, 'M', u'v'),
    (0x24CC, 'M', u'w'),
    (0x24CD, 'M', u'x'),
    (0x24CE, 'M', u'y'),
    (0x24CF, 'M', u'z'),
    (0x24D0, 'M', u'a'),
    (0x24D1, 'M', u'b'),
    (0x24D2, 'M', u'c'),
    (0x24D3, 'M', u'd'),
    (0x24D4, 'M', u'e'),
    (0x24D5, 'M', u'f'),
    (0x24D6, 'M', u'g'),
    (0x24D7, 'M', u'h'),
    (0x24D8, 'M', u'i'),
    (0x24D9, 'M', u'j'),
    (0x24DA, 'M', u'k'),
    (0x24DB, 'M', u'l'),
    (0x24DC, 'M', u'm'),
    (0x24DD, 'M', u'n'),
    (0x24DE, 'M', u'o'),
    (0x24DF, 'M', u'p'),
    (0x24E0, 'M', u'q'),
    (0x24E1, 'M', u'r'),
    (0x24E2, 'M', u's'),
    (0x24E3, 'M', u't'),
    (0x24E4, 'M', u'u'),
    (0x24E5, 'M', u'v'),
    (0x24E6, 'M', u'w'),
    (0x24E7, 'M', u'x'),
    (0x24E8, 'M', u'y'),
    (0x24E9, 'M', u'z'),
    (0x24EA, 'M', u'0'),
    (0x24EB, 'V'),
    (0x2A0C, 'M', u''),
    (0x2A0D, 'V'),
    (0x2A74, '3', u'::='),
    (0x2A75, '3', u'=='),
    (0x2A76, '3', u'==='),
    (0x2A77, 'V'),
    (0x2ADC, 'M', u''),
    (0x2ADD, 'V'),
    (0x2B74, 'X'),
    (0x2B76, 'V'),
    (0x2B96, 'X'),
    (0x2B97, 'V'),
    (0x2C00, 'M', u''),
    (0x2C01, 'M', u''),
    (0x2C02, 'M', u''),
    (0x2C03, 'M', u''),
    (0x2C04, 'M', u''),
    (0x2C05, 'M', u''),
    (0x2C06, 'M', u''),
    (0x2C07, 'M', u''),
    (0x2C08, 'M', u''),
    (0x2C09, 'M', u''),
    (0x2C0A, 'M', u''),
    (0x2C0B, 'M', u''),
    (0x2C0C, 'M', u''),
    (0x2C0D, 'M', u''),
    (0x2C0E, 'M', u''),
    (0x2C0F, 'M', u''),
    (0x2C10, 'M', u''),
    (0x2C11, 'M', u''),
    (0x2C12, 'M', u''),
    (0x2C13, 'M', u''),
    (0x2C14, 'M', u''),
    (0x2C15, 'M', u''),
    (0x2C16, 'M', u''),
    (0x2C17, 'M', u''),
    (0x2C18, 'M', u''),
    (0x2C19, 'M', u''),
    (0x2C1A, 'M', u''),
    (0x2C1B, 'M', u''),
    (0x2C1C, 'M', u''),
    (0x2C1D, 'M', u''),
    (0x2C1E, 'M', u''),
    (0x2C1F, 'M', u''),
    (0x2C20, 'M', u''),
    (0x2C21, 'M', u''),
    (0x2C22, 'M', u''),
    (0x2C23, 'M', u''),
    (0x2C24, 'M', u''),
    (0x2C25, 'M', u''),
    ]

def _seg_25():
    return [
    (0x2C26, 'M', u''),
    (0x2C27, 'M', u''),
    (0x2C28, 'M', u''),
    (0x2C29, 'M', u''),
    (0x2C2A, 'M', u''),
    (0x2C2B, 'M', u''),
    (0x2C2C, 'M', u''),
    (0x2C2D, 'M', u''),
    (0x2C2E, 'M', u''),
    (0x2C2F, 'X'),
    (0x2C30, 'V'),
    (0x2C5F, 'X'),
    (0x2C60, 'M', u''),
    (0x2C61, 'V'),
    (0x2C62, 'M', u''),
    (0x2C63, 'M', u''),
    (0x2C64, 'M', u''),
    (0x2C65, 'V'),
    (0x2C67, 'M', u''),
    (0x2C68, 'V'),
    (0x2C69, 'M', u''),
    (0x2C6A, 'V'),
    (0x2C6B, 'M', u''),
    (0x2C6C, 'V'),
    (0x2C6D, 'M', u''),
    (0x2C6E, 'M', u''),
    (0x2C6F, 'M', u''),
    (0x2C70, 'M', u''),
    (0x2C71, 'V'),
    (0x2C72, 'M', u''),
    (0x2C73, 'V'),
    (0x2C75, 'M', u''),
    (0x2C76, 'V'),
    (0x2C7C, 'M', u'j'),
    (0x2C7D, 'M', u'v'),
    (0x2C7E, 'M', u''),
    (0x2C7F, 'M', u''),
    (0x2C80, 'M', u''),
    (0x2C81, 'V'),
    (0x2C82, 'M', u''),
    (0x2C83, 'V'),
    (0x2C84, 'M', u''),
    (0x2C85, 'V'),
    (0x2C86, 'M', u''),
    (0x2C87, 'V'),
    (0x2C88, 'M', u''),
    (0x2C89, 'V'),
    (0x2C8A, 'M', u''),
    (0x2C8B, 'V'),
    (0x2C8C, 'M', u''),
    (0x2C8D, 'V'),
    (0x2C8E, 'M', u''),
    (0x2C8F, 'V'),
    (0x2C90, 'M', u''),
    (0x2C91, 'V'),
    (0x2C92, 'M', u''),
    (0x2C93, 'V'),
    (0x2C94, 'M', u''),
    (0x2C95, 'V'),
    (0x2C96, 'M', u''),
    (0x2C97, 'V'),
    (0x2C98, 'M', u''),
    (0x2C99, 'V'),
    (0x2C9A, 'M', u''),
    (0x2C9B, 'V'),
    (0x2C9C, 'M', u''),
    (0x2C9D, 'V'),
    (0x2C9E, 'M', u''),
    (0x2C9F, 'V'),
    (0x2CA0, 'M', u''),
    (0x2CA1, 'V'),
    (0x2CA2, 'M', u''),
    (0x2CA3, 'V'),
    (0x2CA4, 'M', u''),
    (0x2CA5, 'V'),
    (0x2CA6, 'M', u''),
    (0x2CA7, 'V'),
    (0x2CA8, 'M', u''),
    (0x2CA9, 'V'),
    (0x2CAA, 'M', u''),
    (0x2CAB, 'V'),
    (0x2CAC, 'M', u''),
    (0x2CAD, 'V'),
    (0x2CAE, 'M', u''),
    (0x2CAF, 'V'),
    (0x2CB0, 'M', u''),
    (0x2CB1, 'V'),
    (0x2CB2, 'M', u''),
    (0x2CB3, 'V'),
    (0x2CB4, 'M', u''),
    (0x2CB5, 'V'),
    (0x2CB6, 'M', u''),
    (0x2CB7, 'V'),
    (0x2CB8, 'M', u''),
    (0x2CB9, 'V'),
    (0x2CBA, 'M', u''),
    (0x2CBB, 'V'),
    (0x2CBC, 'M', u''),
    (0x2CBD, 'V'),
    (0x2CBE, 'M', u''),
    ]

def _seg_26():
    return [
    (0x2CBF, 'V'),
    (0x2CC0, 'M', u''),
    (0x2CC1, 'V'),
    (0x2CC2, 'M', u''),
    (0x2CC3, 'V'),
    (0x2CC4, 'M', u''),
    (0x2CC5, 'V'),
    (0x2CC6, 'M', u''),
    (0x2CC7, 'V'),
    (0x2CC8, 'M', u''),
    (0x2CC9, 'V'),
    (0x2CCA, 'M', u''),
    (0x2CCB, 'V'),
    (0x2CCC, 'M', u''),
    (0x2CCD, 'V'),
    (0x2CCE, 'M', u''),
    (0x2CCF, 'V'),
    (0x2CD0, 'M', u''),
    (0x2CD1, 'V'),
    (0x2CD2, 'M', u''),
    (0x2CD3, 'V'),
    (0x2CD4, 'M', u''),
    (0x2CD5, 'V'),
    (0x2CD6, 'M', u''),
    (0x2CD7, 'V'),
    (0x2CD8, 'M', u''),
    (0x2CD9, 'V'),
    (0x2CDA, 'M', u''),
    (0x2CDB, 'V'),
    (0x2CDC, 'M', u''),
    (0x2CDD, 'V'),
    (0x2CDE, 'M', u''),
    (0x2CDF, 'V'),
    (0x2CE0, 'M', u''),
    (0x2CE1, 'V'),
    (0x2CE2, 'M', u''),
    (0x2CE3, 'V'),
    (0x2CEB, 'M', u''),
    (0x2CEC, 'V'),
    (0x2CED, 'M', u''),
    (0x2CEE, 'V'),
    (0x2CF2, 'M', u''),
    (0x2CF3, 'V'),
    (0x2CF4, 'X'),
    (0x2CF9, 'V'),
    (0x2D26, 'X'),
    (0x2D27, 'V'),
    (0x2D28, 'X'),
    (0x2D2D, 'V'),
    (0x2D2E, 'X'),
    (0x2D30, 'V'),
    (0x2D68, 'X'),
    (0x2D6F, 'M', u''),
    (0x2D70, 'V'),
    (0x2D71, 'X'),
    (0x2D7F, 'V'),
    (0x2D97, 'X'),
    (0x2DA0, 'V'),
    (0x2DA7, 'X'),
    (0x2DA8, 'V'),
    (0x2DAF, 'X'),
    (0x2DB0, 'V'),
    (0x2DB7, 'X'),
    (0x2DB8, 'V'),
    (0x2DBF, 'X'),
    (0x2DC0, 'V'),
    (0x2DC7, 'X'),
    (0x2DC8, 'V'),
    (0x2DCF, 'X'),
    (0x2DD0, 'V'),
    (0x2DD7, 'X'),
    (0x2DD8, 'V'),
    (0x2DDF, 'X'),
    (0x2DE0, 'V'),
    (0x2E53, 'X'),
    (0x2E80, 'V'),
    (0x2E9A, 'X'),
    (0x2E9B, 'V'),
    (0x2E9F, 'M', u''),
    (0x2EA0, 'V'),
    (0x2EF3, 'M', u''),
    (0x2EF4, 'X'),
    (0x2F00, 'M', u''),
    (0x2F01, 'M', u''),
    (0x2F02, 'M', u''),
    (0x2F03, 'M', u''),
    (0x2F04, 'M', u''),
    (0x2F05, 'M', u''),
    (0x2F06, 'M', u''),
    (0x2F07, 'M', u''),
    (0x2F08, 'M', u''),
    (0x2F09, 'M', u''),
    (0x2F0A, 'M', u''),
    (0x2F0B, 'M', u''),
    (0x2F0C, 'M', u''),
    (0x2F0D, 'M', u''),
    (0x2F0E, 'M', u''),
    (0x2F0F, 'M', u''),
    (0x2F10, 'M', u''),
    (0x2F11, 'M', u''),
    ]

def _seg_27():
    return [
    (0x2F12, 'M', u''),
    (0x2F13, 'M', u''),
    (0x2F14, 'M', u''),
    (0x2F15, 'M', u''),
    (0x2F16, 'M', u''),
    (0x2F17, 'M', u''),
    (0x2F18, 'M', u''),
    (0x2F19, 'M', u''),
    (0x2F1A, 'M', u''),
    (0x2F1B, 'M', u''),
    (0x2F1C, 'M', u''),
    (0x2F1D, 'M', u''),
    (0x2F1E, 'M', u''),
    (0x2F1F, 'M', u''),
    (0x2F20, 'M', u''),
    (0x2F21, 'M', u''),
    (0x2F22, 'M', u''),
    (0x2F23, 'M', u''),
    (0x2F24, 'M', u''),
    (0x2F25, 'M', u''),
    (0x2F26, 'M', u''),
    (0x2F27, 'M', u''),
    (0x2F28, 'M', u''),
    (0x2F29, 'M', u''),
    (0x2F2A, 'M', u''),
    (0x2F2B, 'M', u''),
    (0x2F2C, 'M', u''),
    (0x2F2D, 'M', u''),
    (0x2F2E, 'M', u''),
    (0x2F2F, 'M', u''),
    (0x2F30, 'M', u''),
    (0x2F31, 'M', u''),
    (0x2F32, 'M', u''),
    (0x2F33, 'M', u''),
    (0x2F34, 'M', u''),
    (0x2F35, 'M', u''),
    (0x2F36, 'M', u''),
    (0x2F37, 'M', u''),
    (0x2F38, 'M', u''),
    (0x2F39, 'M', u''),
    (0x2F3A, 'M', u''),
    (0x2F3B, 'M', u''),
    (0x2F3C, 'M', u''),
    (0x2F3D, 'M', u''),
    (0x2F3E, 'M', u''),
    (0x2F3F, 'M', u''),
    (0x2F40, 'M', u''),
    (0x2F41, 'M', u''),
    (0x2F42, 'M', u''),
    (0x2F43, 'M', u''),
    (0x2F44, 'M', u''),
    (0x2F45, 'M', u''),
    (0x2F46, 'M', u''),
    (0x2F47, 'M', u''),
    (0x2F48, 'M', u''),
    (0x2F49, 'M', u''),
    (0x2F4A, 'M', u''),
    (0x2F4B, 'M', u''),
    (0x2F4C, 'M', u''),
    (0x2F4D, 'M', u''),
    (0x2F4E, 'M', u''),
    (0x2F4F, 'M', u''),
    (0x2F50, 'M', u''),
    (0x2F51, 'M', u''),
    (0x2F52, 'M', u''),
    (0x2F53, 'M', u''),
    (0x2F54, 'M', u''),
    (0x2F55, 'M', u''),
    (0x2F56, 'M', u''),
    (0x2F57, 'M', u''),
    (0x2F58, 'M', u''),
    (0x2F59, 'M', u''),
    (0x2F5A, 'M', u''),
    (0x2F5B, 'M', u''),
    (0x2F5C, 'M', u''),
    (0x2F5D, 'M', u''),
    (0x2F5E, 'M', u''),
    (0x2F5F, 'M', u''),
    (0x2F60, 'M', u''),
    (0x2F61, 'M', u''),
    (0x2F62, 'M', u''),
    (0x2F63, 'M', u''),
    (0x2F64, 'M', u''),
    (0x2F65, 'M', u''),
    (0x2F66, 'M', u''),
    (0x2F67, 'M', u''),
    (0x2F68, 'M', u''),
    (0x2F69, 'M', u''),
    (0x2F6A, 'M', u''),
    (0x2F6B, 'M', u''),
    (0x2F6C, 'M', u''),
    (0x2F6D, 'M', u''),
    (0x2F6E, 'M', u''),
    (0x2F6F, 'M', u''),
    (0x2F70, 'M', u''),
    (0x2F71, 'M', u''),
    (0x2F72, 'M', u''),
    (0x2F73, 'M', u''),
    (0x2F74, 'M', u''),
    (0x2F75, 'M', u''),
    ]

def _seg_28():
    return [
    (0x2F76, 'M', u''),
    (0x2F77, 'M', u''),
    (0x2F78, 'M', u''),
    (0x2F79, 'M', u''),
    (0x2F7A, 'M', u''),
    (0x2F7B, 'M', u''),
    (0x2F7C, 'M', u''),
    (0x2F7D, 'M', u''),
    (0x2F7E, 'M', u''),
    (0x2F7F, 'M', u''),
    (0x2F80, 'M', u''),
    (0x2F81, 'M', u''),
    (0x2F82, 'M', u''),
    (0x2F83, 'M', u''),
    (0x2F84, 'M', u''),
    (0x2F85, 'M', u''),
    (0x2F86, 'M', u''),
    (0x2F87, 'M', u''),
    (0x2F88, 'M', u''),
    (0x2F89, 'M', u''),
    (0x2F8A, 'M', u''),
    (0x2F8B, 'M', u''),
    (0x2F8C, 'M', u''),
    (0x2F8D, 'M', u''),
    (0x2F8E, 'M', u''),
    (0x2F8F, 'M', u''),
    (0x2F90, 'M', u''),
    (0x2F91, 'M', u''),
    (0x2F92, 'M', u''),
    (0x2F93, 'M', u''),
    (0x2F94, 'M', u''),
    (0x2F95, 'M', u''),
    (0x2F96, 'M', u''),
    (0x2F97, 'M', u''),
    (0x2F98, 'M', u''),
    (0x2F99, 'M', u''),
    (0x2F9A, 'M', u''),
    (0x2F9B, 'M', u''),
    (0x2F9C, 'M', u''),
    (0x2F9D, 'M', u''),
    (0x2F9E, 'M', u''),
    (0x2F9F, 'M', u''),
    (0x2FA0, 'M', u''),
    (0x2FA1, 'M', u''),
    (0x2FA2, 'M', u''),
    (0x2FA3, 'M', u''),
    (0x2FA4, 'M', u''),
    (0x2FA5, 'M', u''),
    (0x2FA6, 'M', u''),
    (0x2FA7, 'M', u''),
    (0x2FA8, 'M', u''),
    (0x2FA9, 'M', u''),
    (0x2FAA, 'M', u''),
    (0x2FAB, 'M', u''),
    (0x2FAC, 'M', u''),
    (0x2FAD, 'M', u''),
    (0x2FAE, 'M', u''),
    (0x2FAF, 'M', u''),
    (0x2FB0, 'M', u''),
    (0x2FB1, 'M', u''),
    (0x2FB2, 'M', u''),
    (0x2FB3, 'M', u''),
    (0x2FB4, 'M', u''),
    (0x2FB5, 'M', u''),
    (0x2FB6, 'M', u''),
    (0x2FB7, 'M', u''),
    (0x2FB8, 'M', u''),
    (0x2FB9, 'M', u''),
    (0x2FBA, 'M', u''),
    (0x2FBB, 'M', u''),
    (0x2FBC, 'M', u''),
    (0x2FBD, 'M', u''),
    (0x2FBE, 'M', u''),
    (0x2FBF, 'M', u''),
    (0x2FC0, 'M', u''),
    (0x2FC1, 'M', u''),
    (0x2FC2, 'M', u''),
    (0x2FC3, 'M', u''),
    (0x2FC4, 'M', u''),
    (0x2FC5, 'M', u''),
    (0x2FC6, 'M', u''),
    (0x2FC7, 'M', u''),
    (0x2FC8, 'M', u''),
    (0x2FC9, 'M', u''),
    (0x2FCA, 'M', u''),
    (0x2FCB, 'M', u''),
    (0x2FCC, 'M', u''),
    (0x2FCD, 'M', u''),
    (0x2FCE, 'M', u''),
    (0x2FCF, 'M', u''),
    (0x2FD0, 'M', u''),
    (0x2FD1, 'M', u''),
    (0x2FD2, 'M', u''),
    (0x2FD3, 'M', u''),
    (0x2FD4, 'M', u''),
    (0x2FD5, 'M', u''),
    (0x2FD6, 'X'),
    (0x3000, '3', u' '),
    (0x3001, 'V'),
    (0x3002, 'M', u'.'),
    ]

def _seg_29():
    return [
    (0x3003, 'V'),
    (0x3036, 'M', u''),
    (0x3037, 'V'),
    (0x3038, 'M', u''),
    (0x3039, 'M', u''),
    (0x303A, 'M', u''),
    (0x303B, 'V'),
    (0x3040, 'X'),
    (0x3041, 'V'),
    (0x3097, 'X'),
    (0x3099, 'V'),
    (0x309B, '3', u' '),
    (0x309C, '3', u' '),
    (0x309D, 'V'),
    (0x309F, 'M', u''),
    (0x30A0, 'V'),
    (0x30FF, 'M', u''),
    (0x3100, 'X'),
    (0x3105, 'V'),
    (0x3130, 'X'),
    (0x3131, 'M', u''),
    (0x3132, 'M', u''),
    (0x3133, 'M', u''),
    (0x3134, 'M', u''),
    (0x3135, 'M', u''),
    (0x3136, 'M', u''),
    (0x3137, 'M', u''),
    (0x3138, 'M', u''),
    (0x3139, 'M', u''),
    (0x313A, 'M', u''),
    (0x313B, 'M', u''),
    (0x313C, 'M', u''),
    (0x313D, 'M', u''),
    (0x313E, 'M', u''),
    (0x313F, 'M', u''),
    (0x3140, 'M', u''),
    (0x3141, 'M', u''),
    (0x3142, 'M', u''),
    (0x3143, 'M', u''),
    (0x3144, 'M', u''),
    (0x3145, 'M', u''),
    (0x3146, 'M', u''),
    (0x3147, 'M', u''),
    (0x3148, 'M', u''),
    (0x3149, 'M', u''),
    (0x314A, 'M', u''),
    (0x314B, 'M', u''),
    (0x314C, 'M', u''),
    (0x314D, 'M', u''),
    (0x314E, 'M', u''),
    (0x314F, 'M', u''),
    (0x3150, 'M', u''),
    (0x3151, 'M', u''),
    (0x3152, 'M', u''),
    (0x3153, 'M', u''),
    (0x3154, 'M', u''),
    (0x3155, 'M', u''),
    (0x3156, 'M', u''),
    (0x3157, 'M', u''),
    (0x3158, 'M', u''),
    (0x3159, 'M', u''),
    (0x315A, 'M', u''),
    (0x315B, 'M', u''),
    (0x315C, 'M', u''),
    (0x315D, 'M', u''),
    (0x315E, 'M', u''),
    (0x315F, 'M', u''),
    (0x3160, 'M', u''),
    (0x3161, 'M', u''),
    (0x3162, 'M', u''),
    (0x3163, 'M', u''),
    (0x3164, 'X'),
    (0x3165, 'M', u''),
    (0x3166, 'M', u''),
    (0x3167, 'M', u''),
    (0x3168, 'M', u''),
    (0x3169, 'M', u''),
    (0x316A, 'M', u''),
    (0x316B, 'M', u''),
    (0x316C, 'M', u''),
    (0x316D, 'M', u''),
    (0x316E, 'M', u''),
    (0x316F, 'M', u''),
    (0x3170, 'M', u''),
    (0x3171, 'M', u''),
    (0x3172, 'M', u''),
    (0x3173, 'M', u''),
    (0x3174, 'M', u''),
    (0x3175, 'M', u''),
    (0x3176, 'M', u''),
    (0x3177, 'M', u''),
    (0x3178, 'M', u''),
    (0x3179, 'M', u''),
    (0x317A, 'M', u''),
    (0x317B, 'M', u''),
    (0x317C, 'M', u''),
    (0x317D, 'M', u''),
    (0x317E, 'M', u''),
    (0x317F, 'M', u''),
    (0x3180, 'M', u''),
    ]

def _seg_30():
    return [
    (0x3181, 'M', u''),
    (0x3182, 'M', u''),
    (0x3183, 'M', u''),
    (0x3184, 'M', u''),
    (0x3185, 'M', u''),
    (0x3186, 'M', u''),
    (0x3187, 'M', u''),
    (0x3188, 'M', u''),
    (0x3189, 'M', u''),
    (0x318A, 'M', u''),
    (0x318B, 'M', u''),
    (0x318C, 'M', u''),
    (0x318D, 'M', u''),
    (0x318E, 'M', u''),
    (0x318F, 'X'),
    (0x3190, 'V'),
    (0x3192, 'M', u''),
    (0x3193, 'M', u''),
    (0x3194, 'M', u''),
    (0x3195, 'M', u''),
    (0x3196, 'M', u''),
    (0x3197, 'M', u''),
    (0x3198, 'M', u''),
    (0x3199, 'M', u''),
    (0x319A, 'M', u''),
    (0x319B, 'M', u''),
    (0x319C, 'M', u''),
    (0x319D, 'M', u''),
    (0x319E, 'M', u''),
    (0x319F, 'M', u''),
    (0x31A0, 'V'),
    (0x31E4, 'X'),
    (0x31F0, 'V'),
    (0x3200, '3', u'()'),
    (0x3201, '3', u'()'),
    (0x3202, '3', u'()'),
    (0x3203, '3', u'()'),
    (0x3204, '3', u'()'),
    (0x3205, '3', u'()'),
    (0x3206, '3', u'()'),
    (0x3207, '3', u'()'),
    (0x3208, '3', u'()'),
    (0x3209, '3', u'()'),
    (0x320A, '3', u'()'),
    (0x320B, '3', u'()'),
    (0x320C, '3', u'()'),
    (0x320D, '3', u'()'),
    (0x320E, '3', u'()'),
    (0x320F, '3', u'()'),
    (0x3210, '3', u'()'),
    (0x3211, '3', u'()'),
    (0x3212, '3', u'()'),
    (0x3213, '3', u'()'),
    (0x3214, '3', u'()'),
    (0x3215, '3', u'()'),
    (0x3216, '3', u'()'),
    (0x3217, '3', u'()'),
    (0x3218, '3', u'()'),
    (0x3219, '3', u'()'),
    (0x321A, '3', u'()'),
    (0x321B, '3', u'()'),
    (0x321C, '3', u'()'),
    (0x321D, '3', u'()'),
    (0x321E, '3', u'()'),
    (0x321F, 'X'),
    (0x3220, '3', u'()'),
    (0x3221, '3', u'()'),
    (0x3222, '3', u'()'),
    (0x3223, '3', u'()'),
    (0x3224, '3', u'()'),
    (0x3225, '3', u'()'),
    (0x3226, '3', u'()'),
    (0x3227, '3', u'()'),
    (0x3228, '3', u'()'),
    (0x3229, '3', u'()'),
    (0x322A, '3', u'()'),
    (0x322B, '3', u'()'),
    (0x322C, '3', u'()'),
    (0x322D, '3', u'()'),
    (0x322E, '3', u'()'),
    (0x322F, '3', u'()'),
    (0x3230, '3', u'()'),
    (0x3231, '3', u'()'),
    (0x3232, '3', u'()'),
    (0x3233, '3', u'()'),
    (0x3234, '3', u'()'),
    (0x3235, '3', u'()'),
    (0x3236, '3', u'()'),
    (0x3237, '3', u'()'),
    (0x3238, '3', u'()'),
    (0x3239, '3', u'()'),
    (0x323A, '3', u'()'),
    (0x323B, '3', u'()'),
    (0x323C, '3', u'()'),
    (0x323D, '3', u'()'),
    (0x323E, '3', u'()'),
    (0x323F, '3', u'()'),
    (0x3240, '3', u'()'),
    (0x3241, '3', u'()'),
    (0x3242, '3', u'()'),
    ]

def _seg_31():
    return [
    (0x3243, '3', u'()'),
    (0x3244, 'M', u''),
    (0x3245, 'M', u''),
    (0x3246, 'M', u''),
    (0x3247, 'M', u''),
    (0x3248, 'V'),
    (0x3250, 'M', u'pte'),
    (0x3251, 'M', u'21'),
    (0x3252, 'M', u'22'),
    (0x3253, 'M', u'23'),
    (0x3254, 'M', u'24'),
    (0x3255, 'M', u'25'),
    (0x3256, 'M', u'26'),
    (0x3257, 'M', u'27'),
    (0x3258, 'M', u'28'),
    (0x3259, 'M', u'29'),
    (0x325A, 'M', u'30'),
    (0x325B, 'M', u'31'),
    (0x325C, 'M', u'32'),
    (0x325D, 'M', u'33'),
    (0x325E, 'M', u'34'),
    (0x325F, 'M', u'35'),
    (0x3260, 'M', u''),
    (0x3261, 'M', u''),
    (0x3262, 'M', u''),
    (0x3263, 'M', u''),
    (0x3264, 'M', u''),
    (0x3265, 'M', u''),
    (0x3266, 'M', u''),
    (0x3267, 'M', u''),
    (0x3268, 'M', u''),
    (0x3269, 'M', u''),
    (0x326A, 'M', u''),
    (0x326B, 'M', u''),
    (0x326C, 'M', u''),
    (0x326D, 'M', u''),
    (0x326E, 'M', u''),
    (0x326F, 'M', u''),
    (0x3270, 'M', u''),
    (0x3271, 'M', u''),
    (0x3272, 'M', u''),
    (0x3273, 'M', u''),
    (0x3274, 'M', u''),
    (0x3275, 'M', u''),
    (0x3276, 'M', u''),
    (0x3277, 'M', u''),
    (0x3278, 'M', u''),
    (0x3279, 'M', u''),
    (0x327A, 'M', u''),
    (0x327B, 'M', u''),
    (0x327C, 'M', u''),
    (0x327D, 'M', u''),
    (0x327E, 'M', u''),
    (0x327F, 'V'),
    (0x3280, 'M', u''),
    (0x3281, 'M', u''),
    (0x3282, 'M', u''),
    (0x3283, 'M', u''),
    (0x3284, 'M', u''),
    (0x3285, 'M', u''),
    (0x3286, 'M', u''),
    (0x3287, 'M', u''),
    (0x3288, 'M', u''),
    (0x3289, 'M', u''),
    (0x328A, 'M', u''),
    (0x328B, 'M', u''),
    (0x328C, 'M', u''),
    (0x328D, 'M', u''),
    (0x328E, 'M', u''),
    (0x328F, 'M', u''),
    (0x3290, 'M', u''),
    (0x3291, 'M', u''),
    (0x3292, 'M', u''),
    (0x3293, 'M', u''),
    (0x3294, 'M', u''),
    (0x3295, 'M', u''),
    (0x3296, 'M', u''),
    (0x3297, 'M', u''),
    (0x3298, 'M', u''),
    (0x3299, 'M', u''),
    (0x329A, 'M', u''),
    (0x329B, 'M', u''),
    (0x329C, 'M', u''),
    (0x329D, 'M', u''),
    (0x329E, 'M', u''),
    (0x329F, 'M', u''),
    (0x32A0, 'M', u''),
    (0x32A1, 'M', u''),
    (0x32A2, 'M', u''),
    (0x32A3, 'M', u''),
    (0x32A4, 'M', u''),
    (0x32A5, 'M', u''),
    (0x32A6, 'M', u''),
    (0x32A7, 'M', u''),
    (0x32A8, 'M', u''),
    (0x32A9, 'M', u''),
    (0x32AA, 'M', u''),
    (0x32AB, 'M', u''),
    (0x32AC, 'M', u''),
    (0x32AD, 'M', u''),
    ]

def _seg_32():
    return [
    (0x32AE, 'M', u''),
    (0x32AF, 'M', u''),
    (0x32B0, 'M', u''),
    (0x32B1, 'M', u'36'),
    (0x32B2, 'M', u'37'),
    (0x32B3, 'M', u'38'),
    (0x32B4, 'M', u'39'),
    (0x32B5, 'M', u'40'),
    (0x32B6, 'M', u'41'),
    (0x32B7, 'M', u'42'),
    (0x32B8, 'M', u'43'),
    (0x32B9, 'M', u'44'),
    (0x32BA, 'M', u'45'),
    (0x32BB, 'M', u'46'),
    (0x32BC, 'M', u'47'),
    (0x32BD, 'M', u'48'),
    (0x32BE, 'M', u'49'),
    (0x32BF, 'M', u'50'),
    (0x32C0, 'M', u'1'),
    (0x32C1, 'M', u'2'),
    (0x32C2, 'M', u'3'),
    (0x32C3, 'M', u'4'),
    (0x32C4, 'M', u'5'),
    (0x32C5, 'M', u'6'),
    (0x32C6, 'M', u'7'),
    (0x32C7, 'M', u'8'),
    (0x32C8, 'M', u'9'),
    (0x32C9, 'M', u'10'),
    (0x32CA, 'M', u'11'),
    (0x32CB, 'M', u'12'),
    (0x32CC, 'M', u'hg'),
    (0x32CD, 'M', u'erg'),
    (0x32CE, 'M', u'ev'),
    (0x32CF, 'M', u'ltd'),
    (0x32D0, 'M', u''),
    (0x32D1, 'M', u''),
    (0x32D2, 'M', u''),
    (0x32D3, 'M', u''),
    (0x32D4, 'M', u''),
    (0x32D5, 'M', u''),
    (0x32D6, 'M', u''),
    (0x32D7, 'M', u''),
    (0x32D8, 'M', u''),
    (0x32D9, 'M', u''),
    (0x32DA, 'M', u''),
    (0x32DB, 'M', u''),
    (0x32DC, 'M', u''),
    (0x32DD, 'M', u''),
    (0x32DE, 'M', u''),
    (0x32DF, 'M', u''),
    (0x32E0, 'M', u''),
    (0x32E1, 'M', u''),
    (0x32E2, 'M', u''),
    (0x32E3, 'M', u''),
    (0x32E4, 'M', u''),
    (0x32E5, 'M', u''),
    (0x32E6, 'M', u''),
    (0x32E7, 'M', u''),
    (0x32E8, 'M', u''),
    (0x32E9, 'M', u''),
    (0x32EA, 'M', u''),
    (0x32EB, 'M', u''),
    (0x32EC, 'M', u''),
    (0x32ED, 'M', u''),
    (0x32EE, 'M', u''),
    (0x32EF, 'M', u''),
    (0x32F0, 'M', u''),
    (0x32F1, 'M', u''),
    (0x32F2, 'M', u''),
    (0x32F3, 'M', u''),
    (0x32F4, 'M', u''),
    (0x32F5, 'M', u''),
    (0x32F6, 'M', u''),
    (0x32F7, 'M', u''),
    (0x32F8, 'M', u''),
    (0x32F9, 'M', u''),
    (0x32FA, 'M', u''),
    (0x32FB, 'M', u''),
    (0x32FC, 'M', u''),
    (0x32FD, 'M', u''),
    (0x32FE, 'M', u''),
    (0x32FF, 'M', u''),
    (0x3300, 'M', u''),
    (0x3301, 'M', u''),
    (0x3302, 'M', u''),
    (0x3303, 'M', u''),
    (0x3304, 'M', u''),
    (0x3305, 'M', u''),
    (0x3306, 'M', u''),
    (0x3307, 'M', u''),
    (0x3308, 'M', u''),
    (0x3309, 'M', u''),
    (0x330A, 'M', u''),
    (0x330B, 'M', u''),
    (0x330C, 'M', u''),
    (0x330D, 'M', u''),
    (0x330E, 'M', u''),
    (0x330F, 'M', u''),
    (0x3310, 'M', u''),
    (0x3311, 'M', u''),
    ]

def _seg_33():
    return [
    (0x3312, 'M', u''),
    (0x3313, 'M', u''),
    (0x3314, 'M', u''),
    (0x3315, 'M', u''),
    (0x3316, 'M', u''),
    (0x3317, 'M', u''),
    (0x3318, 'M', u''),
    (0x3319, 'M', u''),
    (0x331A, 'M', u''),
    (0x331B, 'M', u''),
    (0x331C, 'M', u''),
    (0x331D, 'M', u''),
    (0x331E, 'M', u''),
    (0x331F, 'M', u''),
    (0x3320, 'M', u''),
    (0x3321, 'M', u''),
    (0x3322, 'M', u''),
    (0x3323, 'M', u''),
    (0x3324, 'M', u''),
    (0x3325, 'M', u''),
    (0x3326, 'M', u''),
    (0x3327, 'M', u''),
    (0x3328, 'M', u''),
    (0x3329, 'M', u''),
    (0x332A, 'M', u''),
    (0x332B, 'M', u''),
    (0x332C, 'M', u''),
    (0x332D, 'M', u''),
    (0x332E, 'M', u''),
    (0x332F, 'M', u''),
    (0x3330, 'M', u''),
    (0x3331, 'M', u''),
    (0x3332, 'M', u''),
    (0x3333, 'M', u''),
    (0x3334, 'M', u''),
    (0x3335, 'M', u''),
    (0x3336, 'M', u''),
    (0x3337, 'M', u''),
    (0x3338, 'M', u''),
    (0x3339, 'M', u''),
    (0x333A, 'M', u''),
    (0x333B, 'M', u''),
    (0x333C, 'M', u''),
    (0x333D, 'M', u''),
    (0x333E, 'M', u''),
    (0x333F, 'M', u''),
    (0x3340, 'M', u''),
    (0x3341, 'M', u''),
    (0x3342, 'M', u''),
    (0x3343, 'M', u''),
    (0x3344, 'M', u''),
    (0x3345, 'M', u''),
    (0x3346, 'M', u''),
    (0x3347, 'M', u''),
    (0x3348, 'M', u''),
    (0x3349, 'M', u''),
    (0x334A, 'M', u''),
    (0x334B, 'M', u''),
    (0x334C, 'M', u''),
    (0x334D, 'M', u''),
    (0x334E, 'M', u''),
    (0x334F, 'M', u''),
    (0x3350, 'M', u''),
    (0x3351, 'M', u''),
    (0x3352, 'M', u''),
    (0x3353, 'M', u''),
    (0x3354, 'M', u''),
    (0x3355, 'M', u''),
    (0x3356, 'M', u''),
    (0x3357, 'M', u''),
    (0x3358, 'M', u'0'),
    (0x3359, 'M', u'1'),
    (0x335A, 'M', u'2'),
    (0x335B, 'M', u'3'),
    (0x335C, 'M', u'4'),
    (0x335D, 'M', u'5'),
    (0x335E, 'M', u'6'),
    (0x335F, 'M', u'7'),
    (0x3360, 'M', u'8'),
    (0x3361, 'M', u'9'),
    (0x3362, 'M', u'10'),
    (0x3363, 'M', u'11'),
    (0x3364, 'M', u'12'),
    (0x3365, 'M', u'13'),
    (0x3366, 'M', u'14'),
    (0x3367, 'M', u'15'),
    (0x3368, 'M', u'16'),
    (0x3369, 'M', u'17'),
    (0x336A, 'M', u'18'),
    (0x336B, 'M', u'19'),
    (0x336C, 'M', u'20'),
    (0x336D, 'M', u'21'),
    (0x336E, 'M', u'22'),
    (0x336F, 'M', u'23'),
    (0x3370, 'M', u'24'),
    (0x3371, 'M', u'hpa'),
    (0x3372, 'M', u'da'),
    (0x3373, 'M', u'au'),
    (0x3374, 'M', u'bar'),
    (0x3375, 'M', u'ov'),
    ]

def _seg_34():
    return [
    (0x3376, 'M', u'pc'),
    (0x3377, 'M', u'dm'),
    (0x3378, 'M', u'dm2'),
    (0x3379, 'M', u'dm3'),
    (0x337A, 'M', u'iu'),
    (0x337B, 'M', u''),
    (0x337C, 'M', u''),
    (0x337D, 'M', u''),
    (0x337E, 'M', u''),
    (0x337F, 'M', u''),
    (0x3380, 'M', u'pa'),
    (0x3381, 'M', u'na'),
    (0x3382, 'M', u'a'),
    (0x3383, 'M', u'ma'),
    (0x3384, 'M', u'ka'),
    (0x3385, 'M', u'kb'),
    (0x3386, 'M', u'mb'),
    (0x3387, 'M', u'gb'),
    (0x3388, 'M', u'cal'),
    (0x3389, 'M', u'kcal'),
    (0x338A, 'M', u'pf'),
    (0x338B, 'M', u'nf'),
    (0x338C, 'M', u'f'),
    (0x338D, 'M', u'g'),
    (0x338E, 'M', u'mg'),
    (0x338F, 'M', u'kg'),
    (0x3390, 'M', u'hz'),
    (0x3391, 'M', u'khz'),
    (0x3392, 'M', u'mhz'),
    (0x3393, 'M', u'ghz'),
    (0x3394, 'M', u'thz'),
    (0x3395, 'M', u'l'),
    (0x3396, 'M', u'ml'),
    (0x3397, 'M', u'dl'),
    (0x3398, 'M', u'kl'),
    (0x3399, 'M', u'fm'),
    (0x339A, 'M', u'nm'),
    (0x339B, 'M', u'm'),
    (0x339C, 'M', u'mm'),
    (0x339D, 'M', u'cm'),
    (0x339E, 'M', u'km'),
    (0x339F, 'M', u'mm2'),
    (0x33A0, 'M', u'cm2'),
    (0x33A1, 'M', u'm2'),
    (0x33A2, 'M', u'km2'),
    (0x33A3, 'M', u'mm3'),
    (0x33A4, 'M', u'cm3'),
    (0x33A5, 'M', u'm3'),
    (0x33A6, 'M', u'km3'),
    (0x33A7, 'M', u'ms'),
    (0x33A8, 'M', u'ms2'),
    (0x33A9, 'M', u'pa'),
    (0x33AA, 'M', u'kpa'),
    (0x33AB, 'M', u'mpa'),
    (0x33AC, 'M', u'gpa'),
    (0x33AD, 'M', u'rad'),
    (0x33AE, 'M', u'rads'),
    (0x33AF, 'M', u'rads2'),
    (0x33B0, 'M', u'ps'),
    (0x33B1, 'M', u'ns'),
    (0x33B2, 'M', u's'),
    (0x33B3, 'M', u'ms'),
    (0x33B4, 'M', u'pv'),
    (0x33B5, 'M', u'nv'),
    (0x33B6, 'M', u'v'),
    (0x33B7, 'M', u'mv'),
    (0x33B8, 'M', u'kv'),
    (0x33B9, 'M', u'mv'),
    (0x33BA, 'M', u'pw'),
    (0x33BB, 'M', u'nw'),
    (0x33BC, 'M', u'w'),
    (0x33BD, 'M', u'mw'),
    (0x33BE, 'M', u'kw'),
    (0x33BF, 'M', u'mw'),
    (0x33C0, 'M', u'k'),
    (0x33C1, 'M', u'm'),
    (0x33C2, 'X'),
    (0x33C3, 'M', u'bq'),
    (0x33C4, 'M', u'cc'),
    (0x33C5, 'M', u'cd'),
    (0x33C6, 'M', u'ckg'),
    (0x33C7, 'X'),
    (0x33C8, 'M', u'db'),
    (0x33C9, 'M', u'gy'),
    (0x33CA, 'M', u'ha'),
    (0x33CB, 'M', u'hp'),
    (0x33CC, 'M', u'in'),
    (0x33CD, 'M', u'kk'),
    (0x33CE, 'M', u'km'),
    (0x33CF, 'M', u'kt'),
    (0x33D0, 'M', u'lm'),
    (0x33D1, 'M', u'ln'),
    (0x33D2, 'M', u'log'),
    (0x33D3, 'M', u'lx'),
    (0x33D4, 'M', u'mb'),
    (0x33D5, 'M', u'mil'),
    (0x33D6, 'M', u'mol'),
    (0x33D7, 'M', u'ph'),
    (0x33D8, 'X'),
    (0x33D9, 'M', u'ppm'),
    ]

def _seg_35():
    return [
    (0x33DA, 'M', u'pr'),
    (0x33DB, 'M', u'sr'),
    (0x33DC, 'M', u'sv'),
    (0x33DD, 'M', u'wb'),
    (0x33DE, 'M', u'vm'),
    (0x33DF, 'M', u'am'),
    (0x33E0, 'M', u'1'),
    (0x33E1, 'M', u'2'),
    (0x33E2, 'M', u'3'),
    (0x33E3, 'M', u'4'),
    (0x33E4, 'M', u'5'),
    (0x33E5, 'M', u'6'),
    (0x33E6, 'M', u'7'),
    (0x33E7, 'M', u'8'),
    (0x33E8, 'M', u'9'),
    (0x33E9, 'M', u'10'),
    (0x33EA, 'M', u'11'),
    (0x33EB, 'M', u'12'),
    (0x33EC, 'M', u'13'),
    (0x33ED, 'M', u'14'),
    (0x33EE, 'M', u'15'),
    (0x33EF, 'M', u'16'),
    (0x33F0, 'M', u'17'),
    (0x33F1, 'M', u'18'),
    (0x33F2, 'M', u'19'),
    (0x33F3, 'M', u'20'),
    (0x33F4, 'M', u'21'),
    (0x33F5, 'M', u'22'),
    (0x33F6, 'M', u'23'),
    (0x33F7, 'M', u'24'),
    (0x33F8, 'M', u'25'),
    (0x33F9, 'M', u'26'),
    (0x33FA, 'M', u'27'),
    (0x33FB, 'M', u'28'),
    (0x33FC, 'M', u'29'),
    (0x33FD, 'M', u'30'),
    (0x33FE, 'M', u'31'),
    (0x33FF, 'M', u'gal'),
    (0x3400, 'V'),
    (0x9FFD, 'X'),
    (0xA000, 'V'),
    (0xA48D, 'X'),
    (0xA490, 'V'),
    (0xA4C7, 'X'),
    (0xA4D0, 'V'),
    (0xA62C, 'X'),
    (0xA640, 'M', u''),
    (0xA641, 'V'),
    (0xA642, 'M', u''),
    (0xA643, 'V'),
    (0xA644, 'M', u''),
    (0xA645, 'V'),
    (0xA646, 'M', u''),
    (0xA647, 'V'),
    (0xA648, 'M', u''),
    (0xA649, 'V'),
    (0xA64A, 'M', u''),
    (0xA64B, 'V'),
    (0xA64C, 'M', u''),
    (0xA64D, 'V'),
    (0xA64E, 'M', u''),
    (0xA64F, 'V'),
    (0xA650, 'M', u''),
    (0xA651, 'V'),
    (0xA652, 'M', u''),
    (0xA653, 'V'),
    (0xA654, 'M', u''),
    (0xA655, 'V'),
    (0xA656, 'M', u''),
    (0xA657, 'V'),
    (0xA658, 'M', u''),
    (0xA659, 'V'),
    (0xA65A, 'M', u''),
    (0xA65B, 'V'),
    (0xA65C, 'M', u''),
    (0xA65D, 'V'),
    (0xA65E, 'M', u''),
    (0xA65F, 'V'),
    (0xA660, 'M', u''),
    (0xA661, 'V'),
    (0xA662, 'M', u''),
    (0xA663, 'V'),
    (0xA664, 'M', u''),
    (0xA665, 'V'),
    (0xA666, 'M', u''),
    (0xA667, 'V'),
    (0xA668, 'M', u''),
    (0xA669, 'V'),
    (0xA66A, 'M', u''),
    (0xA66B, 'V'),
    (0xA66C, 'M', u''),
    (0xA66D, 'V'),
    (0xA680, 'M', u''),
    (0xA681, 'V'),
    (0xA682, 'M', u''),
    (0xA683, 'V'),
    (0xA684, 'M', u''),
    (0xA685, 'V'),
    (0xA686, 'M', u''),
    (0xA687, 'V'),
    ]

def _seg_36():
    return [
    (0xA688, 'M', u''),
    (0xA689, 'V'),
    (0xA68A, 'M', u''),
    (0xA68B, 'V'),
    (0xA68C, 'M', u''),
    (0xA68D, 'V'),
    (0xA68E, 'M', u''),
    (0xA68F, 'V'),
    (0xA690, 'M', u''),
    (0xA691, 'V'),
    (0xA692, 'M', u''),
    (0xA693, 'V'),
    (0xA694, 'M', u''),
    (0xA695, 'V'),
    (0xA696, 'M', u''),
    (0xA697, 'V'),
    (0xA698, 'M', u''),
    (0xA699, 'V'),
    (0xA69A, 'M', u''),
    (0xA69B, 'V'),
    (0xA69C, 'M', u''),
    (0xA69D, 'M', u''),
    (0xA69E, 'V'),
    (0xA6F8, 'X'),
    (0xA700, 'V'),
    (0xA722, 'M', u''),
    (0xA723, 'V'),
    (0xA724, 'M', u''),
    (0xA725, 'V'),
    (0xA726, 'M', u''),
    (0xA727, 'V'),
    (0xA728, 'M', u''),
    (0xA729, 'V'),
    (0xA72A, 'M', u''),
    (0xA72B, 'V'),
    (0xA72C, 'M', u''),
    (0xA72D, 'V'),
    (0xA72E, 'M', u''),
    (0xA72F, 'V'),
    (0xA732, 'M', u''),
    (0xA733, 'V'),
    (0xA734, 'M', u''),
    (0xA735, 'V'),
    (0xA736, 'M', u''),
    (0xA737, 'V'),
    (0xA738, 'M', u''),
    (0xA739, 'V'),
    (0xA73A, 'M', u''),
    (0xA73B, 'V'),
    (0xA73C, 'M', u''),
    (0xA73D, 'V'),
    (0xA73E, 'M', u''),
    (0xA73F, 'V'),
    (0xA740, 'M', u''),
    (0xA741, 'V'),
    (0xA742, 'M', u''),
    (0xA743, 'V'),
    (0xA744, 'M', u''),
    (0xA745, 'V'),
    (0xA746, 'M', u''),
    (0xA747, 'V'),
    (0xA748, 'M', u''),
    (0xA749, 'V'),
    (0xA74A, 'M', u''),
    (0xA74B, 'V'),
    (0xA74C, 'M', u''),
    (0xA74D, 'V'),
    (0xA74E, 'M', u''),
    (0xA74F, 'V'),
    (0xA750, 'M', u''),
    (0xA751, 'V'),
    (0xA752, 'M', u''),
    (0xA753, 'V'),
    (0xA754, 'M', u''),
    (0xA755, 'V'),
    (0xA756, 'M', u''),
    (0xA757, 'V'),
    (0xA758, 'M', u''),
    (0xA759, 'V'),
    (0xA75A, 'M', u''),
    (0xA75B, 'V'),
    (0xA75C, 'M', u''),
    (0xA75D, 'V'),
    (0xA75E, 'M', u''),
    (0xA75F, 'V'),
    (0xA760, 'M', u''),
    (0xA761, 'V'),
    (0xA762, 'M', u''),
    (0xA763, 'V'),
    (0xA764, 'M', u''),
    (0xA765, 'V'),
    (0xA766, 'M', u''),
    (0xA767, 'V'),
    (0xA768, 'M', u''),
    (0xA769, 'V'),
    (0xA76A, 'M', u''),
    (0xA76B, 'V'),
    (0xA76C, 'M', u''),
    (0xA76D, 'V'),
    (0xA76E, 'M', u''),
    ]

def _seg_37():
    return [
    (0xA76F, 'V'),
    (0xA770, 'M', u''),
    (0xA771, 'V'),
    (0xA779, 'M', u''),
    (0xA77A, 'V'),
    (0xA77B, 'M', u''),
    (0xA77C, 'V'),
    (0xA77D, 'M', u''),
    (0xA77E, 'M', u''),
    (0xA77F, 'V'),
    (0xA780, 'M', u''),
    (0xA781, 'V'),
    (0xA782, 'M', u''),
    (0xA783, 'V'),
    (0xA784, 'M', u''),
    (0xA785, 'V'),
    (0xA786, 'M', u''),
    (0xA787, 'V'),
    (0xA78B, 'M', u''),
    (0xA78C, 'V'),
    (0xA78D, 'M', u''),
    (0xA78E, 'V'),
    (0xA790, 'M', u''),
    (0xA791, 'V'),
    (0xA792, 'M', u''),
    (0xA793, 'V'),
    (0xA796, 'M', u''),
    (0xA797, 'V'),
    (0xA798, 'M', u''),
    (0xA799, 'V'),
    (0xA79A, 'M', u''),
    (0xA79B, 'V'),
    (0xA79C, 'M', u''),
    (0xA79D, 'V'),
    (0xA79E, 'M', u''),
    (0xA79F, 'V'),
    (0xA7A0, 'M', u''),
    (0xA7A1, 'V'),
    (0xA7A2, 'M', u''),
    (0xA7A3, 'V'),
    (0xA7A4, 'M', u''),
    (0xA7A5, 'V'),
    (0xA7A6, 'M', u''),
    (0xA7A7, 'V'),
    (0xA7A8, 'M', u''),
    (0xA7A9, 'V'),
    (0xA7AA, 'M', u''),
    (0xA7AB, 'M', u''),
    (0xA7AC, 'M', u''),
    (0xA7AD, 'M', u''),
    (0xA7AE, 'M', u''),
    (0xA7AF, 'V'),
    (0xA7B0, 'M', u''),
    (0xA7B1, 'M', u''),
    (0xA7B2, 'M', u''),
    (0xA7B3, 'M', u''),
    (0xA7B4, 'M', u''),
    (0xA7B5, 'V'),
    (0xA7B6, 'M', u''),
    (0xA7B7, 'V'),
    (0xA7B8, 'M', u''),
    (0xA7B9, 'V'),
    (0xA7BA, 'M', u''),
    (0xA7BB, 'V'),
    (0xA7BC, 'M', u''),
    (0xA7BD, 'V'),
    (0xA7BE, 'M', u''),
    (0xA7BF, 'V'),
    (0xA7C0, 'X'),
    (0xA7C2, 'M', u''),
    (0xA7C3, 'V'),
    (0xA7C4, 'M', u''),
    (0xA7C5, 'M', u''),
    (0xA7C6, 'M', u''),
    (0xA7C7, 'M', u''),
    (0xA7C8, 'V'),
    (0xA7C9, 'M', u''),
    (0xA7CA, 'V'),
    (0xA7CB, 'X'),
    (0xA7F5, 'M', u''),
    (0xA7F6, 'V'),
    (0xA7F8, 'M', u''),
    (0xA7F9, 'M', u''),
    (0xA7FA, 'V'),
    (0xA82D, 'X'),
    (0xA830, 'V'),
    (0xA83A, 'X'),
    (0xA840, 'V'),
    (0xA878, 'X'),
    (0xA880, 'V'),
    (0xA8C6, 'X'),
    (0xA8CE, 'V'),
    (0xA8DA, 'X'),
    (0xA8E0, 'V'),
    (0xA954, 'X'),
    (0xA95F, 'V'),
    (0xA97D, 'X'),
    (0xA980, 'V'),
    (0xA9CE, 'X'),
    (0xA9CF, 'V'),
    ]

def _seg_38():
    return [
    (0xA9DA, 'X'),
    (0xA9DE, 'V'),
    (0xA9FF, 'X'),
    (0xAA00, 'V'),
    (0xAA37, 'X'),
    (0xAA40, 'V'),
    (0xAA4E, 'X'),
    (0xAA50, 'V'),
    (0xAA5A, 'X'),
    (0xAA5C, 'V'),
    (0xAAC3, 'X'),
    (0xAADB, 'V'),
    (0xAAF7, 'X'),
    (0xAB01, 'V'),
    (0xAB07, 'X'),
    (0xAB09, 'V'),
    (0xAB0F, 'X'),
    (0xAB11, 'V'),
    (0xAB17, 'X'),
    (0xAB20, 'V'),
    (0xAB27, 'X'),
    (0xAB28, 'V'),
    (0xAB2F, 'X'),
    (0xAB30, 'V'),
    (0xAB5C, 'M', u''),
    (0xAB5D, 'M', u''),
    (0xAB5E, 'M', u''),
    (0xAB5F, 'M', u''),
    (0xAB60, 'V'),
    (0xAB69, 'M', u''),
    (0xAB6A, 'V'),
    (0xAB6C, 'X'),
    (0xAB70, 'M', u''),
    (0xAB71, 'M', u''),
    (0xAB72, 'M', u''),
    (0xAB73, 'M', u''),
    (0xAB74, 'M', u''),
    (0xAB75, 'M', u''),
    (0xAB76, 'M', u''),
    (0xAB77, 'M', u''),
    (0xAB78, 'M', u''),
    (0xAB79, 'M', u''),
    (0xAB7A, 'M', u''),
    (0xAB7B, 'M', u''),
    (0xAB7C, 'M', u''),
    (0xAB7D, 'M', u''),
    (0xAB7E, 'M', u''),
    (0xAB7F, 'M', u''),
    (0xAB80, 'M', u''),
    (0xAB81, 'M', u''),
    (0xAB82, 'M', u''),
    (0xAB83, 'M', u''),
    (0xAB84, 'M', u''),
    (0xAB85, 'M', u''),
    (0xAB86, 'M', u''),
    (0xAB87, 'M', u''),
    (0xAB88, 'M', u''),
    (0xAB89, 'M', u''),
    (0xAB8A, 'M', u''),
    (0xAB8B, 'M', u''),
    (0xAB8C, 'M', u''),
    (0xAB8D, 'M', u''),
    (0xAB8E, 'M', u''),
    (0xAB8F, 'M', u''),
    (0xAB90, 'M', u''),
    (0xAB91, 'M', u''),
    (0xAB92, 'M', u''),
    (0xAB93, 'M', u''),
    (0xAB94, 'M', u''),
    (0xAB95, 'M', u''),
    (0xAB96, 'M', u''),
    (0xAB97, 'M', u''),
    (0xAB98, 'M', u''),
    (0xAB99, 'M', u''),
    (0xAB9A, 'M', u''),
    (0xAB9B, 'M', u''),
    (0xAB9C, 'M', u''),
    (0xAB9D, 'M', u''),
    (0xAB9E, 'M', u''),
    (0xAB9F, 'M', u''),
    (0xABA0, 'M', u''),
    (0xABA1, 'M', u''),
    (0xABA2, 'M', u''),
    (0xABA3, 'M', u''),
    (0xABA4, 'M', u''),
    (0xABA5, 'M', u''),
    (0xABA6, 'M', u''),
    (0xABA7, 'M', u''),
    (0xABA8, 'M', u''),
    (0xABA9, 'M', u''),
    (0xABAA, 'M', u''),
    (0xABAB, 'M', u''),
    (0xABAC, 'M', u''),
    (0xABAD, 'M', u''),
    (0xABAE, 'M', u''),
    (0xABAF, 'M', u''),
    (0xABB0, 'M', u''),
    (0xABB1, 'M', u''),
    (0xABB2, 'M', u''),
    (0xABB3, 'M', u''),
    ]

def _seg_39():
    return [
    (0xABB4, 'M', u''),
    (0xABB5, 'M', u''),
    (0xABB6, 'M', u''),
    (0xABB7, 'M', u''),
    (0xABB8, 'M', u''),
    (0xABB9, 'M', u''),
    (0xABBA, 'M', u''),
    (0xABBB, 'M', u''),
    (0xABBC, 'M', u''),
    (0xABBD, 'M', u''),
    (0xABBE, 'M', u''),
    (0xABBF, 'M', u''),
    (0xABC0, 'V'),
    (0xABEE, 'X'),
    (0xABF0, 'V'),
    (0xABFA, 'X'),
    (0xAC00, 'V'),
    (0xD7A4, 'X'),
    (0xD7B0, 'V'),
    (0xD7C7, 'X'),
    (0xD7CB, 'V'),
    (0xD7FC, 'X'),
    (0xF900, 'M', u''),
    (0xF901, 'M', u''),
    (0xF902, 'M', u''),
    (0xF903, 'M', u''),
    (0xF904, 'M', u''),
    (0xF905, 'M', u''),
    (0xF906, 'M', u''),
    (0xF907, 'M', u''),
    (0xF909, 'M', u''),
    (0xF90A, 'M', u''),
    (0xF90B, 'M', u''),
    (0xF90C, 'M', u''),
    (0xF90D, 'M', u''),
    (0xF90E, 'M', u''),
    (0xF90F, 'M', u''),
    (0xF910, 'M', u''),
    (0xF911, 'M', u''),
    (0xF912, 'M', u''),
    (0xF913, 'M', u''),
    (0xF914, 'M', u''),
    (0xF915, 'M', u''),
    (0xF916, 'M', u''),
    (0xF917, 'M', u''),
    (0xF918, 'M', u''),
    (0xF919, 'M', u''),
    (0xF91A, 'M', u''),
    (0xF91B, 'M', u''),
    (0xF91C, 'M', u''),
    (0xF91D, 'M', u''),
    (0xF91E, 'M', u''),
    (0xF91F, 'M', u''),
    (0xF920, 'M', u''),
    (0xF921, 'M', u''),
    (0xF922, 'M', u''),
    (0xF923, 'M', u''),
    (0xF924, 'M', u''),
    (0xF925, 'M', u''),
    (0xF926, 'M', u''),
    (0xF927, 'M', u''),
    (0xF928, 'M', u''),
    (0xF929, 'M', u''),
    (0xF92A, 'M', u''),
    (0xF92B, 'M', u''),
    (0xF92C, 'M', u''),
    (0xF92D, 'M', u''),
    (0xF92E, 'M', u''),
    (0xF92F, 'M', u''),
    (0xF930, 'M', u''),
    (0xF931, 'M', u''),
    (0xF932, 'M', u''),
    (0xF933, 'M', u''),
    (0xF934, 'M', u''),
    (0xF935, 'M', u''),
    (0xF936, 'M', u''),
    (0xF937, 'M', u''),
    (0xF938, 'M', u''),
    (0xF939, 'M', u''),
    (0xF93A, 'M', u''),
    (0xF93B, 'M', u''),
    (0xF93C, 'M', u''),
    (0xF93D, 'M', u''),
    (0xF93E, 'M', u''),
    (0xF93F, 'M', u''),
    (0xF940, 'M', u''),
    (0xF941, 'M', u''),
    (0xF942, 'M', u''),
    (0xF943, 'M', u''),
    (0xF944, 'M', u''),
    (0xF945, 'M', u''),
    (0xF946, 'M', u''),
    (0xF947, 'M', u''),
    (0xF948, 'M', u''),
    (0xF949, 'M', u''),
    (0xF94A, 'M', u''),
    (0xF94B, 'M', u''),
    (0xF94C, 'M', u''),
    (0xF94D, 'M', u''),
    (0xF94E, 'M', u''),
    ]

def _seg_40():
    return [
    (0xF94F, 'M', u''),
    (0xF950, 'M', u''),
    (0xF951, 'M', u''),
    (0xF952, 'M', u''),
    (0xF953, 'M', u''),
    (0xF954, 'M', u''),
    (0xF955, 'M', u''),
    (0xF956, 'M', u''),
    (0xF957, 'M', u''),
    (0xF958, 'M', u''),
    (0xF959, 'M', u''),
    (0xF95A, 'M', u''),
    (0xF95B, 'M', u''),
    (0xF95C, 'M', u''),
    (0xF95D, 'M', u''),
    (0xF95E, 'M', u''),
    (0xF95F, 'M', u''),
    (0xF960, 'M', u''),
    (0xF961, 'M', u''),
    (0xF962, 'M', u''),
    (0xF963, 'M', u''),
    (0xF964, 'M', u''),
    (0xF965, 'M', u''),
    (0xF966, 'M', u''),
    (0xF967, 'M', u''),
    (0xF968, 'M', u''),
    (0xF969, 'M', u''),
    (0xF96A, 'M', u''),
    (0xF96B, 'M', u''),
    (0xF96C, 'M', u''),
    (0xF96D, 'M', u''),
    (0xF96E, 'M', u''),
    (0xF96F, 'M', u''),
    (0xF970, 'M', u''),
    (0xF971, 'M', u''),
    (0xF972, 'M', u''),
    (0xF973, 'M', u''),
    (0xF974, 'M', u''),
    (0xF975, 'M', u''),
    (0xF976, 'M', u''),
    (0xF977, 'M', u''),
    (0xF978, 'M', u''),
    (0xF979, 'M', u''),
    (0xF97A, 'M', u''),
    (0xF97B, 'M', u''),
    (0xF97C, 'M', u''),
    (0xF97D, 'M', u''),
    (0xF97E, 'M', u''),
    (0xF97F, 'M', u''),
    (0xF980, 'M', u''),
    (0xF981, 'M', u''),
    (0xF982, 'M', u''),
    (0xF983, 'M', u''),
    (0xF984, 'M', u''),
    (0xF985, 'M', u''),
    (0xF986, 'M', u''),
    (0xF987, 'M', u''),
    (0xF988, 'M', u''),
    (0xF989, 'M', u''),
    (0xF98A, 'M', u''),
    (0xF98B, 'M', u''),
    (0xF98C, 'M', u''),
    (0xF98D, 'M', u''),
    (0xF98E, 'M', u''),
    (0xF98F, 'M', u''),
    (0xF990, 'M', u''),
    (0xF991, 'M', u''),
    (0xF992, 'M', u''),
    (0xF993, 'M', u''),
    (0xF994, 'M', u''),
    (0xF995, 'M', u''),
    (0xF996, 'M', u''),
    (0xF997, 'M', u''),
    (0xF998, 'M', u''),
    (0xF999, 'M', u''),
    (0xF99A, 'M', u''),
    (0xF99B, 'M', u''),
    (0xF99C, 'M', u''),
    (0xF99D, 'M', u''),
    (0xF99E, 'M', u''),
    (0xF99F, 'M', u''),
    (0xF9A0, 'M', u''),
    (0xF9A1, 'M', u''),
    (0xF9A2, 'M', u''),
    (0xF9A3, 'M', u''),
    (0xF9A4, 'M', u''),
    (0xF9A5, 'M', u''),
    (0xF9A6, 'M', u''),
    (0xF9A7, 'M', u''),
    (0xF9A8, 'M', u''),
    (0xF9A9, 'M', u''),
    (0xF9AA, 'M', u''),
    (0xF9AB, 'M', u''),
    (0xF9AC, 'M', u''),
    (0xF9AD, 'M', u''),
    (0xF9AE, 'M', u''),
    (0xF9AF, 'M', u''),
    (0xF9B0, 'M', u''),
    (0xF9B1, 'M', u''),
    (0xF9B2, 'M', u''),
    ]

def _seg_41():
    return [
    (0xF9B3, 'M', u''),
    (0xF9B4, 'M', u''),
    (0xF9B5, 'M', u''),
    (0xF9B6, 'M', u''),
    (0xF9B7, 'M', u''),
    (0xF9B8, 'M', u''),
    (0xF9B9, 'M', u''),
    (0xF9BA, 'M', u''),
    (0xF9BB, 'M', u''),
    (0xF9BC, 'M', u''),
    (0xF9BD, 'M', u''),
    (0xF9BE, 'M', u''),
    (0xF9BF, 'M', u''),
    (0xF9C0, 'M', u''),
    (0xF9C1, 'M', u''),
    (0xF9C2, 'M', u''),
    (0xF9C3, 'M', u''),
    (0xF9C4, 'M', u''),
    (0xF9C5, 'M', u''),
    (0xF9C6, 'M', u''),
    (0xF9C7, 'M', u''),
    (0xF9C8, 'M', u''),
    (0xF9C9, 'M', u''),
    (0xF9CA, 'M', u''),
    (0xF9CB, 'M', u''),
    (0xF9CC, 'M', u''),
    (0xF9CD, 'M', u''),
    (0xF9CE, 'M', u''),
    (0xF9CF, 'M', u''),
    (0xF9D0, 'M', u''),
    (0xF9D1, 'M', u''),
    (0xF9D2, 'M', u''),
    (0xF9D3, 'M', u''),
    (0xF9D4, 'M', u''),
    (0xF9D5, 'M', u''),
    (0xF9D6, 'M', u''),
    (0xF9D7, 'M', u''),
    (0xF9D8, 'M', u''),
    (0xF9D9, 'M', u''),
    (0xF9DA, 'M', u''),
    (0xF9DB, 'M', u''),
    (0xF9DC, 'M', u''),
    (0xF9DD, 'M', u''),
    (0xF9DE, 'M', u''),
    (0xF9DF, 'M', u''),
    (0xF9E0, 'M', u''),
    (0xF9E1, 'M', u''),
    (0xF9E2, 'M', u''),
    (0xF9E3, 'M', u''),
    (0xF9E4, 'M', u''),
    (0xF9E5, 'M', u''),
    (0xF9E6, 'M', u''),
    (0xF9E7, 'M', u''),
    (0xF9E8, 'M', u''),
    (0xF9E9, 'M', u''),
    (0xF9EA, 'M', u''),
    (0xF9EB, 'M', u''),
    (0xF9EC, 'M', u''),
    (0xF9ED, 'M', u''),
    (0xF9EE, 'M', u''),
    (0xF9EF, 'M', u''),
    (0xF9F0, 'M', u''),
    (0xF9F1, 'M', u''),
    (0xF9F2, 'M', u''),
    (0xF9F3, 'M', u''),
    (0xF9F4, 'M', u''),
    (0xF9F5, 'M', u''),
    (0xF9F6, 'M', u''),
    (0xF9F7, 'M', u''),
    (0xF9F8, 'M', u''),
    (0xF9F9, 'M', u''),
    (0xF9FA, 'M', u''),
    (0xF9FB, 'M', u''),
    (0xF9FC, 'M', u''),
    (0xF9FD, 'M', u''),
    (0xF9FE, 'M', u''),
    (0xF9FF, 'M', u''),
    (0xFA00, 'M', u''),
    (0xFA01, 'M', u''),
    (0xFA02, 'M', u''),
    (0xFA03, 'M', u''),
    (0xFA04, 'M', u''),
    (0xFA05, 'M', u''),
    (0xFA06, 'M', u''),
    (0xFA07, 'M', u''),
    (0xFA08, 'M', u''),
    (0xFA09, 'M', u''),
    (0xFA0A, 'M', u''),
    (0xFA0B, 'M', u''),
    (0xFA0C, 'M', u''),
    (0xFA0D, 'M', u''),
    (0xFA0E, 'V'),
    (0xFA10, 'M', u''),
    (0xFA11, 'V'),
    (0xFA12, 'M', u''),
    (0xFA13, 'V'),
    (0xFA15, 'M', u''),
    (0xFA16, 'M', u''),
    (0xFA17, 'M', u''),
    (0xFA18, 'M', u''),
    ]

def _seg_42():
    return [
    (0xFA19, 'M', u''),
    (0xFA1A, 'M', u''),
    (0xFA1B, 'M', u''),
    (0xFA1C, 'M', u''),
    (0xFA1D, 'M', u''),
    (0xFA1E, 'M', u''),
    (0xFA1F, 'V'),
    (0xFA20, 'M', u''),
    (0xFA21, 'V'),
    (0xFA22, 'M', u''),
    (0xFA23, 'V'),
    (0xFA25, 'M', u''),
    (0xFA26, 'M', u''),
    (0xFA27, 'V'),
    (0xFA2A, 'M', u''),
    (0xFA2B, 'M', u''),
    (0xFA2C, 'M', u''),
    (0xFA2D, 'M', u''),
    (0xFA2E, 'M', u''),
    (0xFA2F, 'M', u''),
    (0xFA30, 'M', u''),
    (0xFA31, 'M', u''),
    (0xFA32, 'M', u''),
    (0xFA33, 'M', u''),
    (0xFA34, 'M', u''),
    (0xFA35, 'M', u''),
    (0xFA36, 'M', u''),
    (0xFA37, 'M', u''),
    (0xFA38, 'M', u''),
    (0xFA39, 'M', u''),
    (0xFA3A, 'M', u''),
    (0xFA3B, 'M', u''),
    (0xFA3C, 'M', u''),
    (0xFA3D, 'M', u''),
    (0xFA3E, 'M', u''),
    (0xFA3F, 'M', u''),
    (0xFA40, 'M', u''),
    (0xFA41, 'M', u''),
    (0xFA42, 'M', u''),
    (0xFA43, 'M', u''),
    (0xFA44, 'M', u''),
    (0xFA45, 'M', u''),
    (0xFA46, 'M', u''),
    (0xFA47, 'M', u''),
    (0xFA48, 'M', u''),
    (0xFA49, 'M', u''),
    (0xFA4A, 'M', u''),
    (0xFA4B, 'M', u''),
    (0xFA4C, 'M', u''),
    (0xFA4D, 'M', u''),
    (0xFA4E, 'M', u''),
    (0xFA4F, 'M', u''),
    (0xFA50, 'M', u''),
    (0xFA51, 'M', u''),
    (0xFA52, 'M', u''),
    (0xFA53, 'M', u''),
    (0xFA54, 'M', u''),
    (0xFA55, 'M', u''),
    (0xFA56, 'M', u''),
    (0xFA57, 'M', u''),
    (0xFA58, 'M', u''),
    (0xFA59, 'M', u''),
    (0xFA5A, 'M', u''),
    (0xFA5B, 'M', u''),
    (0xFA5C, 'M', u''),
    (0xFA5D, 'M', u''),
    (0xFA5F, 'M', u''),
    (0xFA60, 'M', u''),
    (0xFA61, 'M', u''),
    (0xFA62, 'M', u''),
    (0xFA63, 'M', u''),
    (0xFA64, 'M', u''),
    (0xFA65, 'M', u''),
    (0xFA66, 'M', u''),
    (0xFA67, 'M', u''),
    (0xFA68, 'M', u''),
    (0xFA69, 'M', u''),
    (0xFA6A, 'M', u''),
    (0xFA6B, 'M', u''),
    (0xFA6C, 'M', u''),
    (0xFA6D, 'M', u''),
    (0xFA6E, 'X'),
    (0xFA70, 'M', u''),
    (0xFA71, 'M', u''),
    (0xFA72, 'M', u''),
    (0xFA73, 'M', u''),
    (0xFA74, 'M', u''),
    (0xFA75, 'M', u''),
    (0xFA76, 'M', u''),
    (0xFA77, 'M', u''),
    (0xFA78, 'M', u''),
    (0xFA79, 'M', u''),
    (0xFA7A, 'M', u''),
    (0xFA7B, 'M', u''),
    (0xFA7C, 'M', u''),
    (0xFA7D, 'M', u''),
    (0xFA7E, 'M', u''),
    (0xFA7F, 'M', u''),
    (0xFA80, 'M', u''),
    (0xFA81, 'M', u''),
    ]

def _seg_43():
    return [
    (0xFA82, 'M', u''),
    (0xFA83, 'M', u''),
    (0xFA84, 'M', u''),
    (0xFA85, 'M', u''),
    (0xFA86, 'M', u''),
    (0xFA87, 'M', u''),
    (0xFA88, 'M', u''),
    (0xFA89, 'M', u''),
    (0xFA8A, 'M', u''),
    (0xFA8B, 'M', u''),
    (0xFA8C, 'M', u''),
    (0xFA8D, 'M', u''),
    (0xFA8E, 'M', u''),
    (0xFA8F, 'M', u''),
    (0xFA90, 'M', u''),
    (0xFA91, 'M', u''),
    (0xFA92, 'M', u''),
    (0xFA93, 'M', u''),
    (0xFA94, 'M', u''),
    (0xFA95, 'M', u''),
    (0xFA96, 'M', u''),
    (0xFA97, 'M', u''),
    (0xFA98, 'M', u''),
    (0xFA99, 'M', u''),
    (0xFA9A, 'M', u''),
    (0xFA9B, 'M', u''),
    (0xFA9C, 'M', u''),
    (0xFA9D, 'M', u''),
    (0xFA9E, 'M', u''),
    (0xFA9F, 'M', u''),
    (0xFAA0, 'M', u''),
    (0xFAA1, 'M', u''),
    (0xFAA2, 'M', u''),
    (0xFAA3, 'M', u''),
    (0xFAA4, 'M', u''),
    (0xFAA5, 'M', u''),
    (0xFAA6, 'M', u''),
    (0xFAA7, 'M', u''),
    (0xFAA8, 'M', u''),
    (0xFAA9, 'M', u''),
    (0xFAAA, 'M', u''),
    (0xFAAB, 'M', u''),
    (0xFAAC, 'M', u''),
    (0xFAAD, 'M', u''),
    (0xFAAE, 'M', u''),
    (0xFAAF, 'M', u''),
    (0xFAB0, 'M', u''),
    (0xFAB1, 'M', u''),
    (0xFAB2, 'M', u''),
    (0xFAB3, 'M', u''),
    (0xFAB4, 'M', u''),
    (0xFAB5, 'M', u''),
    (0xFAB6, 'M', u''),
    (0xFAB7, 'M', u''),
    (0xFAB8, 'M', u''),
    (0xFAB9, 'M', u''),
    (0xFABA, 'M', u''),
    (0xFABB, 'M', u''),
    (0xFABC, 'M', u''),
    (0xFABD, 'M', u''),
    (0xFABE, 'M', u''),
    (0xFABF, 'M', u''),
    (0xFAC0, 'M', u''),
    (0xFAC1, 'M', u''),
    (0xFAC2, 'M', u''),
    (0xFAC3, 'M', u''),
    (0xFAC4, 'M', u''),
    (0xFAC5, 'M', u''),
    (0xFAC6, 'M', u''),
    (0xFAC7, 'M', u''),
    (0xFAC8, 'M', u''),
    (0xFAC9, 'M', u''),
    (0xFACA, 'M', u''),
    (0xFACB, 'M', u''),
    (0xFACC, 'M', u''),
    (0xFACD, 'M', u''),
    (0xFACE, 'M', u''),
    (0xFACF, 'M', u''),
    (0xFAD0, 'M', u''),
    (0xFAD1, 'M', u''),
    (0xFAD2, 'M', u''),
    (0xFAD3, 'M', u''),
    (0xFAD4, 'M', u''),
    (0xFAD5, 'M', u''),
    (0xFAD6, 'M', u''),
    (0xFAD7, 'M', u''),
    (0xFAD8, 'M', u''),
    (0xFAD9, 'M', u''),
    (0xFADA, 'X'),
    (0xFB00, 'M', u'ff'),
    (0xFB01, 'M', u'fi'),
    (0xFB02, 'M', u'fl'),
    (0xFB03, 'M', u'ffi'),
    (0xFB04, 'M', u'ffl'),
    (0xFB05, 'M', u'st'),
    (0xFB07, 'X'),
    (0xFB13, 'M', u''),
    (0xFB14, 'M', u''),
    (0xFB15, 'M', u''),
    (0xFB16, 'M', u''),
    ]

def _seg_44():
    return [
    (0xFB17, 'M', u''),
    (0xFB18, 'X'),
    (0xFB1D, 'M', u''),
    (0xFB1E, 'V'),
    (0xFB1F, 'M', u''),
    (0xFB20, 'M', u''),
    (0xFB21, 'M', u''),
    (0xFB22, 'M', u''),
    (0xFB23, 'M', u''),
    (0xFB24, 'M', u''),
    (0xFB25, 'M', u''),
    (0xFB26, 'M', u''),
    (0xFB27, 'M', u''),
    (0xFB28, 'M', u''),
    (0xFB29, '3', u'+'),
    (0xFB2A, 'M', u''),
    (0xFB2B, 'M', u''),
    (0xFB2C, 'M', u''),
    (0xFB2D, 'M', u''),
    (0xFB2E, 'M', u''),
    (0xFB2F, 'M', u''),
    (0xFB30, 'M', u''),
    (0xFB31, 'M', u''),
    (0xFB32, 'M', u''),
    (0xFB33, 'M', u''),
    (0xFB34, 'M', u''),
    (0xFB35, 'M', u''),
    (0xFB36, 'M', u''),
    (0xFB37, 'X'),
    (0xFB38, 'M', u''),
    (0xFB39, 'M', u''),
    (0xFB3A, 'M', u''),
    (0xFB3B, 'M', u''),
    (0xFB3C, 'M', u''),
    (0xFB3D, 'X'),
    (0xFB3E, 'M', u''),
    (0xFB3F, 'X'),
    (0xFB40, 'M', u''),
    (0xFB41, 'M', u''),
    (0xFB42, 'X'),
    (0xFB43, 'M', u''),
    (0xFB44, 'M', u''),
    (0xFB45, 'X'),
    (0xFB46, 'M', u''),
    (0xFB47, 'M', u''),
    (0xFB48, 'M', u''),
    (0xFB49, 'M', u''),
    (0xFB4A, 'M', u''),
    (0xFB4B, 'M', u''),
    (0xFB4C, 'M', u''),
    (0xFB4D, 'M', u''),
    (0xFB4E, 'M', u''),
    (0xFB4F, 'M', u''),
    (0xFB50, 'M', u''),
    (0xFB52, 'M', u''),
    (0xFB56, 'M', u''),
    (0xFB5A, 'M', u''),
    (0xFB5E, 'M', u''),
    (0xFB62, 'M', u''),
    (0xFB66, 'M', u''),
    (0xFB6A, 'M', u''),
    (0xFB6E, 'M', u''),
    (0xFB72, 'M', u''),
    (0xFB76, 'M', u''),
    (0xFB7A, 'M', u''),
    (0xFB7E, 'M', u''),
    (0xFB82, 'M', u''),
    (0xFB84, 'M', u''),
    (0xFB86, 'M', u''),
    (0xFB88, 'M', u''),
    (0xFB8A, 'M', u''),
    (0xFB8C, 'M', u''),
    (0xFB8E, 'M', u''),
    (0xFB92, 'M', u''),
    (0xFB96, 'M', u''),
    (0xFB9A, 'M', u''),
    (0xFB9E, 'M', u''),
    (0xFBA0, 'M', u''),
    (0xFBA4, 'M', u''),
    (0xFBA6, 'M', u''),
    (0xFBAA, 'M', u''),
    (0xFBAE, 'M', u''),
    (0xFBB0, 'M', u''),
    (0xFBB2, 'V'),
    (0xFBC2, 'X'),
    (0xFBD3, 'M', u''),
    (0xFBD7, 'M', u''),
    (0xFBD9, 'M', u''),
    (0xFBDB, 'M', u''),
    (0xFBDD, 'M', u''),
    (0xFBDE, 'M', u''),
    (0xFBE0, 'M', u''),
    (0xFBE2, 'M', u''),
    (0xFBE4, 'M', u''),
    (0xFBE8, 'M', u''),
    (0xFBEA, 'M', u''),
    (0xFBEC, 'M', u''),
    (0xFBEE, 'M', u''),
    (0xFBF0, 'M', u''),
    (0xFBF2, 'M', u''),
    ]

def _seg_45():
    return [
    (0xFBF4, 'M', u''),
    (0xFBF6, 'M', u''),
    (0xFBF9, 'M', u''),
    (0xFBFC, 'M', u''),
    (0xFC00, 'M', u''),
    (0xFC01, 'M', u''),
    (0xFC02, 'M', u''),
    (0xFC03, 'M', u''),
    (0xFC04, 'M', u''),
    (0xFC05, 'M', u''),
    (0xFC06, 'M', u''),
    (0xFC07, 'M', u''),
    (0xFC08, 'M', u''),
    (0xFC09, 'M', u''),
    (0xFC0A, 'M', u''),
    (0xFC0B, 'M', u''),
    (0xFC0C, 'M', u''),
    (0xFC0D, 'M', u''),
    (0xFC0E, 'M', u''),
    (0xFC0F, 'M', u''),
    (0xFC10, 'M', u''),
    (0xFC11, 'M', u''),
    (0xFC12, 'M', u''),
    (0xFC13, 'M', u''),
    (0xFC14, 'M', u''),
    (0xFC15, 'M', u''),
    (0xFC16, 'M', u''),
    (0xFC17, 'M', u''),
    (0xFC18, 'M', u''),
    (0xFC19, 'M', u''),
    (0xFC1A, 'M', u''),
    (0xFC1B, 'M', u''),
    (0xFC1C, 'M', u''),
    (0xFC1D, 'M', u''),
    (0xFC1E, 'M', u''),
    (0xFC1F, 'M', u''),
    (0xFC20, 'M', u''),
    (0xFC21, 'M', u''),
    (0xFC22, 'M', u''),
    (0xFC23, 'M', u''),
    (0xFC24, 'M', u''),
    (0xFC25, 'M', u''),
    (0xFC26, 'M', u''),
    (0xFC27, 'M', u''),
    (0xFC28, 'M', u''),
    (0xFC29, 'M', u''),
    (0xFC2A, 'M', u''),
    (0xFC2B, 'M', u''),
    (0xFC2C, 'M', u''),
    (0xFC2D, 'M', u''),
    (0xFC2E, 'M', u''),
    (0xFC2F, 'M', u''),
    (0xFC30, 'M', u''),
    (0xFC31, 'M', u''),
    (0xFC32, 'M', u''),
    (0xFC33, 'M', u''),
    (0xFC34, 'M', u''),
    (0xFC35, 'M', u''),
    (0xFC36, 'M', u''),
    (0xFC37, 'M', u''),
    (0xFC38, 'M', u''),
    (0xFC39, 'M', u''),
    (0xFC3A, 'M', u''),
    (0xFC3B, 'M', u''),
    (0xFC3C, 'M', u''),
    (0xFC3D, 'M', u''),
    (0xFC3E, 'M', u''),
    (0xFC3F, 'M', u''),
    (0xFC40, 'M', u''),
    (0xFC41, 'M', u''),
    (0xFC42, 'M', u''),
    (0xFC43, 'M', u''),
    (0xFC44, 'M', u''),
    (0xFC45, 'M', u''),
    (0xFC46, 'M', u''),
    (0xFC47, 'M', u''),
    (0xFC48, 'M', u''),
    (0xFC49, 'M', u''),
    (0xFC4A, 'M', u''),
    (0xFC4B, 'M', u''),
    (0xFC4C, 'M', u''),
    (0xFC4D, 'M', u''),
    (0xFC4E, 'M', u''),
    (0xFC4F, 'M', u''),
    (0xFC50, 'M', u''),
    (0xFC51, 'M', u''),
    (0xFC52, 'M', u''),
    (0xFC53, 'M', u''),
    (0xFC54, 'M', u''),
    (0xFC55, 'M', u''),
    (0xFC56, 'M', u''),
    (0xFC57, 'M', u''),
    (0xFC58, 'M', u''),
    (0xFC59, 'M', u''),
    (0xFC5A, 'M', u''),
    (0xFC5B, 'M', u''),
    (0xFC5C, 'M', u''),
    (0xFC5D, 'M', u''),
    (0xFC5E, '3', u' '),
    (0xFC5F, '3', u' '),
    ]

def _seg_46():
    return [
    (0xFC60, '3', u' '),
    (0xFC61, '3', u' '),
    (0xFC62, '3', u' '),
    (0xFC63, '3', u' '),
    (0xFC64, 'M', u''),
    (0xFC65, 'M', u''),
    (0xFC66, 'M', u''),
    (0xFC67, 'M', u''),
    (0xFC68, 'M', u''),
    (0xFC69, 'M', u''),
    (0xFC6A, 'M', u''),
    (0xFC6B, 'M', u''),
    (0xFC6C, 'M', u''),
    (0xFC6D, 'M', u''),
    (0xFC6E, 'M', u''),
    (0xFC6F, 'M', u''),
    (0xFC70, 'M', u''),
    (0xFC71, 'M', u''),
    (0xFC72, 'M', u''),
    (0xFC73, 'M', u''),
    (0xFC74, 'M', u''),
    (0xFC75, 'M', u''),
    (0xFC76, 'M', u''),
    (0xFC77, 'M', u''),
    (0xFC78, 'M', u''),
    (0xFC79, 'M', u''),
    (0xFC7A, 'M', u''),
    (0xFC7B, 'M', u''),
    (0xFC7C, 'M', u''),
    (0xFC7D, 'M', u''),
    (0xFC7E, 'M', u''),
    (0xFC7F, 'M', u''),
    (0xFC80, 'M', u''),
    (0xFC81, 'M', u''),
    (0xFC82, 'M', u''),
    (0xFC83, 'M', u''),
    (0xFC84, 'M', u''),
    (0xFC85, 'M', u''),
    (0xFC86, 'M', u''),
    (0xFC87, 'M', u''),
    (0xFC88, 'M', u''),
    (0xFC89, 'M', u''),
    (0xFC8A, 'M', u''),
    (0xFC8B, 'M', u''),
    (0xFC8C, 'M', u''),
    (0xFC8D, 'M', u''),
    (0xFC8E, 'M', u''),
    (0xFC8F, 'M', u''),
    (0xFC90, 'M', u''),
    (0xFC91, 'M', u''),
    (0xFC92, 'M', u''),
    (0xFC93, 'M', u''),
    (0xFC94, 'M', u''),
    (0xFC95, 'M', u''),
    (0xFC96, 'M', u''),
    (0xFC97, 'M', u''),
    (0xFC98, 'M', u''),
    (0xFC99, 'M', u''),
    (0xFC9A, 'M', u''),
    (0xFC9B, 'M', u''),
    (0xFC9C, 'M', u''),
    (0xFC9D, 'M', u''),
    (0xFC9E, 'M', u''),
    (0xFC9F, 'M', u''),
    (0xFCA0, 'M', u''),
    (0xFCA1, 'M', u''),
    (0xFCA2, 'M', u''),
    (0xFCA3, 'M', u''),
    (0xFCA4, 'M', u''),
    (0xFCA5, 'M', u''),
    (0xFCA6, 'M', u''),
    (0xFCA7, 'M', u''),
    (0xFCA8, 'M', u''),
    (0xFCA9, 'M', u''),
    (0xFCAA, 'M', u''),
    (0xFCAB, 'M', u''),
    (0xFCAC, 'M', u''),
    (0xFCAD, 'M', u''),
    (0xFCAE, 'M', u''),
    (0xFCAF, 'M', u''),
    (0xFCB0, 'M', u''),
    (0xFCB1, 'M', u''),
    (0xFCB2, 'M', u''),
    (0xFCB3, 'M', u''),
    (0xFCB4, 'M', u''),
    (0xFCB5, 'M', u''),
    (0xFCB6, 'M', u''),
    (0xFCB7, 'M', u''),
    (0xFCB8, 'M', u''),
    (0xFCB9, 'M', u''),
    (0xFCBA, 'M', u''),
    (0xFCBB, 'M', u''),
    (0xFCBC, 'M', u''),
    (0xFCBD, 'M', u''),
    (0xFCBE, 'M', u''),
    (0xFCBF, 'M', u''),
    (0xFCC0, 'M', u''),
    (0xFCC1, 'M', u''),
    (0xFCC2, 'M', u''),
    (0xFCC3, 'M', u''),
    ]

def _seg_47():
    return [
    (0xFCC4, 'M', u''),
    (0xFCC5, 'M', u''),
    (0xFCC6, 'M', u''),
    (0xFCC7, 'M', u''),
    (0xFCC8, 'M', u''),
    (0xFCC9, 'M', u''),
    (0xFCCA, 'M', u''),
    (0xFCCB, 'M', u''),
    (0xFCCC, 'M', u''),
    (0xFCCD, 'M', u''),
    (0xFCCE, 'M', u''),
    (0xFCCF, 'M', u''),
    (0xFCD0, 'M', u''),
    (0xFCD1, 'M', u''),
    (0xFCD2, 'M', u''),
    (0xFCD3, 'M', u''),
    (0xFCD4, 'M', u''),
    (0xFCD5, 'M', u''),
    (0xFCD6, 'M', u''),
    (0xFCD7, 'M', u''),
    (0xFCD8, 'M', u''),
    (0xFCD9, 'M', u''),
    (0xFCDA, 'M', u''),
    (0xFCDB, 'M', u''),
    (0xFCDC, 'M', u''),
    (0xFCDD, 'M', u''),
    (0xFCDE, 'M', u''),
    (0xFCDF, 'M', u''),
    (0xFCE0, 'M', u''),
    (0xFCE1, 'M', u''),
    (0xFCE2, 'M', u''),
    (0xFCE3, 'M', u''),
    (0xFCE4, 'M', u''),
    (0xFCE5, 'M', u''),
    (0xFCE6, 'M', u''),
    (0xFCE7, 'M', u''),
    (0xFCE8, 'M', u''),
    (0xFCE9, 'M', u''),
    (0xFCEA, 'M', u''),
    (0xFCEB, 'M', u''),
    (0xFCEC, 'M', u''),
    (0xFCED, 'M', u''),
    (0xFCEE, 'M', u''),
    (0xFCEF, 'M', u''),
    (0xFCF0, 'M', u''),
    (0xFCF1, 'M', u''),
    (0xFCF2, 'M', u''),
    (0xFCF3, 'M', u''),
    (0xFCF4, 'M', u''),
    (0xFCF5, 'M', u''),
    (0xFCF6, 'M', u''),
    (0xFCF7, 'M', u''),
    (0xFCF8, 'M', u''),
    (0xFCF9, 'M', u''),
    (0xFCFA, 'M', u''),
    (0xFCFB, 'M', u''),
    (0xFCFC, 'M', u''),
    (0xFCFD, 'M', u''),
    (0xFCFE, 'M', u''),
    (0xFCFF, 'M', u''),
    (0xFD00, 'M', u''),
    (0xFD01, 'M', u''),
    (0xFD02, 'M', u''),
    (0xFD03, 'M', u''),
    (0xFD04, 'M', u''),
    (0xFD05, 'M', u''),
    (0xFD06, 'M', u''),
    (0xFD07, 'M', u''),
    (0xFD08, 'M', u''),
    (0xFD09, 'M', u''),
    (0xFD0A, 'M', u''),
    (0xFD0B, 'M', u''),
    (0xFD0C, 'M', u''),
    (0xFD0D, 'M', u''),
    (0xFD0E, 'M', u''),
    (0xFD0F, 'M', u''),
    (0xFD10, 'M', u''),
    (0xFD11, 'M', u''),
    (0xFD12, 'M', u''),
    (0xFD13, 'M', u''),
    (0xFD14, 'M', u''),
    (0xFD15, 'M', u''),
    (0xFD16, 'M', u''),
    (0xFD17, 'M', u''),
    (0xFD18, 'M', u''),
    (0xFD19, 'M', u''),
    (0xFD1A, 'M', u''),
    (0xFD1B, 'M', u''),
    (0xFD1C, 'M', u''),
    (0xFD1D, 'M', u''),
    (0xFD1E, 'M', u''),
    (0xFD1F, 'M', u''),
    (0xFD20, 'M', u''),
    (0xFD21, 'M', u''),
    (0xFD22, 'M', u''),
    (0xFD23, 'M', u''),
    (0xFD24, 'M', u''),
    (0xFD25, 'M', u''),
    (0xFD26, 'M', u''),
    (0xFD27, 'M', u''),
    ]

def _seg_48():
    return [
    (0xFD28, 'M', u''),
    (0xFD29, 'M', u''),
    (0xFD2A, 'M', u''),
    (0xFD2B, 'M', u''),
    (0xFD2C, 'M', u''),
    (0xFD2D, 'M', u''),
    (0xFD2E, 'M', u''),
    (0xFD2F, 'M', u''),
    (0xFD30, 'M', u''),
    (0xFD31, 'M', u''),
    (0xFD32, 'M', u''),
    (0xFD33, 'M', u''),
    (0xFD34, 'M', u''),
    (0xFD35, 'M', u''),
    (0xFD36, 'M', u''),
    (0xFD37, 'M', u''),
    (0xFD38, 'M', u''),
    (0xFD39, 'M', u''),
    (0xFD3A, 'M', u''),
    (0xFD3B, 'M', u''),
    (0xFD3C, 'M', u''),
    (0xFD3E, 'V'),
    (0xFD40, 'X'),
    (0xFD50, 'M', u''),
    (0xFD51, 'M', u''),
    (0xFD53, 'M', u''),
    (0xFD54, 'M', u''),
    (0xFD55, 'M', u''),
    (0xFD56, 'M', u''),
    (0xFD57, 'M', u''),
    (0xFD58, 'M', u''),
    (0xFD5A, 'M', u''),
    (0xFD5B, 'M', u''),
    (0xFD5C, 'M', u''),
    (0xFD5D, 'M', u''),
    (0xFD5E, 'M', u''),
    (0xFD5F, 'M', u''),
    (0xFD61, 'M', u''),
    (0xFD62, 'M', u''),
    (0xFD64, 'M', u''),
    (0xFD66, 'M', u''),
    (0xFD67, 'M', u''),
    (0xFD69, 'M', u''),
    (0xFD6A, 'M', u''),
    (0xFD6C, 'M', u''),
    (0xFD6E, 'M', u''),
    (0xFD6F, 'M', u''),
    (0xFD71, 'M', u''),
    (0xFD73, 'M', u''),
    (0xFD74, 'M', u''),
    (0xFD75, 'M', u''),
    (0xFD76, 'M', u''),
    (0xFD78, 'M', u''),
    (0xFD79, 'M', u''),
    (0xFD7A, 'M', u''),
    (0xFD7B, 'M', u''),
    (0xFD7C, 'M', u''),
    (0xFD7E, 'M', u''),
    (0xFD7F, 'M', u''),
    (0xFD80, 'M', u''),
    (0xFD81, 'M', u''),
    (0xFD82, 'M', u''),
    (0xFD83, 'M', u''),
    (0xFD85, 'M', u''),
    (0xFD87, 'M', u''),
    (0xFD89, 'M', u''),
    (0xFD8A, 'M', u''),
    (0xFD8B, 'M', u''),
    (0xFD8C, 'M', u''),
    (0xFD8D, 'M', u''),
    (0xFD8E, 'M', u''),
    (0xFD8F, 'M', u''),
    (0xFD90, 'X'),
    (0xFD92, 'M', u''),
    (0xFD93, 'M', u''),
    (0xFD94, 'M', u''),
    (0xFD95, 'M', u''),
    (0xFD96, 'M', u''),
    (0xFD97, 'M', u''),
    (0xFD99, 'M', u''),
    (0xFD9A, 'M', u''),
    (0xFD9B, 'M', u''),
    (0xFD9C, 'M', u''),
    (0xFD9E, 'M', u''),
    (0xFD9F, 'M', u''),
    (0xFDA0, 'M', u''),
    (0xFDA1, 'M', u''),
    (0xFDA2, 'M', u''),
    (0xFDA3, 'M', u''),
    (0xFDA4, 'M', u''),
    (0xFDA5, 'M', u''),
    (0xFDA6, 'M', u''),
    (0xFDA7, 'M', u''),
    (0xFDA8, 'M', u''),
    (0xFDA9, 'M', u''),
    (0xFDAA, 'M', u''),
    (0xFDAB, 'M', u''),
    (0xFDAC, 'M', u''),
    (0xFDAD, 'M', u''),
    (0xFDAE, 'M', u''),
    ]

def _seg_49():
    return [
    (0xFDAF, 'M', u''),
    (0xFDB0, 'M', u''),
    (0xFDB1, 'M', u''),
    (0xFDB2, 'M', u''),
    (0xFDB3, 'M', u''),
    (0xFDB4, 'M', u''),
    (0xFDB5, 'M', u''),
    (0xFDB6, 'M', u''),
    (0xFDB7, 'M', u''),
    (0xFDB8, 'M', u''),
    (0xFDB9, 'M', u''),
    (0xFDBA, 'M', u''),
    (0xFDBB, 'M', u''),
    (0xFDBC, 'M', u''),
    (0xFDBD, 'M', u''),
    (0xFDBE, 'M', u''),
    (0xFDBF, 'M', u''),
    (0xFDC0, 'M', u''),
    (0xFDC1, 'M', u''),
    (0xFDC2, 'M', u''),
    (0xFDC3, 'M', u''),
    (0xFDC4, 'M', u''),
    (0xFDC5, 'M', u''),
    (0xFDC6, 'M', u''),
    (0xFDC7, 'M', u''),
    (0xFDC8, 'X'),
    (0xFDF0, 'M', u''),
    (0xFDF1, 'M', u''),
    (0xFDF2, 'M', u''),
    (0xFDF3, 'M', u''),
    (0xFDF4, 'M', u''),
    (0xFDF5, 'M', u''),
    (0xFDF6, 'M', u''),
    (0xFDF7, 'M', u''),
    (0xFDF8, 'M', u''),
    (0xFDF9, 'M', u''),
    (0xFDFA, '3', u'   '),
    (0xFDFB, '3', u' '),
    (0xFDFC, 'M', u''),
    (0xFDFD, 'V'),
    (0xFDFE, 'X'),
    (0xFE00, 'I'),
    (0xFE10, '3', u','),
    (0xFE11, 'M', u''),
    (0xFE12, 'X'),
    (0xFE13, '3', u':'),
    (0xFE14, '3', u';'),
    (0xFE15, '3', u'!'),
    (0xFE16, '3', u'?'),
    (0xFE17, 'M', u''),
    (0xFE18, 'M', u''),
    (0xFE19, 'X'),
    (0xFE20, 'V'),
    (0xFE30, 'X'),
    (0xFE31, 'M', u''),
    (0xFE32, 'M', u''),
    (0xFE33, '3', u'_'),
    (0xFE35, '3', u'('),
    (0xFE36, '3', u')'),
    (0xFE37, '3', u'{'),
    (0xFE38, '3', u'}'),
    (0xFE39, 'M', u''),
    (0xFE3A, 'M', u''),
    (0xFE3B, 'M', u''),
    (0xFE3C, 'M', u''),
    (0xFE3D, 'M', u''),
    (0xFE3E, 'M', u''),
    (0xFE3F, 'M', u''),
    (0xFE40, 'M', u''),
    (0xFE41, 'M', u''),
    (0xFE42, 'M', u''),
    (0xFE43, 'M', u''),
    (0xFE44, 'M', u''),
    (0xFE45, 'V'),
    (0xFE47, '3', u'['),
    (0xFE48, '3', u']'),
    (0xFE49, '3', u' '),
    (0xFE4D, '3', u'_'),
    (0xFE50, '3', u','),
    (0xFE51, 'M', u''),
    (0xFE52, 'X'),
    (0xFE54, '3', u';'),
    (0xFE55, '3', u':'),
    (0xFE56, '3', u'?'),
    (0xFE57, '3', u'!'),
    (0xFE58, 'M', u''),
    (0xFE59, '3', u'('),
    (0xFE5A, '3', u')'),
    (0xFE5B, '3', u'{'),
    (0xFE5C, '3', u'}'),
    (0xFE5D, 'M', u''),
    (0xFE5E, 'M', u''),
    (0xFE5F, '3', u'#'),
    (0xFE60, '3', u'&'),
    (0xFE61, '3', u'*'),
    (0xFE62, '3', u'+'),
    (0xFE63, 'M', u'-'),
    (0xFE64, '3', u'<'),
    (0xFE65, '3', u'>'),
    (0xFE66, '3', u'='),
    ]

def _seg_50():
    return [
    (0xFE67, 'X'),
    (0xFE68, '3', u'\\'),
    (0xFE69, '3', u'$'),
    (0xFE6A, '3', u'%'),
    (0xFE6B, '3', u'@'),
    (0xFE6C, 'X'),
    (0xFE70, '3', u' '),
    (0xFE71, 'M', u''),
    (0xFE72, '3', u' '),
    (0xFE73, 'V'),
    (0xFE74, '3', u' '),
    (0xFE75, 'X'),
    (0xFE76, '3', u' '),
    (0xFE77, 'M', u''),
    (0xFE78, '3', u' '),
    (0xFE79, 'M', u''),
    (0xFE7A, '3', u' '),
    (0xFE7B, 'M', u''),
    (0xFE7C, '3', u' '),
    (0xFE7D, 'M', u''),
    (0xFE7E, '3', u' '),
    (0xFE7F, 'M', u''),
    (0xFE80, 'M', u''),
    (0xFE81, 'M', u''),
    (0xFE83, 'M', u''),
    (0xFE85, 'M', u''),
    (0xFE87, 'M', u''),
    (0xFE89, 'M', u''),
    (0xFE8D, 'M', u''),
    (0xFE8F, 'M', u''),
    (0xFE93, 'M', u''),
    (0xFE95, 'M', u''),
    (0xFE99, 'M', u''),
    (0xFE9D, 'M', u''),
    (0xFEA1, 'M', u''),
    (0xFEA5, 'M', u''),
    (0xFEA9, 'M', u''),
    (0xFEAB, 'M', u''),
    (0xFEAD, 'M', u''),
    (0xFEAF, 'M', u''),
    (0xFEB1, 'M', u''),
    (0xFEB5, 'M', u''),
    (0xFEB9, 'M', u''),
    (0xFEBD, 'M', u''),
    (0xFEC1, 'M', u''),
    (0xFEC5, 'M', u''),
    (0xFEC9, 'M', u''),
    (0xFECD, 'M', u''),
    (0xFED1, 'M', u''),
    (0xFED5, 'M', u''),
    (0xFED9, 'M', u''),
    (0xFEDD, 'M', u''),
    (0xFEE1, 'M', u''),
    (0xFEE5, 'M', u''),
    (0xFEE9, 'M', u''),
    (0xFEED, 'M', u''),
    (0xFEEF, 'M', u''),
    (0xFEF1, 'M', u''),
    (0xFEF5, 'M', u''),
    (0xFEF7, 'M', u''),
    (0xFEF9, 'M', u''),
    (0xFEFB, 'M', u''),
    (0xFEFD, 'X'),
    (0xFEFF, 'I'),
    (0xFF00, 'X'),
    (0xFF01, '3', u'!'),
    (0xFF02, '3', u'"'),
    (0xFF03, '3', u'#'),
    (0xFF04, '3', u'$'),
    (0xFF05, '3', u'%'),
    (0xFF06, '3', u'&'),
    (0xFF07, '3', u'\''),
    (0xFF08, '3', u'('),
    (0xFF09, '3', u')'),
    (0xFF0A, '3', u'*'),
    (0xFF0B, '3', u'+'),
    (0xFF0C, '3', u','),
    (0xFF0D, 'M', u'-'),
    (0xFF0E, 'M', u'.'),
    (0xFF0F, '3', u'/'),
    (0xFF10, 'M', u'0'),
    (0xFF11, 'M', u'1'),
    (0xFF12, 'M', u'2'),
    (0xFF13, 'M', u'3'),
    (0xFF14, 'M', u'4'),
    (0xFF15, 'M', u'5'),
    (0xFF16, 'M', u'6'),
    (0xFF17, 'M', u'7'),
    (0xFF18, 'M', u'8'),
    (0xFF19, 'M', u'9'),
    (0xFF1A, '3', u':'),
    (0xFF1B, '3', u';'),
    (0xFF1C, '3', u'<'),
    (0xFF1D, '3', u'='),
    (0xFF1E, '3', u'>'),
    (0xFF1F, '3', u'?'),
    (0xFF20, '3', u'@'),
    (0xFF21, 'M', u'a'),
    (0xFF22, 'M', u'b'),
    (0xFF23, 'M', u'c'),
    ]

def _seg_51():
    return [
    (0xFF24, 'M', u'd'),
    (0xFF25, 'M', u'e'),
    (0xFF26, 'M', u'f'),
    (0xFF27, 'M', u'g'),
    (0xFF28, 'M', u'h'),
    (0xFF29, 'M', u'i'),
    (0xFF2A, 'M', u'j'),
    (0xFF2B, 'M', u'k'),
    (0xFF2C, 'M', u'l'),
    (0xFF2D, 'M', u'm'),
    (0xFF2E, 'M', u'n'),
    (0xFF2F, 'M', u'o'),
    (0xFF30, 'M', u'p'),
    (0xFF31, 'M', u'q'),
    (0xFF32, 'M', u'r'),
    (0xFF33, 'M', u's'),
    (0xFF34, 'M', u't'),
    (0xFF35, 'M', u'u'),
    (0xFF36, 'M', u'v'),
    (0xFF37, 'M', u'w'),
    (0xFF38, 'M', u'x'),
    (0xFF39, 'M', u'y'),
    (0xFF3A, 'M', u'z'),
    (0xFF3B, '3', u'['),
    (0xFF3C, '3', u'\\'),
    (0xFF3D, '3', u']'),
    (0xFF3E, '3', u'^'),
    (0xFF3F, '3', u'_'),
    (0xFF40, '3', u'`'),
    (0xFF41, 'M', u'a'),
    (0xFF42, 'M', u'b'),
    (0xFF43, 'M', u'c'),
    (0xFF44, 'M', u'd'),
    (0xFF45, 'M', u'e'),
    (0xFF46, 'M', u'f'),
    (0xFF47, 'M', u'g'),
    (0xFF48, 'M', u'h'),
    (0xFF49, 'M', u'i'),
    (0xFF4A, 'M', u'j'),
    (0xFF4B, 'M', u'k'),
    (0xFF4C, 'M', u'l'),
    (0xFF4D, 'M', u'm'),
    (0xFF4E, 'M', u'n'),
    (0xFF4F, 'M', u'o'),
    (0xFF50, 'M', u'p'),
    (0xFF51, 'M', u'q'),
    (0xFF52, 'M', u'r'),
    (0xFF53, 'M', u's'),
    (0xFF54, 'M', u't'),
    (0xFF55, 'M', u'u'),
    (0xFF56, 'M', u'v'),
    (0xFF57, 'M', u'w'),
    (0xFF58, 'M', u'x'),
    (0xFF59, 'M', u'y'),
    (0xFF5A, 'M', u'z'),
    (0xFF5B, '3', u'{'),
    (0xFF5C, '3', u'|'),
    (0xFF5D, '3', u'}'),
    (0xFF5E, '3', u'~'),
    (0xFF5F, 'M', u''),
    (0xFF60, 'M', u''),
    (0xFF61, 'M', u'.'),
    (0xFF62, 'M', u''),
    (0xFF63, 'M', u''),
    (0xFF64, 'M', u''),
    (0xFF65, 'M', u''),
    (0xFF66, 'M', u''),
    (0xFF67, 'M', u''),
    (0xFF68, 'M', u''),
    (0xFF69, 'M', u''),
    (0xFF6A, 'M', u''),
    (0xFF6B, 'M', u''),
    (0xFF6C, 'M', u''),
    (0xFF6D, 'M', u''),
    (0xFF6E, 'M', u''),
    (0xFF6F, 'M', u''),
    (0xFF70, 'M', u''),
    (0xFF71, 'M', u''),
    (0xFF72, 'M', u''),
    (0xFF73, 'M', u''),
    (0xFF74, 'M', u''),
    (0xFF75, 'M', u''),
    (0xFF76, 'M', u''),
    (0xFF77, 'M', u''),
    (0xFF78, 'M', u''),
    (0xFF79, 'M', u''),
    (0xFF7A, 'M', u''),
    (0xFF7B, 'M', u''),
    (0xFF7C, 'M', u''),
    (0xFF7D, 'M', u''),
    (0xFF7E, 'M', u''),
    (0xFF7F, 'M', u''),
    (0xFF80, 'M', u''),
    (0xFF81, 'M', u''),
    (0xFF82, 'M', u''),
    (0xFF83, 'M', u''),
    (0xFF84, 'M', u''),
    (0xFF85, 'M', u''),
    (0xFF86, 'M', u''),
    (0xFF87, 'M', u''),
    ]

def _seg_52():
    return [
    (0xFF88, 'M', u''),
    (0xFF89, 'M', u''),
    (0xFF8A, 'M', u''),
    (0xFF8B, 'M', u''),
    (0xFF8C, 'M', u''),
    (0xFF8D, 'M', u''),
    (0xFF8E, 'M', u''),
    (0xFF8F, 'M', u''),
    (0xFF90, 'M', u''),
    (0xFF91, 'M', u''),
    (0xFF92, 'M', u''),
    (0xFF93, 'M', u''),
    (0xFF94, 'M', u''),
    (0xFF95, 'M', u''),
    (0xFF96, 'M', u''),
    (0xFF97, 'M', u''),
    (0xFF98, 'M', u''),
    (0xFF99, 'M', u''),
    (0xFF9A, 'M', u''),
    (0xFF9B, 'M', u''),
    (0xFF9C, 'M', u''),
    (0xFF9D, 'M', u''),
    (0xFF9E, 'M', u''),
    (0xFF9F, 'M', u''),
    (0xFFA0, 'X'),
    (0xFFA1, 'M', u''),
    (0xFFA2, 'M', u''),
    (0xFFA3, 'M', u''),
    (0xFFA4, 'M', u''),
    (0xFFA5, 'M', u''),
    (0xFFA6, 'M', u''),
    (0xFFA7, 'M', u''),
    (0xFFA8, 'M', u''),
    (0xFFA9, 'M', u''),
    (0xFFAA, 'M', u''),
    (0xFFAB, 'M', u''),
    (0xFFAC, 'M', u''),
    (0xFFAD, 'M', u''),
    (0xFFAE, 'M', u''),
    (0xFFAF, 'M', u''),
    (0xFFB0, 'M', u''),
    (0xFFB1, 'M', u''),
    (0xFFB2, 'M', u''),
    (0xFFB3, 'M', u''),
    (0xFFB4, 'M', u''),
    (0xFFB5, 'M', u''),
    (0xFFB6, 'M', u''),
    (0xFFB7, 'M', u''),
    (0xFFB8, 'M', u''),
    (0xFFB9, 'M', u''),
    (0xFFBA, 'M', u''),
    (0xFFBB, 'M', u''),
    (0xFFBC, 'M', u''),
    (0xFFBD, 'M', u''),
    (0xFFBE, 'M', u''),
    (0xFFBF, 'X'),
    (0xFFC2, 'M', u''),
    (0xFFC3, 'M', u''),
    (0xFFC4, 'M', u''),
    (0xFFC5, 'M', u''),
    (0xFFC6, 'M', u''),
    (0xFFC7, 'M', u''),
    (0xFFC8, 'X'),
    (0xFFCA, 'M', u''),
    (0xFFCB, 'M', u''),
    (0xFFCC, 'M', u''),
    (0xFFCD, 'M', u''),
    (0xFFCE, 'M', u''),
    (0xFFCF, 'M', u''),
    (0xFFD0, 'X'),
    (0xFFD2, 'M', u''),
    (0xFFD3, 'M', u''),
    (0xFFD4, 'M', u''),
    (0xFFD5, 'M', u''),
    (0xFFD6, 'M', u''),
    (0xFFD7, 'M', u''),
    (0xFFD8, 'X'),
    (0xFFDA, 'M', u''),
    (0xFFDB, 'M', u''),
    (0xFFDC, 'M', u''),
    (0xFFDD, 'X'),
    (0xFFE0, 'M', u''),
    (0xFFE1, 'M', u''),
    (0xFFE2, 'M', u''),
    (0xFFE3, '3', u' '),
    (0xFFE4, 'M', u''),
    (0xFFE5, 'M', u''),
    (0xFFE6, 'M', u''),
    (0xFFE7, 'X'),
    (0xFFE8, 'M', u''),
    (0xFFE9, 'M', u''),
    (0xFFEA, 'M', u''),
    (0xFFEB, 'M', u''),
    (0xFFEC, 'M', u''),
    (0xFFED, 'M', u''),
    (0xFFEE, 'M', u''),
    (0xFFEF, 'X'),
    (0x10000, 'V'),
    (0x1000C, 'X'),
    (0x1000D, 'V'),
    ]

def _seg_53():
    return [
    (0x10027, 'X'),
    (0x10028, 'V'),
    (0x1003B, 'X'),
    (0x1003C, 'V'),
    (0x1003E, 'X'),
    (0x1003F, 'V'),
    (0x1004E, 'X'),
    (0x10050, 'V'),
    (0x1005E, 'X'),
    (0x10080, 'V'),
    (0x100FB, 'X'),
    (0x10100, 'V'),
    (0x10103, 'X'),
    (0x10107, 'V'),
    (0x10134, 'X'),
    (0x10137, 'V'),
    (0x1018F, 'X'),
    (0x10190, 'V'),
    (0x1019D, 'X'),
    (0x101A0, 'V'),
    (0x101A1, 'X'),
    (0x101D0, 'V'),
    (0x101FE, 'X'),
    (0x10280, 'V'),
    (0x1029D, 'X'),
    (0x102A0, 'V'),
    (0x102D1, 'X'),
    (0x102E0, 'V'),
    (0x102FC, 'X'),
    (0x10300, 'V'),
    (0x10324, 'X'),
    (0x1032D, 'V'),
    (0x1034B, 'X'),
    (0x10350, 'V'),
    (0x1037B, 'X'),
    (0x10380, 'V'),
    (0x1039E, 'X'),
    (0x1039F, 'V'),
    (0x103C4, 'X'),
    (0x103C8, 'V'),
    (0x103D6, 'X'),
    (0x10400, 'M', u''),
    (0x10401, 'M', u''),
    (0x10402, 'M', u''),
    (0x10403, 'M', u''),
    (0x10404, 'M', u''),
    (0x10405, 'M', u''),
    (0x10406, 'M', u''),
    (0x10407, 'M', u''),
    (0x10408, 'M', u''),
    (0x10409, 'M', u''),
    (0x1040A, 'M', u''),
    (0x1040B, 'M', u''),
    (0x1040C, 'M', u''),
    (0x1040D, 'M', u''),
    (0x1040E, 'M', u''),
    (0x1040F, 'M', u''),
    (0x10410, 'M', u''),
    (0x10411, 'M', u''),
    (0x10412, 'M', u''),
    (0x10413, 'M', u''),
    (0x10414, 'M', u''),
    (0x10415, 'M', u''),
    (0x10416, 'M', u''),
    (0x10417, 'M', u''),
    (0x10418, 'M', u''),
    (0x10419, 'M', u''),
    (0x1041A, 'M', u''),
    (0x1041B, 'M', u''),
    (0x1041C, 'M', u''),
    (0x1041D, 'M', u''),
    (0x1041E, 'M', u''),
    (0x1041F, 'M', u''),
    (0x10420, 'M', u''),
    (0x10421, 'M', u''),
    (0x10422, 'M', u''),
    (0x10423, 'M', u''),
    (0x10424, 'M', u''),
    (0x10425, 'M', u''),
    (0x10426, 'M', u''),
    (0x10427, 'M', u''),
    (0x10428, 'V'),
    (0x1049E, 'X'),
    (0x104A0, 'V'),
    (0x104AA, 'X'),
    (0x104B0, 'M', u''),
    (0x104B1, 'M', u''),
    (0x104B2, 'M', u''),
    (0x104B3, 'M', u''),
    (0x104B4, 'M', u''),
    (0x104B5, 'M', u''),
    (0x104B6, 'M', u''),
    (0x104B7, 'M', u''),
    (0x104B8, 'M', u''),
    (0x104B9, 'M', u''),
    (0x104BA, 'M', u''),
    (0x104BB, 'M', u''),
    (0x104BC, 'M', u''),
    (0x104BD, 'M', u''),
    (0x104BE, 'M', u''),
    ]

def _seg_54():
    return [
    (0x104BF, 'M', u''),
    (0x104C0, 'M', u''),
    (0x104C1, 'M', u''),
    (0x104C2, 'M', u''),
    (0x104C3, 'M', u''),
    (0x104C4, 'M', u''),
    (0x104C5, 'M', u''),
    (0x104C6, 'M', u''),
    (0x104C7, 'M', u''),
    (0x104C8, 'M', u''),
    (0x104C9, 'M', u''),
    (0x104CA, 'M', u''),
    (0x104CB, 'M', u''),
    (0x104CC, 'M', u''),
    (0x104CD, 'M', u''),
    (0x104CE, 'M', u''),
    (0x104CF, 'M', u''),
    (0x104D0, 'M', u''),
    (0x104D1, 'M', u''),
    (0x104D2, 'M', u''),
    (0x104D3, 'M', u''),
    (0x104D4, 'X'),
    (0x104D8, 'V'),
    (0x104FC, 'X'),
    (0x10500, 'V'),
    (0x10528, 'X'),
    (0x10530, 'V'),
    (0x10564, 'X'),
    (0x1056F, 'V'),
    (0x10570, 'X'),
    (0x10600, 'V'),
    (0x10737, 'X'),
    (0x10740, 'V'),
    (0x10756, 'X'),
    (0x10760, 'V'),
    (0x10768, 'X'),
    (0x10800, 'V'),
    (0x10806, 'X'),
    (0x10808, 'V'),
    (0x10809, 'X'),
    (0x1080A, 'V'),
    (0x10836, 'X'),
    (0x10837, 'V'),
    (0x10839, 'X'),
    (0x1083C, 'V'),
    (0x1083D, 'X'),
    (0x1083F, 'V'),
    (0x10856, 'X'),
    (0x10857, 'V'),
    (0x1089F, 'X'),
    (0x108A7, 'V'),
    (0x108B0, 'X'),
    (0x108E0, 'V'),
    (0x108F3, 'X'),
    (0x108F4, 'V'),
    (0x108F6, 'X'),
    (0x108FB, 'V'),
    (0x1091C, 'X'),
    (0x1091F, 'V'),
    (0x1093A, 'X'),
    (0x1093F, 'V'),
    (0x10940, 'X'),
    (0x10980, 'V'),
    (0x109B8, 'X'),
    (0x109BC, 'V'),
    (0x109D0, 'X'),
    (0x109D2, 'V'),
    (0x10A04, 'X'),
    (0x10A05, 'V'),
    (0x10A07, 'X'),
    (0x10A0C, 'V'),
    (0x10A14, 'X'),
    (0x10A15, 'V'),
    (0x10A18, 'X'),
    (0x10A19, 'V'),
    (0x10A36, 'X'),
    (0x10A38, 'V'),
    (0x10A3B, 'X'),
    (0x10A3F, 'V'),
    (0x10A49, 'X'),
    (0x10A50, 'V'),
    (0x10A59, 'X'),
    (0x10A60, 'V'),
    (0x10AA0, 'X'),
    (0x10AC0, 'V'),
    (0x10AE7, 'X'),
    (0x10AEB, 'V'),
    (0x10AF7, 'X'),
    (0x10B00, 'V'),
    (0x10B36, 'X'),
    (0x10B39, 'V'),
    (0x10B56, 'X'),
    (0x10B58, 'V'),
    (0x10B73, 'X'),
    (0x10B78, 'V'),
    (0x10B92, 'X'),
    (0x10B99, 'V'),
    (0x10B9D, 'X'),
    (0x10BA9, 'V'),
    (0x10BB0, 'X'),
    ]

def _seg_55():
    return [
    (0x10C00, 'V'),
    (0x10C49, 'X'),
    (0x10C80, 'M', u''),
    (0x10C81, 'M', u''),
    (0x10C82, 'M', u''),
    (0x10C83, 'M', u''),
    (0x10C84, 'M', u''),
    (0x10C85, 'M', u''),
    (0x10C86, 'M', u''),
    (0x10C87, 'M', u''),
    (0x10C88, 'M', u''),
    (0x10C89, 'M', u''),
    (0x10C8A, 'M', u''),
    (0x10C8B, 'M', u''),
    (0x10C8C, 'M', u''),
    (0x10C8D, 'M', u''),
    (0x10C8E, 'M', u''),
    (0x10C8F, 'M', u''),
    (0x10C90, 'M', u''),
    (0x10C91, 'M', u''),
    (0x10C92, 'M', u''),
    (0x10C93, 'M', u''),
    (0x10C94, 'M', u''),
    (0x10C95, 'M', u''),
    (0x10C96, 'M', u''),
    (0x10C97, 'M', u''),
    (0x10C98, 'M', u''),
    (0x10C99, 'M', u''),
    (0x10C9A, 'M', u''),
    (0x10C9B, 'M', u''),
    (0x10C9C, 'M', u''),
    (0x10C9D, 'M', u''),
    (0x10C9E, 'M', u''),
    (0x10C9F, 'M', u''),
    (0x10CA0, 'M', u''),
    (0x10CA1, 'M', u''),
    (0x10CA2, 'M', u''),
    (0x10CA3, 'M', u''),
    (0x10CA4, 'M', u''),
    (0x10CA5, 'M', u''),
    (0x10CA6, 'M', u''),
    (0x10CA7, 'M', u''),
    (0x10CA8, 'M', u''),
    (0x10CA9, 'M', u''),
    (0x10CAA, 'M', u''),
    (0x10CAB, 'M', u''),
    (0x10CAC, 'M', u''),
    (0x10CAD, 'M', u''),
    (0x10CAE, 'M', u''),
    (0x10CAF, 'M', u''),
    (0x10CB0, 'M', u''),
    (0x10CB1, 'M', u''),
    (0x10CB2, 'M', u''),
    (0x10CB3, 'X'),
    (0x10CC0, 'V'),
    (0x10CF3, 'X'),
    (0x10CFA, 'V'),
    (0x10D28, 'X'),
    (0x10D30, 'V'),
    (0x10D3A, 'X'),
    (0x10E60, 'V'),
    (0x10E7F, 'X'),
    (0x10E80, 'V'),
    (0x10EAA, 'X'),
    (0x10EAB, 'V'),
    (0x10EAE, 'X'),
    (0x10EB0, 'V'),
    (0x10EB2, 'X'),
    (0x10F00, 'V'),
    (0x10F28, 'X'),
    (0x10F30, 'V'),
    (0x10F5A, 'X'),
    (0x10FB0, 'V'),
    (0x10FCC, 'X'),
    (0x10FE0, 'V'),
    (0x10FF7, 'X'),
    (0x11000, 'V'),
    (0x1104E, 'X'),
    (0x11052, 'V'),
    (0x11070, 'X'),
    (0x1107F, 'V'),
    (0x110BD, 'X'),
    (0x110BE, 'V'),
    (0x110C2, 'X'),
    (0x110D0, 'V'),
    (0x110E9, 'X'),
    (0x110F0, 'V'),
    (0x110FA, 'X'),
    (0x11100, 'V'),
    (0x11135, 'X'),
    (0x11136, 'V'),
    (0x11148, 'X'),
    (0x11150, 'V'),
    (0x11177, 'X'),
    (0x11180, 'V'),
    (0x111E0, 'X'),
    (0x111E1, 'V'),
    (0x111F5, 'X'),
    (0x11200, 'V'),
    (0x11212, 'X'),
    ]

def _seg_56():
    return [
    (0x11213, 'V'),
    (0x1123F, 'X'),
    (0x11280, 'V'),
    (0x11287, 'X'),
    (0x11288, 'V'),
    (0x11289, 'X'),
    (0x1128A, 'V'),
    (0x1128E, 'X'),
    (0x1128F, 'V'),
    (0x1129E, 'X'),
    (0x1129F, 'V'),
    (0x112AA, 'X'),
    (0x112B0, 'V'),
    (0x112EB, 'X'),
    (0x112F0, 'V'),
    (0x112FA, 'X'),
    (0x11300, 'V'),
    (0x11304, 'X'),
    (0x11305, 'V'),
    (0x1130D, 'X'),
    (0x1130F, 'V'),
    (0x11311, 'X'),
    (0x11313, 'V'),
    (0x11329, 'X'),
    (0x1132A, 'V'),
    (0x11331, 'X'),
    (0x11332, 'V'),
    (0x11334, 'X'),
    (0x11335, 'V'),
    (0x1133A, 'X'),
    (0x1133B, 'V'),
    (0x11345, 'X'),
    (0x11347, 'V'),
    (0x11349, 'X'),
    (0x1134B, 'V'),
    (0x1134E, 'X'),
    (0x11350, 'V'),
    (0x11351, 'X'),
    (0x11357, 'V'),
    (0x11358, 'X'),
    (0x1135D, 'V'),
    (0x11364, 'X'),
    (0x11366, 'V'),
    (0x1136D, 'X'),
    (0x11370, 'V'),
    (0x11375, 'X'),
    (0x11400, 'V'),
    (0x1145C, 'X'),
    (0x1145D, 'V'),
    (0x11462, 'X'),
    (0x11480, 'V'),
    (0x114C8, 'X'),
    (0x114D0, 'V'),
    (0x114DA, 'X'),
    (0x11580, 'V'),
    (0x115B6, 'X'),
    (0x115B8, 'V'),
    (0x115DE, 'X'),
    (0x11600, 'V'),
    (0x11645, 'X'),
    (0x11650, 'V'),
    (0x1165A, 'X'),
    (0x11660, 'V'),
    (0x1166D, 'X'),
    (0x11680, 'V'),
    (0x116B9, 'X'),
    (0x116C0, 'V'),
    (0x116CA, 'X'),
    (0x11700, 'V'),
    (0x1171B, 'X'),
    (0x1171D, 'V'),
    (0x1172C, 'X'),
    (0x11730, 'V'),
    (0x11740, 'X'),
    (0x11800, 'V'),
    (0x1183C, 'X'),
    (0x118A0, 'M', u''),
    (0x118A1, 'M', u''),
    (0x118A2, 'M', u''),
    (0x118A3, 'M', u''),
    (0x118A4, 'M', u''),
    (0x118A5, 'M', u''),
    (0x118A6, 'M', u''),
    (0x118A7, 'M', u''),
    (0x118A8, 'M', u''),
    (0x118A9, 'M', u''),
    (0x118AA, 'M', u''),
    (0x118AB, 'M', u''),
    (0x118AC, 'M', u''),
    (0x118AD, 'M', u''),
    (0x118AE, 'M', u''),
    (0x118AF, 'M', u''),
    (0x118B0, 'M', u''),
    (0x118B1, 'M', u''),
    (0x118B2, 'M', u''),
    (0x118B3, 'M', u''),
    (0x118B4, 'M', u''),
    (0x118B5, 'M', u''),
    (0x118B6, 'M', u''),
    (0x118B7, 'M', u''),
    ]

def _seg_57():
    return [
    (0x118B8, 'M', u''),
    (0x118B9, 'M', u''),
    (0x118BA, 'M', u''),
    (0x118BB, 'M', u''),
    (0x118BC, 'M', u''),
    (0x118BD, 'M', u''),
    (0x118BE, 'M', u''),
    (0x118BF, 'M', u''),
    (0x118C0, 'V'),
    (0x118F3, 'X'),
    (0x118FF, 'V'),
    (0x11907, 'X'),
    (0x11909, 'V'),
    (0x1190A, 'X'),
    (0x1190C, 'V'),
    (0x11914, 'X'),
    (0x11915, 'V'),
    (0x11917, 'X'),
    (0x11918, 'V'),
    (0x11936, 'X'),
    (0x11937, 'V'),
    (0x11939, 'X'),
    (0x1193B, 'V'),
    (0x11947, 'X'),
    (0x11950, 'V'),
    (0x1195A, 'X'),
    (0x119A0, 'V'),
    (0x119A8, 'X'),
    (0x119AA, 'V'),
    (0x119D8, 'X'),
    (0x119DA, 'V'),
    (0x119E5, 'X'),
    (0x11A00, 'V'),
    (0x11A48, 'X'),
    (0x11A50, 'V'),
    (0x11AA3, 'X'),
    (0x11AC0, 'V'),
    (0x11AF9, 'X'),
    (0x11C00, 'V'),
    (0x11C09, 'X'),
    (0x11C0A, 'V'),
    (0x11C37, 'X'),
    (0x11C38, 'V'),
    (0x11C46, 'X'),
    (0x11C50, 'V'),
    (0x11C6D, 'X'),
    (0x11C70, 'V'),
    (0x11C90, 'X'),
    (0x11C92, 'V'),
    (0x11CA8, 'X'),
    (0x11CA9, 'V'),
    (0x11CB7, 'X'),
    (0x11D00, 'V'),
    (0x11D07, 'X'),
    (0x11D08, 'V'),
    (0x11D0A, 'X'),
    (0x11D0B, 'V'),
    (0x11D37, 'X'),
    (0x11D3A, 'V'),
    (0x11D3B, 'X'),
    (0x11D3C, 'V'),
    (0x11D3E, 'X'),
    (0x11D3F, 'V'),
    (0x11D48, 'X'),
    (0x11D50, 'V'),
    (0x11D5A, 'X'),
    (0x11D60, 'V'),
    (0x11D66, 'X'),
    (0x11D67, 'V'),
    (0x11D69, 'X'),
    (0x11D6A, 'V'),
    (0x11D8F, 'X'),
    (0x11D90, 'V'),
    (0x11D92, 'X'),
    (0x11D93, 'V'),
    (0x11D99, 'X'),
    (0x11DA0, 'V'),
    (0x11DAA, 'X'),
    (0x11EE0, 'V'),
    (0x11EF9, 'X'),
    (0x11FB0, 'V'),
    (0x11FB1, 'X'),
    (0x11FC0, 'V'),
    (0x11FF2, 'X'),
    (0x11FFF, 'V'),
    (0x1239A, 'X'),
    (0x12400, 'V'),
    (0x1246F, 'X'),
    (0x12470, 'V'),
    (0x12475, 'X'),
    (0x12480, 'V'),
    (0x12544, 'X'),
    (0x13000, 'V'),
    (0x1342F, 'X'),
    (0x14400, 'V'),
    (0x14647, 'X'),
    (0x16800, 'V'),
    (0x16A39, 'X'),
    (0x16A40, 'V'),
    (0x16A5F, 'X'),
    ]

def _seg_58():
    return [
    (0x16A60, 'V'),
    (0x16A6A, 'X'),
    (0x16A6E, 'V'),
    (0x16A70, 'X'),
    (0x16AD0, 'V'),
    (0x16AEE, 'X'),
    (0x16AF0, 'V'),
    (0x16AF6, 'X'),
    (0x16B00, 'V'),
    (0x16B46, 'X'),
    (0x16B50, 'V'),
    (0x16B5A, 'X'),
    (0x16B5B, 'V'),
    (0x16B62, 'X'),
    (0x16B63, 'V'),
    (0x16B78, 'X'),
    (0x16B7D, 'V'),
    (0x16B90, 'X'),
    (0x16E40, 'M', u''),
    (0x16E41, 'M', u''),
    (0x16E42, 'M', u''),
    (0x16E43, 'M', u''),
    (0x16E44, 'M', u''),
    (0x16E45, 'M', u''),
    (0x16E46, 'M', u''),
    (0x16E47, 'M', u''),
    (0x16E48, 'M', u''),
    (0x16E49, 'M', u''),
    (0x16E4A, 'M', u''),
    (0x16E4B, 'M', u''),
    (0x16E4C, 'M', u''),
    (0x16E4D, 'M', u''),
    (0x16E4E, 'M', u''),
    (0x16E4F, 'M', u''),
    (0x16E50, 'M', u''),
    (0x16E51, 'M', u''),
    (0x16E52, 'M', u''),
    (0x16E53, 'M', u''),
    (0x16E54, 'M', u''),
    (0x16E55, 'M', u''),
    (0x16E56, 'M', u''),
    (0x16E57, 'M', u''),
    (0x16E58, 'M', u''),
    (0x16E59, 'M', u''),
    (0x16E5A, 'M', u''),
    (0x16E5B, 'M', u''),
    (0x16E5C, 'M', u''),
    (0x16E5D, 'M', u''),
    (0x16E5E, 'M', u''),
    (0x16E5F, 'M', u''),
    (0x16E60, 'V'),
    (0x16E9B, 'X'),
    (0x16F00, 'V'),
    (0x16F4B, 'X'),
    (0x16F4F, 'V'),
    (0x16F88, 'X'),
    (0x16F8F, 'V'),
    (0x16FA0, 'X'),
    (0x16FE0, 'V'),
    (0x16FE5, 'X'),
    (0x16FF0, 'V'),
    (0x16FF2, 'X'),
    (0x17000, 'V'),
    (0x187F8, 'X'),
    (0x18800, 'V'),
    (0x18CD6, 'X'),
    (0x18D00, 'V'),
    (0x18D09, 'X'),
    (0x1B000, 'V'),
    (0x1B11F, 'X'),
    (0x1B150, 'V'),
    (0x1B153, 'X'),
    (0x1B164, 'V'),
    (0x1B168, 'X'),
    (0x1B170, 'V'),
    (0x1B2FC, 'X'),
    (0x1BC00, 'V'),
    (0x1BC6B, 'X'),
    (0x1BC70, 'V'),
    (0x1BC7D, 'X'),
    (0x1BC80, 'V'),
    (0x1BC89, 'X'),
    (0x1BC90, 'V'),
    (0x1BC9A, 'X'),
    (0x1BC9C, 'V'),
    (0x1BCA0, 'I'),
    (0x1BCA4, 'X'),
    (0x1D000, 'V'),
    (0x1D0F6, 'X'),
    (0x1D100, 'V'),
    (0x1D127, 'X'),
    (0x1D129, 'V'),
    (0x1D15E, 'M', u''),
    (0x1D15F, 'M', u''),
    (0x1D160, 'M', u''),
    (0x1D161, 'M', u''),
    (0x1D162, 'M', u''),
    (0x1D163, 'M', u''),
    (0x1D164, 'M', u''),
    (0x1D165, 'V'),
    ]

def _seg_59():
    return [
    (0x1D173, 'X'),
    (0x1D17B, 'V'),
    (0x1D1BB, 'M', u''),
    (0x1D1BC, 'M', u''),
    (0x1D1BD, 'M', u''),
    (0x1D1BE, 'M', u''),
    (0x1D1BF, 'M', u''),
    (0x1D1C0, 'M', u''),
    (0x1D1C1, 'V'),
    (0x1D1E9, 'X'),
    (0x1D200, 'V'),
    (0x1D246, 'X'),
    (0x1D2E0, 'V'),
    (0x1D2F4, 'X'),
    (0x1D300, 'V'),
    (0x1D357, 'X'),
    (0x1D360, 'V'),
    (0x1D379, 'X'),
    (0x1D400, 'M', u'a'),
    (0x1D401, 'M', u'b'),
    (0x1D402, 'M', u'c'),
    (0x1D403, 'M', u'd'),
    (0x1D404, 'M', u'e'),
    (0x1D405, 'M', u'f'),
    (0x1D406, 'M', u'g'),
    (0x1D407, 'M', u'h'),
    (0x1D408, 'M', u'i'),
    (0x1D409, 'M', u'j'),
    (0x1D40A, 'M', u'k'),
    (0x1D40B, 'M', u'l'),
    (0x1D40C, 'M', u'm'),
    (0x1D40D, 'M', u'n'),
    (0x1D40E, 'M', u'o'),
    (0x1D40F, 'M', u'p'),
    (0x1D410, 'M', u'q'),
    (0x1D411, 'M', u'r'),
    (0x1D412, 'M', u's'),
    (0x1D413, 'M', u't'),
    (0x1D414, 'M', u'u'),
    (0x1D415, 'M', u'v'),
    (0x1D416, 'M', u'w'),
    (0x1D417, 'M', u'x'),
    (0x1D418, 'M', u'y'),
    (0x1D419, 'M', u'z'),
    (0x1D41A, 'M', u'a'),
    (0x1D41B, 'M', u'b'),
    (0x1D41C, 'M', u'c'),
    (0x1D41D, 'M', u'd'),
    (0x1D41E, 'M', u'e'),
    (0x1D41F, 'M', u'f'),
    (0x1D420, 'M', u'g'),
    (0x1D421, 'M', u'h'),
    (0x1D422, 'M', u'i'),
    (0x1D423, 'M', u'j'),
    (0x1D424, 'M', u'k'),
    (0x1D425, 'M', u'l'),
    (0x1D426, 'M', u'm'),
    (0x1D427, 'M', u'n'),
    (0x1D428, 'M', u'o'),
    (0x1D429, 'M', u'p'),
    (0x1D42A, 'M', u'q'),
    (0x1D42B, 'M', u'r'),
    (0x1D42C, 'M', u's'),
    (0x1D42D, 'M', u't'),
    (0x1D42E, 'M', u'u'),
    (0x1D42F, 'M', u'v'),
    (0x1D430, 'M', u'w'),
    (0x1D431, 'M', u'x'),
    (0x1D432, 'M', u'y'),
    (0x1D433, 'M', u'z'),
    (0x1D434, 'M', u'a'),
    (0x1D435, 'M', u'b'),
    (0x1D436, 'M', u'c'),
    (0x1D437, 'M', u'd'),
    (0x1D438, 'M', u'e'),
    (0x1D439, 'M', u'f'),
    (0x1D43A, 'M', u'g'),
    (0x1D43B, 'M', u'h'),
    (0x1D43C, 'M', u'i'),
    (0x1D43D, 'M', u'j'),
    (0x1D43E, 'M', u'k'),
    (0x1D43F, 'M', u'l'),
    (0x1D440, 'M', u'm'),
    (0x1D441, 'M', u'n'),
    (0x1D442, 'M', u'o'),
    (0x1D443, 'M', u'p'),
    (0x1D444, 'M', u'q'),
    (0x1D445, 'M', u'r'),
    (0x1D446, 'M', u's'),
    (0x1D447, 'M', u't'),
    (0x1D448, 'M', u'u'),
    (0x1D449, 'M', u'v'),
    (0x1D44A, 'M', u'w'),
    (0x1D44B, 'M', u'x'),
    (0x1D44C, 'M', u'y'),
    (0x1D44D, 'M', u'z'),
    (0x1D44E, 'M', u'a'),
    (0x1D44F, 'M', u'b'),
    (0x1D450, 'M', u'c'),
    (0x1D451, 'M', u'd'),
    ]

def _seg_60():
    return [
    (0x1D452, 'M', u'e'),
    (0x1D453, 'M', u'f'),
    (0x1D454, 'M', u'g'),
    (0x1D455, 'X'),
    (0x1D456, 'M', u'i'),
    (0x1D457, 'M', u'j'),
    (0x1D458, 'M', u'k'),
    (0x1D459, 'M', u'l'),
    (0x1D45A, 'M', u'm'),
    (0x1D45B, 'M', u'n'),
    (0x1D45C, 'M', u'o'),
    (0x1D45D, 'M', u'p'),
    (0x1D45E, 'M', u'q'),
    (0x1D45F, 'M', u'r'),
    (0x1D460, 'M', u's'),
    (0x1D461, 'M', u't'),
    (0x1D462, 'M', u'u'),
    (0x1D463, 'M', u'v'),
    (0x1D464, 'M', u'w'),
    (0x1D465, 'M', u'x'),
    (0x1D466, 'M', u'y'),
    (0x1D467, 'M', u'z'),
    (0x1D468, 'M', u'a'),
    (0x1D469, 'M', u'b'),
    (0x1D46A, 'M', u'c'),
    (0x1D46B, 'M', u'd'),
    (0x1D46C, 'M', u'e'),
    (0x1D46D, 'M', u'f'),
    (0x1D46E, 'M', u'g'),
    (0x1D46F, 'M', u'h'),
    (0x1D470, 'M', u'i'),
    (0x1D471, 'M', u'j'),
    (0x1D472, 'M', u'k'),
    (0x1D473, 'M', u'l'),
    (0x1D474, 'M', u'm'),
    (0x1D475, 'M', u'n'),
    (0x1D476, 'M', u'o'),
    (0x1D477, 'M', u'p'),
    (0x1D478, 'M', u'q'),
    (0x1D479, 'M', u'r'),
    (0x1D47A, 'M', u's'),
    (0x1D47B, 'M', u't'),
    (0x1D47C, 'M', u'u'),
    (0x1D47D, 'M', u'v'),
    (0x1D47E, 'M', u'w'),
    (0x1D47F, 'M', u'x'),
    (0x1D480, 'M', u'y'),
    (0x1D481, 'M', u'z'),
    (0x1D482, 'M', u'a'),
    (0x1D483, 'M', u'b'),
    (0x1D484, 'M', u'c'),
    (0x1D485, 'M', u'd'),
    (0x1D486, 'M', u'e'),
    (0x1D487, 'M', u'f'),
    (0x1D488, 'M', u'g'),
    (0x1D489, 'M', u'h'),
    (0x1D48A, 'M', u'i'),
    (0x1D48B, 'M', u'j'),
    (0x1D48C, 'M', u'k'),
    (0x1D48D, 'M', u'l'),
    (0x1D48E, 'M', u'm'),
    (0x1D48F, 'M', u'n'),
    (0x1D490, 'M', u'o'),
    (0x1D491, 'M', u'p'),
    (0x1D492, 'M', u'q'),
    (0x1D493, 'M', u'r'),
    (0x1D494, 'M', u's'),
    (0x1D495, 'M', u't'),
    (0x1D496, 'M', u'u'),
    (0x1D497, 'M', u'v'),
    (0x1D498, 'M', u'w'),
    (0x1D499, 'M', u'x'),
    (0x1D49A, 'M', u'y'),
    (0x1D49B, 'M', u'z'),
    (0x1D49C, 'M', u'a'),
    (0x1D49D, 'X'),
    (0x1D49E, 'M', u'c'),
    (0x1D49F, 'M', u'd'),
    (0x1D4A0, 'X'),
    (0x1D4A2, 'M', u'g'),
    (0x1D4A3, 'X'),
    (0x1D4A5, 'M', u'j'),
    (0x1D4A6, 'M', u'k'),
    (0x1D4A7, 'X'),
    (0x1D4A9, 'M', u'n'),
    (0x1D4AA, 'M', u'o'),
    (0x1D4AB, 'M', u'p'),
    (0x1D4AC, 'M', u'q'),
    (0x1D4AD, 'X'),
    (0x1D4AE, 'M', u's'),
    (0x1D4AF, 'M', u't'),
    (0x1D4B0, 'M', u'u'),
    (0x1D4B1, 'M', u'v'),
    (0x1D4B2, 'M', u'w'),
    (0x1D4B3, 'M', u'x'),
    (0x1D4B4, 'M', u'y'),
    (0x1D4B5, 'M', u'z'),
    (0x1D4B6, 'M', u'a'),
    (0x1D4B7, 'M', u'b'),
    (0x1D4B8, 'M', u'c'),
    ]

def _seg_61():
    return [
    (0x1D4B9, 'M', u'd'),
    (0x1D4BA, 'X'),
    (0x1D4BB, 'M', u'f'),
    (0x1D4BC, 'X'),
    (0x1D4BD, 'M', u'h'),
    (0x1D4BE, 'M', u'i'),
    (0x1D4BF, 'M', u'j'),
    (0x1D4C0, 'M', u'k'),
    (0x1D4C1, 'M', u'l'),
    (0x1D4C2, 'M', u'm'),
    (0x1D4C3, 'M', u'n'),
    (0x1D4C4, 'X'),
    (0x1D4C5, 'M', u'p'),
    (0x1D4C6, 'M', u'q'),
    (0x1D4C7, 'M', u'r'),
    (0x1D4C8, 'M', u's'),
    (0x1D4C9, 'M', u't'),
    (0x1D4CA, 'M', u'u'),
    (0x1D4CB, 'M', u'v'),
    (0x1D4CC, 'M', u'w'),
    (0x1D4CD, 'M', u'x'),
    (0x1D4CE, 'M', u'y'),
    (0x1D4CF, 'M', u'z'),
    (0x1D4D0, 'M', u'a'),
    (0x1D4D1, 'M', u'b'),
    (0x1D4D2, 'M', u'c'),
    (0x1D4D3, 'M', u'd'),
    (0x1D4D4, 'M', u'e'),
    (0x1D4D5, 'M', u'f'),
    (0x1D4D6, 'M', u'g'),
    (0x1D4D7, 'M', u'h'),
    (0x1D4D8, 'M', u'i'),
    (0x1D4D9, 'M', u'j'),
    (0x1D4DA, 'M', u'k'),
    (0x1D4DB, 'M', u'l'),
    (0x1D4DC, 'M', u'm'),
    (0x1D4DD, 'M', u'n'),
    (0x1D4DE, 'M', u'o'),
    (0x1D4DF, 'M', u'p'),
    (0x1D4E0, 'M', u'q'),
    (0x1D4E1, 'M', u'r'),
    (0x1D4E2, 'M', u's'),
    (0x1D4E3, 'M', u't'),
    (0x1D4E4, 'M', u'u'),
    (0x1D4E5, 'M', u'v'),
    (0x1D4E6, 'M', u'w'),
    (0x1D4E7, 'M', u'x'),
    (0x1D4E8, 'M', u'y'),
    (0x1D4E9, 'M', u'z'),
    (0x1D4EA, 'M', u'a'),
    (0x1D4EB, 'M', u'b'),
    (0x1D4EC, 'M', u'c'),
    (0x1D4ED, 'M', u'd'),
    (0x1D4EE, 'M', u'e'),
    (0x1D4EF, 'M', u'f'),
    (0x1D4F0, 'M', u'g'),
    (0x1D4F1, 'M', u'h'),
    (0x1D4F2, 'M', u'i'),
    (0x1D4F3, 'M', u'j'),
    (0x1D4F4, 'M', u'k'),
    (0x1D4F5, 'M', u'l'),
    (0x1D4F6, 'M', u'm'),
    (0x1D4F7, 'M', u'n'),
    (0x1D4F8, 'M', u'o'),
    (0x1D4F9, 'M', u'p'),
    (0x1D4FA, 'M', u'q'),
    (0x1D4FB, 'M', u'r'),
    (0x1D4FC, 'M', u's'),
    (0x1D4FD, 'M', u't'),
    (0x1D4FE, 'M', u'u'),
    (0x1D4FF, 'M', u'v'),
    (0x1D500, 'M', u'w'),
    (0x1D501, 'M', u'x'),
    (0x1D502, 'M', u'y'),
    (0x1D503, 'M', u'z'),
    (0x1D504, 'M', u'a'),
    (0x1D505, 'M', u'b'),
    (0x1D506, 'X'),
    (0x1D507, 'M', u'd'),
    (0x1D508, 'M', u'e'),
    (0x1D509, 'M', u'f'),
    (0x1D50A, 'M', u'g'),
    (0x1D50B, 'X'),
    (0x1D50D, 'M', u'j'),
    (0x1D50E, 'M', u'k'),
    (0x1D50F, 'M', u'l'),
    (0x1D510, 'M', u'm'),
    (0x1D511, 'M', u'n'),
    (0x1D512, 'M', u'o'),
    (0x1D513, 'M', u'p'),
    (0x1D514, 'M', u'q'),
    (0x1D515, 'X'),
    (0x1D516, 'M', u's'),
    (0x1D517, 'M', u't'),
    (0x1D518, 'M', u'u'),
    (0x1D519, 'M', u'v'),
    (0x1D51A, 'M', u'w'),
    (0x1D51B, 'M', u'x'),
    (0x1D51C, 'M', u'y'),
    (0x1D51D, 'X'),
    ]

def _seg_62():
    return [
    (0x1D51E, 'M', u'a'),
    (0x1D51F, 'M', u'b'),
    (0x1D520, 'M', u'c'),
    (0x1D521, 'M', u'd'),
    (0x1D522, 'M', u'e'),
    (0x1D523, 'M', u'f'),
    (0x1D524, 'M', u'g'),
    (0x1D525, 'M', u'h'),
    (0x1D526, 'M', u'i'),
    (0x1D527, 'M', u'j'),
    (0x1D528, 'M', u'k'),
    (0x1D529, 'M', u'l'),
    (0x1D52A, 'M', u'm'),
    (0x1D52B, 'M', u'n'),
    (0x1D52C, 'M', u'o'),
    (0x1D52D, 'M', u'p'),
    (0x1D52E, 'M', u'q'),
    (0x1D52F, 'M', u'r'),
    (0x1D530, 'M', u's'),
    (0x1D531, 'M', u't'),
    (0x1D532, 'M', u'u'),
    (0x1D533, 'M', u'v'),
    (0x1D534, 'M', u'w'),
    (0x1D535, 'M', u'x'),
    (0x1D536, 'M', u'y'),
    (0x1D537, 'M', u'z'),
    (0x1D538, 'M', u'a'),
    (0x1D539, 'M', u'b'),
    (0x1D53A, 'X'),
    (0x1D53B, 'M', u'd'),
    (0x1D53C, 'M', u'e'),
    (0x1D53D, 'M', u'f'),
    (0x1D53E, 'M', u'g'),
    (0x1D53F, 'X'),
    (0x1D540, 'M', u'i'),
    (0x1D541, 'M', u'j'),
    (0x1D542, 'M', u'k'),
    (0x1D543, 'M', u'l'),
    (0x1D544, 'M', u'm'),
    (0x1D545, 'X'),
    (0x1D546, 'M', u'o'),
    (0x1D547, 'X'),
    (0x1D54A, 'M', u's'),
    (0x1D54B, 'M', u't'),
    (0x1D54C, 'M', u'u'),
    (0x1D54D, 'M', u'v'),
    (0x1D54E, 'M', u'w'),
    (0x1D54F, 'M', u'x'),
    (0x1D550, 'M', u'y'),
    (0x1D551, 'X'),
    (0x1D552, 'M', u'a'),
    (0x1D553, 'M', u'b'),
    (0x1D554, 'M', u'c'),
    (0x1D555, 'M', u'd'),
    (0x1D556, 'M', u'e'),
    (0x1D557, 'M', u'f'),
    (0x1D558, 'M', u'g'),
    (0x1D559, 'M', u'h'),
    (0x1D55A, 'M', u'i'),
    (0x1D55B, 'M', u'j'),
    (0x1D55C, 'M', u'k'),
    (0x1D55D, 'M', u'l'),
    (0x1D55E, 'M', u'm'),
    (0x1D55F, 'M', u'n'),
    (0x1D560, 'M', u'o'),
    (0x1D561, 'M', u'p'),
    (0x1D562, 'M', u'q'),
    (0x1D563, 'M', u'r'),
    (0x1D564, 'M', u's'),
    (0x1D565, 'M', u't'),
    (0x1D566, 'M', u'u'),
    (0x1D567, 'M', u'v'),
    (0x1D568, 'M', u'w'),
    (0x1D569, 'M', u'x'),
    (0x1D56A, 'M', u'y'),
    (0x1D56B, 'M', u'z'),
    (0x1D56C, 'M', u'a'),
    (0x1D56D, 'M', u'b'),
    (0x1D56E, 'M', u'c'),
    (0x1D56F, 'M', u'd'),
    (0x1D570, 'M', u'e'),
    (0x1D571, 'M', u'f'),
    (0x1D572, 'M', u'g'),
    (0x1D573, 'M', u'h'),
    (0x1D574, 'M', u'i'),
    (0x1D575, 'M', u'j'),
    (0x1D576, 'M', u'k'),
    (0x1D577, 'M', u'l'),
    (0x1D578, 'M', u'm'),
    (0x1D579, 'M', u'n'),
    (0x1D57A, 'M', u'o'),
    (0x1D57B, 'M', u'p'),
    (0x1D57C, 'M', u'q'),
    (0x1D57D, 'M', u'r'),
    (0x1D57E, 'M', u's'),
    (0x1D57F, 'M', u't'),
    (0x1D580, 'M', u'u'),
    (0x1D581, 'M', u'v'),
    (0x1D582, 'M', u'w'),
    (0x1D583, 'M', u'x'),
    ]

def _seg_63():
    return [
    (0x1D584, 'M', u'y'),
    (0x1D585, 'M', u'z'),
    (0x1D586, 'M', u'a'),
    (0x1D587, 'M', u'b'),
    (0x1D588, 'M', u'c'),
    (0x1D589, 'M', u'd'),
    (0x1D58A, 'M', u'e'),
    (0x1D58B, 'M', u'f'),
    (0x1D58C, 'M', u'g'),
    (0x1D58D, 'M', u'h'),
    (0x1D58E, 'M', u'i'),
    (0x1D58F, 'M', u'j'),
    (0x1D590, 'M', u'k'),
    (0x1D591, 'M', u'l'),
    (0x1D592, 'M', u'm'),
    (0x1D593, 'M', u'n'),
    (0x1D594, 'M', u'o'),
    (0x1D595, 'M', u'p'),
    (0x1D596, 'M', u'q'),
    (0x1D597, 'M', u'r'),
    (0x1D598, 'M', u's'),
    (0x1D599, 'M', u't'),
    (0x1D59A, 'M', u'u'),
    (0x1D59B, 'M', u'v'),
    (0x1D59C, 'M', u'w'),
    (0x1D59D, 'M', u'x'),
    (0x1D59E, 'M', u'y'),
    (0x1D59F, 'M', u'z'),
    (0x1D5A0, 'M', u'a'),
    (0x1D5A1, 'M', u'b'),
    (0x1D5A2, 'M', u'c'),
    (0x1D5A3, 'M', u'd'),
    (0x1D5A4, 'M', u'e'),
    (0x1D5A5, 'M', u'f'),
    (0x1D5A6, 'M', u'g'),
    (0x1D5A7, 'M', u'h'),
    (0x1D5A8, 'M', u'i'),
    (0x1D5A9, 'M', u'j'),
    (0x1D5AA, 'M', u'k'),
    (0x1D5AB, 'M', u'l'),
    (0x1D5AC, 'M', u'm'),
    (0x1D5AD, 'M', u'n'),
    (0x1D5AE, 'M', u'o'),
    (0x1D5AF, 'M', u'p'),
    (0x1D5B0, 'M', u'q'),
    (0x1D5B1, 'M', u'r'),
    (0x1D5B2, 'M', u's'),
    (0x1D5B3, 'M', u't'),
    (0x1D5B4, 'M', u'u'),
    (0x1D5B5, 'M', u'v'),
    (0x1D5B6, 'M', u'w'),
    (0x1D5B7, 'M', u'x'),
    (0x1D5B8, 'M', u'y'),
    (0x1D5B9, 'M', u'z'),
    (0x1D5BA, 'M', u'a'),
    (0x1D5BB, 'M', u'b'),
    (0x1D5BC, 'M', u'c'),
    (0x1D5BD, 'M', u'd'),
    (0x1D5BE, 'M', u'e'),
    (0x1D5BF, 'M', u'f'),
    (0x1D5C0, 'M', u'g'),
    (0x1D5C1, 'M', u'h'),
    (0x1D5C2, 'M', u'i'),
    (0x1D5C3, 'M', u'j'),
    (0x1D5C4, 'M', u'k'),
    (0x1D5C5, 'M', u'l'),
    (0x1D5C6, 'M', u'm'),
    (0x1D5C7, 'M', u'n'),
    (0x1D5C8, 'M', u'o'),
    (0x1D5C9, 'M', u'p'),
    (0x1D5CA, 'M', u'q'),
    (0x1D5CB, 'M', u'r'),
    (0x1D5CC, 'M', u's'),
    (0x1D5CD, 'M', u't'),
    (0x1D5CE, 'M', u'u'),
    (0x1D5CF, 'M', u'v'),
    (0x1D5D0, 'M', u'w'),
    (0x1D5D1, 'M', u'x'),
    (0x1D5D2, 'M', u'y'),
    (0x1D5D3, 'M', u'z'),
    (0x1D5D4, 'M', u'a'),
    (0x1D5D5, 'M', u'b'),
    (0x1D5D6, 'M', u'c'),
    (0x1D5D7, 'M', u'd'),
    (0x1D5D8, 'M', u'e'),
    (0x1D5D9, 'M', u'f'),
    (0x1D5DA, 'M', u'g'),
    (0x1D5DB, 'M', u'h'),
    (0x1D5DC, 'M', u'i'),
    (0x1D5DD, 'M', u'j'),
    (0x1D5DE, 'M', u'k'),
    (0x1D5DF, 'M', u'l'),
    (0x1D5E0, 'M', u'm'),
    (0x1D5E1, 'M', u'n'),
    (0x1D5E2, 'M', u'o'),
    (0x1D5E3, 'M', u'p'),
    (0x1D5E4, 'M', u'q'),
    (0x1D5E5, 'M', u'r'),
    (0x1D5E6, 'M', u's'),
    (0x1D5E7, 'M', u't'),
    ]

def _seg_64():
    return [
    (0x1D5E8, 'M', u'u'),
    (0x1D5E9, 'M', u'v'),
    (0x1D5EA, 'M', u'w'),
    (0x1D5EB, 'M', u'x'),
    (0x1D5EC, 'M', u'y'),
    (0x1D5ED, 'M', u'z'),
    (0x1D5EE, 'M', u'a'),
    (0x1D5EF, 'M', u'b'),
    (0x1D5F0, 'M', u'c'),
    (0x1D5F1, 'M', u'd'),
    (0x1D5F2, 'M', u'e'),
    (0x1D5F3, 'M', u'f'),
    (0x1D5F4, 'M', u'g'),
    (0x1D5F5, 'M', u'h'),
    (0x1D5F6, 'M', u'i'),
    (0x1D5F7, 'M', u'j'),
    (0x1D5F8, 'M', u'k'),
    (0x1D5F9, 'M', u'l'),
    (0x1D5FA, 'M', u'm'),
    (0x1D5FB, 'M', u'n'),
    (0x1D5FC, 'M', u'o'),
    (0x1D5FD, 'M', u'p'),
    (0x1D5FE, 'M', u'q'),
    (0x1D5FF, 'M', u'r'),
    (0x1D600, 'M', u's'),
    (0x1D601, 'M', u't'),
    (0x1D602, 'M', u'u'),
    (0x1D603, 'M', u'v'),
    (0x1D604, 'M', u'w'),
    (0x1D605, 'M', u'x'),
    (0x1D606, 'M', u'y'),
    (0x1D607, 'M', u'z'),
    (0x1D608, 'M', u'a'),
    (0x1D609, 'M', u'b'),
    (0x1D60A, 'M', u'c'),
    (0x1D60B, 'M', u'd'),
    (0x1D60C, 'M', u'e'),
    (0x1D60D, 'M', u'f'),
    (0x1D60E, 'M', u'g'),
    (0x1D60F, 'M', u'h'),
    (0x1D610, 'M', u'i'),
    (0x1D611, 'M', u'j'),
    (0x1D612, 'M', u'k'),
    (0x1D613, 'M', u'l'),
    (0x1D614, 'M', u'm'),
    (0x1D615, 'M', u'n'),
    (0x1D616, 'M', u'o'),
    (0x1D617, 'M', u'p'),
    (0x1D618, 'M', u'q'),
    (0x1D619, 'M', u'r'),
    (0x1D61A, 'M', u's'),
    (0x1D61B, 'M', u't'),
    (0x1D61C, 'M', u'u'),
    (0x1D61D, 'M', u'v'),
    (0x1D61E, 'M', u'w'),
    (0x1D61F, 'M', u'x'),
    (0x1D620, 'M', u'y'),
    (0x1D621, 'M', u'z'),
    (0x1D622, 'M', u'a'),
    (0x1D623, 'M', u'b'),
    (0x1D624, 'M', u'c'),
    (0x1D625, 'M', u'd'),
    (0x1D626, 'M', u'e'),
    (0x1D627, 'M', u'f'),
    (0x1D628, 'M', u'g'),
    (0x1D629, 'M', u'h'),
    (0x1D62A, 'M', u'i'),
    (0x1D62B, 'M', u'j'),
    (0x1D62C, 'M', u'k'),
    (0x1D62D, 'M', u'l'),
    (0x1D62E, 'M', u'm'),
    (0x1D62F, 'M', u'n'),
    (0x1D630, 'M', u'o'),
    (0x1D631, 'M', u'p'),
    (0x1D632, 'M', u'q'),
    (0x1D633, 'M', u'r'),
    (0x1D634, 'M', u's'),
    (0x1D635, 'M', u't'),
    (0x1D636, 'M', u'u'),
    (0x1D637, 'M', u'v'),
    (0x1D638, 'M', u'w'),
    (0x1D639, 'M', u'x'),
    (0x1D63A, 'M', u'y'),
    (0x1D63B, 'M', u'z'),
    (0x1D63C, 'M', u'a'),
    (0x1D63D, 'M', u'b'),
    (0x1D63E, 'M', u'c'),
    (0x1D63F, 'M', u'd'),
    (0x1D640, 'M', u'e'),
    (0x1D641, 'M', u'f'),
    (0x1D642, 'M', u'g'),
    (0x1D643, 'M', u'h'),
    (0x1D644, 'M', u'i'),
    (0x1D645, 'M', u'j'),
    (0x1D646, 'M', u'k'),
    (0x1D647, 'M', u'l'),
    (0x1D648, 'M', u'm'),
    (0x1D649, 'M', u'n'),
    (0x1D64A, 'M', u'o'),
    (0x1D64B, 'M', u'p'),
    ]

def _seg_65():
    return [
    (0x1D64C, 'M', u'q'),
    (0x1D64D, 'M', u'r'),
    (0x1D64E, 'M', u's'),
    (0x1D64F, 'M', u't'),
    (0x1D650, 'M', u'u'),
    (0x1D651, 'M', u'v'),
    (0x1D652, 'M', u'w'),
    (0x1D653, 'M', u'x'),
    (0x1D654, 'M', u'y'),
    (0x1D655, 'M', u'z'),
    (0x1D656, 'M', u'a'),
    (0x1D657, 'M', u'b'),
    (0x1D658, 'M', u'c'),
    (0x1D659, 'M', u'd'),
    (0x1D65A, 'M', u'e'),
    (0x1D65B, 'M', u'f'),
    (0x1D65C, 'M', u'g'),
    (0x1D65D, 'M', u'h'),
    (0x1D65E, 'M', u'i'),
    (0x1D65F, 'M', u'j'),
    (0x1D660, 'M', u'k'),
    (0x1D661, 'M', u'l'),
    (0x1D662, 'M', u'm'),
    (0x1D663, 'M', u'n'),
    (0x1D664, 'M', u'o'),
    (0x1D665, 'M', u'p'),
    (0x1D666, 'M', u'q'),
    (0x1D667, 'M', u'r'),
    (0x1D668, 'M', u's'),
    (0x1D669, 'M', u't'),
    (0x1D66A, 'M', u'u'),
    (0x1D66B, 'M', u'v'),
    (0x1D66C, 'M', u'w'),
    (0x1D66D, 'M', u'x'),
    (0x1D66E, 'M', u'y'),
    (0x1D66F, 'M', u'z'),
    (0x1D670, 'M', u'a'),
    (0x1D671, 'M', u'b'),
    (0x1D672, 'M', u'c'),
    (0x1D673, 'M', u'd'),
    (0x1D674, 'M', u'e'),
    (0x1D675, 'M', u'f'),
    (0x1D676, 'M', u'g'),
    (0x1D677, 'M', u'h'),
    (0x1D678, 'M', u'i'),
    (0x1D679, 'M', u'j'),
    (0x1D67A, 'M', u'k'),
    (0x1D67B, 'M', u'l'),
    (0x1D67C, 'M', u'm'),
    (0x1D67D, 'M', u'n'),
    (0x1D67E, 'M', u'o'),
    (0x1D67F, 'M', u'p'),
    (0x1D680, 'M', u'q'),
    (0x1D681, 'M', u'r'),
    (0x1D682, 'M', u's'),
    (0x1D683, 'M', u't'),
    (0x1D684, 'M', u'u'),
    (0x1D685, 'M', u'v'),
    (0x1D686, 'M', u'w'),
    (0x1D687, 'M', u'x'),
    (0x1D688, 'M', u'y'),
    (0x1D689, 'M', u'z'),
    (0x1D68A, 'M', u'a'),
    (0x1D68B, 'M', u'b'),
    (0x1D68C, 'M', u'c'),
    (0x1D68D, 'M', u'd'),
    (0x1D68E, 'M', u'e'),
    (0x1D68F, 'M', u'f'),
    (0x1D690, 'M', u'g'),
    (0x1D691, 'M', u'h'),
    (0x1D692, 'M', u'i'),
    (0x1D693, 'M', u'j'),
    (0x1D694, 'M', u'k'),
    (0x1D695, 'M', u'l'),
    (0x1D696, 'M', u'm'),
    (0x1D697, 'M', u'n'),
    (0x1D698, 'M', u'o'),
    (0x1D699, 'M', u'p'),
    (0x1D69A, 'M', u'q'),
    (0x1D69B, 'M', u'r'),
    (0x1D69C, 'M', u's'),
    (0x1D69D, 'M', u't'),
    (0x1D69E, 'M', u'u'),
    (0x1D69F, 'M', u'v'),
    (0x1D6A0, 'M', u'w'),
    (0x1D6A1, 'M', u'x'),
    (0x1D6A2, 'M', u'y'),
    (0x1D6A3, 'M', u'z'),
    (0x1D6A4, 'M', u''),
    (0x1D6A5, 'M', u''),
    (0x1D6A6, 'X'),
    (0x1D6A8, 'M', u''),
    (0x1D6A9, 'M', u''),
    (0x1D6AA, 'M', u''),
    (0x1D6AB, 'M', u''),
    (0x1D6AC, 'M', u''),
    (0x1D6AD, 'M', u''),
    (0x1D6AE, 'M', u''),
    (0x1D6AF, 'M', u''),
    (0x1D6B0, 'M', u''),
    ]

def _seg_66():
    return [
    (0x1D6B1, 'M', u''),
    (0x1D6B2, 'M', u''),
    (0x1D6B3, 'M', u''),
    (0x1D6B4, 'M', u''),
    (0x1D6B5, 'M', u''),
    (0x1D6B6, 'M', u''),
    (0x1D6B7, 'M', u''),
    (0x1D6B8, 'M', u''),
    (0x1D6B9, 'M', u''),
    (0x1D6BA, 'M', u''),
    (0x1D6BB, 'M', u''),
    (0x1D6BC, 'M', u''),
    (0x1D6BD, 'M', u''),
    (0x1D6BE, 'M', u''),
    (0x1D6BF, 'M', u''),
    (0x1D6C0, 'M', u''),
    (0x1D6C1, 'M', u''),
    (0x1D6C2, 'M', u''),
    (0x1D6C3, 'M', u''),
    (0x1D6C4, 'M', u''),
    (0x1D6C5, 'M', u''),
    (0x1D6C6, 'M', u''),
    (0x1D6C7, 'M', u''),
    (0x1D6C8, 'M', u''),
    (0x1D6C9, 'M', u''),
    (0x1D6CA, 'M', u''),
    (0x1D6CB, 'M', u''),
    (0x1D6CC, 'M', u''),
    (0x1D6CD, 'M', u''),
    (0x1D6CE, 'M', u''),
    (0x1D6CF, 'M', u''),
    (0x1D6D0, 'M', u''),
    (0x1D6D1, 'M', u''),
    (0x1D6D2, 'M', u''),
    (0x1D6D3, 'M', u''),
    (0x1D6D5, 'M', u''),
    (0x1D6D6, 'M', u''),
    (0x1D6D7, 'M', u''),
    (0x1D6D8, 'M', u''),
    (0x1D6D9, 'M', u''),
    (0x1D6DA, 'M', u''),
    (0x1D6DB, 'M', u''),
    (0x1D6DC, 'M', u''),
    (0x1D6DD, 'M', u''),
    (0x1D6DE, 'M', u''),
    (0x1D6DF, 'M', u''),
    (0x1D6E0, 'M', u''),
    (0x1D6E1, 'M', u''),
    (0x1D6E2, 'M', u''),
    (0x1D6E3, 'M', u''),
    (0x1D6E4, 'M', u''),
    (0x1D6E5, 'M', u''),
    (0x1D6E6, 'M', u''),
    (0x1D6E7, 'M', u''),
    (0x1D6E8, 'M', u''),
    (0x1D6E9, 'M', u''),
    (0x1D6EA, 'M', u''),
    (0x1D6EB, 'M', u''),
    (0x1D6EC, 'M', u''),
    (0x1D6ED, 'M', u''),
    (0x1D6EE, 'M', u''),
    (0x1D6EF, 'M', u''),
    (0x1D6F0, 'M', u''),
    (0x1D6F1, 'M', u''),
    (0x1D6F2, 'M', u''),
    (0x1D6F3, 'M', u''),
    (0x1D6F4, 'M', u''),
    (0x1D6F5, 'M', u''),
    (0x1D6F6, 'M', u''),
    (0x1D6F7, 'M', u''),
    (0x1D6F8, 'M', u''),
    (0x1D6F9, 'M', u''),
    (0x1D6FA, 'M', u''),
    (0x1D6FB, 'M', u''),
    (0x1D6FC, 'M', u''),
    (0x1D6FD, 'M', u''),
    (0x1D6FE, 'M', u''),
    (0x1D6FF, 'M', u''),
    (0x1D700, 'M', u''),
    (0x1D701, 'M', u''),
    (0x1D702, 'M', u''),
    (0x1D703, 'M', u''),
    (0x1D704, 'M', u''),
    (0x1D705, 'M', u''),
    (0x1D706, 'M', u''),
    (0x1D707, 'M', u''),
    (0x1D708, 'M', u''),
    (0x1D709, 'M', u''),
    (0x1D70A, 'M', u''),
    (0x1D70B, 'M', u''),
    (0x1D70C, 'M', u''),
    (0x1D70D, 'M', u''),
    (0x1D70F, 'M', u''),
    (0x1D710, 'M', u''),
    (0x1D711, 'M', u''),
    (0x1D712, 'M', u''),
    (0x1D713, 'M', u''),
    (0x1D714, 'M', u''),
    (0x1D715, 'M', u''),
    (0x1D716, 'M', u''),
    ]

def _seg_67():
    return [
    (0x1D717, 'M', u''),
    (0x1D718, 'M', u''),
    (0x1D719, 'M', u''),
    (0x1D71A, 'M', u''),
    (0x1D71B, 'M', u''),
    (0x1D71C, 'M', u''),
    (0x1D71D, 'M', u''),
    (0x1D71E, 'M', u''),
    (0x1D71F, 'M', u''),
    (0x1D720, 'M', u''),
    (0x1D721, 'M', u''),
    (0x1D722, 'M', u''),
    (0x1D723, 'M', u''),
    (0x1D724, 'M', u''),
    (0x1D725, 'M', u''),
    (0x1D726, 'M', u''),
    (0x1D727, 'M', u''),
    (0x1D728, 'M', u''),
    (0x1D729, 'M', u''),
    (0x1D72A, 'M', u''),
    (0x1D72B, 'M', u''),
    (0x1D72C, 'M', u''),
    (0x1D72D, 'M', u''),
    (0x1D72E, 'M', u''),
    (0x1D72F, 'M', u''),
    (0x1D730, 'M', u''),
    (0x1D731, 'M', u''),
    (0x1D732, 'M', u''),
    (0x1D733, 'M', u''),
    (0x1D734, 'M', u''),
    (0x1D735, 'M', u''),
    (0x1D736, 'M', u''),
    (0x1D737, 'M', u''),
    (0x1D738, 'M', u''),
    (0x1D739, 'M', u''),
    (0x1D73A, 'M', u''),
    (0x1D73B, 'M', u''),
    (0x1D73C, 'M', u''),
    (0x1D73D, 'M', u''),
    (0x1D73E, 'M', u''),
    (0x1D73F, 'M', u''),
    (0x1D740, 'M', u''),
    (0x1D741, 'M', u''),
    (0x1D742, 'M', u''),
    (0x1D743, 'M', u''),
    (0x1D744, 'M', u''),
    (0x1D745, 'M', u''),
    (0x1D746, 'M', u''),
    (0x1D747, 'M', u''),
    (0x1D749, 'M', u''),
    (0x1D74A, 'M', u''),
    (0x1D74B, 'M', u''),
    (0x1D74C, 'M', u''),
    (0x1D74D, 'M', u''),
    (0x1D74E, 'M', u''),
    (0x1D74F, 'M', u''),
    (0x1D750, 'M', u''),
    (0x1D751, 'M', u''),
    (0x1D752, 'M', u''),
    (0x1D753, 'M', u''),
    (0x1D754, 'M', u''),
    (0x1D755, 'M', u''),
    (0x1D756, 'M', u''),
    (0x1D757, 'M', u''),
    (0x1D758, 'M', u''),
    (0x1D759, 'M', u''),
    (0x1D75A, 'M', u''),
    (0x1D75B, 'M', u''),
    (0x1D75C, 'M', u''),
    (0x1D75D, 'M', u''),
    (0x1D75E, 'M', u''),
    (0x1D75F, 'M', u''),
    (0x1D760, 'M', u''),
    (0x1D761, 'M', u''),
    (0x1D762, 'M', u''),
    (0x1D763, 'M', u''),
    (0x1D764, 'M', u''),
    (0x1D765, 'M', u''),
    (0x1D766, 'M', u''),
    (0x1D767, 'M', u''),
    (0x1D768, 'M', u''),
    (0x1D769, 'M', u''),
    (0x1D76A, 'M', u''),
    (0x1D76B, 'M', u''),
    (0x1D76C, 'M', u''),
    (0x1D76D, 'M', u''),
    (0x1D76E, 'M', u''),
    (0x1D76F, 'M', u''),
    (0x1D770, 'M', u''),
    (0x1D771, 'M', u''),
    (0x1D772, 'M', u''),
    (0x1D773, 'M', u''),
    (0x1D774, 'M', u''),
    (0x1D775, 'M', u''),
    (0x1D776, 'M', u''),
    (0x1D777, 'M', u''),
    (0x1D778, 'M', u''),
    (0x1D779, 'M', u''),
    (0x1D77A, 'M', u''),
    (0x1D77B, 'M', u''),
    ]

def _seg_68():
    return [
    (0x1D77C, 'M', u''),
    (0x1D77D, 'M', u''),
    (0x1D77E, 'M', u''),
    (0x1D77F, 'M', u''),
    (0x1D780, 'M', u''),
    (0x1D781, 'M', u''),
    (0x1D783, 'M', u''),
    (0x1D784, 'M', u''),
    (0x1D785, 'M', u''),
    (0x1D786, 'M', u''),
    (0x1D787, 'M', u''),
    (0x1D788, 'M', u''),
    (0x1D789, 'M', u''),
    (0x1D78A, 'M', u''),
    (0x1D78B, 'M', u''),
    (0x1D78C, 'M', u''),
    (0x1D78D, 'M', u''),
    (0x1D78E, 'M', u''),
    (0x1D78F, 'M', u''),
    (0x1D790, 'M', u''),
    (0x1D791, 'M', u''),
    (0x1D792, 'M', u''),
    (0x1D793, 'M', u''),
    (0x1D794, 'M', u''),
    (0x1D795, 'M', u''),
    (0x1D796, 'M', u''),
    (0x1D797, 'M', u''),
    (0x1D798, 'M', u''),
    (0x1D799, 'M', u''),
    (0x1D79A, 'M', u''),
    (0x1D79B, 'M', u''),
    (0x1D79C, 'M', u''),
    (0x1D79D, 'M', u''),
    (0x1D79E, 'M', u''),
    (0x1D79F, 'M', u''),
    (0x1D7A0, 'M', u''),
    (0x1D7A1, 'M', u''),
    (0x1D7A2, 'M', u''),
    (0x1D7A3, 'M', u''),
    (0x1D7A4, 'M', u''),
    (0x1D7A5, 'M', u''),
    (0x1D7A6, 'M', u''),
    (0x1D7A7, 'M', u''),
    (0x1D7A8, 'M', u''),
    (0x1D7A9, 'M', u''),
    (0x1D7AA, 'M', u''),
    (0x1D7AB, 'M', u''),
    (0x1D7AC, 'M', u''),
    (0x1D7AD, 'M', u''),
    (0x1D7AE, 'M', u''),
    (0x1D7AF, 'M', u''),
    (0x1D7B0, 'M', u''),
    (0x1D7B1, 'M', u''),
    (0x1D7B2, 'M', u''),
    (0x1D7B3, 'M', u''),
    (0x1D7B4, 'M', u''),
    (0x1D7B5, 'M', u''),
    (0x1D7B6, 'M', u''),
    (0x1D7B7, 'M', u''),
    (0x1D7B8, 'M', u''),
    (0x1D7B9, 'M', u''),
    (0x1D7BA, 'M', u''),
    (0x1D7BB, 'M', u''),
    (0x1D7BD, 'M', u''),
    (0x1D7BE, 'M', u''),
    (0x1D7BF, 'M', u''),
    (0x1D7C0, 'M', u''),
    (0x1D7C1, 'M', u''),
    (0x1D7C2, 'M', u''),
    (0x1D7C3, 'M', u''),
    (0x1D7C4, 'M', u''),
    (0x1D7C5, 'M', u''),
    (0x1D7C6, 'M', u''),
    (0x1D7C7, 'M', u''),
    (0x1D7C8, 'M', u''),
    (0x1D7C9, 'M', u''),
    (0x1D7CA, 'M', u''),
    (0x1D7CC, 'X'),
    (0x1D7CE, 'M', u'0'),
    (0x1D7CF, 'M', u'1'),
    (0x1D7D0, 'M', u'2'),
    (0x1D7D1, 'M', u'3'),
    (0x1D7D2, 'M', u'4'),
    (0x1D7D3, 'M', u'5'),
    (0x1D7D4, 'M', u'6'),
    (0x1D7D5, 'M', u'7'),
    (0x1D7D6, 'M', u'8'),
    (0x1D7D7, 'M', u'9'),
    (0x1D7D8, 'M', u'0'),
    (0x1D7D9, 'M', u'1'),
    (0x1D7DA, 'M', u'2'),
    (0x1D7DB, 'M', u'3'),
    (0x1D7DC, 'M', u'4'),
    (0x1D7DD, 'M', u'5'),
    (0x1D7DE, 'M', u'6'),
    (0x1D7DF, 'M', u'7'),
    (0x1D7E0, 'M', u'8'),
    (0x1D7E1, 'M', u'9'),
    (0x1D7E2, 'M', u'0'),
    (0x1D7E3, 'M', u'1'),
    ]

def _seg_69():
    return [
    (0x1D7E4, 'M', u'2'),
    (0x1D7E5, 'M', u'3'),
    (0x1D7E6, 'M', u'4'),
    (0x1D7E7, 'M', u'5'),
    (0x1D7E8, 'M', u'6'),
    (0x1D7E9, 'M', u'7'),
    (0x1D7EA, 'M', u'8'),
    (0x1D7EB, 'M', u'9'),
    (0x1D7EC, 'M', u'0'),
    (0x1D7ED, 'M', u'1'),
    (0x1D7EE, 'M', u'2'),
    (0x1D7EF, 'M', u'3'),
    (0x1D7F0, 'M', u'4'),
    (0x1D7F1, 'M', u'5'),
    (0x1D7F2, 'M', u'6'),
    (0x1D7F3, 'M', u'7'),
    (0x1D7F4, 'M', u'8'),
    (0x1D7F5, 'M', u'9'),
    (0x1D7F6, 'M', u'0'),
    (0x1D7F7, 'M', u'1'),
    (0x1D7F8, 'M', u'2'),
    (0x1D7F9, 'M', u'3'),
    (0x1D7FA, 'M', u'4'),
    (0x1D7FB, 'M', u'5'),
    (0x1D7FC, 'M', u'6'),
    (0x1D7FD, 'M', u'7'),
    (0x1D7FE, 'M', u'8'),
    (0x1D7FF, 'M', u'9'),
    (0x1D800, 'V'),
    (0x1DA8C, 'X'),
    (0x1DA9B, 'V'),
    (0x1DAA0, 'X'),
    (0x1DAA1, 'V'),
    (0x1DAB0, 'X'),
    (0x1E000, 'V'),
    (0x1E007, 'X'),
    (0x1E008, 'V'),
    (0x1E019, 'X'),
    (0x1E01B, 'V'),
    (0x1E022, 'X'),
    (0x1E023, 'V'),
    (0x1E025, 'X'),
    (0x1E026, 'V'),
    (0x1E02B, 'X'),
    (0x1E100, 'V'),
    (0x1E12D, 'X'),
    (0x1E130, 'V'),
    (0x1E13E, 'X'),
    (0x1E140, 'V'),
    (0x1E14A, 'X'),
    (0x1E14E, 'V'),
    (0x1E150, 'X'),
    (0x1E2C0, 'V'),
    (0x1E2FA, 'X'),
    (0x1E2FF, 'V'),
    (0x1E300, 'X'),
    (0x1E800, 'V'),
    (0x1E8C5, 'X'),
    (0x1E8C7, 'V'),
    (0x1E8D7, 'X'),
    (0x1E900, 'M', u''),
    (0x1E901, 'M', u''),
    (0x1E902, 'M', u''),
    (0x1E903, 'M', u''),
    (0x1E904, 'M', u''),
    (0x1E905, 'M', u''),
    (0x1E906, 'M', u''),
    (0x1E907, 'M', u''),
    (0x1E908, 'M', u''),
    (0x1E909, 'M', u''),
    (0x1E90A, 'M', u''),
    (0x1E90B, 'M', u''),
    (0x1E90C, 'M', u''),
    (0x1E90D, 'M', u''),
    (0x1E90E, 'M', u''),
    (0x1E90F, 'M', u''),
    (0x1E910, 'M', u''),
    (0x1E911, 'M', u''),
    (0x1E912, 'M', u''),
    (0x1E913, 'M', u''),
    (0x1E914, 'M', u''),
    (0x1E915, 'M', u''),
    (0x1E916, 'M', u''),
    (0x1E917, 'M', u''),
    (0x1E918, 'M', u''),
    (0x1E919, 'M', u''),
    (0x1E91A, 'M', u''),
    (0x1E91B, 'M', u''),
    (0x1E91C, 'M', u''),
    (0x1E91D, 'M', u''),
    (0x1E91E, 'M', u''),
    (0x1E91F, 'M', u''),
    (0x1E920, 'M', u''),
    (0x1E921, 'M', u''),
    (0x1E922, 'V'),
    (0x1E94C, 'X'),
    (0x1E950, 'V'),
    (0x1E95A, 'X'),
    (0x1E95E, 'V'),
    (0x1E960, 'X'),
    ]

def _seg_70():
    return [
    (0x1EC71, 'V'),
    (0x1ECB5, 'X'),
    (0x1ED01, 'V'),
    (0x1ED3E, 'X'),
    (0x1EE00, 'M', u''),
    (0x1EE01, 'M', u''),
    (0x1EE02, 'M', u''),
    (0x1EE03, 'M', u''),
    (0x1EE04, 'X'),
    (0x1EE05, 'M', u''),
    (0x1EE06, 'M', u''),
    (0x1EE07, 'M', u''),
    (0x1EE08, 'M', u''),
    (0x1EE09, 'M', u''),
    (0x1EE0A, 'M', u''),
    (0x1EE0B, 'M', u''),
    (0x1EE0C, 'M', u''),
    (0x1EE0D, 'M', u''),
    (0x1EE0E, 'M', u''),
    (0x1EE0F, 'M', u''),
    (0x1EE10, 'M', u''),
    (0x1EE11, 'M', u''),
    (0x1EE12, 'M', u''),
    (0x1EE13, 'M', u''),
    (0x1EE14, 'M', u''),
    (0x1EE15, 'M', u''),
    (0x1EE16, 'M', u''),
    (0x1EE17, 'M', u''),
    (0x1EE18, 'M', u''),
    (0x1EE19, 'M', u''),
    (0x1EE1A, 'M', u''),
    (0x1EE1B, 'M', u''),
    (0x1EE1C, 'M', u''),
    (0x1EE1D, 'M', u''),
    (0x1EE1E, 'M', u''),
    (0x1EE1F, 'M', u''),
    (0x1EE20, 'X'),
    (0x1EE21, 'M', u''),
    (0x1EE22, 'M', u''),
    (0x1EE23, 'X'),
    (0x1EE24, 'M', u''),
    (0x1EE25, 'X'),
    (0x1EE27, 'M', u''),
    (0x1EE28, 'X'),
    (0x1EE29, 'M', u''),
    (0x1EE2A, 'M', u''),
    (0x1EE2B, 'M', u''),
    (0x1EE2C, 'M', u''),
    (0x1EE2D, 'M', u''),
    (0x1EE2E, 'M', u''),
    (0x1EE2F, 'M', u''),
    (0x1EE30, 'M', u''),
    (0x1EE31, 'M', u''),
    (0x1EE32, 'M', u''),
    (0x1EE33, 'X'),
    (0x1EE34, 'M', u''),
    (0x1EE35, 'M', u''),
    (0x1EE36, 'M', u''),
    (0x1EE37, 'M', u''),
    (0x1EE38, 'X'),
    (0x1EE39, 'M', u''),
    (0x1EE3A, 'X'),
    (0x1EE3B, 'M', u''),
    (0x1EE3C, 'X'),
    (0x1EE42, 'M', u''),
    (0x1EE43, 'X'),
    (0x1EE47, 'M', u''),
    (0x1EE48, 'X'),
    (0x1EE49, 'M', u''),
    (0x1EE4A, 'X'),
    (0x1EE4B, 'M', u''),
    (0x1EE4C, 'X'),
    (0x1EE4D, 'M', u''),
    (0x1EE4E, 'M', u''),
    (0x1EE4F, 'M', u''),
    (0x1EE50, 'X'),
    (0x1EE51, 'M', u''),
    (0x1EE52, 'M', u''),
    (0x1EE53, 'X'),
    (0x1EE54, 'M', u''),
    (0x1EE55, 'X'),
    (0x1EE57, 'M', u''),
    (0x1EE58, 'X'),
    (0x1EE59, 'M', u''),
    (0x1EE5A, 'X'),
    (0x1EE5B, 'M', u''),
    (0x1EE5C, 'X'),
    (0x1EE5D, 'M', u''),
    (0x1EE5E, 'X'),
    (0x1EE5F, 'M', u''),
    (0x1EE60, 'X'),
    (0x1EE61, 'M', u''),
    (0x1EE62, 'M', u''),
    (0x1EE63, 'X'),
    (0x1EE64, 'M', u''),
    (0x1EE65, 'X'),
    (0x1EE67, 'M', u''),
    (0x1EE68, 'M', u''),
    (0x1EE69, 'M', u''),
    (0x1EE6A, 'M', u''),
    ]

def _seg_71():
    return [
    (0x1EE6B, 'X'),
    (0x1EE6C, 'M', u''),
    (0x1EE6D, 'M', u''),
    (0x1EE6E, 'M', u''),
    (0x1EE6F, 'M', u''),
    (0x1EE70, 'M', u''),
    (0x1EE71, 'M', u''),
    (0x1EE72, 'M', u''),
    (0x1EE73, 'X'),
    (0x1EE74, 'M', u''),
    (0x1EE75, 'M', u''),
    (0x1EE76, 'M', u''),
    (0x1EE77, 'M', u''),
    (0x1EE78, 'X'),
    (0x1EE79, 'M', u''),
    (0x1EE7A, 'M', u''),
    (0x1EE7B, 'M', u''),
    (0x1EE7C, 'M', u''),
    (0x1EE7D, 'X'),
    (0x1EE7E, 'M', u''),
    (0x1EE7F, 'X'),
    (0x1EE80, 'M', u''),
    (0x1EE81, 'M', u''),
    (0x1EE82, 'M', u''),
    (0x1EE83, 'M', u''),
    (0x1EE84, 'M', u''),
    (0x1EE85, 'M', u''),
    (0x1EE86, 'M', u''),
    (0x1EE87, 'M', u''),
    (0x1EE88, 'M', u''),
    (0x1EE89, 'M', u''),
    (0x1EE8A, 'X'),
    (0x1EE8B, 'M', u''),
    (0x1EE8C, 'M', u''),
    (0x1EE8D, 'M', u''),
    (0x1EE8E, 'M', u''),
    (0x1EE8F, 'M', u''),
    (0x1EE90, 'M', u''),
    (0x1EE91, 'M', u''),
    (0x1EE92, 'M', u''),
    (0x1EE93, 'M', u''),
    (0x1EE94, 'M', u''),
    (0x1EE95, 'M', u''),
    (0x1EE96, 'M', u''),
    (0x1EE97, 'M', u''),
    (0x1EE98, 'M', u''),
    (0x1EE99, 'M', u''),
    (0x1EE9A, 'M', u''),
    (0x1EE9B, 'M', u''),
    (0x1EE9C, 'X'),
    (0x1EEA1, 'M', u''),
    (0x1EEA2, 'M', u''),
    (0x1EEA3, 'M', u''),
    (0x1EEA4, 'X'),
    (0x1EEA5, 'M', u''),
    (0x1EEA6, 'M', u''),
    (0x1EEA7, 'M', u''),
    (0x1EEA8, 'M', u''),
    (0x1EEA9, 'M', u''),
    (0x1EEAA, 'X'),
    (0x1EEAB, 'M', u''),
    (0x1EEAC, 'M', u''),
    (0x1EEAD, 'M', u''),
    (0x1EEAE, 'M', u''),
    (0x1EEAF, 'M', u''),
    (0x1EEB0, 'M', u''),
    (0x1EEB1, 'M', u''),
    (0x1EEB2, 'M', u''),
    (0x1EEB3, 'M', u''),
    (0x1EEB4, 'M', u''),
    (0x1EEB5, 'M', u''),
    (0x1EEB6, 'M', u''),
    (0x1EEB7, 'M', u''),
    (0x1EEB8, 'M', u''),
    (0x1EEB9, 'M', u''),
    (0x1EEBA, 'M', u''),
    (0x1EEBB, 'M', u''),
    (0x1EEBC, 'X'),
    (0x1EEF0, 'V'),
    (0x1EEF2, 'X'),
    (0x1F000, 'V'),
    (0x1F02C, 'X'),
    (0x1F030, 'V'),
    (0x1F094, 'X'),
    (0x1F0A0, 'V'),
    (0x1F0AF, 'X'),
    (0x1F0B1, 'V'),
    (0x1F0C0, 'X'),
    (0x1F0C1, 'V'),
    (0x1F0D0, 'X'),
    (0x1F0D1, 'V'),
    (0x1F0F6, 'X'),
    (0x1F101, '3', u'0,'),
    (0x1F102, '3', u'1,'),
    (0x1F103, '3', u'2,'),
    (0x1F104, '3', u'3,'),
    (0x1F105, '3', u'4,'),
    (0x1F106, '3', u'5,'),
    (0x1F107, '3', u'6,'),
    (0x1F108, '3', u'7,'),
    ]

def _seg_72():
    return [
    (0x1F109, '3', u'8,'),
    (0x1F10A, '3', u'9,'),
    (0x1F10B, 'V'),
    (0x1F110, '3', u'(a)'),
    (0x1F111, '3', u'(b)'),
    (0x1F112, '3', u'(c)'),
    (0x1F113, '3', u'(d)'),
    (0x1F114, '3', u'(e)'),
    (0x1F115, '3', u'(f)'),
    (0x1F116, '3', u'(g)'),
    (0x1F117, '3', u'(h)'),
    (0x1F118, '3', u'(i)'),
    (0x1F119, '3', u'(j)'),
    (0x1F11A, '3', u'(k)'),
    (0x1F11B, '3', u'(l)'),
    (0x1F11C, '3', u'(m)'),
    (0x1F11D, '3', u'(n)'),
    (0x1F11E, '3', u'(o)'),
    (0x1F11F, '3', u'(p)'),
    (0x1F120, '3', u'(q)'),
    (0x1F121, '3', u'(r)'),
    (0x1F122, '3', u'(s)'),
    (0x1F123, '3', u'(t)'),
    (0x1F124, '3', u'(u)'),
    (0x1F125, '3', u'(v)'),
    (0x1F126, '3', u'(w)'),
    (0x1F127, '3', u'(x)'),
    (0x1F128, '3', u'(y)'),
    (0x1F129, '3', u'(z)'),
    (0x1F12A, 'M', u's'),
    (0x1F12B, 'M', u'c'),
    (0x1F12C, 'M', u'r'),
    (0x1F12D, 'M', u'cd'),
    (0x1F12E, 'M', u'wz'),
    (0x1F12F, 'V'),
    (0x1F130, 'M', u'a'),
    (0x1F131, 'M', u'b'),
    (0x1F132, 'M', u'c'),
    (0x1F133, 'M', u'd'),
    (0x1F134, 'M', u'e'),
    (0x1F135, 'M', u'f'),
    (0x1F136, 'M', u'g'),
    (0x1F137, 'M', u'h'),
    (0x1F138, 'M', u'i'),
    (0x1F139, 'M', u'j'),
    (0x1F13A, 'M', u'k'),
    (0x1F13B, 'M', u'l'),
    (0x1F13C, 'M', u'm'),
    (0x1F13D, 'M', u'n'),
    (0x1F13E, 'M', u'o'),
    (0x1F13F, 'M', u'p'),
    (0x1F140, 'M', u'q'),
    (0x1F141, 'M', u'r'),
    (0x1F142, 'M', u's'),
    (0x1F143, 'M', u't'),
    (0x1F144, 'M', u'u'),
    (0x1F145, 'M', u'v'),
    (0x1F146, 'M', u'w'),
    (0x1F147, 'M', u'x'),
    (0x1F148, 'M', u'y'),
    (0x1F149, 'M', u'z'),
    (0x1F14A, 'M', u'hv'),
    (0x1F14B, 'M', u'mv'),
    (0x1F14C, 'M', u'sd'),
    (0x1F14D, 'M', u'ss'),
    (0x1F14E, 'M', u'ppv'),
    (0x1F14F, 'M', u'wc'),
    (0x1F150, 'V'),
    (0x1F16A, 'M', u'mc'),
    (0x1F16B, 'M', u'md'),
    (0x1F16C, 'M', u'mr'),
    (0x1F16D, 'V'),
    (0x1F190, 'M', u'dj'),
    (0x1F191, 'V'),
    (0x1F1AE, 'X'),
    (0x1F1E6, 'V'),
    (0x1F200, 'M', u''),
    (0x1F201, 'M', u''),
    (0x1F202, 'M', u''),
    (0x1F203, 'X'),
    (0x1F210, 'M', u''),
    (0x1F211, 'M', u''),
    (0x1F212, 'M', u''),
    (0x1F213, 'M', u''),
    (0x1F214, 'M', u''),
    (0x1F215, 'M', u''),
    (0x1F216, 'M', u''),
    (0x1F217, 'M', u''),
    (0x1F218, 'M', u''),
    (0x1F219, 'M', u''),
    (0x1F21A, 'M', u''),
    (0x1F21B, 'M', u''),
    (0x1F21C, 'M', u''),
    (0x1F21D, 'M', u''),
    (0x1F21E, 'M', u''),
    (0x1F21F, 'M', u''),
    (0x1F220, 'M', u''),
    (0x1F221, 'M', u''),
    (0x1F222, 'M', u''),
    (0x1F223, 'M', u''),
    ]

def _seg_73():
    return [
    (0x1F224, 'M', u''),
    (0x1F225, 'M', u''),
    (0x1F226, 'M', u''),
    (0x1F227, 'M', u''),
    (0x1F228, 'M', u''),
    (0x1F229, 'M', u''),
    (0x1F22A, 'M', u''),
    (0x1F22B, 'M', u''),
    (0x1F22C, 'M', u''),
    (0x1F22D, 'M', u''),
    (0x1F22E, 'M', u''),
    (0x1F22F, 'M', u''),
    (0x1F230, 'M', u''),
    (0x1F231, 'M', u''),
    (0x1F232, 'M', u''),
    (0x1F233, 'M', u''),
    (0x1F234, 'M', u''),
    (0x1F235, 'M', u''),
    (0x1F236, 'M', u''),
    (0x1F237, 'M', u''),
    (0x1F238, 'M', u''),
    (0x1F239, 'M', u''),
    (0x1F23A, 'M', u''),
    (0x1F23B, 'M', u''),
    (0x1F23C, 'X'),
    (0x1F240, 'M', u''),
    (0x1F241, 'M', u''),
    (0x1F242, 'M', u''),
    (0x1F243, 'M', u''),
    (0x1F244, 'M', u''),
    (0x1F245, 'M', u''),
    (0x1F246, 'M', u''),
    (0x1F247, 'M', u''),
    (0x1F248, 'M', u''),
    (0x1F249, 'X'),
    (0x1F250, 'M', u''),
    (0x1F251, 'M', u''),
    (0x1F252, 'X'),
    (0x1F260, 'V'),
    (0x1F266, 'X'),
    (0x1F300, 'V'),
    (0x1F6D8, 'X'),
    (0x1F6E0, 'V'),
    (0x1F6ED, 'X'),
    (0x1F6F0, 'V'),
    (0x1F6FD, 'X'),
    (0x1F700, 'V'),
    (0x1F774, 'X'),
    (0x1F780, 'V'),
    (0x1F7D9, 'X'),
    (0x1F7E0, 'V'),
    (0x1F7EC, 'X'),
    (0x1F800, 'V'),
    (0x1F80C, 'X'),
    (0x1F810, 'V'),
    (0x1F848, 'X'),
    (0x1F850, 'V'),
    (0x1F85A, 'X'),
    (0x1F860, 'V'),
    (0x1F888, 'X'),
    (0x1F890, 'V'),
    (0x1F8AE, 'X'),
    (0x1F8B0, 'V'),
    (0x1F8B2, 'X'),
    (0x1F900, 'V'),
    (0x1F979, 'X'),
    (0x1F97A, 'V'),
    (0x1F9CC, 'X'),
    (0x1F9CD, 'V'),
    (0x1FA54, 'X'),
    (0x1FA60, 'V'),
    (0x1FA6E, 'X'),
    (0x1FA70, 'V'),
    (0x1FA75, 'X'),
    (0x1FA78, 'V'),
    (0x1FA7B, 'X'),
    (0x1FA80, 'V'),
    (0x1FA87, 'X'),
    (0x1FA90, 'V'),
    (0x1FAA9, 'X'),
    (0x1FAB0, 'V'),
    (0x1FAB7, 'X'),
    (0x1FAC0, 'V'),
    (0x1FAC3, 'X'),
    (0x1FAD0, 'V'),
    (0x1FAD7, 'X'),
    (0x1FB00, 'V'),
    (0x1FB93, 'X'),
    (0x1FB94, 'V'),
    (0x1FBCB, 'X'),
    (0x1FBF0, 'M', u'0'),
    (0x1FBF1, 'M', u'1'),
    (0x1FBF2, 'M', u'2'),
    (0x1FBF3, 'M', u'3'),
    (0x1FBF4, 'M', u'4'),
    (0x1FBF5, 'M', u'5'),
    (0x1FBF6, 'M', u'6'),
    (0x1FBF7, 'M', u'7'),
    (0x1FBF8, 'M', u'8'),
    (0x1FBF9, 'M', u'9'),
    ]

def _seg_74():
    return [
    (0x1FBFA, 'X'),
    (0x20000, 'V'),
    (0x2A6DE, 'X'),
    (0x2A700, 'V'),
    (0x2B735, 'X'),
    (0x2B740, 'V'),
    (0x2B81E, 'X'),
    (0x2B820, 'V'),
    (0x2CEA2, 'X'),
    (0x2CEB0, 'V'),
    (0x2EBE1, 'X'),
    (0x2F800, 'M', u''),
    (0x2F801, 'M', u''),
    (0x2F802, 'M', u''),
    (0x2F803, 'M', u''),
    (0x2F804, 'M', u''),
    (0x2F805, 'M', u''),
    (0x2F806, 'M', u''),
    (0x2F807, 'M', u''),
    (0x2F808, 'M', u''),
    (0x2F809, 'M', u''),
    (0x2F80A, 'M', u''),
    (0x2F80B, 'M', u''),
    (0x2F80C, 'M', u''),
    (0x2F80D, 'M', u''),
    (0x2F80E, 'M', u''),
    (0x2F80F, 'M', u''),
    (0x2F810, 'M', u''),
    (0x2F811, 'M', u''),
    (0x2F812, 'M', u''),
    (0x2F813, 'M', u''),
    (0x2F814, 'M', u''),
    (0x2F815, 'M', u''),
    (0x2F816, 'M', u''),
    (0x2F817, 'M', u''),
    (0x2F818, 'M', u''),
    (0x2F819, 'M', u''),
    (0x2F81A, 'M', u''),
    (0x2F81B, 'M', u''),
    (0x2F81C, 'M', u''),
    (0x2F81D, 'M', u''),
    (0x2F81E, 'M', u''),
    (0x2F81F, 'M', u''),
    (0x2F820, 'M', u''),
    (0x2F821, 'M', u''),
    (0x2F822, 'M', u''),
    (0x2F823, 'M', u''),
    (0x2F824, 'M', u''),
    (0x2F825, 'M', u''),
    (0x2F826, 'M', u''),
    (0x2F827, 'M', u''),
    (0x2F828, 'M', u''),
    (0x2F829, 'M', u''),
    (0x2F82A, 'M', u''),
    (0x2F82B, 'M', u''),
    (0x2F82C, 'M', u''),
    (0x2F82D, 'M', u''),
    (0x2F82E, 'M', u''),
    (0x2F82F, 'M', u''),
    (0x2F830, 'M', u''),
    (0x2F831, 'M', u''),
    (0x2F834, 'M', u''),
    (0x2F835, 'M', u''),
    (0x2F836, 'M', u''),
    (0x2F837, 'M', u''),
    (0x2F838, 'M', u''),
    (0x2F839, 'M', u''),
    (0x2F83A, 'M', u''),
    (0x2F83B, 'M', u''),
    (0x2F83C, 'M', u''),
    (0x2F83D, 'M', u''),
    (0x2F83E, 'M', u''),
    (0x2F83F, 'M', u''),
    (0x2F840, 'M', u''),
    (0x2F841, 'M', u''),
    (0x2F842, 'M', u''),
    (0x2F843, 'M', u''),
    (0x2F844, 'M', u''),
    (0x2F845, 'M', u''),
    (0x2F847, 'M', u''),
    (0x2F848, 'M', u''),
    (0x2F849, 'M', u''),
    (0x2F84A, 'M', u''),
    (0x2F84B, 'M', u''),
    (0x2F84C, 'M', u''),
    (0x2F84D, 'M', u''),
    (0x2F84E, 'M', u''),
    (0x2F84F, 'M', u''),
    (0x2F850, 'M', u''),
    (0x2F851, 'M', u''),
    (0x2F852, 'M', u''),
    (0x2F853, 'M', u''),
    (0x2F854, 'M', u''),
    (0x2F855, 'M', u''),
    (0x2F856, 'M', u''),
    (0x2F857, 'M', u''),
    (0x2F858, 'M', u''),
    (0x2F859, 'M', u''),
    (0x2F85A, 'M', u''),
    (0x2F85B, 'M', u''),
    ]

def _seg_75():
    return [
    (0x2F85C, 'M', u''),
    (0x2F85D, 'M', u''),
    (0x2F85E, 'M', u''),
    (0x2F85F, 'M', u''),
    (0x2F860, 'M', u''),
    (0x2F861, 'M', u''),
    (0x2F862, 'M', u''),
    (0x2F863, 'M', u''),
    (0x2F864, 'M', u''),
    (0x2F865, 'M', u''),
    (0x2F866, 'M', u''),
    (0x2F867, 'M', u''),
    (0x2F868, 'X'),
    (0x2F869, 'M', u''),
    (0x2F86A, 'M', u''),
    (0x2F86C, 'M', u''),
    (0x2F86D, 'M', u''),
    (0x2F86E, 'M', u''),
    (0x2F86F, 'M', u''),
    (0x2F870, 'M', u''),
    (0x2F871, 'M', u''),
    (0x2F872, 'M', u''),
    (0x2F873, 'M', u''),
    (0x2F874, 'X'),
    (0x2F875, 'M', u''),
    (0x2F876, 'M', u''),
    (0x2F877, 'M', u''),
    (0x2F878, 'M', u''),
    (0x2F879, 'M', u''),
    (0x2F87A, 'M', u''),
    (0x2F87B, 'M', u''),
    (0x2F87C, 'M', u''),
    (0x2F87D, 'M', u''),
    (0x2F87E, 'M', u''),
    (0x2F87F, 'M', u''),
    (0x2F880, 'M', u''),
    (0x2F881, 'M', u''),
    (0x2F882, 'M', u''),
    (0x2F883, 'M', u''),
    (0x2F884, 'M', u''),
    (0x2F885, 'M', u''),
    (0x2F886, 'M', u''),
    (0x2F887, 'M', u''),
    (0x2F888, 'M', u''),
    (0x2F889, 'M', u''),
    (0x2F88A, 'M', u''),
    (0x2F88B, 'M', u''),
    (0x2F88C, 'M', u''),
    (0x2F88D, 'M', u''),
    (0x2F88E, 'M', u''),
    (0x2F88F, 'M', u''),
    (0x2F890, 'M', u''),
    (0x2F891, 'M', u''),
    (0x2F893, 'M', u''),
    (0x2F894, 'M', u''),
    (0x2F896, 'M', u''),
    (0x2F897, 'M', u''),
    (0x2F898, 'M', u''),
    (0x2F899, 'M', u''),
    (0x2F89A, 'M', u''),
    (0x2F89B, 'M', u''),
    (0x2F89C, 'M', u''),
    (0x2F89D, 'M', u''),
    (0x2F89E, 'M', u''),
    (0x2F89F, 'M', u''),
    (0x2F8A0, 'M', u''),
    (0x2F8A1, 'M', u''),
    (0x2F8A2, 'M', u''),
    (0x2F8A3, 'M', u''),
    (0x2F8A4, 'M', u''),
    (0x2F8A5, 'M', u''),
    (0x2F8A6, 'M', u''),
    (0x2F8A7, 'M', u''),
    (0x2F8A8, 'M', u''),
    (0x2F8A9, 'M', u''),
    (0x2F8AA, 'M', u''),
    (0x2F8AB, 'M', u''),
    (0x2F8AC, 'M', u''),
    (0x2F8AD, 'M', u''),
    (0x2F8AE, 'M', u''),
    (0x2F8AF, 'M', u''),
    (0x2F8B0, 'M', u''),
    (0x2F8B1, 'M', u''),
    (0x2F8B2, 'M', u''),
    (0x2F8B3, 'M', u''),
    (0x2F8B4, 'M', u''),
    (0x2F8B5, 'M', u''),
    (0x2F8B6, 'M', u''),
    (0x2F8B7, 'M', u''),
    (0x2F8B8, 'M', u''),
    (0x2F8B9, 'M', u''),
    (0x2F8BA, 'M', u''),
    (0x2F8BB, 'M', u''),
    (0x2F8BC, 'M', u''),
    (0x2F8BD, 'M', u''),
    (0x2F8BE, 'M', u''),
    (0x2F8BF, 'M', u''),
    (0x2F8C0, 'M', u''),
    (0x2F8C1, 'M', u''),
    (0x2F8C2, 'M', u''),
    ]

def _seg_76():
    return [
    (0x2F8C3, 'M', u''),
    (0x2F8C4, 'M', u''),
    (0x2F8C5, 'M', u''),
    (0x2F8C6, 'M', u''),
    (0x2F8C7, 'M', u''),
    (0x2F8C8, 'M', u''),
    (0x2F8C9, 'M', u''),
    (0x2F8CA, 'M', u''),
    (0x2F8CB, 'M', u''),
    (0x2F8CC, 'M', u''),
    (0x2F8CD, 'M', u''),
    (0x2F8CE, 'M', u''),
    (0x2F8CF, 'M', u''),
    (0x2F8D0, 'M', u''),
    (0x2F8D1, 'M', u''),
    (0x2F8D2, 'M', u''),
    (0x2F8D3, 'M', u''),
    (0x2F8D4, 'M', u''),
    (0x2F8D5, 'M', u''),
    (0x2F8D6, 'M', u''),
    (0x2F8D7, 'M', u''),
    (0x2F8D8, 'M', u''),
    (0x2F8D9, 'M', u''),
    (0x2F8DA, 'M', u''),
    (0x2F8DB, 'M', u''),
    (0x2F8DC, 'M', u''),
    (0x2F8DD, 'M', u''),
    (0x2F8DE, 'M', u''),
    (0x2F8DF, 'M', u''),
    (0x2F8E0, 'M', u''),
    (0x2F8E1, 'M', u''),
    (0x2F8E2, 'M', u''),
    (0x2F8E3, 'M', u''),
    (0x2F8E4, 'M', u''),
    (0x2F8E5, 'M', u''),
    (0x2F8E6, 'M', u''),
    (0x2F8E7, 'M', u''),
    (0x2F8E8, 'M', u''),
    (0x2F8E9, 'M', u''),
    (0x2F8EA, 'M', u''),
    (0x2F8EB, 'M', u''),
    (0x2F8EC, 'M', u''),
    (0x2F8ED, 'M', u''),
    (0x2F8EE, 'M', u''),
    (0x2F8EF, 'M', u''),
    (0x2F8F0, 'M', u''),
    (0x2F8F1, 'M', u''),
    (0x2F8F2, 'M', u''),
    (0x2F8F3, 'M', u''),
    (0x2F8F4, 'M', u''),
    (0x2F8F5, 'M', u''),
    (0x2F8F6, 'M', u''),
    (0x2F8F7, 'M', u''),
    (0x2F8F8, 'M', u''),
    (0x2F8F9, 'M', u''),
    (0x2F8FA, 'M', u''),
    (0x2F8FB, 'M', u''),
    (0x2F8FC, 'M', u''),
    (0x2F8FD, 'M', u''),
    (0x2F8FE, 'M', u''),
    (0x2F8FF, 'M', u''),
    (0x2F900, 'M', u''),
    (0x2F901, 'M', u''),
    (0x2F902, 'M', u''),
    (0x2F903, 'M', u''),
    (0x2F904, 'M', u''),
    (0x2F905, 'M', u''),
    (0x2F906, 'M', u''),
    (0x2F907, 'M', u''),
    (0x2F908, 'M', u''),
    (0x2F909, 'M', u''),
    (0x2F90A, 'M', u''),
    (0x2F90B, 'M', u''),
    (0x2F90C, 'M', u''),
    (0x2F90D, 'M', u''),
    (0x2F90E, 'M', u''),
    (0x2F90F, 'M', u''),
    (0x2F910, 'M', u''),
    (0x2F911, 'M', u''),
    (0x2F912, 'M', u''),
    (0x2F913, 'M', u''),
    (0x2F914, 'M', u''),
    (0x2F915, 'M', u''),
    (0x2F916, 'M', u''),
    (0x2F917, 'M', u''),
    (0x2F918, 'M', u''),
    (0x2F919, 'M', u''),
    (0x2F91A, 'M', u''),
    (0x2F91B, 'M', u''),
    (0x2F91C, 'M', u''),
    (0x2F91D, 'M', u''),
    (0x2F91E, 'M', u''),
    (0x2F91F, 'X'),
    (0x2F920, 'M', u''),
    (0x2F921, 'M', u''),
    (0x2F922, 'M', u''),
    (0x2F923, 'M', u''),
    (0x2F924, 'M', u''),
    (0x2F925, 'M', u''),
    (0x2F926, 'M', u''),
    ]

def _seg_77():
    return [
    (0x2F927, 'M', u''),
    (0x2F928, 'M', u''),
    (0x2F929, 'M', u''),
    (0x2F92A, 'M', u''),
    (0x2F92B, 'M', u''),
    (0x2F92C, 'M', u''),
    (0x2F92E, 'M', u''),
    (0x2F92F, 'M', u''),
    (0x2F930, 'M', u''),
    (0x2F931, 'M', u''),
    (0x2F932, 'M', u''),
    (0x2F933, 'M', u''),
    (0x2F934, 'M', u''),
    (0x2F935, 'M', u''),
    (0x2F936, 'M', u''),
    (0x2F937, 'M', u''),
    (0x2F938, 'M', u''),
    (0x2F939, 'M', u''),
    (0x2F93A, 'M', u''),
    (0x2F93B, 'M', u''),
    (0x2F93C, 'M', u''),
    (0x2F93D, 'M', u''),
    (0x2F93E, 'M', u''),
    (0x2F93F, 'M', u''),
    (0x2F940, 'M', u''),
    (0x2F941, 'M', u''),
    (0x2F942, 'M', u''),
    (0x2F943, 'M', u''),
    (0x2F944, 'M', u''),
    (0x2F945, 'M', u''),
    (0x2F946, 'M', u''),
    (0x2F948, 'M', u''),
    (0x2F949, 'M', u''),
    (0x2F94A, 'M', u''),
    (0x2F94B, 'M', u''),
    (0x2F94C, 'M', u''),
    (0x2F94D, 'M', u''),
    (0x2F94E, 'M', u''),
    (0x2F94F, 'M', u''),
    (0x2F950, 'M', u''),
    (0x2F951, 'M', u''),
    (0x2F952, 'M', u''),
    (0x2F953, 'M', u''),
    (0x2F954, 'M', u''),
    (0x2F955, 'M', u''),
    (0x2F956, 'M', u''),
    (0x2F957, 'M', u''),
    (0x2F958, 'M', u''),
    (0x2F959, 'M', u''),
    (0x2F95A, 'M', u''),
    (0x2F95B, 'M', u''),
    (0x2F95C, 'M', u''),
    (0x2F95D, 'M', u''),
    (0x2F95F, 'X'),
    (0x2F960, 'M', u''),
    (0x2F961, 'M', u''),
    (0x2F962, 'M', u''),
    (0x2F963, 'M', u''),
    (0x2F964, 'M', u''),
    (0x2F965, 'M', u''),
    (0x2F966, 'M', u''),
    (0x2F967, 'M', u''),
    (0x2F968, 'M', u''),
    (0x2F969, 'M', u''),
    (0x2F96A, 'M', u''),
    (0x2F96B, 'M', u''),
    (0x2F96C, 'M', u''),
    (0x2F96D, 'M', u''),
    (0x2F96E, 'M', u''),
    (0x2F96F, 'M', u''),
    (0x2F970, 'M', u''),
    (0x2F971, 'M', u''),
    (0x2F972, 'M', u''),
    (0x2F973, 'M', u''),
    (0x2F974, 'M', u''),
    (0x2F975, 'M', u''),
    (0x2F976, 'M', u''),
    (0x2F977, 'M', u''),
    (0x2F978, 'M', u''),
    (0x2F979, 'M', u''),
    (0x2F97A, 'M', u''),
    (0x2F97B, 'M', u''),
    (0x2F97C, 'M', u''),
    (0x2F97D, 'M', u''),
    (0x2F97E, 'M', u''),
    (0x2F97F, 'M', u''),
    (0x2F980, 'M', u''),
    (0x2F981, 'M', u''),
    (0x2F982, 'M', u''),
    (0x2F983, 'M', u''),
    (0x2F984, 'M', u''),
    (0x2F985, 'M', u''),
    (0x2F986, 'M', u''),
    (0x2F987, 'M', u''),
    (0x2F988, 'M', u''),
    (0x2F989, 'M', u''),
    (0x2F98A, 'M', u''),
    (0x2F98B, 'M', u''),
    (0x2F98C, 'M', u''),
    (0x2F98D, 'M', u''),
    ]

def _seg_78():
    return [
    (0x2F98E, 'M', u''),
    (0x2F98F, 'M', u''),
    (0x2F990, 'M', u''),
    (0x2F991, 'M', u''),
    (0x2F992, 'M', u''),
    (0x2F993, 'M', u''),
    (0x2F994, 'M', u''),
    (0x2F995, 'M', u''),
    (0x2F996, 'M', u''),
    (0x2F997, 'M', u''),
    (0x2F998, 'M', u''),
    (0x2F999, 'M', u''),
    (0x2F99A, 'M', u''),
    (0x2F99B, 'M', u''),
    (0x2F99C, 'M', u''),
    (0x2F99D, 'M', u''),
    (0x2F99E, 'M', u''),
    (0x2F99F, 'M', u''),
    (0x2F9A0, 'M', u''),
    (0x2F9A1, 'M', u''),
    (0x2F9A2, 'M', u''),
    (0x2F9A3, 'M', u''),
    (0x2F9A4, 'M', u''),
    (0x2F9A5, 'M', u''),
    (0x2F9A6, 'M', u''),
    (0x2F9A7, 'M', u''),
    (0x2F9A8, 'M', u''),
    (0x2F9A9, 'M', u''),
    (0x2F9AA, 'M', u''),
    (0x2F9AB, 'M', u''),
    (0x2F9AC, 'M', u''),
    (0x2F9AD, 'M', u''),
    (0x2F9AE, 'M', u''),
    (0x2F9AF, 'M', u''),
    (0x2F9B0, 'M', u''),
    (0x2F9B1, 'M', u''),
    (0x2F9B2, 'M', u''),
    (0x2F9B3, 'M', u''),
    (0x2F9B4, 'M', u''),
    (0x2F9B5, 'M', u''),
    (0x2F9B6, 'M', u''),
    (0x2F9B7, 'M', u''),
    (0x2F9B8, 'M', u''),
    (0x2F9B9, 'M', u''),
    (0x2F9BA, 'M', u''),
    (0x2F9BB, 'M', u''),
    (0x2F9BC, 'M', u''),
    (0x2F9BD, 'M', u''),
    (0x2F9BE, 'M', u''),
    (0x2F9BF, 'X'),
    (0x2F9C0, 'M', u''),
    (0x2F9C1, 'M', u''),
    (0x2F9C2, 'M', u''),
    (0x2F9C3, 'M', u''),
    (0x2F9C4, 'M', u''),
    (0x2F9C5, 'M', u''),
    (0x2F9C6, 'M', u''),
    (0x2F9C7, 'M', u''),
    (0x2F9C8, 'M', u''),
    (0x2F9C9, 'M', u''),
    (0x2F9CA, 'M', u''),
    (0x2F9CB, 'M', u''),
    (0x2F9CC, 'M', u''),
    (0x2F9CD, 'M', u''),
    (0x2F9CE, 'M', u''),
    (0x2F9CF, 'M', u''),
    (0x2F9D0, 'M', u''),
    (0x2F9D1, 'M', u''),
    (0x2F9D2, 'M', u''),
    (0x2F9D3, 'M', u''),
    (0x2F9D4, 'M', u''),
    (0x2F9D5, 'M', u''),
    (0x2F9D6, 'M', u''),
    (0x2F9D7, 'M', u''),
    (0x2F9D8, 'M', u''),
    (0x2F9D9, 'M', u''),
    (0x2F9DA, 'M', u''),
    (0x2F9DB, 'M', u''),
    (0x2F9DC, 'M', u''),
    (0x2F9DD, 'M', u''),
    (0x2F9DE, 'M', u''),
    (0x2F9DF, 'M', u''),
    (0x2F9E0, 'M', u''),
    (0x2F9E1, 'M', u''),
    (0x2F9E2, 'M', u''),
    (0x2F9E3, 'M', u''),
    (0x2F9E4, 'M', u''),
    (0x2F9E5, 'M', u''),
    (0x2F9E6, 'M', u''),
    (0x2F9E7, 'M', u''),
    (0x2F9E8, 'M', u''),
    (0x2F9E9, 'M', u''),
    (0x2F9EA, 'M', u''),
    (0x2F9EB, 'M', u''),
    (0x2F9EC, 'M', u''),
    (0x2F9ED, 'M', u''),
    (0x2F9EE, 'M', u''),
    (0x2F9EF, 'M', u''),
    (0x2F9F0, 'M', u''),
    (0x2F9F1, 'M', u''),
    ]

def _seg_79():
    return [
    (0x2F9F2, 'M', u''),
    (0x2F9F3, 'M', u''),
    (0x2F9F4, 'M', u''),
    (0x2F9F5, 'M', u''),
    (0x2F9F6, 'M', u''),
    (0x2F9F7, 'M', u''),
    (0x2F9F8, 'M', u''),
    (0x2F9F9, 'M', u''),
    (0x2F9FA, 'M', u''),
    (0x2F9FB, 'M', u''),
    (0x2F9FC, 'M', u''),
    (0x2F9FD, 'M', u''),
    (0x2F9FE, 'M', u''),
    (0x2FA00, 'M', u''),
    (0x2FA01, 'M', u''),
    (0x2FA02, 'M', u''),
    (0x2FA03, 'M', u''),
    (0x2FA04, 'M', u''),
    (0x2FA05, 'M', u''),
    (0x2FA06, 'M', u''),
    (0x2FA07, 'M', u''),
    (0x2FA08, 'M', u''),
    (0x2FA09, 'M', u''),
    (0x2FA0A, 'M', u''),
    (0x2FA0B, 'M', u''),
    (0x2FA0C, 'M', u''),
    (0x2FA0D, 'M', u''),
    (0x2FA0E, 'M', u''),
    (0x2FA0F, 'M', u''),
    (0x2FA10, 'M', u''),
    (0x2FA11, 'M', u''),
    (0x2FA12, 'M', u''),
    (0x2FA13, 'M', u''),
    (0x2FA14, 'M', u''),
    (0x2FA15, 'M', u''),
    (0x2FA16, 'M', u''),
    (0x2FA17, 'M', u''),
    (0x2FA18, 'M', u''),
    (0x2FA19, 'M', u''),
    (0x2FA1A, 'M', u''),
    (0x2FA1B, 'M', u''),
    (0x2FA1C, 'M', u''),
    (0x2FA1D, 'M', u''),
    (0x2FA1E, 'X'),
    (0x30000, 'V'),
    (0x3134B, 'X'),
    (0xE0100, 'I'),
    (0xE01F0, 'X'),
    ]

uts46data = tuple(
    _seg_0()
    + _seg_1()
    + _seg_2()
    + _seg_3()
    + _seg_4()
    + _seg_5()
    + _seg_6()
    + _seg_7()
    + _seg_8()
    + _seg_9()
    + _seg_10()
    + _seg_11()
    + _seg_12()
    + _seg_13()
    + _seg_14()
    + _seg_15()
    + _seg_16()
    + _seg_17()
    + _seg_18()
    + _seg_19()
    + _seg_20()
    + _seg_21()
    + _seg_22()
    + _seg_23()
    + _seg_24()
    + _seg_25()
    + _seg_26()
    + _seg_27()
    + _seg_28()
    + _seg_29()
    + _seg_30()
    + _seg_31()
    + _seg_32()
    + _seg_33()
    + _seg_34()
    + _seg_35()
    + _seg_36()
    + _seg_37()
    + _seg_38()
    + _seg_39()
    + _seg_40()
    + _seg_41()
    + _seg_42()
    + _seg_43()
    + _seg_44()
    + _seg_45()
    + _seg_46()
    + _seg_47()
    + _seg_48()
    + _seg_49()
    + _seg_50()
    + _seg_51()
    + _seg_52()
    + _seg_53()
    + _seg_54()
    + _seg_55()
    + _seg_56()
    + _seg_57()
    + _seg_58()
    + _seg_59()
    + _seg_60()
    + _seg_61()
    + _seg_62()
    + _seg_63()
    + _seg_64()
    + _seg_65()
    + _seg_66()
    + _seg_67()
    + _seg_68()
    + _seg_69()
    + _seg_70()
    + _seg_71()
    + _seg_72()
    + _seg_73()
    + _seg_74()
    + _seg_75()
    + _seg_76()
    + _seg_77()
    + _seg_78()
    + _seg_79()
)




############################################################
### File: version.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""dnspython release version information."""

#: MAJOR
MAJOR = 1
#: MINOR
MINOR = 16
#: MICRO
MICRO = 0
#: RELEASELEVEL
RELEASELEVEL = 0x0f
#: SERIAL
SERIAL = 0

if RELEASELEVEL == 0x0f:
    #: version
    version = '%d.%d.%d' % (MAJOR, MINOR, MICRO)
elif RELEASELEVEL == 0x00:
    version = '%d.%d.%dx%d' % \
              (MAJOR, MINOR, MICRO, SERIAL)
else:
    version = '%d.%d.%d%x%d' % \
              (MAJOR, MINOR, MICRO, RELEASELEVEL, SERIAL)

#: hexversion
hexversion = MAJOR << 24 | MINOR << 16 | MICRO << 8 | RELEASELEVEL << 4 | \
    SERIAL




############################################################
### File: webvtt.py
############################################################
import re
import six
import sys
import datetime
from copy import deepcopy


from .base import (
    BaseReader, BaseWriter, CaptionSet, CaptionList, Caption, CaptionNode
)

from .geometry import Layout

from .exceptions import (
    CaptionReadError, CaptionReadSyntaxError, CaptionReadNoCaptions,
    InvalidInputError
)

# A WebVTT timing line has both start/end times and layout related settings
# (referred to as 'cue settings' in the documentation)
# The following pattern captures [start], [end] and [cue settings] if existent
from .geometry import HorizontalAlignmentEnum

TIMING_LINE_PATTERN = re.compile(r'^(\S+)\s+-->\s+(\S+)(?:\s+(.*?))?\s*$')
TIMESTAMP_PATTERN = re.compile(r'^(\d+):(\d{2})(:\d{2})?\.(\d{3})')
VOICE_SPAN_PATTERN = re.compile('<v(\\.\\w+)* ([^>]*)>')
OTHER_SPAN_PATTERN = (
    re.compile(
        r'</?([cibuv]|ruby|rt|lang|(\d+):(\d{2})(:\d{2})?\.(\d{3})).*?>'
    )
)  # These WebVTT tags are stripped off the cues on conversion

WEBVTT_VERSION_OF = {
    HorizontalAlignmentEnum.LEFT: 'left',
    HorizontalAlignmentEnum.CENTER: 'middle',
    HorizontalAlignmentEnum.RIGHT: 'right',
    HorizontalAlignmentEnum.START: 'start',
    HorizontalAlignmentEnum.END: 'end'
}

DEFAULT_ALIGNMENT = 'middle'


def microseconds(h, m, s, f):
    """
    Returns an integer representing a number of microseconds
    :rtype: int
    """
    return (int(h) * 3600 + int(m) * 60 + int(s)) * 1000000 + int(f) * 1000


class WebVTTReader(BaseReader):
    def __init__(self, ignore_timing_errors=True, *args, **kwargs):
        """
        :param ignore_timing_errors: Whether to ignore timing checks
        """
        self.ignore_timing_errors = ignore_timing_errors

    def detect(self, content):
        return 'WEBVTT' in content

    def read(self, content, lang='en-US'):
        if type(content) != six.text_type:
            raise InvalidInputError('The content is not a unicode string.')

        caption_set = CaptionSet({lang: self._parse(content.splitlines())})

        if caption_set.is_empty():
            raise CaptionReadNoCaptions("empty caption file")

        return caption_set

    def _parse(self, lines):
        captions = CaptionList()
        start = None
        end = None
        nodes = []
        layout_info = None
        found_timing = False

        for i, line in enumerate(lines):
            if '-->' in line:
                found_timing = True
                timing_line = i
                last_start_time = captions[-1].start if captions else 0
                try:
                    start, end, layout_info = self._parse_timing_line(
                        line, last_start_time)
                except CaptionReadError as e:
                    new_message = '%s (line %d)' % (e.args[0], timing_line)
                    six.reraise(type(e), type(e)(new_message), sys.exc_info()[2])

            elif '' == line:
                if found_timing:
                    found_timing = False
                    if nodes:
                        caption = Caption(
                            start, end, nodes, layout_info=layout_info)
                        captions.append(caption)
                        nodes = []
            else:
                if found_timing:
                    if nodes:
                        nodes.append(CaptionNode.create_break())
                    nodes.append(CaptionNode.create_text(
                        self._decode(line)))
                else:
                    # it's a comment or some metadata; ignore it
                    pass

        # Add a last caption if there are remaining nodes
        if nodes:
            caption = Caption(start, end, nodes, layout_info=layout_info)
            captions.append(caption)

        return captions

    def _remove_styles(self, line):
        partial_result = VOICE_SPAN_PATTERN.sub('\\2: ', line)
        return OTHER_SPAN_PATTERN.sub('', partial_result)

    def _validate_timings(self, start, end, last_start_time):
        if start is None:
            raise CaptionReadSyntaxError(
                'Invalid cue start timestamp.')
        if end is None:
            raise CaptionReadSyntaxError('Invalid cue end timestamp.')
        if start > end:
            raise CaptionReadError(
                'End timestamp is not greater than start timestamp.')
        if start < last_start_time:
            raise CaptionReadError(
                'Start timestamp is not greater than or equal'
                'to start timestamp of previous cue.')

    def _parse_timing_line(self, line, last_start_time):
        """
        :returns: Tuple (int, int, Layout)
        """
        m = TIMING_LINE_PATTERN.search(line)
        if not m:
            raise CaptionReadSyntaxError(
                'Invalid timing format.')

        start = self._parse_timestamp(m.group(1))
        end = self._parse_timestamp(m.group(2))

        cue_settings = m.group(3)

        if not self.ignore_timing_errors:
            self._validate_timings(start, end, last_start_time)

        layout_info = None
        if cue_settings:
            layout_info = Layout(webvtt_positioning=cue_settings)

        return start, end, layout_info

    def _parse_timestamp(self, timestamp):
        """Returns an integer representing a number of microseconds
        :rtype: int
        """
        m = TIMESTAMP_PATTERN.search(timestamp)
        if not m:
            raise CaptionReadSyntaxError(
                'Invalid timing format.')

        m = m.groups()

        if m[2]:
            # Timestamp takes the form of [hours]:[minutes]:[seconds].[milliseconds]
            return microseconds(m[0], m[1], m[2].replace(":", ""), m[3])
        else:
            # Timestamp takes the form of [minutes]:[seconds].[milliseconds]
            return microseconds(0, m[0], m[1], m[3])

    def _decode(self, s):
        """
        Convert cue text from WebVTT XML-like format to plain unicode.
        :type s: unicode
        """
        s = s.strip()
        # Covert voice span
        s = VOICE_SPAN_PATTERN.sub('\\2: ', s)
        # TODO: Add support for other WebVTT tags. For now just strip them
        # off the text.
        s = OTHER_SPAN_PATTERN.sub('', s)
        # Replace WebVTT special XML codes with plain unicode values
        s = s.replace('&lt;', '<')
        s = s.replace('&gt;', '>')
        s = s.replace('&lrm;', '\u200e')
        s = s.replace('&rlm;', '\u200f')
        s = s.replace('&nbsp;', '\u00a0')
        # Must do ampersand last
        s = s.replace('&amp;', '&')
        return s


class WebVTTWriter(BaseWriter):
    HEADER = 'WEBVTT\n\n'
    global_layout = None
    video_width = None
    video_height = None

    def write(self, caption_set):
        """
        :type caption_set: CaptionSet
        """
        output = self.HEADER

        if caption_set.is_empty():
            return output

        caption_set = deepcopy(caption_set)

        # TODO: styles. These go into a separate CSS file, which doesn't really
        # fit the API here. Figure that out.  Though some style stuff can be
        # done in-line.  This format is a little bit crazy.

        # WebVTT's language support seems to be a bit crazy, so let's just
        # support a single one for now.
        lang = list(caption_set.get_languages())[0]

        self.global_layout = caption_set.get_layout_info(lang)

        captions = caption_set.get_captions(lang)
        for i, caption in enumerate(captions):
            merge = i > 0 and captions[i-1].start == caption.start and captions[i-1].end == caption.end
            if not merge:
                output += '\n'
            else:
                #we merging with last subtitle so remove previous newline
                output = output.rstrip()
                output += ' '

            output += self._write_caption(caption_set, caption, merge=merge)

        return output

    def _timestamp(self, timestamp):
        td = datetime.timedelta(microseconds=timestamp)
        mm, ss = divmod(td.seconds, 60)
        hh, mm = divmod(mm, 60)
        return "%02u:%02u:%02u.%03u" % (hh, mm, ss, td.microseconds/1000)

    def _tags_for_style(self, style):
        if style == 'italics':
            return ['<i>', '</i>']
        elif style == 'underline':
            return ['<u>', '</u>']
        elif style == 'bold':
            return ['<b>', '</b>']
        else:
            return ['', '']

    def _calculate_resulting_style(self, style, caption_set):
        resulting_style = {}

        style_classes = []
        if 'classes' in style:
            style_classes = style['classes']
        elif 'class' in style:
            style_classes = [style['class']]

        for style_class in style_classes:
            sub_style = caption_set.get_style(style_class).copy()
            # Recursively resolve class attributes and calculate style
            resulting_style.update(self._calculate_resulting_style(sub_style, caption_set))

        resulting_style.update(style)

        return resulting_style

    def _write_caption(self, caption_set, caption, merge=False):
        """
        :type caption: Caption
        """
        layout_groups = self._layout_groups(caption.nodes, caption_set)

        start = self._timestamp(caption.start)
        end = self._timestamp(caption.end)
        timespan = "{} --> {}".format(start, end)

        output = ''

        cue_style_tags = ['', '']

        style = self._calculate_resulting_style(caption.style, caption_set)
        for key, value in sorted(style.items()):
            if value:
                tags = self._tags_for_style(key)
#                    print "tags: " + str(tags) + "\n"
                cue_style_tags[0] += tags[0]
                cue_style_tags[1] = tags[1] + cue_style_tags[1]

        for cue_text, layout in layout_groups:
            if not layout:
                layout = caption.layout_info or self.global_layout
            cue_settings = self._cue_settings_from(layout)
            if not merge:
                output += timespan + cue_settings + '\n'
            elif cue_text.startswith('-'):
                output += '\n'
            output += cue_style_tags[0] + cue_text + cue_style_tags[1] + '\n'

        return output

    def _cue_settings_from(self, layout):
        """
        Return WebVTT cue settings string based on layout info
        :type layout: Layout
        :rtype: unicode
        """
        if not layout:
            return ''

        # If it's converting from WebVTT to WebVTT, keep positioning info
        # unchanged
        if layout.webvtt_positioning:
            return ' {}'.format(layout.webvtt_positioning)

        left_offset = None
        top_offset = None
        cue_width = None
        alignment = None

        already_relative = False
        if not self.relativize:
            if layout.is_relative():
                already_relative = True
            else:
                # There are absolute positioning values for this cue but the
                # Writer is explicitly configured not to do any relativization.
                # Ignore all positioning for this cue.
                return ''

        # Ensure that all positioning values are measured using percentage.
        # This may raise an exception if layout.is_relative() == False
        # If you want to avoid it, you have to turn off relativization by
        # initializing this Writer with relativize=False.
        if not already_relative:
            layout = layout.as_percentage_of(
                self.video_width, self.video_height)

        # Ensure that when there's a left offset the caption is not pushed out
        # of the screen. If the execution got this far it means origin and
        # extent are already relative by now.
        if self.fit_to_screen:
            layout = layout.fit_to_screen()

        if layout.origin:
            left_offset = layout.origin.x
            top_offset = layout.origin.y

        if layout.extent:
            cue_width = layout.extent.horizontal

        if layout.padding:
            if layout.padding.start and left_offset:
                # Since there is no padding in WebVTT, the left padding is
                # added to the total left offset (if it is defined and not
                # relative),
                if left_offset:
                    left_offset += layout.padding.start
                # and removed from the total cue width
                if cue_width:
                    cue_width -= layout.padding.start
            # the right padding is cut out of the total cue width,
            if layout.padding.end and cue_width:
                cue_width -= layout.padding.end
            # the top padding is added to the top offset
            # (if it is defined and not relative)
            if layout.padding.before and top_offset:
                top_offset += layout.padding.before
            # and the bottom padding is ignored because the cue box is only as
            # long vertically as the text it contains and nothing can be cut
            # out

        try:
            alignment = WEBVTT_VERSION_OF[layout.alignment.horizontal]
        except (AttributeError, KeyError):
            pass

        cue_settings = ''

        if alignment and alignment != 'middle':
            cue_settings += " align:" + alignment
        if left_offset:
            cue_settings += " position:{},start".format(six.text_type(left_offset))
        if top_offset:
            cue_settings += " line:" + six.text_type(top_offset)
        if cue_width:
            cue_settings += " size:" + six.text_type(cue_width)

        return cue_settings

    def _layout_groups(self, nodes, caption_set):
        """
        Convert a Caption's nodes to WebVTT cue or cues (depending on
        whether they have the same positioning or not).
        """
        if not nodes:
            return []

        current_layout = None

        # A list with layout groups. Since WebVTT only support positioning
        # for different cues, each layout group has to be represented in a
        # new cue with the same timing but different positioning settings.
        layout_groups = []
        # A properly encoded WebVTT string (plain unicode must be properly
        # escaped before being appended to this string)
        s = ''
        for i, node in enumerate(nodes):
            if node.type_ == CaptionNode.TEXT:
                if s and current_layout and node.layout_info != current_layout:
                    # If the positioning changes from one text node to
                    # another, a new WebVTT cue has to be created.
                    layout_groups.append((s, current_layout))
                    s = ''
                # ATTENTION: This is where the plain unicode node content is
                # finally encoded as WebVTT.
                s += self._encode(node.content) or '&nbsp;'
                current_layout = node.layout_info
            elif node.type_ == CaptionNode.STYLE:
                resulting_style = self._calculate_resulting_style(node.content, caption_set)

                styles = ['italics', 'underline', 'bold']
                if not node.start:
                    styles.reverse()

                for style in styles:
                    if style in resulting_style and resulting_style[style]:
                        tags = self._tags_for_style(style)
                        if node.start:
                            s += tags[0]
                        else:
                            s += tags[1]

                # TODO: Refactor pycaption and eliminate the concept of a
                # "Style node"
            elif node.type_ == CaptionNode.BREAK:
                if i > 0 and nodes[i - 1].type_ != CaptionNode.TEXT:
                    s += '&nbsp;'
                if i == 0:  # cue text starts with a break
                    s += '&nbsp;'
                s += '\n'

        if s:
            layout_groups.append((s, current_layout))
        return layout_groups

    def _encode(self, s):
        """
        Convert cue text from plain unicode to WebVTT XML-like format
        escaping illegal characters. For a list of illegal characters see:
            - http://dev.w3.org/html5/webvtt/#dfn-webvtt-cue-text-span
        :type s: unicode
        """
        s = s.replace('&', '&amp;')
        s = s.replace('<', '&lt;')

        # The substring "-->" is also not allowed according to this:
        #   - http://dev.w3.org/html5/webvtt/#dfn-webvtt-cue-block
        s = s.replace('-->', '--&gt;')

        # The following characters have escaping codes for some reason, but
        # they're not illegal, so for now I'll leave this commented out so that
        # we stay as close as possible to the specification and avoid doing
        # extra stuff "just to be safe".
        # s = s.replace(u'>', u'&gt;')
        # s = s.replace(u'\u200e', u'&lrm;')
        # s = s.replace(u'\u200f', u'&rlm;')
        # s = s.replace(u'\u00a0', u'&nbsp;')
        return s




############################################################
### File: win_inet_pton.py
############################################################
# This software released into the public domain. Anyone is free to copy,
# modify, publish, use, compile, sell, or distribute this software,
# either in source code form or as a compiled binary, for any purpose,
# commercial or non-commercial, and by any means.

import socket
import os
import sys


def inject_into_socket():
    import ctypes

    class in_addr(ctypes.Structure):
        _fields_ = [("S_addr", ctypes.c_ubyte * 4)]

    class in6_addr(ctypes.Structure):
        _fields_ = [("Byte", ctypes.c_ubyte * 16)]

    if hasattr(ctypes, "windll"):
        # InetNtopW(
        #   INT         family,
        #   const VOID  *pAddr,
        #   PWSTR       pStringBuf,
        #   size_t      StringBufSize
        # ) -> PCWSTR
        InetNtopW = ctypes.windll.ws2_32.InetNtopW

        # InetPtonW(
        #   INT         family,
        #   PCWSTR      pszAddrString,
        #   PVOID       pAddrBuf
        # ) -> INT
        InetPtonW = ctypes.windll.ws2_32.InetPtonW

        # WSAGetLastError() -> INT
        WSAGetLastError = ctypes.windll.ws2_32.WSAGetLastError
    else:

        def not_windows():
            raise SystemError("Invalid platform. ctypes.windll must be available.")

        InetNtopW = not_windows
        InetPtonW = not_windows
        WSAGetLastError = not_windows

    def inet_pton(address_family, ip_string):
        if sys.version_info[0] > 2 and isinstance(ip_string, bytes):
            raise TypeError("inet_pton() argument 2 must be str, not bytes")

        if address_family == socket.AF_INET:
            family = 2
            addr = in_addr()
        elif address_family == socket.AF_INET6:
            family = 23
            addr = in6_addr()
        else:
            raise OSError("unknown address family")

        ip_string = ctypes.c_wchar_p(ip_string)
        ret = InetPtonW(ctypes.c_int(family), ip_string, ctypes.byref(addr))

        if ret == 1:
            if address_family == socket.AF_INET:
                return ctypes.string_at(addr.S_addr, 4)
            else:
                return ctypes.string_at(addr.Byte, 16)
        elif ret == 0:
            raise socket.error("illegal IP address string passed to inet_pton")
        else:
            err = WSAGetLastError()
            if err == 10047:
                e = socket.error("unknown address family")
            elif err == 10014:
                e = OSError("bad address")
            else:
                e = OSError("unknown error from inet_ntop")
            e.errno = err
            raise e

    def inet_ntop(address_family, packed_ip):
        if address_family == socket.AF_INET:
            addr = in_addr()
            if len(packed_ip) != ctypes.sizeof(addr.S_addr):
                raise ValueError("packed IP wrong length for inet_ntop")

            ctypes.memmove(addr.S_addr, packed_ip, 4)
            buffer_len = 16
            family = 2

        elif address_family == socket.AF_INET6:
            addr = in6_addr()
            if len(packed_ip) != ctypes.sizeof(addr.Byte):
                raise ValueError("packed IP wrong length for inet_ntop")

            ctypes.memmove(addr.Byte, packed_ip, 16)
            buffer_len = 46
            family = 23
        else:
            raise ValueError("unknown address family")

        buffer = ctypes.create_unicode_buffer(buffer_len)

        ret = InetNtopW(
            ctypes.c_int(family),
            ctypes.byref(addr),
            ctypes.byref(buffer),
            ctypes.sizeof(buffer),
        )
        if ret is None:
            err = WSAGetLastError()
            if err == 10047:
                e = ValueError("unknown address family")
            else:
                e = OSError("unknown error from inet_ntop")
            e.errno = err

        return ctypes.wstring_at(buffer, buffer_len).rstrip("\x00")

    # Adding our two functions to the socket library
    socket.inet_pton = inet_pton
    socket.inet_ntop = inet_ntop


if os.name == "nt" and not hasattr(socket, "inet_pton"):
    inject_into_socket()




############################################################
### File: win32.py
############################################################
try:
    import _winreg as winreg
except ImportError:
    import winreg

import pytz

from tzlocal.windows_tz import win_tz
from tzlocal import utils

_cache_tz = None


def valuestodict(key):
    """Convert a registry key's values to a dictionary."""
    dict = {}
    size = winreg.QueryInfoKey(key)[1]
    for i in range(size):
        data = winreg.EnumValue(key, i)
        dict[data[0]] = data[1]
    return dict


def get_localzone_name():
    # Windows is special. It has unique time zone names (in several
    # meanings of the word) available, but unfortunately, they can be
    # translated to the language of the operating system, so we need to
    # do a backwards lookup, by going through all time zones and see which
    # one matches.
    handle = winreg.ConnectRegistry(None, winreg.HKEY_LOCAL_MACHINE)

    TZLOCALKEYNAME = r"SYSTEM\CurrentControlSet\Control\TimeZoneInformation"
    localtz = winreg.OpenKey(handle, TZLOCALKEYNAME)
    keyvalues = valuestodict(localtz)
    localtz.Close()

    if 'TimeZoneKeyName' in keyvalues:
        # Windows 7 (and Vista?)

        # For some reason this returns a string with loads of NUL bytes at
        # least on some systems. I don't know if this is a bug somewhere, I
        # just work around it.
        tzkeyname = keyvalues['TimeZoneKeyName'].split('\x00', 1)[0]
    else:
        # Windows 2000 or XP

        # This is the localized name:
        tzwin = keyvalues['StandardName']

        # Open the list of timezones to look up the real name:
        TZKEYNAME = r"SOFTWARE\Microsoft\Windows NT\CurrentVersion\Time Zones"
        tzkey = winreg.OpenKey(handle, TZKEYNAME)

        # Now, match this value to Time Zone information
        tzkeyname = None
        for i in range(winreg.QueryInfoKey(tzkey)[0]):
            subkey = winreg.EnumKey(tzkey, i)
            sub = winreg.OpenKey(tzkey, subkey)
            data = valuestodict(sub)
            sub.Close()
            try:
                if data['Std'] == tzwin:
                    tzkeyname = subkey
                    break
            except KeyError:
                # This timezone didn't have proper configuration.
                # Ignore it.
                pass

        tzkey.Close()
        handle.Close()

    if tzkeyname is None:
        raise LookupError('Can not find Windows timezone configuration')

    timezone = win_tz.get(tzkeyname)
    if timezone is None:
        # Nope, that didn't work. Try adding "Standard Time",
        # it seems to work a lot of times:
        timezone = win_tz.get(tzkeyname + " Standard Time")

    # Return what we have.
    if timezone is None:
        raise pytz.UnknownTimeZoneError('Can not find timezone ' + tzkeyname)

    return timezone


def get_localzone():
    """Returns the zoneinfo-based tzinfo object that matches the Windows-configured timezone."""
    global _cache_tz
    if _cache_tz is None:
        _cache_tz = pytz.timezone(get_localzone_name())

    utils.assert_tz_offset(_cache_tz)
    return _cache_tz


def reload_localzone():
    """Reload the cached localzone. You need to call this if the timezone has changed."""
    global _cache_tz
    _cache_tz = pytz.timezone(get_localzone_name())
    utils.assert_tz_offset(_cache_tz)
    return _cache_tz




############################################################
### File: windows_tz.py
############################################################
# This file is autogenerated by the update_windows_mapping.py script
# Do not edit.
win_tz = {'AUS Central Standard Time': 'Australia/Darwin',
 'AUS Eastern Standard Time': 'Australia/Sydney',
 'Afghanistan Standard Time': 'Asia/Kabul',
 'Alaskan Standard Time': 'America/Anchorage',
 'Aleutian Standard Time': 'America/Adak',
 'Altai Standard Time': 'Asia/Barnaul',
 'Arab Standard Time': 'Asia/Riyadh',
 'Arabian Standard Time': 'Asia/Dubai',
 'Arabic Standard Time': 'Asia/Baghdad',
 'Argentina Standard Time': 'America/Buenos_Aires',
 'Astrakhan Standard Time': 'Europe/Astrakhan',
 'Atlantic Standard Time': 'America/Halifax',
 'Aus Central W. Standard Time': 'Australia/Eucla',
 'Azerbaijan Standard Time': 'Asia/Baku',
 'Azores Standard Time': 'Atlantic/Azores',
 'Bahia Standard Time': 'America/Bahia',
 'Bangladesh Standard Time': 'Asia/Dhaka',
 'Belarus Standard Time': 'Europe/Minsk',
 'Bougainville Standard Time': 'Pacific/Bougainville',
 'Canada Central Standard Time': 'America/Regina',
 'Cape Verde Standard Time': 'Atlantic/Cape_Verde',
 'Caucasus Standard Time': 'Asia/Yerevan',
 'Cen. Australia Standard Time': 'Australia/Adelaide',
 'Central America Standard Time': 'America/Guatemala',
 'Central Asia Standard Time': 'Asia/Almaty',
 'Central Brazilian Standard Time': 'America/Cuiaba',
 'Central Europe Standard Time': 'Europe/Budapest',
 'Central European Standard Time': 'Europe/Warsaw',
 'Central Pacific Standard Time': 'Pacific/Guadalcanal',
 'Central Standard Time': 'America/Chicago',
 'Central Standard Time (Mexico)': 'America/Mexico_City',
 'Chatham Islands Standard Time': 'Pacific/Chatham',
 'China Standard Time': 'Asia/Shanghai',
 'Cuba Standard Time': 'America/Havana',
 'Dateline Standard Time': 'Etc/GMT+12',
 'E. Africa Standard Time': 'Africa/Nairobi',
 'E. Australia Standard Time': 'Australia/Brisbane',
 'E. Europe Standard Time': 'Europe/Chisinau',
 'E. South America Standard Time': 'America/Sao_Paulo',
 'Easter Island Standard Time': 'Pacific/Easter',
 'Eastern Standard Time': 'America/New_York',
 'Eastern Standard Time (Mexico)': 'America/Cancun',
 'Egypt Standard Time': 'Africa/Cairo',
 'Ekaterinburg Standard Time': 'Asia/Yekaterinburg',
 'FLE Standard Time': 'Europe/Kiev',
 'Fiji Standard Time': 'Pacific/Fiji',
 'GMT Standard Time': 'Europe/London',
 'GTB Standard Time': 'Europe/Bucharest',
 'Georgian Standard Time': 'Asia/Tbilisi',
 'Greenland Standard Time': 'America/Godthab',
 'Greenwich Standard Time': 'Atlantic/Reykjavik',
 'Haiti Standard Time': 'America/Port-au-Prince',
 'Hawaiian Standard Time': 'Pacific/Honolulu',
 'India Standard Time': 'Asia/Calcutta',
 'Iran Standard Time': 'Asia/Tehran',
 'Israel Standard Time': 'Asia/Jerusalem',
 'Jordan Standard Time': 'Asia/Amman',
 'Kaliningrad Standard Time': 'Europe/Kaliningrad',
 'Korea Standard Time': 'Asia/Seoul',
 'Libya Standard Time': 'Africa/Tripoli',
 'Line Islands Standard Time': 'Pacific/Kiritimati',
 'Lord Howe Standard Time': 'Australia/Lord_Howe',
 'Magadan Standard Time': 'Asia/Magadan',
 'Magallanes Standard Time': 'America/Punta_Arenas',
 'Marquesas Standard Time': 'Pacific/Marquesas',
 'Mauritius Standard Time': 'Indian/Mauritius',
 'Middle East Standard Time': 'Asia/Beirut',
 'Montevideo Standard Time': 'America/Montevideo',
 'Morocco Standard Time': 'Africa/Casablanca',
 'Mountain Standard Time': 'America/Denver',
 'Mountain Standard Time (Mexico)': 'America/Chihuahua',
 'Myanmar Standard Time': 'Asia/Rangoon',
 'N. Central Asia Standard Time': 'Asia/Novosibirsk',
 'Namibia Standard Time': 'Africa/Windhoek',
 'Nepal Standard Time': 'Asia/Katmandu',
 'New Zealand Standard Time': 'Pacific/Auckland',
 'Newfoundland Standard Time': 'America/St_Johns',
 'Norfolk Standard Time': 'Pacific/Norfolk',
 'North Asia East Standard Time': 'Asia/Irkutsk',
 'North Asia Standard Time': 'Asia/Krasnoyarsk',
 'North Korea Standard Time': 'Asia/Pyongyang',
 'Omsk Standard Time': 'Asia/Omsk',
 'Pacific SA Standard Time': 'America/Santiago',
 'Pacific Standard Time': 'America/Los_Angeles',
 'Pacific Standard Time (Mexico)': 'America/Tijuana',
 'Pakistan Standard Time': 'Asia/Karachi',
 'Paraguay Standard Time': 'America/Asuncion',
 'Qyzylorda Standard Time': 'Asia/Qyzylorda',
 'Romance Standard Time': 'Europe/Paris',
 'Russia Time Zone 10': 'Asia/Srednekolymsk',
 'Russia Time Zone 11': 'Asia/Kamchatka',
 'Russia Time Zone 3': 'Europe/Samara',
 'Russian Standard Time': 'Europe/Moscow',
 'SA Eastern Standard Time': 'America/Cayenne',
 'SA Pacific Standard Time': 'America/Bogota',
 'SA Western Standard Time': 'America/La_Paz',
 'SE Asia Standard Time': 'Asia/Bangkok',
 'Saint Pierre Standard Time': 'America/Miquelon',
 'Sakhalin Standard Time': 'Asia/Sakhalin',
 'Samoa Standard Time': 'Pacific/Apia',
 'Sao Tome Standard Time': 'Africa/Sao_Tome',
 'Saratov Standard Time': 'Europe/Saratov',
 'Singapore Standard Time': 'Asia/Singapore',
 'South Africa Standard Time': 'Africa/Johannesburg',
 'Sri Lanka Standard Time': 'Asia/Colombo',
 'Sudan Standard Time': 'Africa/Khartoum',
 'Syria Standard Time': 'Asia/Damascus',
 'Taipei Standard Time': 'Asia/Taipei',
 'Tasmania Standard Time': 'Australia/Hobart',
 'Tocantins Standard Time': 'America/Araguaina',
 'Tokyo Standard Time': 'Asia/Tokyo',
 'Tomsk Standard Time': 'Asia/Tomsk',
 'Tonga Standard Time': 'Pacific/Tongatapu',
 'Transbaikal Standard Time': 'Asia/Chita',
 'Turkey Standard Time': 'Europe/Istanbul',
 'Turks And Caicos Standard Time': 'America/Grand_Turk',
 'US Eastern Standard Time': 'America/Indianapolis',
 'US Mountain Standard Time': 'America/Phoenix',
 'UTC': 'Etc/GMT',
 'UTC+12': 'Etc/GMT-12',
 'UTC+13': 'Etc/GMT-13',
 'UTC-02': 'Etc/GMT+2',
 'UTC-08': 'Etc/GMT+8',
 'UTC-09': 'Etc/GMT+9',
 'UTC-11': 'Etc/GMT+11',
 'Ulaanbaatar Standard Time': 'Asia/Ulaanbaatar',
 'Venezuela Standard Time': 'America/Caracas',
 'Vladivostok Standard Time': 'Asia/Vladivostok',
 'Volgograd Standard Time': 'Europe/Volgograd',
 'W. Australia Standard Time': 'Australia/Perth',
 'W. Central Africa Standard Time': 'Africa/Lagos',
 'W. Europe Standard Time': 'Europe/Berlin',
 'W. Mongolia Standard Time': 'Asia/Hovd',
 'West Asia Standard Time': 'Asia/Tashkent',
 'West Bank Standard Time': 'Asia/Hebron',
 'West Pacific Standard Time': 'Pacific/Port_Moresby',
 'Yakutsk Standard Time': 'Asia/Yakutsk'}

# Old name for the win_tz variable:
tz_names = win_tz

tz_win = {'Africa/Abidjan': 'Greenwich Standard Time',
 'Africa/Accra': 'Greenwich Standard Time',
 'Africa/Addis_Ababa': 'E. Africa Standard Time',
 'Africa/Algiers': 'W. Central Africa Standard Time',
 'Africa/Asmera': 'E. Africa Standard Time',
 'Africa/Bamako': 'Greenwich Standard Time',
 'Africa/Bangui': 'W. Central Africa Standard Time',
 'Africa/Banjul': 'Greenwich Standard Time',
 'Africa/Bissau': 'Greenwich Standard Time',
 'Africa/Blantyre': 'South Africa Standard Time',
 'Africa/Brazzaville': 'W. Central Africa Standard Time',
 'Africa/Bujumbura': 'South Africa Standard Time',
 'Africa/Cairo': 'Egypt Standard Time',
 'Africa/Casablanca': 'Morocco Standard Time',
 'Africa/Ceuta': 'Romance Standard Time',
 'Africa/Conakry': 'Greenwich Standard Time',
 'Africa/Dakar': 'Greenwich Standard Time',
 'Africa/Dar_es_Salaam': 'E. Africa Standard Time',
 'Africa/Djibouti': 'E. Africa Standard Time',
 'Africa/Douala': 'W. Central Africa Standard Time',
 'Africa/El_Aaiun': 'Morocco Standard Time',
 'Africa/Freetown': 'Greenwich Standard Time',
 'Africa/Gaborone': 'South Africa Standard Time',
 'Africa/Harare': 'South Africa Standard Time',
 'Africa/Johannesburg': 'South Africa Standard Time',
 'Africa/Juba': 'E. Africa Standard Time',
 'Africa/Kampala': 'E. Africa Standard Time',
 'Africa/Khartoum': 'Sudan Standard Time',
 'Africa/Kigali': 'South Africa Standard Time',
 'Africa/Kinshasa': 'W. Central Africa Standard Time',
 'Africa/Lagos': 'W. Central Africa Standard Time',
 'Africa/Libreville': 'W. Central Africa Standard Time',
 'Africa/Lome': 'Greenwich Standard Time',
 'Africa/Luanda': 'W. Central Africa Standard Time',
 'Africa/Lubumbashi': 'South Africa Standard Time',
 'Africa/Lusaka': 'South Africa Standard Time',
 'Africa/Malabo': 'W. Central Africa Standard Time',
 'Africa/Maputo': 'South Africa Standard Time',
 'Africa/Maseru': 'South Africa Standard Time',
 'Africa/Mbabane': 'South Africa Standard Time',
 'Africa/Mogadishu': 'E. Africa Standard Time',
 'Africa/Monrovia': 'Greenwich Standard Time',
 'Africa/Nairobi': 'E. Africa Standard Time',
 'Africa/Ndjamena': 'W. Central Africa Standard Time',
 'Africa/Niamey': 'W. Central Africa Standard Time',
 'Africa/Nouakchott': 'Greenwich Standard Time',
 'Africa/Ouagadougou': 'Greenwich Standard Time',
 'Africa/Porto-Novo': 'W. Central Africa Standard Time',
 'Africa/Sao_Tome': 'Sao Tome Standard Time',
 'Africa/Timbuktu': 'Greenwich Standard Time',
 'Africa/Tripoli': 'Libya Standard Time',
 'Africa/Tunis': 'W. Central Africa Standard Time',
 'Africa/Windhoek': 'Namibia Standard Time',
 'America/Adak': 'Aleutian Standard Time',
 'America/Anchorage': 'Alaskan Standard Time',
 'America/Anguilla': 'SA Western Standard Time',
 'America/Antigua': 'SA Western Standard Time',
 'America/Araguaina': 'Tocantins Standard Time',
 'America/Argentina/La_Rioja': 'Argentina Standard Time',
 'America/Argentina/Rio_Gallegos': 'Argentina Standard Time',
 'America/Argentina/Salta': 'Argentina Standard Time',
 'America/Argentina/San_Juan': 'Argentina Standard Time',
 'America/Argentina/San_Luis': 'Argentina Standard Time',
 'America/Argentina/Tucuman': 'Argentina Standard Time',
 'America/Argentina/Ushuaia': 'Argentina Standard Time',
 'America/Aruba': 'SA Western Standard Time',
 'America/Asuncion': 'Paraguay Standard Time',
 'America/Atka': 'Aleutian Standard Time',
 'America/Bahia': 'Bahia Standard Time',
 'America/Bahia_Banderas': 'Central Standard Time (Mexico)',
 'America/Barbados': 'SA Western Standard Time',
 'America/Belem': 'SA Eastern Standard Time',
 'America/Belize': 'Central America Standard Time',
 'America/Blanc-Sablon': 'SA Western Standard Time',
 'America/Boa_Vista': 'SA Western Standard Time',
 'America/Bogota': 'SA Pacific Standard Time',
 'America/Boise': 'Mountain Standard Time',
 'America/Buenos_Aires': 'Argentina Standard Time',
 'America/Cambridge_Bay': 'Mountain Standard Time',
 'America/Campo_Grande': 'Central Brazilian Standard Time',
 'America/Cancun': 'Eastern Standard Time (Mexico)',
 'America/Caracas': 'Venezuela Standard Time',
 'America/Catamarca': 'Argentina Standard Time',
 'America/Cayenne': 'SA Eastern Standard Time',
 'America/Cayman': 'SA Pacific Standard Time',
 'America/Chicago': 'Central Standard Time',
 'America/Chihuahua': 'Mountain Standard Time (Mexico)',
 'America/Coral_Harbour': 'SA Pacific Standard Time',
 'America/Cordoba': 'Argentina Standard Time',
 'America/Costa_Rica': 'Central America Standard Time',
 'America/Creston': 'US Mountain Standard Time',
 'America/Cuiaba': 'Central Brazilian Standard Time',
 'America/Curacao': 'SA Western Standard Time',
 'America/Danmarkshavn': 'UTC',
 'America/Dawson': 'Pacific Standard Time',
 'America/Dawson_Creek': 'US Mountain Standard Time',
 'America/Denver': 'Mountain Standard Time',
 'America/Detroit': 'Eastern Standard Time',
 'America/Dominica': 'SA Western Standard Time',
 'America/Edmonton': 'Mountain Standard Time',
 'America/Eirunepe': 'SA Pacific Standard Time',
 'America/El_Salvador': 'Central America Standard Time',
 'America/Ensenada': 'Pacific Standard Time (Mexico)',
 'America/Fort_Nelson': 'US Mountain Standard Time',
 'America/Fortaleza': 'SA Eastern Standard Time',
 'America/Glace_Bay': 'Atlantic Standard Time',
 'America/Godthab': 'Greenland Standard Time',
 'America/Goose_Bay': 'Atlantic Standard Time',
 'America/Grand_Turk': 'Turks And Caicos Standard Time',
 'America/Grenada': 'SA Western Standard Time',
 'America/Guadeloupe': 'SA Western Standard Time',
 'America/Guatemala': 'Central America Standard Time',
 'America/Guayaquil': 'SA Pacific Standard Time',
 'America/Guyana': 'SA Western Standard Time',
 'America/Halifax': 'Atlantic Standard Time',
 'America/Havana': 'Cuba Standard Time',
 'America/Hermosillo': 'US Mountain Standard Time',
 'America/Indiana/Knox': 'Central Standard Time',
 'America/Indiana/Marengo': 'US Eastern Standard Time',
 'America/Indiana/Petersburg': 'Eastern Standard Time',
 'America/Indiana/Tell_City': 'Central Standard Time',
 'America/Indiana/Vevay': 'US Eastern Standard Time',
 'America/Indiana/Vincennes': 'Eastern Standard Time',
 'America/Indiana/Winamac': 'Eastern Standard Time',
 'America/Indianapolis': 'US Eastern Standard Time',
 'America/Inuvik': 'Mountain Standard Time',
 'America/Iqaluit': 'Eastern Standard Time',
 'America/Jamaica': 'SA Pacific Standard Time',
 'America/Jujuy': 'Argentina Standard Time',
 'America/Juneau': 'Alaskan Standard Time',
 'America/Kentucky/Monticello': 'Eastern Standard Time',
 'America/Knox_IN': 'Central Standard Time',
 'America/Kralendijk': 'SA Western Standard Time',
 'America/La_Paz': 'SA Western Standard Time',
 'America/Lima': 'SA Pacific Standard Time',
 'America/Los_Angeles': 'Pacific Standard Time',
 'America/Louisville': 'Eastern Standard Time',
 'America/Lower_Princes': 'SA Western Standard Time',
 'America/Maceio': 'SA Eastern Standard Time',
 'America/Managua': 'Central America Standard Time',
 'America/Manaus': 'SA Western Standard Time',
 'America/Marigot': 'SA Western Standard Time',
 'America/Martinique': 'SA Western Standard Time',
 'America/Matamoros': 'Central Standard Time',
 'America/Mazatlan': 'Mountain Standard Time (Mexico)',
 'America/Mendoza': 'Argentina Standard Time',
 'America/Menominee': 'Central Standard Time',
 'America/Merida': 'Central Standard Time (Mexico)',
 'America/Metlakatla': 'Alaskan Standard Time',
 'America/Mexico_City': 'Central Standard Time (Mexico)',
 'America/Miquelon': 'Saint Pierre Standard Time',
 'America/Moncton': 'Atlantic Standard Time',
 'America/Monterrey': 'Central Standard Time (Mexico)',
 'America/Montevideo': 'Montevideo Standard Time',
 'America/Montreal': 'Eastern Standard Time',
 'America/Montserrat': 'SA Western Standard Time',
 'America/Nassau': 'Eastern Standard Time',
 'America/New_York': 'Eastern Standard Time',
 'America/Nipigon': 'Eastern Standard Time',
 'America/Nome': 'Alaskan Standard Time',
 'America/Noronha': 'UTC-02',
 'America/North_Dakota/Beulah': 'Central Standard Time',
 'America/North_Dakota/Center': 'Central Standard Time',
 'America/North_Dakota/New_Salem': 'Central Standard Time',
 'America/Ojinaga': 'Mountain Standard Time',
 'America/Panama': 'SA Pacific Standard Time',
 'America/Pangnirtung': 'Eastern Standard Time',
 'America/Paramaribo': 'SA Eastern Standard Time',
 'America/Phoenix': 'US Mountain Standard Time',
 'America/Port-au-Prince': 'Haiti Standard Time',
 'America/Port_of_Spain': 'SA Western Standard Time',
 'America/Porto_Acre': 'SA Pacific Standard Time',
 'America/Porto_Velho': 'SA Western Standard Time',
 'America/Puerto_Rico': 'SA Western Standard Time',
 'America/Punta_Arenas': 'Magallanes Standard Time',
 'America/Rainy_River': 'Central Standard Time',
 'America/Rankin_Inlet': 'Central Standard Time',
 'America/Recife': 'SA Eastern Standard Time',
 'America/Regina': 'Canada Central Standard Time',
 'America/Resolute': 'Central Standard Time',
 'America/Rio_Branco': 'SA Pacific Standard Time',
 'America/Santa_Isabel': 'Pacific Standard Time (Mexico)',
 'America/Santarem': 'SA Eastern Standard Time',
 'America/Santiago': 'Pacific SA Standard Time',
 'America/Santo_Domingo': 'SA Western Standard Time',
 'America/Sao_Paulo': 'E. South America Standard Time',
 'America/Scoresbysund': 'Azores Standard Time',
 'America/Shiprock': 'Mountain Standard Time',
 'America/Sitka': 'Alaskan Standard Time',
 'America/St_Barthelemy': 'SA Western Standard Time',
 'America/St_Johns': 'Newfoundland Standard Time',
 'America/St_Kitts': 'SA Western Standard Time',
 'America/St_Lucia': 'SA Western Standard Time',
 'America/St_Thomas': 'SA Western Standard Time',
 'America/St_Vincent': 'SA Western Standard Time',
 'America/Swift_Current': 'Canada Central Standard Time',
 'America/Tegucigalpa': 'Central America Standard Time',
 'America/Thule': 'Atlantic Standard Time',
 'America/Thunder_Bay': 'Eastern Standard Time',
 'America/Tijuana': 'Pacific Standard Time (Mexico)',
 'America/Toronto': 'Eastern Standard Time',
 'America/Tortola': 'SA Western Standard Time',
 'America/Vancouver': 'Pacific Standard Time',
 'America/Virgin': 'SA Western Standard Time',
 'America/Whitehorse': 'Pacific Standard Time',
 'America/Winnipeg': 'Central Standard Time',
 'America/Yakutat': 'Alaskan Standard Time',
 'America/Yellowknife': 'Mountain Standard Time',
 'Antarctica/Casey': 'Singapore Standard Time',
 'Antarctica/Davis': 'SE Asia Standard Time',
 'Antarctica/DumontDUrville': 'West Pacific Standard Time',
 'Antarctica/Macquarie': 'Central Pacific Standard Time',
 'Antarctica/Mawson': 'West Asia Standard Time',
 'Antarctica/McMurdo': 'New Zealand Standard Time',
 'Antarctica/Palmer': 'SA Eastern Standard Time',
 'Antarctica/Rothera': 'SA Eastern Standard Time',
 'Antarctica/South_Pole': 'New Zealand Standard Time',
 'Antarctica/Syowa': 'E. Africa Standard Time',
 'Antarctica/Vostok': 'Central Asia Standard Time',
 'Arctic/Longyearbyen': 'W. Europe Standard Time',
 'Asia/Aden': 'Arab Standard Time',
 'Asia/Almaty': 'Central Asia Standard Time',
 'Asia/Amman': 'Jordan Standard Time',
 'Asia/Anadyr': 'Russia Time Zone 11',
 'Asia/Aqtau': 'West Asia Standard Time',
 'Asia/Aqtobe': 'West Asia Standard Time',
 'Asia/Ashgabat': 'West Asia Standard Time',
 'Asia/Ashkhabad': 'West Asia Standard Time',
 'Asia/Atyrau': 'West Asia Standard Time',
 'Asia/Baghdad': 'Arabic Standard Time',
 'Asia/Bahrain': 'Arab Standard Time',
 'Asia/Baku': 'Azerbaijan Standard Time',
 'Asia/Bangkok': 'SE Asia Standard Time',
 'Asia/Barnaul': 'Altai Standard Time',
 'Asia/Beirut': 'Middle East Standard Time',
 'Asia/Bishkek': 'Central Asia Standard Time',
 'Asia/Brunei': 'Singapore Standard Time',
 'Asia/Calcutta': 'India Standard Time',
 'Asia/Chita': 'Transbaikal Standard Time',
 'Asia/Choibalsan': 'Ulaanbaatar Standard Time',
 'Asia/Chongqing': 'China Standard Time',
 'Asia/Chungking': 'China Standard Time',
 'Asia/Colombo': 'Sri Lanka Standard Time',
 'Asia/Dacca': 'Bangladesh Standard Time',
 'Asia/Damascus': 'Syria Standard Time',
 'Asia/Dhaka': 'Bangladesh Standard Time',
 'Asia/Dili': 'Tokyo Standard Time',
 'Asia/Dubai': 'Arabian Standard Time',
 'Asia/Dushanbe': 'West Asia Standard Time',
 'Asia/Famagusta': 'GTB Standard Time',
 'Asia/Gaza': 'West Bank Standard Time',
 'Asia/Harbin': 'China Standard Time',
 'Asia/Hebron': 'West Bank Standard Time',
 'Asia/Hong_Kong': 'China Standard Time',
 'Asia/Hovd': 'W. Mongolia Standard Time',
 'Asia/Irkutsk': 'North Asia East Standard Time',
 'Asia/Jakarta': 'SE Asia Standard Time',
 'Asia/Jayapura': 'Tokyo Standard Time',
 'Asia/Jerusalem': 'Israel Standard Time',
 'Asia/Kabul': 'Afghanistan Standard Time',
 'Asia/Kamchatka': 'Russia Time Zone 11',
 'Asia/Karachi': 'Pakistan Standard Time',
 'Asia/Kashgar': 'Central Asia Standard Time',
 'Asia/Katmandu': 'Nepal Standard Time',
 'Asia/Khandyga': 'Yakutsk Standard Time',
 'Asia/Krasnoyarsk': 'North Asia Standard Time',
 'Asia/Kuala_Lumpur': 'Singapore Standard Time',
 'Asia/Kuching': 'Singapore Standard Time',
 'Asia/Kuwait': 'Arab Standard Time',
 'Asia/Macao': 'China Standard Time',
 'Asia/Macau': 'China Standard Time',
 'Asia/Magadan': 'Magadan Standard Time',
 'Asia/Makassar': 'Singapore Standard Time',
 'Asia/Manila': 'Singapore Standard Time',
 'Asia/Muscat': 'Arabian Standard Time',
 'Asia/Nicosia': 'GTB Standard Time',
 'Asia/Novokuznetsk': 'North Asia Standard Time',
 'Asia/Novosibirsk': 'N. Central Asia Standard Time',
 'Asia/Omsk': 'Omsk Standard Time',
 'Asia/Oral': 'West Asia Standard Time',
 'Asia/Phnom_Penh': 'SE Asia Standard Time',
 'Asia/Pontianak': 'SE Asia Standard Time',
 'Asia/Pyongyang': 'North Korea Standard Time',
 'Asia/Qatar': 'Arab Standard Time',
 'Asia/Qostanay': 'Central Asia Standard Time',
 'Asia/Qyzylorda': 'Qyzylorda Standard Time',
 'Asia/Rangoon': 'Myanmar Standard Time',
 'Asia/Riyadh': 'Arab Standard Time',
 'Asia/Saigon': 'SE Asia Standard Time',
 'Asia/Sakhalin': 'Sakhalin Standard Time',
 'Asia/Samarkand': 'West Asia Standard Time',
 'Asia/Seoul': 'Korea Standard Time',
 'Asia/Shanghai': 'China Standard Time',
 'Asia/Singapore': 'Singapore Standard Time',
 'Asia/Srednekolymsk': 'Russia Time Zone 10',
 'Asia/Taipei': 'Taipei Standard Time',
 'Asia/Tashkent': 'West Asia Standard Time',
 'Asia/Tbilisi': 'Georgian Standard Time',
 'Asia/Tehran': 'Iran Standard Time',
 'Asia/Tel_Aviv': 'Israel Standard Time',
 'Asia/Thimbu': 'Bangladesh Standard Time',
 'Asia/Thimphu': 'Bangladesh Standard Time',
 'Asia/Tokyo': 'Tokyo Standard Time',
 'Asia/Tomsk': 'Tomsk Standard Time',
 'Asia/Ujung_Pandang': 'Singapore Standard Time',
 'Asia/Ulaanbaatar': 'Ulaanbaatar Standard Time',
 'Asia/Ulan_Bator': 'Ulaanbaatar Standard Time',
 'Asia/Urumqi': 'Central Asia Standard Time',
 'Asia/Ust-Nera': 'Vladivostok Standard Time',
 'Asia/Vientiane': 'SE Asia Standard Time',
 'Asia/Vladivostok': 'Vladivostok Standard Time',
 'Asia/Yakutsk': 'Yakutsk Standard Time',
 'Asia/Yekaterinburg': 'Ekaterinburg Standard Time',
 'Asia/Yerevan': 'Caucasus Standard Time',
 'Atlantic/Azores': 'Azores Standard Time',
 'Atlantic/Bermuda': 'Atlantic Standard Time',
 'Atlantic/Canary': 'GMT Standard Time',
 'Atlantic/Cape_Verde': 'Cape Verde Standard Time',
 'Atlantic/Faeroe': 'GMT Standard Time',
 'Atlantic/Jan_Mayen': 'W. Europe Standard Time',
 'Atlantic/Madeira': 'GMT Standard Time',
 'Atlantic/Reykjavik': 'Greenwich Standard Time',
 'Atlantic/South_Georgia': 'UTC-02',
 'Atlantic/St_Helena': 'Greenwich Standard Time',
 'Atlantic/Stanley': 'SA Eastern Standard Time',
 'Australia/ACT': 'AUS Eastern Standard Time',
 'Australia/Adelaide': 'Cen. Australia Standard Time',
 'Australia/Brisbane': 'E. Australia Standard Time',
 'Australia/Broken_Hill': 'Cen. Australia Standard Time',
 'Australia/Canberra': 'AUS Eastern Standard Time',
 'Australia/Currie': 'Tasmania Standard Time',
 'Australia/Darwin': 'AUS Central Standard Time',
 'Australia/Eucla': 'Aus Central W. Standard Time',
 'Australia/Hobart': 'Tasmania Standard Time',
 'Australia/LHI': 'Lord Howe Standard Time',
 'Australia/Lindeman': 'E. Australia Standard Time',
 'Australia/Lord_Howe': 'Lord Howe Standard Time',
 'Australia/Melbourne': 'AUS Eastern Standard Time',
 'Australia/NSW': 'AUS Eastern Standard Time',
 'Australia/North': 'AUS Central Standard Time',
 'Australia/Perth': 'W. Australia Standard Time',
 'Australia/Queensland': 'E. Australia Standard Time',
 'Australia/South': 'Cen. Australia Standard Time',
 'Australia/Sydney': 'AUS Eastern Standard Time',
 'Australia/Tasmania': 'Tasmania Standard Time',
 'Australia/Victoria': 'AUS Eastern Standard Time',
 'Australia/West': 'W. Australia Standard Time',
 'Australia/Yancowinna': 'Cen. Australia Standard Time',
 'Brazil/Acre': 'SA Pacific Standard Time',
 'Brazil/DeNoronha': 'UTC-02',
 'Brazil/East': 'E. South America Standard Time',
 'Brazil/West': 'SA Western Standard Time',
 'CST6CDT': 'Central Standard Time',
 'Canada/Atlantic': 'Atlantic Standard Time',
 'Canada/Central': 'Central Standard Time',
 'Canada/Eastern': 'Eastern Standard Time',
 'Canada/Mountain': 'Mountain Standard Time',
 'Canada/Newfoundland': 'Newfoundland Standard Time',
 'Canada/Pacific': 'Pacific Standard Time',
 'Canada/Saskatchewan': 'Canada Central Standard Time',
 'Canada/Yukon': 'Pacific Standard Time',
 'Chile/Continental': 'Pacific SA Standard Time',
 'Chile/EasterIsland': 'Easter Island Standard Time',
 'Cuba': 'Cuba Standard Time',
 'EST5EDT': 'Eastern Standard Time',
 'Egypt': 'Egypt Standard Time',
 'Eire': 'GMT Standard Time',
 'Etc/GMT': 'UTC',
 'Etc/GMT+1': 'Cape Verde Standard Time',
 'Etc/GMT+10': 'Hawaiian Standard Time',
 'Etc/GMT+11': 'UTC-11',
 'Etc/GMT+12': 'Dateline Standard Time',
 'Etc/GMT+2': 'UTC-02',
 'Etc/GMT+3': 'SA Eastern Standard Time',
 'Etc/GMT+4': 'SA Western Standard Time',
 'Etc/GMT+5': 'SA Pacific Standard Time',
 'Etc/GMT+6': 'Central America Standard Time',
 'Etc/GMT+7': 'US Mountain Standard Time',
 'Etc/GMT+8': 'UTC-08',
 'Etc/GMT+9': 'UTC-09',
 'Etc/GMT-1': 'W. Central Africa Standard Time',
 'Etc/GMT-10': 'West Pacific Standard Time',
 'Etc/GMT-11': 'Central Pacific Standard Time',
 'Etc/GMT-12': 'UTC+12',
 'Etc/GMT-13': 'UTC+13',
 'Etc/GMT-14': 'Line Islands Standard Time',
 'Etc/GMT-2': 'South Africa Standard Time',
 'Etc/GMT-3': 'E. Africa Standard Time',
 'Etc/GMT-4': 'Arabian Standard Time',
 'Etc/GMT-5': 'West Asia Standard Time',
 'Etc/GMT-6': 'Central Asia Standard Time',
 'Etc/GMT-7': 'SE Asia Standard Time',
 'Etc/GMT-8': 'Singapore Standard Time',
 'Etc/GMT-9': 'Tokyo Standard Time',
 'Etc/UCT': 'UTC',
 'Etc/UTC': 'UTC',
 'Europe/Amsterdam': 'W. Europe Standard Time',
 'Europe/Andorra': 'W. Europe Standard Time',
 'Europe/Astrakhan': 'Astrakhan Standard Time',
 'Europe/Athens': 'GTB Standard Time',
 'Europe/Belfast': 'GMT Standard Time',
 'Europe/Belgrade': 'Central Europe Standard Time',
 'Europe/Berlin': 'W. Europe Standard Time',
 'Europe/Bratislava': 'Central Europe Standard Time',
 'Europe/Brussels': 'Romance Standard Time',
 'Europe/Bucharest': 'GTB Standard Time',
 'Europe/Budapest': 'Central Europe Standard Time',
 'Europe/Busingen': 'W. Europe Standard Time',
 'Europe/Chisinau': 'E. Europe Standard Time',
 'Europe/Copenhagen': 'Romance Standard Time',
 'Europe/Dublin': 'GMT Standard Time',
 'Europe/Gibraltar': 'W. Europe Standard Time',
 'Europe/Guernsey': 'GMT Standard Time',
 'Europe/Helsinki': 'FLE Standard Time',
 'Europe/Isle_of_Man': 'GMT Standard Time',
 'Europe/Istanbul': 'Turkey Standard Time',
 'Europe/Jersey': 'GMT Standard Time',
 'Europe/Kaliningrad': 'Kaliningrad Standard Time',
 'Europe/Kiev': 'FLE Standard Time',
 'Europe/Kirov': 'Russian Standard Time',
 'Europe/Lisbon': 'GMT Standard Time',
 'Europe/Ljubljana': 'Central Europe Standard Time',
 'Europe/London': 'GMT Standard Time',
 'Europe/Luxembourg': 'W. Europe Standard Time',
 'Europe/Madrid': 'Romance Standard Time',
 'Europe/Malta': 'W. Europe Standard Time',
 'Europe/Mariehamn': 'FLE Standard Time',
 'Europe/Minsk': 'Belarus Standard Time',
 'Europe/Monaco': 'W. Europe Standard Time',
 'Europe/Moscow': 'Russian Standard Time',
 'Europe/Oslo': 'W. Europe Standard Time',
 'Europe/Paris': 'Romance Standard Time',
 'Europe/Podgorica': 'Central Europe Standard Time',
 'Europe/Prague': 'Central Europe Standard Time',
 'Europe/Riga': 'FLE Standard Time',
 'Europe/Rome': 'W. Europe Standard Time',
 'Europe/Samara': 'Russia Time Zone 3',
 'Europe/San_Marino': 'W. Europe Standard Time',
 'Europe/Sarajevo': 'Central European Standard Time',
 'Europe/Saratov': 'Saratov Standard Time',
 'Europe/Simferopol': 'Russian Standard Time',
 'Europe/Skopje': 'Central European Standard Time',
 'Europe/Sofia': 'FLE Standard Time',
 'Europe/Stockholm': 'W. Europe Standard Time',
 'Europe/Tallinn': 'FLE Standard Time',
 'Europe/Tirane': 'Central Europe Standard Time',
 'Europe/Tiraspol': 'E. Europe Standard Time',
 'Europe/Ulyanovsk': 'Astrakhan Standard Time',
 'Europe/Uzhgorod': 'FLE Standard Time',
 'Europe/Vaduz': 'W. Europe Standard Time',
 'Europe/Vatican': 'W. Europe Standard Time',
 'Europe/Vienna': 'W. Europe Standard Time',
 'Europe/Vilnius': 'FLE Standard Time',
 'Europe/Volgograd': 'Volgograd Standard Time',
 'Europe/Warsaw': 'Central European Standard Time',
 'Europe/Zagreb': 'Central European Standard Time',
 'Europe/Zaporozhye': 'FLE Standard Time',
 'Europe/Zurich': 'W. Europe Standard Time',
 'GB': 'GMT Standard Time',
 'GB-Eire': 'GMT Standard Time',
 'GMT+0': 'UTC',
 'GMT-0': 'UTC',
 'GMT0': 'UTC',
 'Greenwich': 'UTC',
 'Hongkong': 'China Standard Time',
 'Iceland': 'Greenwich Standard Time',
 'Indian/Antananarivo': 'E. Africa Standard Time',
 'Indian/Chagos': 'Central Asia Standard Time',
 'Indian/Christmas': 'SE Asia Standard Time',
 'Indian/Cocos': 'Myanmar Standard Time',
 'Indian/Comoro': 'E. Africa Standard Time',
 'Indian/Kerguelen': 'West Asia Standard Time',
 'Indian/Mahe': 'Mauritius Standard Time',
 'Indian/Maldives': 'West Asia Standard Time',
 'Indian/Mauritius': 'Mauritius Standard Time',
 'Indian/Mayotte': 'E. Africa Standard Time',
 'Indian/Reunion': 'Mauritius Standard Time',
 'Iran': 'Iran Standard Time',
 'Israel': 'Israel Standard Time',
 'Jamaica': 'SA Pacific Standard Time',
 'Japan': 'Tokyo Standard Time',
 'Kwajalein': 'UTC+12',
 'Libya': 'Libya Standard Time',
 'MST7MDT': 'Mountain Standard Time',
 'Mexico/BajaNorte': 'Pacific Standard Time (Mexico)',
 'Mexico/BajaSur': 'Mountain Standard Time (Mexico)',
 'Mexico/General': 'Central Standard Time (Mexico)',
 'NZ': 'New Zealand Standard Time',
 'NZ-CHAT': 'Chatham Islands Standard Time',
 'Navajo': 'Mountain Standard Time',
 'PRC': 'China Standard Time',
 'PST8PDT': 'Pacific Standard Time',
 'Pacific/Apia': 'Samoa Standard Time',
 'Pacific/Auckland': 'New Zealand Standard Time',
 'Pacific/Bougainville': 'Bougainville Standard Time',
 'Pacific/Chatham': 'Chatham Islands Standard Time',
 'Pacific/Easter': 'Easter Island Standard Time',
 'Pacific/Efate': 'Central Pacific Standard Time',
 'Pacific/Enderbury': 'UTC+13',
 'Pacific/Fakaofo': 'UTC+13',
 'Pacific/Fiji': 'Fiji Standard Time',
 'Pacific/Funafuti': 'UTC+12',
 'Pacific/Galapagos': 'Central America Standard Time',
 'Pacific/Gambier': 'UTC-09',
 'Pacific/Guadalcanal': 'Central Pacific Standard Time',
 'Pacific/Guam': 'West Pacific Standard Time',
 'Pacific/Honolulu': 'Hawaiian Standard Time',
 'Pacific/Johnston': 'Hawaiian Standard Time',
 'Pacific/Kiritimati': 'Line Islands Standard Time',
 'Pacific/Kosrae': 'Central Pacific Standard Time',
 'Pacific/Kwajalein': 'UTC+12',
 'Pacific/Majuro': 'UTC+12',
 'Pacific/Marquesas': 'Marquesas Standard Time',
 'Pacific/Midway': 'UTC-11',
 'Pacific/Nauru': 'UTC+12',
 'Pacific/Niue': 'UTC-11',
 'Pacific/Norfolk': 'Norfolk Standard Time',
 'Pacific/Noumea': 'Central Pacific Standard Time',
 'Pacific/Pago_Pago': 'UTC-11',
 'Pacific/Palau': 'Tokyo Standard Time',
 'Pacific/Pitcairn': 'UTC-08',
 'Pacific/Ponape': 'Central Pacific Standard Time',
 'Pacific/Port_Moresby': 'West Pacific Standard Time',
 'Pacific/Rarotonga': 'Hawaiian Standard Time',
 'Pacific/Saipan': 'West Pacific Standard Time',
 'Pacific/Samoa': 'UTC-11',
 'Pacific/Tahiti': 'Hawaiian Standard Time',
 'Pacific/Tarawa': 'UTC+12',
 'Pacific/Tongatapu': 'Tonga Standard Time',
 'Pacific/Truk': 'West Pacific Standard Time',
 'Pacific/Wake': 'UTC+12',
 'Pacific/Wallis': 'UTC+12',
 'Poland': 'Central European Standard Time',
 'Portugal': 'GMT Standard Time',
 'ROC': 'Taipei Standard Time',
 'ROK': 'Korea Standard Time',
 'Singapore': 'Singapore Standard Time',
 'Turkey': 'Turkey Standard Time',
 'UCT': 'UTC',
 'US/Alaska': 'Alaskan Standard Time',
 'US/Aleutian': 'Aleutian Standard Time',
 'US/Arizona': 'US Mountain Standard Time',
 'US/Central': 'Central Standard Time',
 'US/Eastern': 'Eastern Standard Time',
 'US/Hawaii': 'Hawaiian Standard Time',
 'US/Indiana-Starke': 'Central Standard Time',
 'US/Michigan': 'Eastern Standard Time',
 'US/Mountain': 'Mountain Standard Time',
 'US/Pacific': 'Pacific Standard Time',
 'US/Samoa': 'UTC-11',
 'UTC': 'UTC',
 'Universal': 'UTC',
 'W-SU': 'Russian Standard Time',
 'Zulu': 'UTC'}




############################################################
### File: wiredata.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2011,2017 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Wire Data Helper"""

import dns.exception
from ._compat import binary_type, string_types, PY2

# Figure out what constant python passes for an unspecified slice bound.
# It's supposed to be sys.maxint, yet on 64-bit windows sys.maxint is 2^31 - 1
# but Python uses 2^63 - 1 as the constant.  Rather than making pointless
# extra comparisons, duplicating code, or weakening WireData, we just figure
# out what constant Python will use.


class _SliceUnspecifiedBound(binary_type):

    def __getitem__(self, key):
        return key.stop

    if PY2:
        def __getslice__(self, i, j):  # pylint: disable=getslice-method
            return self.__getitem__(slice(i, j))

_unspecified_bound = _SliceUnspecifiedBound()[1:]


class WireData(binary_type):
    # WireData is a binary type with stricter slicing

    def __getitem__(self, key):
        try:
            if isinstance(key, slice):
                # make sure we are not going outside of valid ranges,
                # do stricter control of boundaries than python does
                # by default
                start = key.start
                stop = key.stop

                if PY2:
                    if stop == _unspecified_bound:
                        # handle the case where the right bound is unspecified
                        stop = len(self)

                    if start < 0 or stop < 0:
                        raise dns.exception.FormError
                    # If it's not an empty slice, access left and right bounds
                    # to make sure they're valid
                    if start != stop:
                        super(WireData, self).__getitem__(start)
                        super(WireData, self).__getitem__(stop - 1)
                else:
                    for index in (start, stop):
                        if index is None:
                            continue
                        elif abs(index) > len(self):
                            raise dns.exception.FormError

                return WireData(super(WireData, self).__getitem__(
                    slice(start, stop)))
            return bytearray(self.unwrap())[key]
        except IndexError:
            raise dns.exception.FormError

    if PY2:
        def __getslice__(self, i, j):  # pylint: disable=getslice-method
            return self.__getitem__(slice(i, j))

    def __iter__(self):
        i = 0
        while 1:
            try:
                yield self[i]
                i += 1
            except dns.exception.FormError:
                raise StopIteration

    def unwrap(self):
        return binary_type(self)


def maybe_wrap(wire):
    if isinstance(wire, WireData):
        return wire
    elif isinstance(wire, binary_type):
        return WireData(wire)
    elif isinstance(wire, string_types):
        return WireData(wire.encode())
    raise ValueError("unhandled type %s" % type(wire))




############################################################
### File: xbmc.py
############################################################
# coding: utf-8
# Created on: 04.01.2018
# Author: Roman Miroshnychenko aka Roman V.M. (roman1972@gmail.com)
"""
General classes and functions for interacting with Kodi
"""

from __future__ import absolute_import
import sys as _sys
from .utils import PY2 as _PY2, ModuleWrapper as _ModuleWrapper

if _PY2:
    import xbmc as _xbmc
    _wrapped_xbmc = _ModuleWrapper(_xbmc)
    _sys.modules[__name__] = _wrapped_xbmc
else:
    from xbmc import *

    try:
        from xbmcvfs import translatePath as newTranslatePath
        translatePath = newTranslatePath
    except ImportError:
        pass



############################################################
### File: xbmcaddon.py
############################################################
# coding: utf-8
# Created on: 04.01.2018
# Author: Roman Miroshnychenko aka Roman V.M. (roman1972@gmail.com)
"""
A class for accessing addon properties
"""

from __future__ import absolute_import
import sys as _sys
from .utils import PY2 as _PY2, ModuleWrapper as _ModuleWrapper

if _PY2:
    import xbmcaddon as _xbmcaddon
    _wrapped_xbmcaddon = _ModuleWrapper(_xbmcaddon)
    _sys.modules[__name__] = _wrapped_xbmcaddon
else:
    from xbmcaddon import *




############################################################
### File: xbmcdrm.py
############################################################
# coding: utf-8
# Created on: 20.01.2019
# Author: Roman Miroshnychenko aka Roman V.M. (roman1972@gmail.com)
"""
A class for working with DRM
"""

from __future__ import absolute_import
import sys as _sys
from .utils import PY2 as _PY2, ModuleWrapper as _ModuleWrapper

if _PY2:
    import xbmcdrm as _xbmcdrm
    _wrapped_xbmcdrm = _ModuleWrapper(_xbmcdrm)
    _sys.modules[__name__] = _wrapped_xbmcdrm
else:
    from xbmcdrm import *




############################################################
### File: xbmcgui.py
############################################################
# coding: utf-8
# Created on: 04.01.2018
# Author: Roman Miroshnychenko aka Roman V.M. (roman1972@gmail.com)
"""
Classes and functions for interacting with Kodi GUI
"""

from __future__ import absolute_import
import sys as _sys
from .utils import PY2 as _PY2, ModuleWrapper as _ModuleWrapper

if _PY2:
    import xbmcgui as _xbmcgui
    _wrapped_xbmcgui = _ModuleWrapper(_xbmcgui)
    _sys.modules[__name__] = _wrapped_xbmcgui
else:
    from xbmcgui import *




############################################################
### File: xbmcplugin.py
############################################################
# coding: utf-8
# Created on: 04.01.2018
# Author: Roman Miroshnychenko aka Roman V.M. (roman1972@gmail.com)
"""
Functions to create media contents plugins
"""

from __future__ import absolute_import
import sys as _sys
from .utils import PY2 as _PY2, ModuleWrapper as _ModuleWrapper

if _PY2:
    import xbmcplugin as _xbmcplugin
    _wrapped_xbmcplugin = _ModuleWrapper(_xbmcplugin)
    _sys.modules[__name__] = _wrapped_xbmcplugin
else:
    from xbmcplugin import *




############################################################
### File: xbmcvfs.py
############################################################
# coding: utf-8
# Created on: 04.01.2018
# Author: Roman Miroshnychenko aka Roman V.M. (roman1972@gmail.com)
"""
Functions and classes to work with files and folders
"""

from __future__ import absolute_import
import sys as _sys
from .utils import PY2 as _PY2, ModuleWrapper as _ModuleWrapper

if _PY2:
    import xbmcvfs as _xbmcvfs
    _wrapped_xbmcvfs = _ModuleWrapper(_xbmcvfs)
    _sys.modules[__name__] = _wrapped_xbmcvfs
else:
    from xbmcvfs import *




############################################################
### File: zone.py
############################################################
# Copyright (C) Dnspython Contributors, see LICENSE for text of ISC license

# Copyright (C) 2003-2007, 2009-2011 Nominum, Inc.
#
# Permission to use, copy, modify, and distribute this software and its
# documentation for any purpose with or without fee is hereby granted,
# provided that the above copyright notice and this permission notice
# appear in all copies.
#
# THE SOFTWARE IS PROVIDED "AS IS" AND NOMINUM DISCLAIMS ALL WARRANTIES
# WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF
# MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL NOMINUM BE LIABLE FOR
# ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES
# WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN
# ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT
# OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.

"""DNS Zones."""

from __future__ import generators

import sys
import re
import os
from io import BytesIO

import dns.exception
import dns.name
import dns.node
import dns.rdataclass
import dns.rdatatype
import dns.rdata
import dns.rdtypes.ANY.SOA
import dns.rrset
import dns.tokenizer
import dns.ttl
import dns.grange
from ._compat import string_types, text_type, PY3


class BadZone(dns.exception.DNSException):

    """The DNS zone is malformed."""


class NoSOA(BadZone):

    """The DNS zone has no SOA RR at its origin."""


class NoNS(BadZone):

    """The DNS zone has no NS RRset at its origin."""


class UnknownOrigin(BadZone):

    """The DNS zone's origin is unknown."""


class Zone(object):

    """A DNS zone.

    A Zone is a mapping from names to nodes.  The zone object may be
    treated like a Python dictionary, e.g. zone[name] will retrieve
    the node associated with that name.  The I{name} may be a
    dns.name.Name object, or it may be a string.  In the either case,
    if the name is relative it is treated as relative to the origin of
    the zone.

    @ivar rdclass: The zone's rdata class; the default is class IN.
    @type rdclass: int
    @ivar origin: The origin of the zone.
    @type origin: dns.name.Name object
    @ivar nodes: A dictionary mapping the names of nodes in the zone to the
    nodes themselves.
    @type nodes: dict
    @ivar relativize: should names in the zone be relativized?
    @type relativize: bool
    @cvar node_factory: the factory used to create a new node
    @type node_factory: class or callable
    """

    node_factory = dns.node.Node

    __slots__ = ['rdclass', 'origin', 'nodes', 'relativize']

    def __init__(self, origin, rdclass=dns.rdataclass.IN, relativize=True):
        """Initialize a zone object.

        @param origin: The origin of the zone.
        @type origin: dns.name.Name object
        @param rdclass: The zone's rdata class; the default is class IN.
        @type rdclass: int"""

        if origin is not None:
            if isinstance(origin, string_types):
                origin = dns.name.from_text(origin)
            elif not isinstance(origin, dns.name.Name):
                raise ValueError("origin parameter must be convertible to a "
                                 "DNS name")
            if not origin.is_absolute():
                raise ValueError("origin parameter must be an absolute name")
        self.origin = origin
        self.rdclass = rdclass
        self.nodes = {}
        self.relativize = relativize

    def __eq__(self, other):
        """Two zones are equal if they have the same origin, class, and
        nodes.
        @rtype: bool
        """

        if not isinstance(other, Zone):
            return False
        if self.rdclass != other.rdclass or \
           self.origin != other.origin or \
           self.nodes != other.nodes:
            return False
        return True

    def __ne__(self, other):
        """Are two zones not equal?
        @rtype: bool
        """

        return not self.__eq__(other)

    def _validate_name(self, name):
        if isinstance(name, string_types):
            name = dns.name.from_text(name, None)
        elif not isinstance(name, dns.name.Name):
            raise KeyError("name parameter must be convertible to a DNS name")
        if name.is_absolute():
            if not name.is_subdomain(self.origin):
                raise KeyError(
                    "name parameter must be a subdomain of the zone origin")
            if self.relativize:
                name = name.relativize(self.origin)
        return name

    def __getitem__(self, key):
        key = self._validate_name(key)
        return self.nodes[key]

    def __setitem__(self, key, value):
        key = self._validate_name(key)
        self.nodes[key] = value

    def __delitem__(self, key):
        key = self._validate_name(key)
        del self.nodes[key]

    def __iter__(self):
        return self.nodes.__iter__()

    def iterkeys(self):
        if PY3:
            return self.nodes.keys() # pylint: disable=dict-keys-not-iterating
        else:
            return self.nodes.iterkeys()  # pylint: disable=dict-iter-method

    def keys(self):
        return self.nodes.keys() # pylint: disable=dict-keys-not-iterating

    def itervalues(self):
        if PY3:
            return self.nodes.values() # pylint: disable=dict-values-not-iterating
        else:
            return self.nodes.itervalues()  # pylint: disable=dict-iter-method

    def values(self):
        return self.nodes.values() # pylint: disable=dict-values-not-iterating

    def items(self):
        return self.nodes.items() # pylint: disable=dict-items-not-iterating

    iteritems = items

    def get(self, key):
        key = self._validate_name(key)
        return self.nodes.get(key)

    def __contains__(self, other):
        return other in self.nodes

    def find_node(self, name, create=False):
        """Find a node in the zone, possibly creating it.

        @param name: the name of the node to find
        @type name: dns.name.Name object or string
        @param create: should the node be created if it doesn't exist?
        @type create: bool
        @raises KeyError: the name is not known and create was not specified.
        @rtype: dns.node.Node object
        """

        name = self._validate_name(name)
        node = self.nodes.get(name)
        if node is None:
            if not create:
                raise KeyError
            node = self.node_factory()
            self.nodes[name] = node
        return node

    def get_node(self, name, create=False):
        """Get a node in the zone, possibly creating it.

        This method is like L{find_node}, except it returns None instead
        of raising an exception if the node does not exist and creation
        has not been requested.

        @param name: the name of the node to find
        @type name: dns.name.Name object or string
        @param create: should the node be created if it doesn't exist?
        @type create: bool
        @rtype: dns.node.Node object or None
        """

        try:
            node = self.find_node(name, create)
        except KeyError:
            node = None
        return node

    def delete_node(self, name):
        """Delete the specified node if it exists.

        It is not an error if the node does not exist.
        """

        name = self._validate_name(name)
        if name in self.nodes:
            del self.nodes[name]

    def find_rdataset(self, name, rdtype, covers=dns.rdatatype.NONE,
                      create=False):
        """Look for rdata with the specified name and type in the zone,
        and return an rdataset encapsulating it.

        The I{name}, I{rdtype}, and I{covers} parameters may be
        strings, in which case they will be converted to their proper
        type.

        The rdataset returned is not a copy; changes to it will change
        the zone.

        KeyError is raised if the name or type are not found.
        Use L{get_rdataset} if you want to have None returned instead.

        @param name: the owner name to look for
        @type name: DNS.name.Name object or string
        @param rdtype: the rdata type desired
        @type rdtype: int or string
        @param covers: the covered type (defaults to None)
        @type covers: int or string
        @param create: should the node and rdataset be created if they do not
        exist?
        @type create: bool
        @raises KeyError: the node or rdata could not be found
        @rtype: dns.rdataset.Rdataset object
        """

        name = self._validate_name(name)
        if isinstance(rdtype, string_types):
            rdtype = dns.rdatatype.from_text(rdtype)
        if isinstance(covers, string_types):
            covers = dns.rdatatype.from_text(covers)
        node = self.find_node(name, create)
        return node.find_rdataset(self.rdclass, rdtype, covers, create)

    def get_rdataset(self, name, rdtype, covers=dns.rdatatype.NONE,
                     create=False):
        """Look for rdata with the specified name and type in the zone,
        and return an rdataset encapsulating it.

        The I{name}, I{rdtype}, and I{covers} parameters may be
        strings, in which case they will be converted to their proper
        type.

        The rdataset returned is not a copy; changes to it will change
        the zone.

        None is returned if the name or type are not found.
        Use L{find_rdataset} if you want to have KeyError raised instead.

        @param name: the owner name to look for
        @type name: DNS.name.Name object or string
        @param rdtype: the rdata type desired
        @type rdtype: int or string
        @param covers: the covered type (defaults to None)
        @type covers: int or string
        @param create: should the node and rdataset be created if they do not
        exist?
        @type create: bool
        @rtype: dns.rdataset.Rdataset object or None
        """

        try:
            rdataset = self.find_rdataset(name, rdtype, covers, create)
        except KeyError:
            rdataset = None
        return rdataset

    def delete_rdataset(self, name, rdtype, covers=dns.rdatatype.NONE):
        """Delete the rdataset matching I{rdtype} and I{covers}, if it
        exists at the node specified by I{name}.

        The I{name}, I{rdtype}, and I{covers} parameters may be
        strings, in which case they will be converted to their proper
        type.

        It is not an error if the node does not exist, or if there is no
        matching rdataset at the node.

        If the node has no rdatasets after the deletion, it will itself
        be deleted.

        @param name: the owner name to look for
        @type name: DNS.name.Name object or string
        @param rdtype: the rdata type desired
        @type rdtype: int or string
        @param covers: the covered type (defaults to None)
        @type covers: int or string
        """

        name = self._validate_name(name)
        if isinstance(rdtype, string_types):
            rdtype = dns.rdatatype.from_text(rdtype)
        if isinstance(covers, string_types):
            covers = dns.rdatatype.from_text(covers)
        node = self.get_node(name)
        if node is not None:
            node.delete_rdataset(self.rdclass, rdtype, covers)
            if len(node) == 0:
                self.delete_node(name)

    def replace_rdataset(self, name, replacement):
        """Replace an rdataset at name.

        It is not an error if there is no rdataset matching I{replacement}.

        Ownership of the I{replacement} object is transferred to the zone;
        in other words, this method does not store a copy of I{replacement}
        at the node, it stores I{replacement} itself.

        If the I{name} node does not exist, it is created.

        @param name: the owner name
        @type name: DNS.name.Name object or string
        @param replacement: the replacement rdataset
        @type replacement: dns.rdataset.Rdataset
        """

        if replacement.rdclass != self.rdclass:
            raise ValueError('replacement.rdclass != zone.rdclass')
        node = self.find_node(name, True)
        node.replace_rdataset(replacement)

    def find_rrset(self, name, rdtype, covers=dns.rdatatype.NONE):
        """Look for rdata with the specified name and type in the zone,
        and return an RRset encapsulating it.

        The I{name}, I{rdtype}, and I{covers} parameters may be
        strings, in which case they will be converted to their proper
        type.

        This method is less efficient than the similar
        L{find_rdataset} because it creates an RRset instead of
        returning the matching rdataset.  It may be more convenient
        for some uses since it returns an object which binds the owner
        name to the rdata.

        This method may not be used to create new nodes or rdatasets;
        use L{find_rdataset} instead.

        KeyError is raised if the name or type are not found.
        Use L{get_rrset} if you want to have None returned instead.

        @param name: the owner name to look for
        @type name: DNS.name.Name object or string
        @param rdtype: the rdata type desired
        @type rdtype: int or string
        @param covers: the covered type (defaults to None)
        @type covers: int or string
        @raises KeyError: the node or rdata could not be found
        @rtype: dns.rrset.RRset object
        """

        name = self._validate_name(name)
        if isinstance(rdtype, string_types):
            rdtype = dns.rdatatype.from_text(rdtype)
        if isinstance(covers, string_types):
            covers = dns.rdatatype.from_text(covers)
        rdataset = self.nodes[name].find_rdataset(self.rdclass, rdtype, covers)
        rrset = dns.rrset.RRset(name, self.rdclass, rdtype, covers)
        rrset.update(rdataset)
        return rrset

    def get_rrset(self, name, rdtype, covers=dns.rdatatype.NONE):
        """Look for rdata with the specified name and type in the zone,
        and return an RRset encapsulating it.

        The I{name}, I{rdtype}, and I{covers} parameters may be
        strings, in which case they will be converted to their proper
        type.

        This method is less efficient than the similar L{get_rdataset}
        because it creates an RRset instead of returning the matching
        rdataset.  It may be more convenient for some uses since it
        returns an object which binds the owner name to the rdata.

        This method may not be used to create new nodes or rdatasets;
        use L{find_rdataset} instead.

        None is returned if the name or type are not found.
        Use L{find_rrset} if you want to have KeyError raised instead.

        @param name: the owner name to look for
        @type name: DNS.name.Name object or string
        @param rdtype: the rdata type desired
        @type rdtype: int or string
        @param covers: the covered type (defaults to None)
        @type covers: int or string
        @rtype: dns.rrset.RRset object
        """

        try:
            rrset = self.find_rrset(name, rdtype, covers)
        except KeyError:
            rrset = None
        return rrset

    def iterate_rdatasets(self, rdtype=dns.rdatatype.ANY,
                          covers=dns.rdatatype.NONE):
        """Return a generator which yields (name, rdataset) tuples for
        all rdatasets in the zone which have the specified I{rdtype}
        and I{covers}.  If I{rdtype} is dns.rdatatype.ANY, the default,
        then all rdatasets will be matched.

        @param rdtype: int or string
        @type rdtype: int or string
        @param covers: the covered type (defaults to None)
        @type covers: int or string
        """

        if isinstance(rdtype, string_types):
            rdtype = dns.rdatatype.from_text(rdtype)
        if isinstance(covers, string_types):
            covers = dns.rdatatype.from_text(covers)
        for (name, node) in self.iteritems(): # pylint: disable=dict-iter-method
            for rds in node:
                if rdtype == dns.rdatatype.ANY or \
                   (rds.rdtype == rdtype and rds.covers == covers):
                    yield (name, rds)

    def iterate_rdatas(self, rdtype=dns.rdatatype.ANY,
                       covers=dns.rdatatype.NONE):
        """Return a generator which yields (name, ttl, rdata) tuples for
        all rdatas in the zone which have the specified I{rdtype}
        and I{covers}.  If I{rdtype} is dns.rdatatype.ANY, the default,
        then all rdatas will be matched.

        @param rdtype: int or string
        @type rdtype: int or string
        @param covers: the covered type (defaults to None)
        @type covers: int or string
        """

        if isinstance(rdtype, string_types):
            rdtype = dns.rdatatype.from_text(rdtype)
        if isinstance(covers, string_types):
            covers = dns.rdatatype.from_text(covers)
        for (name, node) in self.iteritems(): # pylint: disable=dict-iter-method
            for rds in node:
                if rdtype == dns.rdatatype.ANY or \
                   (rds.rdtype == rdtype and rds.covers == covers):
                    for rdata in rds:
                        yield (name, rds.ttl, rdata)

    def to_file(self, f, sorted=True, relativize=True, nl=None):
        """Write a zone to a file.

        @param f: file or string.  If I{f} is a string, it is treated
        as the name of a file to open.
        @param sorted: if True, the file will be written with the
        names sorted in DNSSEC order from least to greatest.  Otherwise
        the names will be written in whatever order they happen to have
        in the zone's dictionary.
        @param relativize: if True, domain names in the output will be
        relativized to the zone's origin (if possible).
        @type relativize: bool
        @param nl: The end of line string.  If not specified, the
        output will use the platform's native end-of-line marker (i.e.
        LF on POSIX, CRLF on Windows, CR on Macintosh).
        @type nl: string or None
        """

        if isinstance(f, string_types):
            f = open(f, 'wb')
            want_close = True
        else:
            want_close = False

        # must be in this way, f.encoding may contain None, or even attribute
        # may not be there
        file_enc = getattr(f, 'encoding', None)
        if file_enc is None:
            file_enc = 'utf-8'

        if nl is None:
            nl_b = os.linesep.encode(file_enc)  # binary mode, '\n' is not enough
            nl = u'\n'
        elif isinstance(nl, string_types):
            nl_b = nl.encode(file_enc)
        else:
            nl_b = nl
            nl = nl.decode()

        try:
            if sorted:
                names = list(self.keys())
                names.sort()
            else:
                names = self.iterkeys() # pylint: disable=dict-iter-method
            for n in names:
                l = self[n].to_text(n, origin=self.origin,
                                    relativize=relativize)
                if isinstance(l, text_type):
                    l_b = l.encode(file_enc)
                else:
                    l_b = l
                    l = l.decode()

                try:
                    f.write(l_b)
                    f.write(nl_b)
                except TypeError:  # textual mode
                    f.write(l)
                    f.write(nl)
        finally:
            if want_close:
                f.close()

    def to_text(self, sorted=True, relativize=True, nl=None):
        """Return a zone's text as though it were written to a file.

        @param sorted: if True, the file will be written with the
        names sorted in DNSSEC order from least to greatest.  Otherwise
        the names will be written in whatever order they happen to have
        in the zone's dictionary.
        @param relativize: if True, domain names in the output will be
        relativized to the zone's origin (if possible).
        @type relativize: bool
        @param nl: The end of line string.  If not specified, the
        output will use the platform's native end-of-line marker (i.e.
        LF on POSIX, CRLF on Windows, CR on Macintosh).
        @type nl: string or None
        """
        temp_buffer = BytesIO()
        self.to_file(temp_buffer, sorted, relativize, nl)
        return_value = temp_buffer.getvalue()
        temp_buffer.close()
        return return_value

    def check_origin(self):
        """Do some simple checking of the zone's origin.

        @raises dns.zone.NoSOA: there is no SOA RR
        @raises dns.zone.NoNS: there is no NS RRset
        @raises KeyError: there is no origin node
        """
        if self.relativize:
            name = dns.name.empty
        else:
            name = self.origin
        if self.get_rdataset(name, dns.rdatatype.SOA) is None:
            raise NoSOA
        if self.get_rdataset(name, dns.rdatatype.NS) is None:
            raise NoNS


class _MasterReader(object):

    """Read a DNS master file

    @ivar tok: The tokenizer
    @type tok: dns.tokenizer.Tokenizer object
    @ivar last_ttl: The last seen explicit TTL for an RR
    @type last_ttl: int
    @ivar last_ttl_known: Has last TTL been detected
    @type last_ttl_known: bool
    @ivar default_ttl: The default TTL from a $TTL directive or SOA RR
    @type default_ttl: int
    @ivar default_ttl_known: Has default TTL been detected
    @type default_ttl_known: bool
    @ivar last_name: The last name read
    @type last_name: dns.name.Name object
    @ivar current_origin: The current origin
    @type current_origin: dns.name.Name object
    @ivar relativize: should names in the zone be relativized?
    @type relativize: bool
    @ivar zone: the zone
    @type zone: dns.zone.Zone object
    @ivar saved_state: saved reader state (used when processing $INCLUDE)
    @type saved_state: list of (tokenizer, current_origin, last_name, file,
    last_ttl, last_ttl_known, default_ttl, default_ttl_known) tuples.
    @ivar current_file: the file object of the $INCLUDed file being parsed
    (None if no $INCLUDE is active).
    @ivar allow_include: is $INCLUDE allowed?
    @type allow_include: bool
    @ivar check_origin: should sanity checks of the origin node be done?
    The default is True.
    @type check_origin: bool
    """

    def __init__(self, tok, origin, rdclass, relativize, zone_factory=Zone,
                 allow_include=False, check_origin=True):
        if isinstance(origin, string_types):
            origin = dns.name.from_text(origin)
        self.tok = tok
        self.current_origin = origin
        self.relativize = relativize
        self.last_ttl = 0
        self.last_ttl_known = False
        self.default_ttl = 0
        self.default_ttl_known = False
        self.last_name = self.current_origin
        self.zone = zone_factory(origin, rdclass, relativize=relativize)
        self.saved_state = []
        self.current_file = None
        self.allow_include = allow_include
        self.check_origin = check_origin

    def _eat_line(self):
        while 1:
            token = self.tok.get()
            if token.is_eol_or_eof():
                break

    def _rr_line(self):
        """Process one line from a DNS master file."""
        # Name
        if self.current_origin is None:
            raise UnknownOrigin
        token = self.tok.get(want_leading=True)
        if not token.is_whitespace():
            self.last_name = dns.name.from_text(
                token.value, self.current_origin)
        else:
            token = self.tok.get()
            if token.is_eol_or_eof():
                # treat leading WS followed by EOL/EOF as if they were EOL/EOF.
                return
            self.tok.unget(token)
        name = self.last_name
        if not name.is_subdomain(self.zone.origin):
            self._eat_line()
            return
        if self.relativize:
            name = name.relativize(self.zone.origin)
        token = self.tok.get()
        if not token.is_identifier():
            raise dns.exception.SyntaxError
        # TTL
        try:
            ttl = dns.ttl.from_text(token.value)
            self.last_ttl = ttl
            self.last_ttl_known = True
            token = self.tok.get()
            if not token.is_identifier():
                raise dns.exception.SyntaxError
        except dns.ttl.BadTTL:
            if not (self.last_ttl_known or self.default_ttl_known):
                raise dns.exception.SyntaxError("Missing default TTL value")
            if self.default_ttl_known:
                ttl = self.default_ttl
            else:
                ttl = self.last_ttl
        # Class
        try:
            rdclass = dns.rdataclass.from_text(token.value)
            token = self.tok.get()
            if not token.is_identifier():
                raise dns.exception.SyntaxError
        except dns.exception.SyntaxError:
            raise dns.exception.SyntaxError
        except Exception:
            rdclass = self.zone.rdclass
        if rdclass != self.zone.rdclass:
            raise dns.exception.SyntaxError("RR class is not zone's class")
        # Type
        try:
            rdtype = dns.rdatatype.from_text(token.value)
        except:
            raise dns.exception.SyntaxError(
                "unknown rdatatype '%s'" % token.value)
        n = self.zone.nodes.get(name)
        if n is None:
            n = self.zone.node_factory()
            self.zone.nodes[name] = n
        try:
            rd = dns.rdata.from_text(rdclass, rdtype, self.tok,
                                     self.current_origin, False)
        except dns.exception.SyntaxError:
            # Catch and reraise.
            (ty, va) = sys.exc_info()[:2]
            raise va
        except:
            # All exceptions that occur in the processing of rdata
            # are treated as syntax errors.  This is not strictly
            # correct, but it is correct almost all of the time.
            # We convert them to syntax errors so that we can emit
            # helpful filename:line info.
            (ty, va) = sys.exc_info()[:2]
            raise dns.exception.SyntaxError(
                "caught exception {}: {}".format(str(ty), str(va)))

        if not self.default_ttl_known and isinstance(rd, dns.rdtypes.ANY.SOA.SOA):
            # The pre-RFC2308 and pre-BIND9 behavior inherits the zone default
            # TTL from the SOA minttl if no $TTL statement is present before the
            # SOA is parsed.
            self.default_ttl = rd.minimum
            self.default_ttl_known = True

        rd.choose_relativity(self.zone.origin, self.relativize)
        covers = rd.covers()
        rds = n.find_rdataset(rdclass, rdtype, covers, True)
        rds.add(rd, ttl)

    def _parse_modify(self, side):
        # Here we catch everything in '{' '}' in a group so we can replace it
        # with ''.
        is_generate1 = re.compile("^.*\$({(\+|-?)(\d+),(\d+),(.)}).*$")
        is_generate2 = re.compile("^.*\$({(\+|-?)(\d+)}).*$")
        is_generate3 = re.compile("^.*\$({(\+|-?)(\d+),(\d+)}).*$")
        # Sometimes there are modifiers in the hostname. These come after
        # the dollar sign. They are in the form: ${offset[,width[,base]]}.
        # Make names
        g1 = is_generate1.match(side)
        if g1:
            mod, sign, offset, width, base = g1.groups()
            if sign == '':
                sign = '+'
        g2 = is_generate2.match(side)
        if g2:
            mod, sign, offset = g2.groups()
            if sign == '':
                sign = '+'
            width = 0
            base = 'd'
        g3 = is_generate3.match(side)
        if g3:
            mod, sign, offset, width = g1.groups()
            if sign == '':
                sign = '+'
            width = g1.groups()[2]
            base = 'd'

        if not (g1 or g2 or g3):
            mod = ''
            sign = '+'
            offset = 0
            width = 0
            base = 'd'

        if base != 'd':
            raise NotImplementedError()

        return mod, sign, offset, width, base

    def _generate_line(self):
        # range lhs [ttl] [class] type rhs [ comment ]
        """Process one line containing the GENERATE statement from a DNS
        master file."""
        if self.current_origin is None:
            raise UnknownOrigin

        token = self.tok.get()
        # Range (required)
        try:
            start, stop, step = dns.grange.from_text(token.value)
            token = self.tok.get()
            if not token.is_identifier():
                raise dns.exception.SyntaxError
        except:
            raise dns.exception.SyntaxError

        # lhs (required)
        try:
            lhs = token.value
            token = self.tok.get()
            if not token.is_identifier():
                raise dns.exception.SyntaxError
        except:
            raise dns.exception.SyntaxError

        # TTL
        try:
            ttl = dns.ttl.from_text(token.value)
            self.last_ttl = ttl
            self.last_ttl_known = True
            token = self.tok.get()
            if not token.is_identifier():
                raise dns.exception.SyntaxError
        except dns.ttl.BadTTL:
            if not (self.last_ttl_known or self.default_ttl_known):
                raise dns.exception.SyntaxError("Missing default TTL value")
            if self.default_ttl_known:
                ttl = self.default_ttl
            else:
                ttl = self.last_ttl
        # Class
        try:
            rdclass = dns.rdataclass.from_text(token.value)
            token = self.tok.get()
            if not token.is_identifier():
                raise dns.exception.SyntaxError
        except dns.exception.SyntaxError:
            raise dns.exception.SyntaxError
        except Exception:
            rdclass = self.zone.rdclass
        if rdclass != self.zone.rdclass:
            raise dns.exception.SyntaxError("RR class is not zone's class")
        # Type
        try:
            rdtype = dns.rdatatype.from_text(token.value)
            token = self.tok.get()
            if not token.is_identifier():
                raise dns.exception.SyntaxError
        except Exception:
            raise dns.exception.SyntaxError("unknown rdatatype '%s'" %
                                            token.value)

        # lhs (required)
        try:
            rhs = token.value
        except:
            raise dns.exception.SyntaxError

        lmod, lsign, loffset, lwidth, lbase = self._parse_modify(lhs)
        rmod, rsign, roffset, rwidth, rbase = self._parse_modify(rhs)
        for i in range(start, stop + 1, step):
            # +1 because bind is inclusive and python is exclusive

            if lsign == u'+':
                lindex = i + int(loffset)
            elif lsign == u'-':
                lindex = i - int(loffset)

            if rsign == u'-':
                rindex = i - int(roffset)
            elif rsign == u'+':
                rindex = i + int(roffset)

            lzfindex = str(lindex).zfill(int(lwidth))
            rzfindex = str(rindex).zfill(int(rwidth))

            name = lhs.replace(u'$%s' % (lmod), lzfindex)
            rdata = rhs.replace(u'$%s' % (rmod), rzfindex)

            self.last_name = dns.name.from_text(name, self.current_origin)
            name = self.last_name
            if not name.is_subdomain(self.zone.origin):
                self._eat_line()
                return
            if self.relativize:
                name = name.relativize(self.zone.origin)

            n = self.zone.nodes.get(name)
            if n is None:
                n = self.zone.node_factory()
                self.zone.nodes[name] = n
            try:
                rd = dns.rdata.from_text(rdclass, rdtype, rdata,
                                         self.current_origin, False)
            except dns.exception.SyntaxError:
                # Catch and reraise.
                (ty, va) = sys.exc_info()[:2]
                raise va
            except:
                # All exceptions that occur in the processing of rdata
                # are treated as syntax errors.  This is not strictly
                # correct, but it is correct almost all of the time.
                # We convert them to syntax errors so that we can emit
                # helpful filename:line info.
                (ty, va) = sys.exc_info()[:2]
                raise dns.exception.SyntaxError("caught exception %s: %s" %
                                                (str(ty), str(va)))

            rd.choose_relativity(self.zone.origin, self.relativize)
            covers = rd.covers()
            rds = n.find_rdataset(rdclass, rdtype, covers, True)
            rds.add(rd, ttl)

    def read(self):
        """Read a DNS master file and build a zone object.

        @raises dns.zone.NoSOA: No SOA RR was found at the zone origin
        @raises dns.zone.NoNS: No NS RRset was found at the zone origin
        """

        try:
            while 1:
                token = self.tok.get(True, True)
                if token.is_eof():
                    if self.current_file is not None:
                        self.current_file.close()
                    if len(self.saved_state) > 0:
                        (self.tok,
                         self.current_origin,
                         self.last_name,
                         self.current_file,
                         self.last_ttl,
                         self.last_ttl_known,
                         self.default_ttl,
                         self.default_ttl_known) = self.saved_state.pop(-1)
                        continue
                    break
                elif token.is_eol():
                    continue
                elif token.is_comment():
                    self.tok.get_eol()
                    continue
                elif token.value[0] == u'$':
                    c = token.value.upper()
                    if c == u'$TTL':
                        token = self.tok.get()
                        if not token.is_identifier():
                            raise dns.exception.SyntaxError("bad $TTL")
                        self.default_ttl = dns.ttl.from_text(token.value)
                        self.default_ttl_known = True
                        self.tok.get_eol()
                    elif c == u'$ORIGIN':
                        self.current_origin = self.tok.get_name()
                        self.tok.get_eol()
                        if self.zone.origin is None:
                            self.zone.origin = self.current_origin
                    elif c == u'$INCLUDE' and self.allow_include:
                        token = self.tok.get()
                        filename = token.value
                        token = self.tok.get()
                        if token.is_identifier():
                            new_origin =\
                                dns.name.from_text(token.value,
                                                   self.current_origin)
                            self.tok.get_eol()
                        elif not token.is_eol_or_eof():
                            raise dns.exception.SyntaxError(
                                "bad origin in $INCLUDE")
                        else:
                            new_origin = self.current_origin
                        self.saved_state.append((self.tok,
                                                 self.current_origin,
                                                 self.last_name,
                                                 self.current_file,
                                                 self.last_ttl,
                                                 self.last_ttl_known,
                                                 self.default_ttl,
                                                 self.default_ttl_known))
                        self.current_file = open(filename, 'r')
                        self.tok = dns.tokenizer.Tokenizer(self.current_file,
                                                           filename)
                        self.current_origin = new_origin
                    elif c == u'$GENERATE':
                        self._generate_line()
                    else:
                        raise dns.exception.SyntaxError(
                            "Unknown master file directive '" + c + "'")
                    continue
                self.tok.unget(token)
                self._rr_line()
        except dns.exception.SyntaxError as detail:
            (filename, line_number) = self.tok.where()
            if detail is None:
                detail = "syntax error"
            raise dns.exception.SyntaxError(
                "%s:%d: %s" % (filename, line_number, detail))

        # Now that we're done reading, do some basic checking of the zone.
        if self.check_origin:
            self.zone.check_origin()


def from_text(text, origin=None, rdclass=dns.rdataclass.IN,
              relativize=True, zone_factory=Zone, filename=None,
              allow_include=False, check_origin=True):
    """Build a zone object from a master file format string.

    @param text: the master file format input
    @type text: string.
    @param origin: The origin of the zone; if not specified, the first
    $ORIGIN statement in the master file will determine the origin of the
    zone.
    @type origin: dns.name.Name object or string
    @param rdclass: The zone's rdata class; the default is class IN.
    @type rdclass: int
    @param relativize: should names be relativized?  The default is True
    @type relativize: bool
    @param zone_factory: The zone factory to use
    @type zone_factory: function returning a Zone
    @param filename: The filename to emit when describing where an error
    occurred; the default is '<string>'.
    @type filename: string
    @param allow_include: is $INCLUDE allowed?
    @type allow_include: bool
    @param check_origin: should sanity checks of the origin node be done?
    The default is True.
    @type check_origin: bool
    @raises dns.zone.NoSOA: No SOA RR was found at the zone origin
    @raises dns.zone.NoNS: No NS RRset was found at the zone origin
    @rtype: dns.zone.Zone object
    """

    # 'text' can also be a file, but we don't publish that fact
    # since it's an implementation detail.  The official file
    # interface is from_file().

    if filename is None:
        filename = '<string>'
    tok = dns.tokenizer.Tokenizer(text, filename)
    reader = _MasterReader(tok, origin, rdclass, relativize, zone_factory,
                           allow_include=allow_include,
                           check_origin=check_origin)
    reader.read()
    return reader.zone


def from_file(f, origin=None, rdclass=dns.rdataclass.IN,
              relativize=True, zone_factory=Zone, filename=None,
              allow_include=True, check_origin=True):
    """Read a master file and build a zone object.

    @param f: file or string.  If I{f} is a string, it is treated
    as the name of a file to open.
    @param origin: The origin of the zone; if not specified, the first
    $ORIGIN statement in the master file will determine the origin of the
    zone.
    @type origin: dns.name.Name object or string
    @param rdclass: The zone's rdata class; the default is class IN.
    @type rdclass: int
    @param relativize: should names be relativized?  The default is True
    @type relativize: bool
    @param zone_factory: The zone factory to use
    @type zone_factory: function returning a Zone
    @param filename: The filename to emit when describing where an error
    occurred; the default is '<file>', or the value of I{f} if I{f} is a
    string.
    @type filename: string
    @param allow_include: is $INCLUDE allowed?
    @type allow_include: bool
    @param check_origin: should sanity checks of the origin node be done?
    The default is True.
    @type check_origin: bool
    @raises dns.zone.NoSOA: No SOA RR was found at the zone origin
    @raises dns.zone.NoNS: No NS RRset was found at the zone origin
    @rtype: dns.zone.Zone object
    """

    str_type = string_types
    if PY3:
        opts = 'r'
    else:
        opts = 'rU'

    if isinstance(f, str_type):
        if filename is None:
            filename = f
        f = open(f, opts)
        want_close = True
    else:
        if filename is None:
            filename = '<file>'
        want_close = False

    try:
        z = from_text(f, origin, rdclass, relativize, zone_factory,
                      filename, allow_include, check_origin)
    finally:
        if want_close:
            f.close()
    return z


def from_xfr(xfr, zone_factory=Zone, relativize=True, check_origin=True):
    """Convert the output of a zone transfer generator into a zone object.

    @param xfr: The xfr generator
    @type xfr: generator of dns.message.Message objects
    @param relativize: should names be relativized?  The default is True.
    It is essential that the relativize setting matches the one specified
    to dns.query.xfr().
    @type relativize: bool
    @param check_origin: should sanity checks of the origin node be done?
    The default is True.
    @type check_origin: bool
    @raises dns.zone.NoSOA: No SOA RR was found at the zone origin
    @raises dns.zone.NoNS: No NS RRset was found at the zone origin
    @rtype: dns.zone.Zone object
    """

    z = None
    for r in xfr:
        if z is None:
            if relativize:
                origin = r.origin
            else:
                origin = r.answer[0].name
            rdclass = r.answer[0].rdclass
            z = zone_factory(origin, rdclass, relativize=relativize)
        for rrset in r.answer:
            znode = z.nodes.get(rrset.name)
            if not znode:
                znode = z.node_factory()
                z.nodes[rrset.name] = znode
            zrds = znode.find_rdataset(rrset.rdclass, rrset.rdtype,
                                       rrset.covers, True)
            zrds.update_ttl(rrset.ttl)
            for rd in rrset:
                rd.choose_relativity(z.origin, relativize)
                zrds.add(rd)
    if check_origin:
        z.check_origin()
    return z


